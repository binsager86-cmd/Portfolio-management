# ui.py â€” Portfolio Pro Application
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ðŸ”‘ CRON HANDLER - MUST BE FIRST THING IN FILE (before ANY Streamlit imports)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import os
import sys
import time
import logging
from urllib.parse import parse_qs

_QUERY_STRING = os.environ.get("QUERY_STRING", "")
_QUERY_PARAMS = parse_qs(_QUERY_STRING) if _QUERY_STRING else {}

if "cron" in _QUERY_PARAMS:
    _cron_action = _QUERY_PARAMS["cron"][0]
    _cron_key = _QUERY_PARAMS.get("key", [""])[0]
    _expected_key = os.environ.get("CRON_SECRET_KEY", "")
    
    # Setup minimal logging for cron
    logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
    _logger = logging.getLogger("cron")
    
    if not _expected_key:
        _logger.error("CRON_SECRET_KEY not set in environment")
        print("ERROR: CRON_SECRET_KEY not set")
        sys.exit(1)
    
    if _cron_key != _expected_key:
        _logger.warning(f"Invalid cron key attempt: {_cron_key}")
        print("ERROR: Invalid key")
        sys.exit(1)
    
    # âœ… VALID CRON REQUEST â€” execute job
    if _cron_action == "update_prices":
        _logger.info("ðŸš€ Executing cron job: update_prices")
        
        # Import ONLY what's needed (avoid Streamlit imports)
        import sqlite3
        from datetime import datetime
        import yfinance as yf
        
        try:
            # Hardcode user_id=1 for cron context (no session state available)
            user_id = 1
            
            # Connect to DB - try multiple possible paths
            db_paths = [
                '/mount/data/app_data.db',  # Render persistent disk
                os.path.join(os.path.dirname(__file__), 'portfolio.db'),  # Local dev
                'portfolio.db'  # Fallback
            ]
            
            # Debug: Log all paths being checked
            _logger.info(f"ðŸ” Current working dir: {os.getcwd()}")
            _logger.info(f"ðŸ” Script dir: {os.path.dirname(os.path.abspath(__file__))}")
            for p in db_paths:
                _logger.info(f"ðŸ” Checking DB path: {p} (exists: {os.path.exists(p)}, abs: {os.path.abspath(p)})")
            
            conn = None
            for db_path in db_paths:
                if os.path.exists(db_path):
                    conn = sqlite3.connect(db_path)
                    _logger.info(f"ðŸ“‚ Connected to DB: {os.path.abspath(db_path)}")
                    break
            
            if conn is None:
                raise Exception(f"No database found. Tried: {db_paths}")
            
            cur = conn.cursor()
            
            # Get stocks with positive holdings
            cur.execute("""
                SELECT s.symbol, s.currency,
                    COALESCE(SUM(CASE WHEN t.txn_type = 'Buy' THEN t.shares ELSE 0 END) -
                             SUM(CASE WHEN t.txn_type = 'Sell' THEN t.shares ELSE 0 END), 0) as net_shares
                FROM stocks s
                LEFT JOIN transactions t ON s.symbol = t.stock_symbol AND s.user_id = t.user_id
                WHERE s.user_id = ? AND s.symbol IS NOT NULL AND s.symbol != ''
                GROUP BY s.symbol, s.currency
                HAVING net_shares > 0.001
            """, (user_id,))
            stocks = cur.fetchall()
            
            _logger.info(f"ðŸ“Š Found {len(stocks)} stocks with positive holdings")
            
            success_count = 0
            for symbol, currency, _ in stocks:
                try:
                    # Fetch price - add .KW suffix for Kuwait stocks if no suffix
                    ticker_symbol = symbol if "." in symbol else f"{symbol}.KW"
                    ticker = yf.Ticker(ticker_symbol)
                    hist = ticker.history(period="1d")
                    
                    if not hist.empty:
                        price = hist['Close'].iloc[-1]
                        
                        # Normalize KWD prices (handle /1000 convention)
                        if currency == 'KWD' and price > 50:
                            price = price / 1000
                        
                        # Update DB
                        cur.execute("""
                            UPDATE stocks 
                            SET current_price = ?, last_updated = ? 
                            WHERE symbol = ? AND user_id = ?
                        """, (price, int(time.time()), symbol, user_id))
                        conn.commit()
                        
                        _logger.info(f"âœ… {symbol}: {price:.4f} {currency}")
                        success_count += 1
                    else:
                        _logger.warning(f"âš ï¸ No price data for {symbol}")
                except Exception as e:
                    _logger.warning(f"âŒ Error updating {symbol}: {e}")
                    continue
            
            conn.close()
            _logger.info(f"âœ… SUCCESS: Updated {success_count}/{len(stocks)} prices")
            print(f"OK - cron 'update_prices' executed successfully ({success_count}/{len(stocks)} updated)")
            sys.exit(0)
            
        except Exception as e:
            _logger.exception(f"ðŸ”¥ CRITICAL ERROR: {e}")
            print(f"ERROR: {e}")
            sys.exit(1)
    
    else:
        _logger.warning(f"Unknown cron action: {_cron_action}")
        print(f"ERROR: Unknown cron action '{_cron_action}'")
        sys.exit(1)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# âœ… ONLY NOW import Streamlit and render UI (cron path already exited)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import streamlit as st

# Set page config IMMEDIATELY after Streamlit import (must be first st command)
try:
    st.set_page_config(page_title="Portfolio Pro", page_icon="ðŸ’¼", layout="wide")
except st.errors.StreamlitAPIException:
    pass  # Already set by app.py router

# Setup logging for UI (reconfigure after cron section)
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
_cron_logger = logging.getLogger("cron_handler")  # Keep for backward compat

from typing import Optional
import sqlite3
# time already imported above
import uuid
import html
import warnings
import re
import pandas as pd

# Import Modified TWR Calculator (dynamic deposit handling, full history reconstruction)
try:
    from modified_twr_calculator import calculate_modified_twr, get_initial_capital
    _MODIFIED_TWR_AVAILABLE = True
except ImportError:
    _MODIFIED_TWR_AVAILABLE = False

# Re-import logging for rest of app (already configured above)

# ====== LOGGING SETUP ======
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ====== STARTUP TIMING DIAGNOSTICS ======
_startup_time = time.time()
def _log_startup(msg: str):
    """Log startup timing for performance diagnostics."""
    elapsed = time.time() - _startup_time
    logger.info(f"[{elapsed:.2f}s] {msg}")


# ====== INPUT VALIDATION & SECURITY HELPERS ======
# Strict allowlist pattern for stock symbols:
# - 2-10 alphanumeric characters
# - Optional exchange suffix: .XX (e.g., .KW, .US, .L)
# - No SQL injection possible with this format
_VALID_SYMBOL_PATTERN = re.compile(r'^[A-Z0-9]{1,10}(\.[A-Z]{1,4})?$')

# Cached valid symbols from securities_master (lazy-loaded)
_VALID_SYMBOLS_CACHE: set[str] = set()
_VALID_SYMBOLS_LOADED: bool = False


def _load_valid_symbols_cache() -> None:
    """Load valid symbols from securities_master and security_aliases into cache.
    
    This provides an allowlist of known-good symbols for validation.
    Called lazily on first symbol validation after DB is available.
    """
    global _VALID_SYMBOLS_CACHE, _VALID_SYMBOLS_LOADED
    
    if _VALID_SYMBOLS_LOADED:
        return
        
    try:
        conn = get_conn()
        cursor = conn.cursor()
        
        # Get canonical tickers from securities_master
        db_execute(cursor, "SELECT canonical_ticker FROM securities_master")
        for row in cursor.fetchall():
            if row[0]:
                _VALID_SYMBOLS_CACHE.add(row[0].upper())
        
        # Get aliases from security_aliases
        db_execute(cursor, "SELECT alias_name FROM security_aliases")
        for row in cursor.fetchall():
            if row[0]:
                _VALID_SYMBOLS_CACHE.add(row[0].upper())
        
        # Get existing symbols from stocks table (user-added)
        db_execute(cursor, "SELECT DISTINCT symbol FROM stocks")
        for row in cursor.fetchall():
            if row[0]:
                _VALID_SYMBOLS_CACHE.add(row[0].upper())
        
        conn.close()
        _VALID_SYMBOLS_LOADED = True
        logger.info(f"Loaded {len(_VALID_SYMBOLS_CACHE)} valid symbols into security cache")
    except Exception as e:
        # Don't fail on cache load errors - pattern matching still works
        logger.warning(f"Could not load symbols cache: {e}")
        _VALID_SYMBOLS_LOADED = True  # Mark as loaded to avoid repeated failures


def refresh_valid_symbols_cache() -> None:
    """Force refresh of the valid symbols cache.
    
    Call this after adding new symbols to securities_master or stocks.
    """
    global _VALID_SYMBOLS_LOADED
    _VALID_SYMBOLS_LOADED = False
    _VALID_SYMBOLS_CACHE.clear()
    _load_valid_symbols_cache()


def validate_stock_symbol(symbol: str, allow_new: bool = True) -> tuple[bool, str]:
    """Validate a stock symbol for safety and format.
    
    Security approach:
    1. Check against cached allowlist (securities_master + stocks)
    2. If not in allowlist, apply strict format validation
    3. All DB queries use parameterized queries - format validation is defense-in-depth
    
    Args:
        symbol: The stock symbol to validate
        allow_new: If True, allow new symbols that match format pattern.
                   If False, symbol must exist in securities_master/stocks.
    
    Returns:
        (is_valid, error_message) - error_message is empty if valid
    """
    if not symbol:
        return False, "Symbol cannot be empty"
    
    # Normalize: strip whitespace, uppercase, remove any HTML entities
    symbol = html.escape(symbol.strip().upper())
    
    if len(symbol) > 15:
        return False, "Symbol too long (max 15 characters)"
    
    # Lazy-load the valid symbols cache
    if not _VALID_SYMBOLS_LOADED:
        _load_valid_symbols_cache()
    
    # Check 1: Known-good symbol from securities_master or stocks
    if symbol in _VALID_SYMBOLS_CACHE:
        return True, ""
    
    # Check 2: For new symbols, validate strict format
    if not allow_new:
        return False, f"Unknown symbol: {symbol}. Add it to Securities Master first."
    
    # Strict format: 1-10 alphanumeric chars, optional .XX exchange suffix
    if not _VALID_SYMBOL_PATTERN.match(symbol):
        logger.warning(f"Invalid symbol format rejected: {repr(symbol[:20])}")
        return False, "Invalid symbol format. Use uppercase letters/numbers (e.g., AAPL, MSFT, NBK.KW)"
    
    return True, ""


def normalize_stock_symbol(raw_symbol: str, portfolio: str = 'KFH') -> str:
    """
    Normalize a stock symbol using built-in mappings and the symbol_mappings table.
    
    This provides automatic resolution of user-entered variations to canonical tickers.
    E.g., 'agility kuwait' -> 'AGILITY', 'mabanee' -> 'MABANEE', 'AGLTY' -> 'AGILITY'
    
    Args:
        raw_symbol: The raw user input (any case, may include spaces)
        portfolio: The portfolio context (to determine exchange for new symbols)
        
    Returns:
        Canonical ticker (uppercase, cleaned) or raw_symbol if no mapping found
    """
    if not raw_symbol:
        return ""
    
    # Clean the input
    sym = str(raw_symbol).strip().upper()
    
    # =========================================================================
    # BUILT-IN SYMBOL VARIATIONS (checked BEFORE database lookup for speed)
    # =========================================================================
    # These are common variations seen in Excel uploads
    
    # Kuwait stock variations
    KUWAIT_VARIATIONS = {
        # AGILITY variations
        'AGLTY': 'AGILITY',
        'AGILITY PLC': 'AGILITY',
        'AGILITYPLC': 'AGILITY',
        'AGILITY KUWAIT': 'AGILITY',
        'AGILITY.KW': 'AGILITY',
        
        # MABANEE variations
        'MABNEE': 'MABANEE',
        'MABNE': 'MABANEE',
        'MABAN': 'MABANEE',
        'MABANEE.KW': 'MABANEE',
        
        # OOREDOO variations
        'OORED': 'OOREDOO',
        'OREDOO': 'OOREDOO',
        'ORODOO': 'OOREDOO',
        'OOREDOO KUWAIT': 'OOREDOO',
        'OOREDOO.KW': 'OOREDOO',
        
        # HUMANSOFT variations
        'HUMAN SOFT': 'HUMANSOFT',
        'H-SOFT': 'HUMANSOFT',
        'HSOFT': 'HUMANSOFT',
        'HUMANSOFT.KW': 'HUMANSOFT',
        
        # SANAM variations
        'SANAM BUSINESS': 'SANAM',
        'SANAM SYS': 'SANAM',
        'SANAM SYSTEMS': 'SANAM',
        'SANAM.KW': 'SANAM',
        
        # KFH variations
        'KUWAIT FINANCE HOUSE': 'KFH',
        'KFH.KW': 'KFH',
        
        # ZAIN variations
        'ZAIN KUWAIT': 'ZAIN',
        'ZAIN.KW': 'ZAIN',
        
        # GFH variations
        'GFH FINANCIAL': 'GFH',
        'GFH.BH': 'GFH',
        
        # NIH variations
        'NATIONAL INVESTMENTS': 'NIH',
        'NIH.KW': 'NIH',
        
        # KRE variations
        'KUWAIT REAL ESTATE': 'KRE',
        'KRE.KW': 'KRE',
        
        # BPCC variations
        'BOUBYAN PETROCHEMICAL': 'BPCC',
        'BPCC.KW': 'BPCC',
        
        # KIB variations
        'KUWAIT INTERNATIONAL BANK': 'KIB',
        'KIB.KW': 'KIB',
        
        # MUNSHAAT variations
        'MUNSHAAT.KW': 'MUNSHAAT',
        
        # ALG variations
        'ALG.KW': 'ALG',
    }
    
    # US stock variations (common typos/variations)
    US_VARIATIONS = {
        'INCYTE': 'INCY',
        'INCYTE CORP': 'INCY',
        'INCYTE CORPORATION': 'INCY',
    }
    
    # Check built-in variations first (fast, no DB query)
    if sym in KUWAIT_VARIATIONS:
        return KUWAIT_VARIATIONS[sym]
    if sym in US_VARIATIONS:
        return US_VARIATIONS[sym]
    
    # Remove common suffixes and try again
    for suffix in ['.KW', '.BH', '.US', ' KW', ' BH']:
        if sym.endswith(suffix):
            base_sym = sym[:-len(suffix)]
            if base_sym in KUWAIT_VARIATIONS:
                return KUWAIT_VARIATIONS[base_sym]
            # Return the base symbol if it's clean
            if base_sym.isalpha():
                sym = base_sym
                break
    
    # =========================================================================
    # DATABASE LOOKUP (for user-defined mappings)
    # =========================================================================
    try:
        conn = get_conn()
        cursor = conn.cursor()
        
        # Check symbol_mappings table first (case-insensitive match)
        db_execute(cursor, """
            SELECT canonical_ticker FROM symbol_mappings 
            WHERE UPPER(user_input) = UPPER(?)
        """, (raw_symbol,))
        result = cursor.fetchone()
        
        if result:
            canonical = result[0]
            conn.close()
            return canonical
        
        # Check stocks_master table directly (case-insensitive)
        db_execute(cursor, """
            SELECT ticker FROM stocks_master 
            WHERE UPPER(ticker) = ? OR UPPER(name) = ?
        """, (sym, sym))
        result = cursor.fetchone()
        
        if result:
            canonical = result[0]
            conn.close()
            return canonical
        
        # Check securities_master table (existing fallback)
        db_execute(cursor, """
            SELECT ticker FROM securities_master 
            WHERE UPPER(ticker) = ? OR UPPER(name) = ?
        """, (sym, sym))
        result = cursor.fetchone()
        
        if result:
            canonical = result[0]
            conn.close()
            return canonical
            
        conn.close()
        
    except Exception as e:
        logger.debug(f"Error normalizing symbol '{raw_symbol}': {e}")
    
    # Fallback: return cleaned uppercase version
    return sym


def fix_transaction_symbols(transactions_df: pd.DataFrame, portfolio: str = 'KFH') -> pd.DataFrame:
    """
    Normalize ALL symbol variations in a transaction DataFrame before upload.
    
    This is the PRIMARY ENTRY POINT for symbol normalization during uploads.
    Call this on your DataFrame BEFORE inserting into the database.
    
    Args:
        transactions_df: DataFrame with stock_symbol or symbol column
        portfolio: Portfolio context for normalization
        
    Returns:
        DataFrame with normalized symbols
    """
    fixed_df = transactions_df.copy()
    
    # Normalize stock_symbol column
    if 'stock_symbol' in fixed_df.columns:
        fixed_df['stock_symbol'] = fixed_df['stock_symbol'].apply(
            lambda x: normalize_stock_symbol(str(x), portfolio) if pd.notna(x) and str(x).strip() else ""
        )
    
    # Also fix 'symbol' column if present
    if 'symbol' in fixed_df.columns:
        fixed_df['symbol'] = fixed_df['symbol'].apply(
            lambda x: normalize_stock_symbol(str(x), portfolio) if pd.notna(x) and str(x).strip() else ""
        )
    
    # Also fix 'ticker' column if present
    if 'ticker' in fixed_df.columns:
        fixed_df['ticker'] = fixed_df['ticker'].apply(
            lambda x: normalize_stock_symbol(str(x), portfolio) if pd.notna(x) and str(x).strip() else ""
        )
    
    return fixed_df


def upload_transactions_fixed(
    user_id: int, 
    excel_file, 
    portfolio_id: int,
    stock_symbol: str = None,
    debug_log: list = None
) -> dict:
    """
    FIXED UPLOAD HANDLER - Handles all symbol/date/data issues.
    
    This is the COMPLETE upload handler that:
    1. Reads Excel file
    2. Fixes dates (critical for position calculation)
    3. Normalizes symbols (handles AGLTY -> AGILITY, MABNEE -> MABANEE, etc.)
    4. Fixes zero-share bonus transactions
    5. Fixes missing purchase cost
    6. Soft-deletes previous uploads from same file (preserves manual entries)
    7. Inserts fixed transactions
    8. Refreshes position snapshots
    
    Args:
        user_id: User ID
        excel_file: File object or path to Excel file
        portfolio_id: Portfolio ID (KFH=1, BBYN=2, USA=3)
        stock_symbol: Optional - if provided, all transactions go to this symbol
        debug_log: Optional list to append debug messages to
        
    Returns:
        Dict with 'success', 'uploaded', 'errors', 'soft_deleted', 'debug_log'
    """
    if debug_log is None:
        debug_log = []
    
    result = {
        'success': False,
        'uploaded': 0,
        'soft_deleted': 0,
        'errors': [],
        'debug_log': debug_log
    }
    
    try:
        # 1. Read Excel
        debug_log.append(f"[UPLOAD] Starting fixed upload for user={user_id}, portfolio={portfolio_id}")
        
        if hasattr(excel_file, 'read'):
            # File-like object
            df = pd.read_excel(excel_file)
            filename = getattr(excel_file, 'name', 'upload')
        else:
            # File path
            df = pd.read_excel(excel_file)
            filename = str(excel_file).split('/')[-1].split('\\')[-1]
        
        if df.empty:
            result['errors'].append("Excel file is empty")
            return result
        
        # Normalize column names
        df.columns = [str(c).strip().lower().replace(' ', '_') for c in df.columns]
        debug_log.append(f"[UPLOAD] Rows: {len(df)}, Columns: {list(df.columns)}")
        
        # Map portfolio ID to name
        portfolio_map = {1: 'KFH', 2: 'BBYN', 3: 'USA'}
        portfolio_name = portfolio_map.get(portfolio_id, 'KFH')
        
        # 2. FIX DATES FIRST (critical for position calculation)
        date_col = None
        for col in ['txn_date', 'date', 'trade_date']:
            if col in df.columns:
                date_col = col
                break
        
        if date_col:
            debug_log.append(f"[UPLOAD] Found date column: {date_col}")
            df['txn_date'] = df[date_col].apply(_parse_date)
        else:
            # No date column - use today
            df['txn_date'] = time.strftime('%Y-%m-%d')
            debug_log.append("[UPLOAD] No date column found, using today's date")
        
        # 3. FIX SYMBOLS (primary fix for variations)
        symbol_col = None
        for col in ['stock_symbol', 'symbol', 'ticker']:
            if col in df.columns:
                symbol_col = col
                break
        
        if stock_symbol:
            # All transactions go to specified symbol
            df['stock_symbol'] = stock_symbol
            debug_log.append(f"[UPLOAD] Using fixed symbol: {stock_symbol}")
        elif symbol_col:
            # Normalize each symbol
            df['stock_symbol'] = df[symbol_col].apply(
                lambda x: normalize_stock_symbol(str(x).strip(), portfolio_name) if pd.notna(x) else ''
            )
            debug_log.append(f"[UPLOAD] Normalized symbols from column: {symbol_col}")
            
            # Log first few symbol normalizations
            for i, row in df.head(3).iterrows():
                raw = row.get(symbol_col) if symbol_col else ''
                normalized = row.get('stock_symbol', '')
                debug_log.append(f"  [ROW {i+2}] symbol: {raw!r} -> {normalized}")
        else:
            result['errors'].append("No symbol/ticker column found in Excel")
            return result
        
        # 4. EXTRACT TXN_TYPE
        type_col = None
        for col in ['txn_type', 'type', 'side', 'transaction_type']:
            if col in df.columns:
                type_col = col
                break
        
        if type_col:
            df['txn_type'] = df[type_col].apply(lambda x: str(x).strip().title() if pd.notna(x) else 'Buy')
        else:
            df['txn_type'] = 'Buy'
            debug_log.append("[UPLOAD] No txn_type column found, defaulting to Buy")
        
        # 5. EXTRACT SHARES
        shares_col = None
        for col in ['shares', 'quantity', 'qty']:
            if col in df.columns:
                shares_col = col
                break
        
        if shares_col:
            df['shares'] = pd.to_numeric(df[shares_col], errors='coerce').fillna(0)
        else:
            df['shares'] = 0
            debug_log.append("[UPLOAD] No shares column found")
        
        # 6. EXTRACT BONUS_SHARES
        bonus_col = None
        for col in ['bonus_shares', 'bonus']:
            if col in df.columns:
                bonus_col = col
                break
        
        if bonus_col:
            df['bonus_shares'] = pd.to_numeric(df[bonus_col], errors='coerce').fillna(0)
        else:
            df['bonus_shares'] = 0
        
        # 7. FIX ZERO-SHARE BONUS TRANSACTIONS
        # If bonus_shares > 0 but shares == 0, treat as Buy with bonus shares
        mask_bonus = (df['bonus_shares'] > 0) & (df['shares'] == 0)
        if mask_bonus.any():
            count = mask_bonus.sum()
            df.loc[mask_bonus, 'shares'] = df.loc[mask_bonus, 'bonus_shares']
            df.loc[mask_bonus, 'txn_type'] = 'Buy'  # Must be Buy to add shares
            debug_log.append(f"[UPLOAD] Fixed {count} zero-share bonus transactions")
        
        # 8. EXTRACT COSTS/VALUES
        purchase_col = None
        for col in ['purchase_cost', 'buy_cost', 'cost', 'amount']:
            if col in df.columns:
                purchase_col = col
                break
        
        if purchase_col:
            df['purchase_cost'] = pd.to_numeric(df[purchase_col], errors='coerce').fillna(0)
        else:
            df['purchase_cost'] = 0
        
        sell_col = None
        for col in ['sell_value', 'proceeds', 'sale_value']:
            if col in df.columns:
                sell_col = col
                break
        
        if sell_col:
            df['sell_value'] = pd.to_numeric(df[sell_col], errors='coerce').fillna(0)
        else:
            df['sell_value'] = 0
        
        # 9. FIX MISSING PURCHASE COST for buys with price
        price_col = None
        for col in ['price', 'unit_price', 'avg_price']:
            if col in df.columns:
                price_col = col
                break
        
        if price_col:
            df['price'] = pd.to_numeric(df[price_col], errors='coerce').fillna(0)
            
            # If purchase_cost is 0 but we have price and shares, calculate it
            mask_missing_cost = (df['txn_type'] == 'Buy') & (df['purchase_cost'] == 0) & (df['price'] > 0) & (df['shares'] > 0)
            if mask_missing_cost.any():
                df.loc[mask_missing_cost, 'purchase_cost'] = (
                    df.loc[mask_missing_cost, 'shares'] * df.loc[mask_missing_cost, 'price']
                )
                debug_log.append(f"[UPLOAD] Calculated purchase_cost for {mask_missing_cost.sum()} rows from price*shares")
        
        # 10. EXTRACT OTHER FIELDS
        cash_div_col = None
        for col in ['cash_dividend', 'dividend']:
            if col in df.columns:
                cash_div_col = col
                break
        
        if cash_div_col:
            df['cash_dividend'] = pd.to_numeric(df[cash_div_col], errors='coerce').fillna(0)
        else:
            df['cash_dividend'] = 0
        
        reinv_col = None
        for col in ['reinvested_dividend', 'reinvested']:
            if col in df.columns:
                reinv_col = col
                break
        
        if reinv_col:
            df['reinvested_dividend'] = pd.to_numeric(df[reinv_col], errors='coerce').fillna(0)
        else:
            df['reinvested_dividend'] = 0
        
        fees_col = None
        for col in ['fees', 'commission', 'brokerage']:
            if col in df.columns:
                fees_col = col
                break
        
        if fees_col:
            df['fees'] = pd.to_numeric(df[fees_col], errors='coerce').fillna(0)
        else:
            df['fees'] = 0
        
        # 11. SOFT DELETE PREVIOUS UPLOADS (preserve manual entries)
        conn = get_conn()
        cur = conn.cursor()
        
        # Only delete previous uploads from SAME file (not manual entries)
        db_execute(cur, """
            UPDATE transactions
            SET is_deleted = 1, deleted_at = ?, deleted_by = ?
            WHERE user_id = ?
            AND source = 'UPLOAD'
            AND source_reference LIKE ?
            AND (is_deleted = 0 OR is_deleted IS NULL)
        """, (int(time.time()), user_id, user_id, f"{filename}%"))
        
        soft_deleted = cur.rowcount
        if soft_deleted > 0:
            debug_log.append(f"[UPLOAD] Soft-deleted {soft_deleted} previous entries from '{filename}'")
        result['soft_deleted'] = soft_deleted
        
        # 11b. AUTO-CREATE STOCKS ENTRIES (critical for Trading Section display)
        # Get unique symbols from the upload and ensure they exist in stocks table
        unique_symbols = df['stock_symbol'].dropna().unique()
        stocks_created = 0
        
        # Currency mapping
        portfolio_currency = {'KFH': 'KWD', 'BBYN': 'KWD', 'USA': 'USD'}
        currency = portfolio_currency.get(portfolio_name, 'KWD')
        
        for symbol in unique_symbols:
            if not symbol:
                continue
            # Check if stock exists
            db_execute(cur, "SELECT id FROM stocks WHERE symbol = ? AND user_id = ?", (symbol, user_id))
            if not cur.fetchone():
                # Create stock entry
                try:
                    db_execute(cur, """
                        INSERT INTO stocks (symbol, name, current_price, portfolio, currency, user_id)
                        VALUES (?, ?, 0, ?, ?, ?)
                    """, (symbol, symbol, portfolio_name, currency, user_id))
                    stocks_created += 1
                except Exception as e:
                    debug_log.append(f"[UPLOAD] Warning: Could not create stock {symbol}: {e}")
        
        if stocks_created > 0:
            debug_log.append(f"[UPLOAD] Auto-created {stocks_created} stock entries")
        
        # 12. INSERT FIXED TRANSACTIONS
        current_fx = get_current_fx_rate()
        inserted = 0
        
        for idx, row in df.iterrows():
            try:
                # Skip invalid rows
                symbol = row.get('stock_symbol', '')
                txn_date = row.get('txn_date', '')
                txn_type = row.get('txn_type', '')
                
                if not symbol or not txn_date:
                    result['errors'].append(f"Row {idx+2}: Missing symbol or date")
                    continue
                
                if txn_type not in ['Buy', 'Sell']:
                    result['errors'].append(f"Row {idx+2}: Invalid txn_type '{txn_type}'")
                    continue
                
                # Source reference with timestamp for uniqueness
                source_ref = f"{filename}:row{idx+2}:{int(time.time())}"
                
                db_execute(cur, """
                    INSERT INTO transactions (
                        user_id, portfolio, stock_symbol, txn_date, txn_type,
                        shares, purchase_cost, sell_value, cash_dividend,
                        bonus_shares, reinvested_dividend, fees,
                        category, fx_rate_at_txn,
                        source, source_reference, created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'portfolio', ?, 'UPLOAD', ?, ?)
                """, (
                    user_id,
                    portfolio_name,
                    symbol,
                    txn_date,
                    txn_type,
                    float(row.get('shares', 0) or 0),
                    float(row.get('purchase_cost', 0) or 0),
                    float(row.get('sell_value', 0) or 0),
                    float(row.get('cash_dividend', 0) or 0),
                    float(row.get('bonus_shares', 0) or 0),
                    float(row.get('reinvested_dividend', 0) or 0),
                    float(row.get('fees', 0) or 0),
                    current_fx,
                    source_ref,
                    int(time.time())
                ))
                inserted += 1
                
            except Exception as e:
                result['errors'].append(f"Row {idx+2}: {str(e)}")
        
        conn.commit()
        conn.close()
        
        result['uploaded'] = inserted
        result['success'] = inserted > 0
        debug_log.append(f"[UPLOAD COMPLETE] Inserted {inserted} transactions, {len(result['errors'])} errors")
        
        # 13. REFRESH POSITION SNAPSHOTS (critical!)
        if inserted > 0:
            try:
                refresh_result = refresh_all_position_snapshots(user_id)
                debug_log.append(f"[UPLOAD] Refreshed position snapshots: {refresh_result}")
            except Exception as e:
                debug_log.append(f"[UPLOAD] Warning: Failed to refresh snapshots: {e}")
        
        return result
        
    except Exception as e:
        result['errors'].append(str(e))
        debug_log.append(f"[UPLOAD ERROR] {str(e)}")
        logger.error(f"upload_transactions_fixed error: {e}")
        return result


def add_symbol_mapping(user_input: str, canonical_ticker: str, stock_id: int = None) -> bool:
    """
    Add a new symbol mapping to the symbol_mappings table.
    
    Args:
        user_input: The variation (e.g., 'agility kuwait', 'AGLTY')
        canonical_ticker: The canonical ticker (e.g., 'AGILITY')
        stock_id: Optional reference to stocks_master.id
        
    Returns:
        True if successful, False otherwise
    """
    if not user_input or not canonical_ticker:
        return False
        
    try:
        conn = get_conn()
        cursor = conn.cursor()
        ts = int(time.time())
        
        if is_postgres():
            db_execute(cursor, """
                INSERT INTO symbol_mappings 
                (user_input, canonical_ticker, stock_id, created_at)
                VALUES (?, ?, ?, ?)
                ON CONFLICT (user_input) DO UPDATE SET
                    canonical_ticker = EXCLUDED.canonical_ticker,
                    stock_id = EXCLUDED.stock_id,
                    created_at = EXCLUDED.created_at
            """, (user_input.strip(), canonical_ticker.strip().upper(), stock_id, ts))
        else:
            db_execute(cursor, """
                INSERT OR REPLACE INTO symbol_mappings 
                (user_input, canonical_ticker, stock_id, created_at)
                VALUES (?, ?, ?, ?)
            """, (user_input.strip(), canonical_ticker.strip().upper(), stock_id, ts))
        
        conn.commit()
        conn.close()
        return True
        
    except Exception as e:
        logger.warning(f"Failed to add symbol mapping: {e}")
        return False


# ============================================================================
# PHASE 2: CASH FLOW RECONCILIATION
# ============================================================================

# Valid cash flow types
CASH_FLOW_TYPES = [
    'DEPOSIT',           # Cash deposited into account
    'WITHDRAWAL',        # Cash withdrawn from account
    'DIVIDEND_RECEIVED', # Dividend payment received
    'SALE_PROCEEDS',     # Cash from selling stocks
    'PURCHASE_PAYMENT',  # Cash paid to buy stocks
    'FEE',               # Broker fees, commissions
    'TRANSFER_IN',       # Transfer from another account
    'TRANSFER_OUT',      # Transfer to another account
    'INTEREST',          # Interest earned
    'TAX',               # Tax payment
    'ADJUSTMENT',        # Manual adjustment
]


def record_cash_flow(
    user_id: int,
    account_id: int,
    flow_type: str,
    amount: float,
    flow_date: str,
    currency: str = 'KWD',
    related_txn_id: int = None,
    description: str = None
) -> int:
    """
    Record a cash flow entry for an external account.
    
    Cash flows track all money movements:
    - DEPOSIT/WITHDRAWAL: Direct cash movements
    - DIVIDEND_RECEIVED: Cash dividends from stocks
    - SALE_PROCEEDS: Cash received from selling stocks (positive)
    - PURCHASE_PAYMENT: Cash spent buying stocks (negative)
    - FEE: Broker fees (negative)
    
    Args:
        user_id: User ID
        account_id: External account ID (from external_accounts table)
        flow_type: One of CASH_FLOW_TYPES
        amount: Amount (positive for inflows, negative for outflows)
        flow_date: Date of flow (ISO format: YYYY-MM-DD)
        currency: Currency code (default: KWD)
        related_txn_id: Optional link to transactions.id
        description: Optional description
        
    Returns:
        The new cash_flows.id, or -1 on error
    """
    if flow_type not in CASH_FLOW_TYPES:
        logger.warning(f"Invalid flow type: {flow_type}")
        return -1
    
    try:
        conn = get_conn()
        cursor = conn.cursor()
        ts = int(time.time())
        
        db_execute(cursor, """
            INSERT INTO cash_flows 
            (user_id, account_id, flow_type, amount, currency, related_txn_id, flow_date, description, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (user_id, account_id, flow_type, amount, currency, related_txn_id, flow_date, description, ts))
        
        # Get the inserted ID
        if is_postgres():
            cursor.execute("SELECT lastval()")
        else:
            cursor.execute("SELECT last_insert_rowid()")
        result = cursor.fetchone()
        new_id = result[0] if result else -1
        
        conn.commit()
        conn.close()
        return new_id
        
    except Exception as e:
        logger.warning(f"Failed to record cash flow: {e}")
        return -1


def get_account_cash_flows(user_id: int, account_id: int = None, start_date: str = None, end_date: str = None) -> pd.DataFrame:
    """
    Get cash flows for a user's accounts.
    
    Args:
        user_id: User ID
        account_id: Optional filter by specific account
        start_date: Optional start date filter (ISO format)
        end_date: Optional end date filter (ISO format)
        
    Returns:
        DataFrame with cash flows
    """
    query = """
        SELECT cf.id, cf.account_id, ea.name as account_name, 
               cf.flow_type, cf.amount, cf.currency, 
               cf.flow_date, cf.description, cf.related_txn_id, cf.reconciled
        FROM cash_flows cf
        LEFT JOIN external_accounts ea ON cf.account_id = ea.id
        WHERE cf.user_id = ?
    """
    params = [user_id]
    
    if account_id:
        query += " AND cf.account_id = ?"
        params.append(account_id)
    
    if start_date:
        query += " AND cf.flow_date >= ?"
        params.append(start_date)
    
    if end_date:
        query += " AND cf.flow_date <= ?"
        params.append(end_date)
    
    query += " ORDER BY cf.flow_date DESC, cf.id DESC"
    
    return query_df(query, tuple(params))


def reconcile_accounts(user_id: int) -> pd.DataFrame:
    """
    Reconcile external accounts by comparing system balance vs calculated balance.
    
    This performs the reconciliation query:
    - System Balance: current_balance from external_accounts (user-entered)
    - Calculated Balance: SUM of all cash_flows for that account
    - Variance: Difference (should be 0 if fully reconciled)
    
    Args:
        user_id: User ID
        
    Returns:
        DataFrame with reconciliation results
    """
    query = """
        SELECT 
            ea.id as account_id,
            ea.name as account_name,
            ea.currency,
            ea.current_balance as system_balance,
            COALESCE((
                SELECT SUM(amount) 
                FROM cash_flows 
                WHERE account_id = ea.id AND user_id = ?
            ), 0) as calculated_balance,
            ea.current_balance - COALESCE((
                SELECT SUM(amount) 
                FROM cash_flows 
                WHERE account_id = ea.id AND user_id = ?
            ), 0) as variance,
            ea.last_reconciled_date
        FROM external_accounts ea
        WHERE ea.user_id = ?
        ORDER BY ea.name
    """
    return query_df(query, (user_id, user_id, user_id))


def auto_generate_cash_flows_from_transactions(user_id: int) -> dict:
    """
    Auto-generate cash flow entries from existing transactions.
    
    This analyzes transactions and creates corresponding cash_flows:
    - Buy transactions -> PURCHASE_PAYMENT (negative)
    - Sell transactions -> SALE_PROCEEDS (positive)
    - Dividends -> DIVIDEND_RECEIVED (positive)
    - Fees -> FEE (negative)
    
    Returns:
        Dict with stats: flows_created, errors
    """
    stats = {'flows_created': 0, 'skipped': 0, 'errors': []}
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        
        # Get account IDs mapping by portfolio
        db_execute(cur, """
            SELECT ea.id, p.name as portfolio_name, ea.currency
            FROM external_accounts ea
            JOIN portfolios p ON ea.portfolio_id = p.id
            WHERE ea.user_id = ?
        """, (user_id,))
        account_map = {row[1]: {'id': row[0], 'currency': row[2]} for row in cur.fetchall()}
        
        if not account_map:
            stats['errors'].append("No external accounts found. Run migration first.")
            conn.close()
            return stats
        
        # Get transactions that don't have linked cash flows
        soft_del = _soft_delete_filter()
        db_execute(cur, f"""
            SELECT t.id, t.portfolio, t.txn_type, t.txn_date, 
                   t.purchase_cost, t.sell_value, t.cash_dividend, t.fees, t.stock_symbol
            FROM transactions t
            WHERE t.user_id = ? {soft_del}
            AND NOT EXISTS (
                SELECT 1 FROM cash_flows cf WHERE cf.related_txn_id = t.id
            )
            ORDER BY t.txn_date
        """, (user_id,))
        
        transactions = cur.fetchall()
        
        for txn in transactions:
            txn_id, portfolio, txn_type, txn_date, purchase_cost, sell_value, cash_div, fees, symbol = txn
            
            account_info = account_map.get(portfolio)
            if not account_info:
                stats['skipped'] += 1
                continue
            
            account_id = account_info['id']
            currency = account_info['currency']
            
            # Generate cash flows based on transaction type
            flows_to_create = []
            
            if txn_type == 'Buy' and purchase_cost and float(purchase_cost) > 0:
                # Purchase payment (outflow - negative)
                flows_to_create.append({
                    'flow_type': 'PURCHASE_PAYMENT',
                    'amount': -abs(float(purchase_cost)),
                    'description': f"Purchase: {symbol}"
                })
            
            if txn_type == 'Sell' and sell_value and float(sell_value) > 0:
                # Sale proceeds (inflow - positive)
                flows_to_create.append({
                    'flow_type': 'SALE_PROCEEDS',
                    'amount': abs(float(sell_value)),
                    'description': f"Sale: {symbol}"
                })
            
            if cash_div and float(cash_div) > 0:
                # Dividend received (inflow - positive)
                flows_to_create.append({
                    'flow_type': 'DIVIDEND_RECEIVED',
                    'amount': abs(float(cash_div)),
                    'description': f"Dividend: {symbol}"
                })
            
            if fees and float(fees) > 0:
                # Fee (outflow - negative)
                flows_to_create.append({
                    'flow_type': 'FEE',
                    'amount': -abs(float(fees)),
                    'description': f"Fee: {symbol}"
                })
            
            # Insert all flows for this transaction
            for flow in flows_to_create:
                try:
                    db_execute(cur, """
                        INSERT INTO cash_flows 
                        (user_id, account_id, flow_type, amount, currency, related_txn_id, flow_date, description, created_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (user_id, account_id, flow['flow_type'], flow['amount'], currency, txn_id, txn_date, flow['description'], ts))
                    stats['flows_created'] += 1
                except Exception as e:
                    stats['errors'].append(f"Txn {txn_id}: {e}")
        
        # Also generate flows from cash_deposits table
        db_execute(cur, """
            SELECT cd.id, cd.portfolio, cd.deposit_date, cd.amount, cd.currency, cd.description
            FROM cash_deposits cd
            WHERE cd.user_id = ?
            AND NOT EXISTS (
                SELECT 1 FROM cash_flows cf 
                WHERE cf.description LIKE 'Deposit ID:%' || cd.id || '%'
            )
        """, (user_id,))
        
        deposits = cur.fetchall()
        for dep in deposits:
            dep_id, portfolio, dep_date, amount, currency, desc = dep
            account_info = account_map.get(portfolio)
            if not account_info:
                continue
            
            try:
                db_execute(cur, """
                    INSERT INTO cash_flows 
                    (user_id, account_id, flow_type, amount, currency, flow_date, description, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (user_id, account_info['id'], 'DEPOSIT', abs(float(amount)), currency or account_info['currency'], 
                      dep_date, f"Deposit ID:{dep_id} - {desc or 'Cash Deposit'}", ts))
                stats['flows_created'] += 1
            except Exception as e:
                stats['errors'].append(f"Deposit {dep_id}: {e}")
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        stats['errors'].append(str(e))
    
    return stats


def update_account_balance(user_id: int, account_id: int, new_balance: float, reconcile_date: str = None) -> bool:
    """
    Update an external account's current balance and mark as reconciled.
    
    Args:
        user_id: User ID
        account_id: External account ID
        new_balance: New balance amount
        reconcile_date: Date of reconciliation (defaults to today)
        
    Returns:
        True if successful
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        if not reconcile_date:
            reconcile_date = date.today().isoformat()
        
        db_execute(cur, """
            UPDATE external_accounts 
            SET current_balance = ?, last_reconciled_date = ?
            WHERE id = ? AND user_id = ?
        """, (new_balance, reconcile_date, account_id, user_id))
        
        conn.commit()
        conn.close()
        return True
        
    except Exception as e:
        logger.warning(f"Failed to update account balance: {e}")
        return False


# ============================================================================
# STEP 1: DATA AUDIT & PRE-UPLOAD VALIDATION LAYER
# ============================================================================

def validate_stock_upload(raw_data: list, user_id: int = None) -> dict:
    """
    Pre-upload validation layer for stock/transaction data.
    
    Validates each row against master data before import:
    1. Match by ISIN first (most reliable)
    2. If no ISIN, match by ticker + exchange
    3. Try symbol_mappings for known variations
    4. If still no match, flag for manual review
    
    Args:
        raw_data: List of dicts with keys like 'ticker', 'isin', 'exchange', 'stock_symbol', etc.
        user_id: Optional user ID for user-specific lookups
        
    Returns:
        {
            'validated': [...],  # Rows with stock_id resolved
            'errors': [...],     # Rows needing manual review
            'stats': {...}       # Summary statistics
        }
    """
    validated = []
    errors = []
    stats = {
        'total_rows': len(raw_data),
        'matched_by_isin': 0,
        'matched_by_ticker': 0,
        'matched_by_mapping': 0,
        'matched_by_case': 0,
        'auto_created': 0,
        'unresolved': 0
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        for idx, row in enumerate(raw_data):
            row_num = idx + 1
            stock_id = None
            match_method = None
            
            # Extract possible identifiers from row
            isin = str(row.get('isin', '') or '').strip().upper()
            ticker = str(row.get('ticker') or row.get('stock_symbol') or row.get('symbol', '')).strip()
            exchange = str(row.get('exchange', 'KSE')).strip().upper()
            portfolio = str(row.get('portfolio', 'KFH')).strip()
            
            # Infer exchange from portfolio
            if portfolio == 'USA':
                exchange = 'NASDAQ' if exchange == 'KSE' else exchange
            
            # 1. Match by ISIN first (most reliable)
            if isin and len(isin) == 12:
                db_execute(cur, "SELECT id, ticker FROM stocks_master WHERE isin = ?", (isin,))
                result = cur.fetchone()
                if result:
                    stock_id = result[0]
                    ticker = result[1]  # Use canonical ticker
                    match_method = 'isin'
                    stats['matched_by_isin'] += 1
            
            # 2. If no ISIN match, try ticker + exchange
            if not stock_id and ticker:
                # First try exact match
                db_execute(cur, """
                    SELECT id, ticker FROM stocks_master 
                    WHERE ticker = ? AND exchange = ?
                """, (ticker.upper(), exchange))
                result = cur.fetchone()
                if result:
                    stock_id = result[0]
                    ticker = result[1]
                    match_method = 'ticker'
                    stats['matched_by_ticker'] += 1
            
            # 3. Try symbol_mappings for known variations
            if not stock_id and ticker:
                db_execute(cur, """
                    SELECT sm.stock_id, sm.canonical_ticker 
                    FROM symbol_mappings sm 
                    WHERE UPPER(sm.user_input) = UPPER(?)
                """, (ticker,))
                result = cur.fetchone()
                if result and result[0]:
                    stock_id = result[0]
                    ticker = result[1]
                    match_method = 'mapping'
                    stats['matched_by_mapping'] += 1
                elif result:
                    # Mapping exists but no stock_id, try to find by canonical ticker
                    canonical = result[1]
                    db_execute(cur, "SELECT id FROM stocks_master WHERE ticker = ?", (canonical,))
                    sm_result = cur.fetchone()
                    if sm_result:
                        stock_id = sm_result[0]
                        ticker = canonical
                        match_method = 'mapping'
                        stats['matched_by_mapping'] += 1
            
            # 4. Try case-insensitive ticker match
            if not stock_id and ticker:
                db_execute(cur, """
                    SELECT id, ticker FROM stocks_master 
                    WHERE UPPER(ticker) = ?
                """, (ticker.upper(),))
                result = cur.fetchone()
                if result:
                    stock_id = result[0]
                    ticker = result[1]
                    match_method = 'case_match'
                    stats['matched_by_case'] += 1
                    
                    # Auto-add mapping for future
                    if ticker.upper() != row.get('ticker', '').upper():
                        add_symbol_mapping(row.get('ticker', ''), ticker)
            
            # 5. If still no match, flag for review
            if not stock_id:
                stats['unresolved'] += 1
                errors.append({
                    'row_number': row_num,
                    'ticker': ticker,
                    'isin': isin,
                    'exchange': exchange,
                    'issue': 'No matching stock found',
                    'suggested_action': 'Add to stocks_master or correct ticker/ISIN',
                    'original_data': row
                })
            else:
                # Add stock_id to validated row
                validated_row = dict(row)
                validated_row['stock_id'] = stock_id
                validated_row['canonical_ticker'] = ticker
                validated_row['match_method'] = match_method
                validated.append(validated_row)
        
        conn.close()
        
    except Exception as e:
        logger.error(f"Validation error: {e}")
        errors.append({
            'row_number': 0,
            'issue': f'Validation system error: {str(e)}',
            'suggested_action': 'Contact support'
        })
    
    return {
        'validated': validated,
        'errors': errors,
        'stats': stats
    }


def auto_create_missing_stocks(errors: list, user_id: int, auto_create: bool = False) -> dict:
    """
    Attempt to auto-create stocks_master entries for unresolved symbols.
    
    Args:
        errors: List of error dicts from validate_stock_upload
        user_id: User ID
        auto_create: If True, automatically create entries. If False, just return suggestions.
        
    Returns:
        {
            'created': [...],    # Successfully created stocks
            'skipped': [...],    # Skipped (validation failed or already exists)
            'suggestions': [...] # Suggested entries if auto_create=False
        }
    """
    result = {'created': [], 'skipped': [], 'suggestions': []}
    
    if not errors:
        return result
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        
        for err in errors:
            ticker = str(err.get('ticker', '')).strip().upper()
            exchange = err.get('exchange', 'KSE')
            isin = err.get('isin', '')
            original = err.get('original_data', {})
            
            if not ticker:
                result['skipped'].append({'error': err, 'reason': 'No ticker provided'})
                continue
            
            # Validate ticker format
            is_valid, msg = validate_stock_symbol(ticker, allow_new=True)
            if not is_valid:
                result['skipped'].append({'error': err, 'reason': msg})
                continue
            
            # Check if already exists
            db_execute(cur, "SELECT id FROM stocks_master WHERE ticker = ? AND exchange = ?", (ticker, exchange))
            if cur.fetchone():
                result['skipped'].append({'error': err, 'reason': 'Already exists'})
                continue
            
            # Prepare suggestion/creation
            currency = 'USD' if exchange in ('NASDAQ', 'NYSE', 'AMEX') else 'KWD'
            country = 'US' if currency == 'USD' else 'KW'
            name = original.get('stock_name') or original.get('name') or ticker
            
            suggestion = {
                'ticker': ticker,
                'name': name,
                'exchange': exchange,
                'currency': currency,
                'isin': isin,
                'country': country
            }
            
            if auto_create:
                try:
                    db_execute(cur, """
                        INSERT INTO stocks_master (ticker, name, exchange, currency, isin, country, status, created_at, updated_at)
                        VALUES (?, ?, ?, ?, ?, ?, 'active', ?, ?)
                    """, (ticker, name, exchange, currency, isin or None, country, ts, ts))
                    
                    # Get the new ID
                    db_execute(cur, "SELECT id FROM stocks_master WHERE ticker = ? AND exchange = ?", (ticker, exchange))
                    new_id = cur.fetchone()[0]
                    suggestion['stock_id'] = new_id
                    result['created'].append(suggestion)
                    
                except Exception as e:
                    result['skipped'].append({'error': err, 'reason': str(e)})
            else:
                result['suggestions'].append(suggestion)
        
        if auto_create:
            conn.commit()
        conn.close()
        
    except Exception as e:
        logger.error(f"Auto-create error: {e}")
    
    return result


def run_data_audit(user_id: int) -> dict:
    """
    Run comprehensive data audit to find issues.
    
    Checks for:
    1. Orphaned transactions (no matching stock in stocks_master)
    2. Positions with zero shares but still OPEN
    3. Cash flow mismatches
    4. Unlinked transactions (no cash_flows entry)
    
    Args:
        user_id: User ID to audit
        
    Returns:
        Dict with audit results
    """
    audit = {
        'orphaned_transactions': [],
        'zero_share_open_positions': [],
        'cash_flow_mismatches': [],
        'unlinked_transactions': [],
        'symbol_summary': [],
        'is_healthy': True
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # 1. Orphaned transactions
        db_execute(cur, """
            SELECT t.id, t.stock_symbol, t.portfolio, t.txn_type, t.txn_date
            FROM transactions t
            WHERE t.user_id = ?
            AND t.stock_symbol NOT IN (SELECT ticker FROM stocks_master)
        """, (user_id,))
        orphans = cur.fetchall()
        audit['orphaned_transactions'] = [
            {'id': r[0], 'symbol': r[1], 'portfolio': r[2], 'type': r[3], 'date': r[4]}
            for r in orphans
        ]
        if orphans:
            audit['is_healthy'] = False
        
        # 2. Zero-share open positions (check position_snapshots if exists)
        try:
            db_execute(cur, """
                SELECT ps.id, sm.ticker, ps.total_shares, ps.status
                FROM position_snapshots ps
                LEFT JOIN stocks_master sm ON ps.stock_id = sm.id
                WHERE ps.user_id = ? AND ps.total_shares = 0 AND ps.status = 'OPEN'
            """, (user_id,))
            zero_open = cur.fetchall()
            audit['zero_share_open_positions'] = [
                {'id': r[0], 'ticker': r[1], 'shares': r[2], 'status': r[3]}
                for r in zero_open
            ]
        except:
            pass  # Table may not exist yet
        
        # 3. Cash flow mismatches
        db_execute(cur, """
            SELECT 
                ea.id, ea.name, ea.currency, ea.current_balance,
                COALESCE((SELECT SUM(amount) FROM cash_flows WHERE account_id = ea.id), 0) as calc_balance
            FROM external_accounts ea
            WHERE ea.user_id = ?
        """, (user_id,))
        for r in cur.fetchall():
            variance = r[3] - r[4]
            if abs(variance) > 0.01:
                audit['cash_flow_mismatches'].append({
                    'account_id': r[0],
                    'account_name': r[1],
                    'currency': r[2],
                    'system_balance': r[3],
                    'calculated_balance': r[4],
                    'variance': variance
                })
                audit['is_healthy'] = False
        
        # 4. Unlinked transactions
        db_execute(cur, """
            SELECT t.id, t.stock_symbol, t.txn_type, t.txn_date
            FROM transactions t
            WHERE t.user_id = ?
            AND NOT EXISTS (SELECT 1 FROM cash_flows cf WHERE cf.related_txn_id = t.id)
        """, (user_id,))
        unlinked = cur.fetchall()
        audit['unlinked_transactions'] = [
            {'id': r[0], 'symbol': r[1], 'type': r[2], 'date': r[3]}
            for r in unlinked
        ]
        
        # 5. Symbol summary
        db_execute(cur, """
            SELECT stock_symbol, 
                   SUM(CASE WHEN txn_type='Buy' THEN shares ELSE 0 END) as bought,
                   SUM(CASE WHEN txn_type='Sell' THEN shares ELSE 0 END) as sold
            FROM transactions WHERE user_id = ?
            GROUP BY stock_symbol
        """, (user_id,))
        for r in cur.fetchall():
            net = r[1] - r[2]
            audit['symbol_summary'].append({
                'symbol': r[0],
                'bought': r[1],
                'sold': r[2],
                'net': net,
                'status': 'CLOSED' if abs(net) < 0.001 else 'OPEN'
            })
        
        conn.close()
        
    except Exception as e:
        audit['error'] = str(e)
        audit['is_healthy'] = False
    
    return audit


def fix_orphaned_transactions(user_id: int) -> dict:
    """
    Attempt to fix orphaned transactions by normalizing symbols.
    
    Uses symbol_mappings and case-insensitive matching to resolve orphans.
    
    Args:
        user_id: User ID
        
    Returns:
        Stats dict with fixes applied
    """
    stats = {'fixed': 0, 'remaining': [], 'mappings_added': 0}
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        
        # Get all mappings
        db_execute(cur, "SELECT user_input, canonical_ticker FROM symbol_mappings")
        mappings = {row[0].lower(): row[1] for row in cur.fetchall()}
        
        # Get orphaned symbols
        db_execute(cur, """
            SELECT DISTINCT stock_symbol FROM transactions 
            WHERE user_id = ? AND stock_symbol NOT IN (SELECT ticker FROM stocks_master)
        """, (user_id,))
        orphan_symbols = [row[0] for row in cur.fetchall()]
        
        for sym in orphan_symbols:
            canonical = None
            
            # Try mapping
            canonical = mappings.get(sym.lower())
            
            # Try case-insensitive match
            if not canonical:
                db_execute(cur, "SELECT ticker FROM stocks_master WHERE UPPER(ticker) = ?", (sym.upper(),))
                result = cur.fetchone()
                if result:
                    canonical = result[0]
                    # Add mapping for future
                    db_execute(cur, """
                        INSERT OR IGNORE INTO symbol_mappings (user_input, canonical_ticker, created_at)
                        VALUES (?, ?, ?)
                    """, (sym, canonical, ts))
                    stats['mappings_added'] += 1
            
            if canonical:
                db_execute(cur, """
                    UPDATE transactions SET stock_symbol = ?
                    WHERE stock_symbol = ? AND user_id = ?
                """, (canonical, sym, user_id))
                stats['fixed'] += cur.rowcount
            else:
                stats['remaining'].append(sym)
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        stats['error'] = str(e)
    
    return stats


# ============================================================================
# STEP 3: POSITION CLOSURE LOGIC
# ============================================================================

def apply_transaction_to_position(user_id: int, txn_id: int, txn_data: dict = None) -> dict:
    """
    Apply a transaction and update the position snapshot.
    
    This implements proper position state management:
    - Updates total_shares, total_cost, avg_cost
    - Calculates realized P&L on sells
    - Marks position as CLOSED when shares reach 0
    
    Args:
        user_id: User ID
        txn_id: Transaction ID to apply
        txn_data: Optional pre-fetched transaction data
        
    Returns:
        New position state dict
    """
    result = {
        'success': False,
        'position_id': None,
        'new_state': {},
        'status_changed': False
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        
        # Fetch transaction if not provided
        if not txn_data:
            db_execute(cur, """
                SELECT id, stock_symbol, portfolio, txn_type, txn_date, shares, 
                       purchase_cost, sell_value, cash_dividend, bonus_shares
                FROM transactions WHERE id = ? AND user_id = ?
            """, (txn_id, user_id))
            row = cur.fetchone()
            if not row:
                result['error'] = f"Transaction {txn_id} not found"
                conn.close()
                return result
            
            txn_data = {
                'id': row[0], 'stock_symbol': row[1], 'portfolio': row[2],
                'txn_type': row[3], 'txn_date': row[4], 'shares': row[5] or 0,
                'purchase_cost': row[6] or 0, 'sell_value': row[7] or 0,
                'cash_dividend': row[8] or 0, 'bonus_shares': row[9] or 0
            }
        
        symbol = txn_data['stock_symbol']
        portfolio = txn_data['portfolio']
        txn_type = txn_data['txn_type']
        shares = float(txn_data.get('shares', 0))
        cost = float(txn_data.get('purchase_cost', 0))
        proceeds = float(txn_data.get('sell_value', 0))
        dividend = float(txn_data.get('cash_dividend', 0))
        bonus = float(txn_data.get('bonus_shares', 0))
        
        # Get stock_id and portfolio_id
        db_execute(cur, "SELECT id FROM stocks_master WHERE ticker = ?", (symbol,))
        stock_row = cur.fetchone()
        stock_id = stock_row[0] if stock_row else None
        
        db_execute(cur, "SELECT id FROM portfolios WHERE user_id = ? AND name = ?", (user_id, portfolio))
        port_row = cur.fetchone()
        portfolio_id = port_row[0] if port_row else None
        
        # Get current position state (most recent snapshot)
        db_execute(cur, """
            SELECT id, total_shares, total_cost, avg_cost, realized_pnl, 
                   cash_dividends_received, status
            FROM position_snapshots 
            WHERE user_id = ? AND stock_symbol = ? AND portfolio_id = ?
            ORDER BY snapshot_date DESC, id DESC
            LIMIT 1
        """, (user_id, symbol, portfolio_id))
        
        pos_row = cur.fetchone()
        
        if pos_row:
            # Existing position
            pos_id = pos_row[0]
            old_shares = float(pos_row[1] or 0)
            old_cost = float(pos_row[2] or 0)
            old_avg = float(pos_row[3] or 0)
            old_realized = float(pos_row[4] or 0)
            old_dividends = float(pos_row[5] or 0)
            old_status = pos_row[6]
        else:
            # New position
            pos_id = None
            old_shares = 0
            old_cost = 0
            old_avg = 0
            old_realized = 0
            old_dividends = 0
            old_status = 'OPEN'
        
        # Calculate new state based on transaction type
        new_shares = old_shares
        new_cost = old_cost
        new_realized = old_realized
        new_dividends = old_dividends
        
        if txn_type == 'Buy':
            new_shares = old_shares + shares + bonus
            new_cost = old_cost + cost
        
        elif txn_type == 'Sell':
            # Realized P&L = proceeds - (avg_cost * shares_sold)
            realized_on_sale = proceeds - (old_avg * shares) if old_avg > 0 else proceeds
            new_shares = old_shares - shares
            new_realized = old_realized + realized_on_sale
            # Cost basis reduces proportionally (optional - depends on accounting method)
            # For WAC, we don't reduce cost basis, just track shares
        
        elif txn_type == 'DIVIDEND_ONLY':
            new_dividends = old_dividends + dividend
        
        # Calculate new average cost
        if new_shares > 0:
            new_avg = new_cost / new_shares if new_cost > 0 else old_avg
        else:
            new_avg = 0
        
        # Determine new status
        if abs(new_shares) < 0.001:
            new_status = 'CLOSED'
        else:
            new_status = 'OPEN'
        
        status_changed = new_status != old_status
        
        # Update or insert position snapshot
        today = txn_data.get('txn_date', time.strftime('%Y-%m-%d'))
        
        if pos_id:
            # Update existing
            db_execute(cur, """
                UPDATE position_snapshots 
                SET total_shares = ?, total_cost = ?, avg_cost = ?, 
                    realized_pnl = ?, cash_dividends_received = ?, 
                    status = ?, txn_id = ?, snapshot_date = ?
                WHERE id = ?
            """, (new_shares, new_cost, new_avg, new_realized, new_dividends, 
                  new_status, txn_id, today, pos_id))
            result['position_id'] = pos_id
        else:
            # Insert new
            db_execute(cur, """
                INSERT INTO position_snapshots 
                (user_id, stock_id, portfolio_id, stock_symbol, txn_id, snapshot_date,
                 total_shares, total_cost, avg_cost, realized_pnl, 
                 cash_dividends_received, status, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (user_id, stock_id, portfolio_id, symbol, txn_id, today,
                  new_shares, new_cost, new_avg, new_realized, new_dividends, new_status, ts))
            
            if is_postgres():
                cur.execute("SELECT lastval()")
            else:
                cur.execute("SELECT last_insert_rowid()")
            result['position_id'] = cur.fetchone()[0]
        
        conn.commit()
        conn.close()
        
        result['success'] = True
        result['status_changed'] = status_changed
        result['new_state'] = {
            'total_shares': new_shares,
            'total_cost': new_cost,
            'avg_cost': new_avg,
            'realized_pnl': new_realized,
            'cash_dividends': new_dividends,
            'status': new_status
        }
        
        if status_changed:
            logger.info(f"Position {symbol} status changed: {old_status} -> {new_status}")
        
    except Exception as e:
        result['error'] = str(e)
        logger.error(f"Error applying transaction: {e}")
    
    return result


def calculate_portfolio_pnl(user_id: int, portfolio_id: int = None, include_closed: bool = False) -> dict:
    """
    Calculate portfolio P&L using position snapshots.
    
    Only calculates unrealized P&L for OPEN positions.
    Closed positions only contribute realized P&L.
    
    Args:
        user_id: User ID
        portfolio_id: Optional filter by portfolio
        include_closed: If True, include closed positions in summary
        
    Returns:
        Dict with position-level and portfolio-level P&L
    """
    result = {
        'positions': [],
        'summary': {
            'total_unrealized_pnl': 0,
            'total_realized_pnl': 0,
            'total_dividends': 0,
            'total_pnl': 0,
            'open_positions': 0,
            'closed_positions': 0
        }
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # Build query
        status_filter = "" if include_closed else "AND ps.status = 'OPEN'"
        portfolio_filter = "AND ps.portfolio_id = ?" if portfolio_id else ""
        
        query = f"""
            SELECT ps.id, ps.stock_symbol, ps.portfolio_id, p.name as portfolio_name,
                   ps.total_shares, ps.avg_cost, ps.realized_pnl, 
                   ps.cash_dividends_received, ps.status,
                   COALESCE(sm.current_price, s.current_price, 0) as current_price
            FROM position_snapshots ps
            LEFT JOIN portfolios p ON ps.portfolio_id = p.id
            LEFT JOIN stocks_master sm ON ps.stock_id = sm.id
            LEFT JOIN stocks s ON ps.stock_symbol = s.symbol AND s.user_id = ps.user_id
            WHERE ps.user_id = ? {status_filter} {portfolio_filter}
            ORDER BY ps.status, ps.stock_symbol
        """
        
        params = [user_id]
        if portfolio_id:
            params.append(portfolio_id)
        
        db_execute(cur, query, tuple(params))
        
        for row in cur.fetchall():
            pos_id, symbol, port_id, port_name, shares, avg_cost, realized, dividends, status, price = row
            
            shares = float(shares or 0)
            avg_cost = float(avg_cost or 0)
            realized = float(realized or 0)
            dividends = float(dividends or 0)
            price = float(price or 0)
            
            # Calculate unrealized P&L (only for OPEN positions with shares)
            if status == 'OPEN' and shares > 0 and price > 0:
                unrealized = (price - avg_cost) * shares
            else:
                unrealized = 0
            
            total_pnl = realized + unrealized + dividends
            
            position_data = {
                'position_id': pos_id,
                'stock_symbol': symbol,
                'portfolio_id': port_id,
                'portfolio_name': port_name or 'Unknown',
                'total_shares': shares,
                'avg_cost': avg_cost,
                'current_price': price,
                'unrealized_pnl': unrealized,
                'realized_pnl': realized,
                'dividends': dividends,
                'total_pnl': total_pnl,
                'status': status
            }
            
            result['positions'].append(position_data)
            
            # Update summary
            result['summary']['total_unrealized_pnl'] += unrealized
            result['summary']['total_realized_pnl'] += realized
            result['summary']['total_dividends'] += dividends
            
            if status == 'OPEN':
                result['summary']['open_positions'] += 1
            else:
                result['summary']['closed_positions'] += 1
        
        result['summary']['total_pnl'] = (
            result['summary']['total_unrealized_pnl'] + 
            result['summary']['total_realized_pnl'] + 
            result['summary']['total_dividends']
        )
        
        conn.close()
        
    except Exception as e:
        result['error'] = str(e)
        logger.error(f"Error calculating portfolio P&L: {e}")
    
    return result


def close_position(user_id: int, stock_symbol: str, portfolio_id: int) -> bool:
    """
    Manually close a position (mark as CLOSED).
    
    Use when shares are 0 but status wasn't auto-updated.
    
    Args:
        user_id: User ID
        stock_symbol: Stock symbol
        portfolio_id: Portfolio ID
        
    Returns:
        True if successful
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        db_execute(cur, """
            UPDATE position_snapshots 
            SET status = 'CLOSED'
            WHERE user_id = ? AND stock_symbol = ? AND portfolio_id = ?
            AND total_shares = 0
        """, (user_id, stock_symbol, portfolio_id))
        
        updated = cur.rowcount
        conn.commit()
        conn.close()
        
        if updated > 0:
            logger.info(f"Closed position: {stock_symbol}")
        return updated > 0
        
    except Exception as e:
        logger.error(f"Error closing position: {e}")
        return False


def reopen_position(user_id: int, stock_symbol: str, portfolio_id: int) -> bool:
    """
    Reopen a closed position (mark as OPEN).
    
    Use when adding shares back to a previously closed position.
    
    Args:
        user_id: User ID
        stock_symbol: Stock symbol
        portfolio_id: Portfolio ID
        
    Returns:
        True if successful
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        db_execute(cur, """
            UPDATE position_snapshots 
            SET status = 'OPEN'
            WHERE user_id = ? AND stock_symbol = ? AND portfolio_id = ?
            AND total_shares > 0
        """, (user_id, stock_symbol, portfolio_id))
        
        updated = cur.rowcount
        conn.commit()
        conn.close()
        
        if updated > 0:
            logger.info(f"Reopened position: {stock_symbol}")
        return updated > 0
        
    except Exception as e:
        logger.error(f"Error reopening position: {e}")
        return False


def refresh_all_position_snapshots(user_id: int) -> dict:
    """
    Recalculate all position snapshots from transactions.
    
    Use to fix inconsistencies or after bulk imports.
    
    Args:
        user_id: User ID
        
    Returns:
        Stats dict
    """
    stats = {'updated': 0, 'created': 0, 'errors': []}
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        today = time.strftime('%Y-%m-%d')
        
        # Get portfolio and stock mappings
        db_execute(cur, "SELECT id, name FROM portfolios WHERE user_id = ?", (user_id,))
        portfolio_map = {row[1]: row[0] for row in cur.fetchall()}
        
        db_execute(cur, "SELECT id, ticker FROM stocks_master")
        stock_map = {row[1]: row[0] for row in cur.fetchall()}
        
        # Calculate current state from transactions
        soft_del = _soft_delete_filter()
        db_execute(cur, f"""
            SELECT 
                stock_symbol, portfolio,
                SUM(CASE WHEN txn_type = 'Buy' THEN shares ELSE 0 END) as bought,
                SUM(CASE WHEN txn_type = 'Sell' THEN shares ELSE 0 END) as sold,
                SUM(CASE WHEN txn_type = 'Buy' THEN purchase_cost ELSE 0 END) as cost,
                SUM(CASE WHEN txn_type = 'Sell' THEN sell_value ELSE 0 END) as proceeds,
                SUM(COALESCE(cash_dividend, 0)) as dividends,
                SUM(COALESCE(bonus_shares, 0)) as bonus
            FROM transactions
            WHERE user_id = ? {soft_del}
            GROUP BY stock_symbol, portfolio
        """, (user_id,))
        
        positions = cur.fetchall()
        
        for pos in positions:
            symbol, portfolio, bought, sold, cost, proceeds, dividends, bonus = pos
            
            bought = float(bought or 0)
            sold = float(sold or 0)
            cost = float(cost or 0)
            proceeds = float(proceeds or 0)
            dividends = float(dividends or 0)
            bonus = float(bonus or 0)
            
            # Calculate net shares including bonus
            net_shares = bought - sold + bonus
            stock_id = stock_map.get(symbol)
            portfolio_id = portfolio_map.get(portfolio)
            
            # Calculate average cost using WAC method
            # Total shares acquired = bought + bonus
            # Avg cost = total_cost / total_shares_acquired (before sells)
            total_shares_acquired = bought + bonus
            if total_shares_acquired > 0:
                avg_cost_at_acquisition = cost / total_shares_acquired
            else:
                avg_cost_at_acquisition = 0.0
            
            # Realized P&L = proceeds - (avg_cost Ã— shares_sold)
            realized_pnl = proceeds - (avg_cost_at_acquisition * sold) if sold > 0 else 0.0
            
            # Remaining cost basis = original_cost - (avg_cost Ã— shares_sold)
            remaining_cost = cost - (avg_cost_at_acquisition * sold) if sold > 0 else cost
            remaining_cost = max(remaining_cost, 0.0)
            
            # Current average cost for remaining shares
            avg_cost = remaining_cost / net_shares if net_shares > 0.001 else 0.0
            
            status = 'CLOSED' if abs(net_shares) < 0.001 else 'OPEN'
            
            # Check if snapshot exists
            db_execute(cur, """
                SELECT id FROM position_snapshots 
                WHERE user_id = ? AND stock_symbol = ? AND portfolio_id = ?
            """, (user_id, symbol, portfolio_id))
            
            existing = cur.fetchone()
            
            if existing:
                # Update with remaining cost (after sells)
                db_execute(cur, """
                    UPDATE position_snapshots 
                    SET total_shares = ?, total_cost = ?, avg_cost = ?,
                        realized_pnl = ?, cash_dividends_received = ?,
                        status = ?, snapshot_date = ?
                    WHERE id = ?
                """, (net_shares, remaining_cost, avg_cost, realized_pnl, dividends, status, today, existing[0]))
                stats['updated'] += 1
            else:
                # Insert with remaining cost (after sells)
                db_execute(cur, """
                    INSERT INTO position_snapshots 
                    (user_id, stock_id, portfolio_id, stock_symbol, snapshot_date,
                     total_shares, total_cost, avg_cost, realized_pnl,
                     cash_dividends_received, status, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (user_id, stock_id, portfolio_id, symbol, today,
                      net_shares, remaining_cost, avg_cost, realized_pnl, dividends, status, ts))
                stats['created'] += 1
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        stats['errors'].append(str(e))
        logger.error(f"Error refreshing position snapshots: {e}")
    
    return stats


# ============================================================================
# AVG COST BACKFILL - Store avg_cost in transactions for historical accuracy
# ============================================================================

def recalculate_and_store_avg_costs(user_id: int) -> dict:
    """
    Backfill avg_cost_at_txn, realized_pnl_at_txn for ALL transactions.
    
    This function processes all transactions chronologically per (symbol, portfolio)
    and stores the weighted average cost (WAC) at the time of each transaction.
    This ensures that even for closed positions, we have accurate historical
    cost basis for P&L calculations.
    
    IMPORTANT: Avg cost is calculated PER PORTFOLIO - the same stock in different
    portfolios will have independent avg cost calculations.
    
    CFA/IFRS Compliant Weighted Average Cost Method:
    - Buy: avg_cost = total_cost / total_shares (includes fees)
    - Sell: realized_pnl = proceeds - (avg_cost Ã— shares_sold)
    - Bonus: shares increase, cost unchanged (dilutes avg_cost)
    - Dividend: No cost basis impact
    
    Args:
        user_id: User ID to recalculate
        
    Returns:
        Dict with stats: {'updated': int, 'errors': list}
    """
    stats = {'updated': 0, 'positions_processed': 0, 'errors': []}
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # Get all distinct (symbol, portfolio) combinations with transactions
        soft_del = _soft_delete_filter()
        db_execute(cur, f"""
            SELECT DISTINCT stock_symbol, portfolio 
            FROM transactions 
            WHERE user_id = ? {soft_del} 
            AND stock_symbol IS NOT NULL AND stock_symbol != ''
        """, (user_id,))
        positions = cur.fetchall()
        
        for symbol, portfolio in positions:
            try:
                # Get all transactions for this (symbol, portfolio), sorted chronologically
                db_execute(cur, f"""
                    SELECT id, txn_type, txn_date, shares, purchase_cost, sell_value, 
                           fees, bonus_shares, cash_dividend
                    FROM transactions
                    WHERE user_id = ? AND stock_symbol = ? AND portfolio = ? {soft_del}
                    ORDER BY txn_date ASC, id ASC
                """, (user_id, symbol, portfolio))
                
                txns = cur.fetchall()
                
                # Track running state for this (symbol, portfolio)
                total_shares = 0.0
                total_cost = 0.0
                
                for txn in txns:
                    txn_id, txn_type, txn_date, shares, purchase_cost, sell_value, fees, bonus_shares, cash_dividend = txn
                    
                    shares = float(shares or 0)
                    purchase_cost = float(purchase_cost or 0)
                    sell_value = float(sell_value or 0)
                    fees = float(fees or 0)
                    bonus_shares = float(bonus_shares or 0)
                    
                    realized_pnl = 0.0
                    avg_cost = 0.0
                    txn_type_upper = (txn_type or '').upper()
                    
                    if txn_type_upper == 'BUY':
                        # BUY: Add cost + shares (fees increase cost basis)
                        buy_cost = purchase_cost + fees
                        total_cost += buy_cost
                        total_shares += shares
                        
                        # Handle bonus shares if present on buy transaction
                        if bonus_shares > 0:
                            total_shares += bonus_shares
                        
                        avg_cost = total_cost / total_shares if total_shares > 0 else 0
                    
                    elif txn_type_upper == 'SELL':
                        # SELL: Calculate realized P&L using WAC at time of sale
                        if total_shares > 0 and shares > 0:
                            avg_cost_before_sale = total_cost / total_shares
                            proceeds = sell_value - fees
                            cost_of_shares_sold = avg_cost_before_sale * shares
                            realized_pnl = proceeds - cost_of_shares_sold
                            
                            # Reduce state
                            total_cost -= cost_of_shares_sold
                            total_shares -= shares
                            
                            # Keep the avg_cost_before_sale for this sell transaction
                            avg_cost = avg_cost_before_sale
                        else:
                            # No shares to sell - unusual but store 0
                            avg_cost = 0
                    
                    elif txn_type_upper in ('BONUS SHARES', 'BONUS', 'DIVIDEND_ONLY', 'DIVIDEND', 'STOCK SPLIT'):
                        # Check for bonus shares attached to ANY of these transaction types
                        # DIVIDEND_ONLY can have bonus_shares (stock dividend) attached
                        if bonus_shares > 0:
                            total_shares += bonus_shares
                        elif txn_type_upper in ('BONUS SHARES', 'BONUS', 'STOCK SPLIT') and shares > 0:
                            # Fallback: use shares field for dedicated bonus transactions
                            total_shares += shares
                        
                        # Recalculate avg_cost after adding bonus shares (cost unchanged)
                        avg_cost = total_cost / total_shares if total_shares > 0 else 0
                    
                    else:
                        # Other types (Deposit, Withdrawal) - just record current state
                        avg_cost = total_cost / total_shares if total_shares > 0 else 0
                    
                    # Ensure non-negative values
                    total_cost = max(total_cost, 0)
                    total_shares = max(total_shares, 0)
                    
                    # Update the transaction with calculated values
                    db_execute(cur, """
                        UPDATE transactions 
                        SET avg_cost_at_txn = ?,
                            realized_pnl_at_txn = ?,
                            cost_basis_at_txn = ?,
                            shares_held_at_txn = ?
                        WHERE id = ?
                    """, (round(avg_cost, 8), round(realized_pnl, 4), 
                          round(total_cost, 4), round(total_shares, 6), txn_id))
                    
                    stats['updated'] += 1
                
                stats['positions_processed'] += 1
                
            except Exception as e:
                stats['errors'].append(f"{symbol}/{portfolio}: {str(e)}")
                logger.error(f"Error processing {symbol}/{portfolio}: {e}")
        
        conn.commit()
        conn.close()
        
        logger.info(f"âœ… Backfilled avg_cost for {stats['positions_processed']} positions, {stats['updated']} transactions")
        
    except Exception as e:
        stats['errors'].append(str(e))
        logger.error(f"Error in avg_cost backfill: {e}")
    
    return stats


def check_stock_exclusivity(symbol: str, target_mode: str, user_id: int) -> tuple[bool, str]:
    """
    CFA Compliance: Ensures a stock is not tracked in both Portfolio and Trading simultaneously.
    This prevents mixing accounting methods (Avg Cost vs FIFO) for the same stock.
    
    Args:
        symbol: Stock symbol to check
        target_mode: 'portfolio' or 'trading'
        user_id: User ID
        
    Returns:
        (is_allowed, error_message) - error_message is empty if allowed
    """
    conn = get_conn()
    cursor = conn.cursor()
    
    # Check Portfolio (transactions table) - only count if has shares
    # Exclude soft-deleted transactions (if column exists)
    soft_del = _soft_delete_filter()
    db_execute(cursor, f"""
        SELECT COALESCE(SUM(CASE WHEN txn_type = 'Buy' THEN shares ELSE 0 END) - 
                        SUM(CASE WHEN txn_type = 'Sell' THEN shares ELSE 0 END), 0) as net_shares
        FROM transactions WHERE stock_symbol = ? AND user_id = ?{soft_del}
    """, (symbol, user_id))
    result = cursor.fetchone()
    in_portfolio = result[0] > 0 if result else False
    
    conn.close()
    
    # All transactions are now in the transactions table (master storage)
    return True, ""


def sanitize_text_input(text: str, max_length: int = 500) -> str:
    """Sanitize user text input - escape HTML and enforce length."""
    if not text:
        return ""
    text = str(text).strip()[:max_length]
    return html.escape(text)


# File upload validation constants
MAX_UPLOAD_ROWS = 50000  # Maximum rows allowed in uploaded files
MAX_UPLOAD_SIZE_MB = 10  # Maximum file size in MB
ALLOWED_EXCEL_MIMES = {
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',  # xlsx
    'application/vnd.ms-excel',  # xls
}


def validate_file_upload(uploaded_file, max_rows: int = MAX_UPLOAD_ROWS) -> tuple[bool, str, Optional['pd.DataFrame']]:
    """Validate an uploaded Excel file for safety.
    
    Returns:
        (is_valid, error_message, dataframe_or_none)
    """
    if uploaded_file is None:
        return False, "No file uploaded", None
    
    # Check file size
    file_size_mb = uploaded_file.size / (1024 * 1024)
    if file_size_mb > MAX_UPLOAD_SIZE_MB:
        return False, f"File too large ({file_size_mb:.1f}MB > {MAX_UPLOAD_SIZE_MB}MB limit)", None
    
    # Check MIME type (if available)
    if hasattr(uploaded_file, 'type') and uploaded_file.type:
        if uploaded_file.type not in ALLOWED_EXCEL_MIMES:
            logger.warning(f"Rejected file upload with MIME: {uploaded_file.type}")
            return False, f"Invalid file type. Expected Excel file.", None
    
    try:
        df = pd.read_excel(uploaded_file, sheet_name=0, nrows=max_rows + 1)
        
        if len(df) > max_rows:
            return False, f"Too many rows ({len(df):,} > {max_rows:,} limit). Please split the file.", None
        
        return True, "", df
    except Exception as e:
        logger.warning(f"File upload parse error: {e}")
        return False, f"Could not read Excel file: {str(e)[:100]}", None

_log_startup("Starting imports...")

# Suppress Pandas/SQLAlchemy warnings
warnings.filterwarnings('ignore', category=UserWarning, module='pandas')

try:
    import pandas as pd
    from datetime import date, datetime, timedelta # Added for peer analysis
except ImportError:
    pass

_log_startup("pandas imported")

import bcrypt

# Import centralized stock data and helpers
from stock_data import (
    KUWAIT_STOCKS, US_STOCKS,
    normalize_kwd_price,
    get_kuwait_stock_options, get_us_stock_options,
    parse_stock_selection, parse_kuwait_stock_selection
)

try:
    import extra_streamlit_components as stx
except ImportError:
    stx = None

try:
    import streamlit_antd_components as sac
except ImportError:
    sac = None

import numpy as np
import io
import sys
import streamlit as st

# ============================================================
# CRON ENDPOINT (MUST RUN BEFORE ANY UI IS RENDERED)
# ============================================================
# This block intercepts cron requests and returns plain text response.
# It runs BEFORE any UI elements are rendered.

# Get query params - Streamlit 1.30+ uses st.query_params (dict-like)
_cron_action = st.query_params.get("cron", "")
_cron_key = st.query_params.get("key", "")

if _cron_action:  # If cron param exists
    _expected_key = os.environ.get("CRON_SECRET_KEY", "")
    
    if not _expected_key:
        st.text("ERROR: CRON_SECRET_KEY not configured on server")
        st.stop()
    
    if _cron_key != _expected_key:
        st.text("INVALID KEY")
        st.stop()
    
    # Valid cron request - run the job
    st.text(f"Starting cron job: {_cron_action}")
    
    try:
        from auto_price_scheduler import run_price_update_job
        run_price_update_job()
        st.text(f"OK - cron '{_cron_action}' executed successfully")
    except Exception as e:
        st.text(f"ERROR: {e}")
    
    st.stop()  # CRITICAL: Stop here, do not render UI

# ============================================================
# END CRON ENDPOINT
# Normal Streamlit UI code continues below
# ============================================================

_log_startup("streamlit imported")

# âœ… PROFESSIONAL: Python version check (checks actual version, not path)
REQUIRED = (3, 11)

if sys.version_info < REQUIRED:
    st.error("âŒ **Wrong Python Version Detected**")
    st.error(f"Expected: Python {REQUIRED[0]}.{REQUIRED[1]}+")
    st.error(f"Detected: Python {sys.version.split()[0]}")
    st.code(f"Executable: {sys.executable}")
    st.info("ðŸ’¡ **Solution:** Run app inside Python 3.11 virtual environment")
    st.code("venv\\Scripts\\activate\npython -m streamlit run ui.py", language="bash")
    st.stop()

try:
    import altair as alt
except Exception:
    alt = None
import math

try:
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
except Exception:
    px = None
    go = None
    make_subplots = None
import json
import urllib.request
import urllib.parse
try:
    import requests
except Exception:
    requests = None

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# Check yfinance availability WITH DIAGNOSTICS
YFINANCE_AVAILABLE = False
YFINANCE_ERROR = None

# =========================
# CONFIGURATION
# =========================

# Configuration for the 8 Tables in Peer Analysis
PEER_METRICS = {
    "Total Return": {
        "1 Month": "calc_ret_1mo",
        "3 Month": "calc_ret_3mo",
        "6 Month": "calc_ret_6mo",
        "9 Month": "calc_ret_9mo",
        "YTD": "calc_ret_ytd",
        "1 Year": "calc_ret_1y",
        "3 Year": "calc_ret_3y",
        "5 Year": "calc_ret_5y",
        "10 Year": "calc_ret_10y"
    },
    "Dividends": {
        "Dividend Yield (TTM)": "info_dividendYield",
        "Payout Ratio": "info_payoutRatio",
        "5 Year Avg Yield": "info_fiveYearAvgDividendYield",
        "Dividend Rate (TTM)": "info_dividendRate",
        "Ex-Dividend Date": "info_exDividendDate"
    },
    "Valuation": {
        "P/E (TTM)": "info_trailingPE",
        "Forward P/E": "info_forwardPE",
        "PEG Ratio": "info_pegRatio",
        "Price/Sales (TTM)": "info_priceToSalesTrailing12Months",
        "Price/Book (TTM)": "info_priceToBook",
        "EV/Revenue": "info_enterpriseToRevenue",
        "EV/EBITDA": "info_enterpriseToEbitda",
        "Price/Cash Flow": "info_operatingCashflow" # Note: Usually calc needed, strictly info here per request
    },
    "Growth": {
        "Revenue Growth (YoY)": "info_revenueGrowth",
        "Earnings Growth (YoY)": "info_earningsGrowth",
        "Revenue 3Y CAGR": "calc_cagr_revenue_3y",
        "Net Income 3Y CAGR": "calc_cagr_netincome_3y",
        "EPS Diluted 3Y CAGR": "calc_cagr_eps_3y"
    },
    "Profitability": {
        "Gross Margin": "info_grossMargins",
        "EBITDA Margin": "info_ebitdaMargins",
        "Operating Margin": "info_operatingMargins",
        "Net Profit Margin": "info_profitMargins",
        "Return on Equity (ROE)": "info_returnOnEquity",
        "Return on Assets (ROA)": "info_returnOnAssets"
    },
    "Performance": {
        "1 Year Price Perf": "calc_ret_1y",
        "52 Week High": "info_fiftyTwoWeekHigh",
        "52 Week Low": "info_fiftyTwoWeekLow",
        "Beta": "info_beta"
    },
    "Income Statement (TTM/MRQ)": {
        "Total Revenue": "info_totalRevenue",
        "Gross Profit": "sheet_Gross Profit",
        "EBITDA": "info_ebitda",
        "Operating Income": "sheet_Operating Income",
        "Net Income": "sheet_Net Income",
        "EPS Diluted": "info_trailingEps"
    },
    "Balance Sheet (MRQ)": {
        "Total Cash": "info_totalCash",
        "Total Debt": "info_totalDebt",
        "Net Debt": "calc_net_debt", 
        "Total Debt/Equity": "info_debtToEquity",
        "Current Ratio": "info_currentRatio",
        "Quick Ratio": "info_quickRatio",
        "Book Value Per Share": "info_bookValue"
    },
    "Cash Flow": {
        "Operating Cash Flow": "info_operatingCashflow",
        "Free Cash Flow": "info_freeCashflow",
        "CapEx": "calc_capex" 
    }
}

# Currency Configuration (Single Source of Truth)
BASE_CCY = "KWD"  # Overall portfolio must be in KWD
USD_CCY = "USD"
DEFAULT_USD_TO_KWD = 0.307190  # Default USDâ†’KWD rate

# Portfolio Currency Mapping
PORTFOLIO_CCY = {
    "KFH": "KWD",
    "BBYN": "KWD",
    "USA": "USD",
}
YFINANCE_PATH = None

# NOTE: yfinance is now LAZY-LOADED to improve cold start time
# The actual import happens in _ensure_yfinance() when first needed
yf = None  # Will be set by _ensure_yfinance()

_log_startup("yfinance deferred (lazy-load)")


def _ensure_yfinance():
    """Lazy-load yfinance only when actually needed.
    
    This saves 15-20 seconds on cold starts since yfinance
    has many heavy dependencies that are only loaded when needed.
    """
    global YFINANCE_AVAILABLE, YFINANCE_ERROR, YFINANCE_PATH, yf
    
    # Already loaded?
    if yf is not None:
        return YFINANCE_AVAILABLE
    
    # Already tried and failed?
    if YFINANCE_ERROR is not None:
        return False
    
    try:
        import yfinance as _yf
        yf = _yf  # Set the global
        YFINANCE_AVAILABLE = True
        YFINANCE_PATH = _yf.__file__
        _log_startup("yfinance loaded on-demand")
        return True
    except Exception as e:
        YFINANCE_ERROR = str(e)
        YFINANCE_AVAILABLE = False
        yf = None
        logger.warning(f"yfinance import failed: {e}")
        return False


@st.cache_resource(ttl=3600)  # Cache Ticker objects for 1 hour
def _get_yf_ticker(symbol: str):
    """Get a cached yfinance Ticker object.
    
    Using @st.cache_resource avoids recreating Ticker objects
    on every rerun, which saves network round-trips.
    """
    if not _ensure_yfinance():
        return None
    return yf.Ticker(symbol)


def session_tv(timeout=20):
    """Create a TradingView session with proper browser-like headers and cookie warm-up."""
    s = requests.Session()
    s.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "en-US,en;q=0.9",
        "Referer": "https://www.tradingview.com/",
        "Origin": "https://www.tradingview.com",
        "DNT": "1",
        "Connection": "keep-alive",
    })
    try:
        s.get("https://www.tradingview.com/", timeout=timeout)
    except Exception:
        pass
    return s


@st.cache_data(ttl=3600, show_spinner=False)
def get_pe_ratios(items: tuple):
    """
    Fetch P/E ratios for a tuple of (symbol, currency) tuples.
    Use tuple(items) when calling for proper cache hashability.
    Returns a dict {symbol: pe_ratio}.
    """
    # Lazy-load yfinance
    if not _ensure_yfinance():
        return {}
        
    results = {}
    # Create a progress bar if there are many items
    progress_bar = None
    if len(items) > 5:
        progress_bar = st.progress(0, text="Fetching P/E ratios...")
        
    for i, (sym, ccy) in enumerate(items):
        ticker_name = sym
        # Heuristic for Kuwaiti stocks
        if ccy == "KWD" and not sym.endswith(".KW"):
            ticker_name = f"{sym}.KW"
            
        try:
            # Use cached Ticker to avoid recreating on each rerun
            t = _get_yf_ticker(ticker_name)
            if t is None:
                results[sym] = None
                continue
            # Accessing info triggers the fetch
            info = t.info
            pe = info.get('trailingPE')
            if pe is None:
                pe = info.get('forwardPE')
            results[sym] = pe
        except Exception:
            results[sym] = None
            
        if progress_bar:
            progress_bar.progress((i + 1) / len(items))
            
    if progress_bar:
        progress_bar.empty()
        
    return results


# Stock data and helper functions imported from stock_data.py

def normalize_tv_key(exchange: str, symbol: str) -> str:
    """Normalize TradingView exchange:symbol key."""
    return f"{(exchange or '').strip().upper()}:{(symbol or '').strip().upper()}"


def tradingview_search(query: str, exchange: str = None, limit: int = 20, session=None):
    """Search TradingView symbols using their public symbol_search endpoint.
    Returns list of results with 'exchange', 'symbol', 'full_name', 'description'.
    Per TradingView docs: exchange param is mandatory for Kuwait stocks (use 'KSE').
    """
    if not query:
        return [], None
    if session is None:
        session = session_tv() if requests else None
    
    url = "https://symbol-search.tradingview.com/symbol_search/"
    params = {"text": query, "hl": 1, "lang": "en"}
    if exchange:
        params["exchange"] = exchange
    
    try:
        if requests is not None and session:
            r = session.get(url, params=params, timeout=20)
            r.raise_for_status()
            data = r.json()
        else:
            q = urllib.parse.urlencode(params)
            with urllib.request.urlopen(url + "?" + q, timeout=20) as resp:
                data = json.loads(resp.read().decode())
        if isinstance(data, list):
            return data[:limit], None
        return data, None
    except Exception as e:
        return None, str(e)


def map_to_tradingview(symbol: str, exchange: str = "KSE", limit: int = 20):
    """Return candidate TradingView symbols for a given local symbol.
    Defaults to KSE (Kuwait Stock Exchange) but can override.
    """
    import re
    candidates = []
    seen = set()
    session = session_tv() if requests else None
    
    # Try with specified exchange first
    data, err = tradingview_search(symbol, exchange=exchange, limit=limit, session=session)
    if data and isinstance(data, list):
        for item in data:
            sym = item.get("symbol") or item.get("ticker")
            exch = item.get("exchange") or item.get("exchange_short")
            if not sym:
                continue
            # Strip HTML tags (TradingView may return <em> tags)
            sym = re.sub(r'<[^>]+>', '', sym).strip()
            key = normalize_tv_key(exch, sym)
            if key in seen:
                continue
            seen.add(key)
            full_name = item.get("full_name") or item.get("description") or ""
            full_name = re.sub(r'<[^>]+>', '', full_name).strip()
            candidates.append({
                "tv_symbol": sym,
                "exchange": exch,
                "full_name": full_name,
                "type": item.get("type"),
            })
    
    # If no results, try without exchange filter
    if not candidates:
        data, err = tradingview_search(symbol, exchange=None, limit=limit, session=session)
        if data and isinstance(data, list):
            for item in data:
                sym = item.get("symbol") or item.get("ticker")
                exch = item.get("exchange") or item.get("exchange_short")
                if not sym:
                    continue
                sym = re.sub(r'<[^>]+>', '', sym).strip()
                key = normalize_tv_key(exch, sym)
                if key in seen:
                    continue
                seen.add(key)
                full_name = item.get("full_name") or item.get("description") or ""
                full_name = re.sub(r'<[^>]+>', '', full_name).strip()
                candidates.append({
                    "tv_symbol": sym,
                    "exchange": exch,
                    "full_name": full_name,
                    "type": item.get("type"),
                })
    
    return candidates

# =========================
# CONFIG
# =========================
# NOTE: st.set_page_config() is now called at the top of the file,
# immediately after Streamlit import (required to be first st command)


# =========================
# DATABASE LAYER (Supports SQLite & PostgreSQL/Supabase)
# =========================
from db_layer import (
    get_conn, 
    query_df, 
    query_val, 
    exec_sql, 
    table_columns, 
    add_column_if_missing,
    get_db_type,
    is_postgres,
    init_postgres_schema,
    get_connection,
    convert_sql,
    convert_params,
    execute_with_cursor,
    DB_TYPE,
    DB_CONFIG,
    IS_PRODUCTION
)

# NOTE: Database initialization is now DEFERRED to main() for fast startup
# The init_postgres_schema() call was moved to avoid blocking module import
_log_startup("db_layer imported (connection deferred)")


# =============================================================================
# SOFT DELETE HELPERS (Early definition - used throughout the file)
# =============================================================================
# Cache for column existence checks (cleared on app restart)
_COLUMN_EXISTS_CACHE = {}

def _column_exists(table_name: str, column_name: str) -> bool:
    """
    Check if a column exists in a table. Results are cached for performance.
    Used to provide backward compatibility with databases that don't have
    the soft-delete columns yet.
    """
    cache_key = f"{table_name}.{column_name}"
    if cache_key in _COLUMN_EXISTS_CACHE:
        return _COLUMN_EXISTS_CACHE[cache_key]
    
    try:
        cols = table_columns(table_name)
        exists = column_name in cols
        _COLUMN_EXISTS_CACHE[cache_key] = exists
        return exists
    except Exception:
        return False


def _soft_delete_filter(table_alias: str = "") -> str:
    """
    Returns the SQL fragment for filtering out soft-deleted records.
    Returns empty string if is_deleted column doesn't exist yet.
    
    This provides backward compatibility: queries work on both new databases
    (with soft-delete columns) and legacy databases (without them).
    
    Args:
        table_alias: Optional table alias (e.g., "t" for "t.is_deleted")
    
    Returns:
        " AND COALESCE(is_deleted, 0) = 0" if column exists, else ""
    """
    # Check if transactions has is_deleted column (both tables added together)
    if not _column_exists("transactions", "is_deleted"):
        return ""
    
    prefix = f"{table_alias}." if table_alias else ""
    return f" AND COALESCE({prefix}is_deleted, 0) = 0"


def _soft_delete_filter_deposits(table_alias: str = "") -> str:
    """
    Returns the SQL fragment for filtering out soft-deleted cash_deposits.
    Returns empty string if is_deleted column doesn't exist yet.
    """
    if not _column_exists("cash_deposits", "is_deleted"):
        return ""
    
    prefix = f"{table_alias}." if table_alias else ""
    return f" AND COALESCE({prefix}is_deleted, 0) = 0"


_log_startup("Function definitions starting")

def get_db_info():
    """Get current database type and status for display."""
    try:
        from db_layer import DB_TYPE, DB_CONFIG, IS_PRODUCTION
        from urllib.parse import urlparse
        
        if DB_TYPE == 'postgres':
            # Parse URL to show host safely
            url = DB_CONFIG.get('url', '')
            if url:
                try:
                    parsed = urlparse(url)
                    host = parsed.hostname or 'unknown'
                    dbname = parsed.path.lstrip('/') if parsed.path else 'unknown'
                    return f"ðŸ˜ PostgreSQL ({host[:20]}.../{dbname})"
                except:
                    pass
            return "ðŸ˜ PostgreSQL (persistent)"
        elif DB_TYPE == 'sqlite':
            path = DB_CONFIG.get('path', 'portfolio.db')
            if '/tmp/' in path:
                return "âš ï¸ SQLite (EPHEMERAL - /tmp)"
            if IS_PRODUCTION:
                return "âŒ SQLite in PRODUCTION (DATA LOSS RISK!)"
            return f"ðŸ“ SQLite ({path}) - Local Dev"
        return "â“ Unknown"
    except Exception as e:
        return f"ðŸ“ SQLite ({e})"


# --- DATABASE PERFORMANCE OPTIMIZATION ---
# Store connection in a mutable container so we can replace it if it becomes stale
_connection_container = {"conn": None}

class PersistentConnectionWrapper:
    """
    Wrapper that prevents accidental closing of the shared connection.
    Calls to close() are ignored to keep the connection alive across reruns.
    """
    def __init__(self, real_conn):
        self._conn = real_conn
    
    def cursor(self):
        return self._conn.cursor()
    
    def commit(self):
        return self._conn.commit()
    
    def rollback(self):
        return self._conn.rollback()
    
    def close(self):
        # NO-OP: Don't actually close the persistent connection
        # This prevents "connection already closed" errors when code calls conn.close()
        pass
    
    def _real_close(self):
        """Only for internal use when we need to actually close and reconnect."""
        return self._conn.close()
    
    def __getattr__(self, name):
        # Proxy all other attributes to the real connection
        return getattr(self._conn, name)

def get_db_connection_pool():
    """
    Creates a PERSISTENT database connection that stays open across reruns.
    This eliminates the 300ms-1s SSL handshake latency on every click.
    Validates the connection before returning and reconnects if stale.
    """
    from db_layer import get_conn as _db_get_conn
    
    wrapper = _connection_container.get("conn")
    
    # Validate existing connection
    if wrapper is not None:
        try:
            # Test if connection is still alive
            cur = wrapper.cursor()
            cur.execute("SELECT 1")
            cur.fetchone()
            cur.close()
            return wrapper
        except Exception:
            # Connection is stale, close it and create a new one
            try:
                wrapper._real_close()
            except Exception:
                pass
            _connection_container["conn"] = None
    
    # Create new connection and wrap it
    new_conn = _db_get_conn()
    wrapper = PersistentConnectionWrapper(new_conn)
    _connection_container["conn"] = wrapper
    return wrapper

def get_cached_connection():
    """Wrapper to use the cached connection pool."""
    return get_db_connection_pool()

def get_conn():
    """Local wrapper to use persistent cached connection."""
    return get_db_connection_pool()

def db_execute(cur, sql: str, params: tuple = ()) -> None:
    """Execute SQL with automatic ? to %s conversion for PostgreSQL.
    
    Use this wrapper instead of cur.execute() to ensure cross-database compatibility.
    Note: For write operations, we use the cursor passed in.
    For reads using cached connection, use get_cached_connection().
    """
    return execute_with_cursor(None, cur, sql, params)


def convert_sql_placeholders(sql: str) -> str:
    """Convert ? placeholders to %s for PostgreSQL compatibility.
    
    Use this for pd.read_sql_query() which doesn't use db_execute().
    """
    if is_postgres():
        return sql.replace("?", "%s")
    return sql


def normalize_symbol(symbol: str, user_id: int = None) -> str:
    """Normalize a stock symbol to match existing symbols in the database.
    
    This ensures consistency when recording transactions - the symbol will match
    the exact format stored in the stocks table (case, suffix, etc.).
    
    Args:
        symbol: The symbol to normalize
        user_id: Optional user_id to look up their specific stock symbols
    
    Returns:
        The normalized symbol matching the database format, or the original
        symbol (uppercased and trimmed) if no match found.
    """
    if not symbol:
        return symbol
    
    symbol = str(symbol).strip()
    symbol_upper = symbol.upper()
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # Get all known stock symbols for matching
        if user_id:
            db_execute(cur, "SELECT symbol FROM stocks WHERE user_id = ?", (user_id,))
        else:
            db_execute(cur, "SELECT DISTINCT symbol FROM stocks")
        
        known_symbols = {row[0].upper().strip(): row[0] for row in cur.fetchall()}
        conn.close()
        
        # Try exact match (case-insensitive)
        if symbol_upper in known_symbols:
            return known_symbols[symbol_upper]
        
        # Try partial match (e.g., "ZAIN" matches "ZAIN.KW")
        for known_upper, known_original in known_symbols.items():
            # Check if one contains the other
            if symbol_upper in known_upper or known_upper in symbol_upper:
                return known_original
            # Compare base symbols (before the dot)
            known_base = known_upper.split('.')[0]
            symbol_base = symbol_upper.split('.')[0]
            if known_base == symbol_base:
                return known_original
        
        # No match found - return uppercase trimmed version
        return symbol_upper
        
    except Exception:
        # If any error, just return uppercase trimmed
        return symbol_upper


# =========================
# SECURITIES MASTER FUNCTIONS (Three-Layer Architecture)
# =========================

# Exchange configuration with suffix rules for price APIs
EXCHANGE_CONFIG = {
    "KSE": {
        "name": "Kuwait Stock Exchange",
        "country": "KW",
        "currency": "KWD",
        "api_suffix": ".KW",  # Yahoo Finance requires .KW suffix
        "trading_days": [6, 0, 1, 2, 3],  # Sun-Thu (Python weekday: 0=Mon)
    },
    "BSE": {
        "name": "Bahrain Bourse",
        "country": "BH", 
        "currency": "BHD",
        "api_suffix": ".BH",
        "trading_days": [6, 0, 1, 2, 3],  # Sun-Thu
    },
    "NYSE": {
        "name": "New York Stock Exchange",
        "country": "US",
        "currency": "USD",
        "api_suffix": "",  # No suffix for US stocks
        "trading_days": [0, 1, 2, 3, 4],  # Mon-Fri
    },
    "NASDAQ": {
        "name": "NASDAQ",
        "country": "US",
        "currency": "USD",
        "api_suffix": "",
        "trading_days": [0, 1, 2, 3, 4],
    },
    "AMEX": {
        "name": "American Stock Exchange",
        "country": "US",
        "currency": "USD",
        "api_suffix": "",
        "trading_days": [0, 1, 2, 3, 4],
    },
}

def generate_security_id(ticker: str, exchange: str) -> str:
    """Generate a canonical security_id in format SEC_{TICKER}_{EXCHANGE}."""
    clean_ticker = ticker.upper().strip().replace(".", "").replace(" ", "_")
    clean_exchange = exchange.upper().strip()
    return f"SEC_{clean_ticker}_{clean_exchange}"


def create_security(
    canonical_ticker: str,
    exchange: str,
    display_name: str = None,
    isin: str = None,
    currency: str = None,
    country: str = None,
    sector: str = None,
    aliases: list = None,
    user_id: int = 1
) -> str:
    """
    Create a new security in the securities master table.
    
    Args:
        canonical_ticker: Official exchange ticker WITHOUT suffix (e.g., 'OOREDOO' not 'OOREDOO.KW')
        exchange: Exchange code (KSE, BSE, NYSE, NASDAQ, AMEX)
        display_name: User-friendly name
        isin: ISIN code if known
        currency: Currency code (defaults to exchange default)
        country: Country code (defaults to exchange default)
        sector: Sector classification
        aliases: List of alias names to register
        user_id: User ID for per-user security isolation
        
    Returns:
        security_id of the created security
    """
    security_id = generate_security_id(canonical_ticker, exchange)
    
    # Get defaults from exchange config
    exchange_info = EXCHANGE_CONFIG.get(exchange.upper(), {})
    if not currency:
        currency = exchange_info.get("currency", "KWD")
    if not country:
        country = exchange_info.get("country", "KW")
    if not display_name:
        display_name = canonical_ticker
    
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        db_execute(cur, """
            INSERT OR IGNORE INTO securities_master 
            (security_id, exchange, canonical_ticker, display_name, isin, currency, country, sector, status, user_id, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, 'active', ?, ?, ?)
        """, (
            security_id,
            exchange.upper(),
            canonical_ticker.upper().strip(),
            display_name,
            isin,
            currency,
            country,
            sector,
            user_id,
            int(time.time()),
            int(time.time())
        ))
        
        # Register default aliases (canonical ticker and with/without suffix)
        default_aliases = [
            canonical_ticker.upper(),
            canonical_ticker.lower(),
        ]
        
        # Add suffix version as alias
        api_suffix = exchange_info.get("api_suffix", "")
        if api_suffix:
            default_aliases.append(f"{canonical_ticker.upper()}{api_suffix}")
            default_aliases.append(f"{canonical_ticker.lower()}{api_suffix.lower()}")
        
        # Add user-provided aliases
        if aliases:
            default_aliases.extend(aliases)
        
        # Register all aliases
        for alias in set(default_aliases):
            register_alias(security_id, alias, "official", user_id=user_id, cur=cur)
        
        conn.commit()
        return security_id
        
    except Exception as e:
        conn.rollback()
        logger.error(f"Error creating security {canonical_ticker}: {e}")
        raise
    finally:
        conn.close()


def register_alias(
    security_id: str,
    alias_name: str,
    alias_type: str = "user_input",
    valid_from: str = None,
    valid_until: str = None,
    user_id: int = 1,
    cur=None
):
    """
    Register an alias for a security.
    
    Args:
        security_id: The canonical security_id
        alias_name: The raw symbol variation
        alias_type: Type of alias (user_input, broker_format, official, legacy)
        valid_from: Date alias became valid (YYYY-MM-DD)
        valid_until: Date alias expired (NULL = still valid)
        user_id: User ID for per-user alias isolation
        cur: Optional cursor for transaction batching
    """
    close_conn = False
    if cur is None:
        conn = get_conn()
        cur = conn.cursor()
        close_conn = True
    
    try:
        db_execute(cur, """
            INSERT OR IGNORE INTO security_aliases 
            (security_id, alias_name, alias_type, valid_from, valid_until, user_id, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            security_id,
            alias_name.strip(),
            alias_type,
            valid_from or date.today().isoformat(),
            valid_until,
            user_id,
            int(time.time())
        ))
        
        if close_conn:
            cur.connection.commit()
            
    except Exception as e:
        logger.debug(f"Alias registration note: {e}")
    finally:
        if close_conn:
            cur.connection.close()


def resolve_symbol_to_security(raw_symbol: str, portfolio: str = None) -> dict:
    """
    Resolve a raw symbol to its canonical security_id.
    
    This is the primary function for symbol lookup. It uses:
    1. Alias table (case-insensitive match)
    2. Direct canonical_ticker match with exchange inference from portfolio
    3. Fuzzy matching against display_name
    
    Args:
        raw_symbol: The raw symbol from user input or import
        portfolio: Optional portfolio name to infer exchange (KFH/BBYN â†’ KSE, USA â†’ NYSE/NASDAQ)
        
    Returns:
        dict with keys: security_id, canonical_ticker, exchange, currency, display_name
        or None if not found
    """
    if not raw_symbol:
        return None
    
    clean_symbol = raw_symbol.strip()
    
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        # Step 1: Check alias table (case-insensitive)
        # Tables may not exist yet, so wrap in try-except
        try:
            db_execute(cur, """
                SELECT sm.security_id, sm.canonical_ticker, sm.exchange, sm.currency, sm.display_name
                FROM security_aliases sa
                JOIN securities_master sm ON sa.security_id = sm.security_id
                WHERE LOWER(sa.alias_name) = LOWER(?)
                  AND (sa.valid_until IS NULL OR sa.valid_until >= date('now'))
                  AND sm.status = 'active'
                LIMIT 1
            """, (clean_symbol,))
            
            row = cur.fetchone()
            if row:
                return {
                    "security_id": row[0],
                    "canonical_ticker": row[1],
                    "exchange": row[2],
                    "currency": row[3],
                    "display_name": row[4]
                }
        except Exception:
            # Tables don't exist yet - that's fine, continue to other lookups
            pass
        
        # Step 2: Direct canonical_ticker match
        # Infer exchange from portfolio if provided
        exchanges = None
        if portfolio:
            portfolio_upper = portfolio.upper()
            if portfolio_upper in ("KFH", "BBYN"):
                exchanges = ("KSE",)
            elif portfolio_upper == "USA":
                exchanges = ("NYSE", "NASDAQ", "AMEX")
        
        try:
            if exchanges:
                placeholders = ",".join("?" * len(exchanges))
                db_execute(cur, f"""
                    SELECT security_id, canonical_ticker, exchange, currency, display_name
                    FROM securities_master
                    WHERE UPPER(canonical_ticker) = UPPER(?)
                      AND exchange IN ({placeholders})
                      AND status = 'active'
                    LIMIT 1
                """, (clean_symbol.split('.')[0],) + exchanges)
            else:
                db_execute(cur, """
                    SELECT security_id, canonical_ticker, exchange, currency, display_name
                    FROM securities_master
                    WHERE UPPER(canonical_ticker) = UPPER(?)
                      AND status = 'active'
                    LIMIT 1
                """, (clean_symbol.split('.')[0],))
            
            row = cur.fetchone()
            if row:
                return {
                    "security_id": row[0],
                    "canonical_ticker": row[1],
                    "exchange": row[2],
                    "currency": row[3],
                    "display_name": row[4]
                }
        except Exception:
            # Table doesn't exist yet
            pass
        
        return None
        
    finally:
        conn.close()


def get_price_fetch_symbol(security_id: str) -> tuple:
    """
    Get the correct symbol format for price API calls.
    
    Returns (api_symbol, exchange, currency) where api_symbol has the correct
    suffix for the exchange (e.g., 'OOREDOO.KW' for Kuwait stocks).
    """
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        db_execute(cur, """
            SELECT canonical_ticker, exchange, currency
            FROM securities_master
            WHERE security_id = ?
        """, (security_id,))
        
        row = cur.fetchone()
        if not row:
            return None, None, None
        
        ticker, exchange, currency = row
        exchange_info = EXCHANGE_CONFIG.get(exchange, {})
        api_suffix = exchange_info.get("api_suffix", "")
        
        api_symbol = f"{ticker}{api_suffix}"
        return api_symbol, exchange, currency
        
    finally:
        conn.close()


def get_security_info(security_id: str) -> dict:
    """Get full security information by security_id."""
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        db_execute(cur, """
            SELECT security_id, exchange, canonical_ticker, display_name, isin, 
                   currency, country, status, sector
            FROM securities_master
            WHERE security_id = ?
        """, (security_id,))
        
        row = cur.fetchone()
        if row:
            return {
                "security_id": row[0],
                "exchange": row[1],
                "canonical_ticker": row[2],
                "display_name": row[3],
                "isin": row[4],
                "currency": row[5],
                "country": row[6],
                "status": row[7],
                "sector": row[8]
            }
        return None
        
    finally:
        conn.close()


def migrate_transactions_to_security_id(user_id: int = None):
    """
    Migrate existing transactions to use security_id.
    
    This resolves raw stock_symbol to security_id using the alias table.
    Should be run after populating securities_master and security_aliases.
    """
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        # Get transactions without security_id
        if user_id:
            db_execute(cur, """
                SELECT DISTINCT stock_symbol, portfolio
                FROM transactions
                WHERE user_id = ? AND (security_id IS NULL OR security_id = '')
            """, (user_id,))
        else:
            db_execute(cur, """
                SELECT DISTINCT stock_symbol, portfolio
                FROM transactions
                WHERE security_id IS NULL OR security_id = ''
            """)
        
        symbols_to_resolve = cur.fetchall()
        resolved_count = 0
        unresolved = []
        
        for stock_symbol, portfolio in symbols_to_resolve:
            security = resolve_symbol_to_security(stock_symbol, portfolio)
            
            if security:
                if user_id:
                    db_execute(cur, """
                        UPDATE transactions 
                        SET security_id = ?
                        WHERE stock_symbol = ? AND user_id = ? AND (security_id IS NULL OR security_id = '')
                    """, (security["security_id"], stock_symbol, user_id))
                else:
                    db_execute(cur, """
                        UPDATE transactions 
                        SET security_id = ?
                        WHERE stock_symbol = ? AND (security_id IS NULL OR security_id = '')
                    """, (security["security_id"], stock_symbol))
                
                resolved_count += cur.rowcount
            else:
                unresolved.append(stock_symbol)
        
        conn.commit()
        logger.info(f"âœ… Migrated {resolved_count} transactions to security_id")
        
        if unresolved:
            logger.warning(f"âš ï¸ Unresolved symbols: {unresolved}")
        
        return resolved_count, unresolved
        
    finally:
        conn.close()


def auto_create_security_from_stock(symbol: str, portfolio: str = None, display_name: str = None, user_id: int = 1):
    """
    Automatically create a security from a stock symbol if it doesn't exist.
    
    Infers exchange from portfolio and creates both the security and initial aliases.
    """
    # Check if already exists
    existing = resolve_symbol_to_security(symbol, portfolio)
    if existing:
        return existing["security_id"]
    
    # Infer exchange from portfolio
    portfolio_upper = (portfolio or "KFH").upper()
    if portfolio_upper in ("KFH", "BBYN"):
        exchange = "KSE"
    elif portfolio_upper == "USA":
        # Default to NASDAQ for US stocks, can be updated later
        exchange = "NASDAQ"
    else:
        exchange = "KSE"  # Default
    
    # Clean the ticker (remove any suffix)
    clean_ticker = symbol.upper().strip().split('.')[0]
    
    # Create the security
    security_id = create_security(
        canonical_ticker=clean_ticker,
        exchange=exchange,
        display_name=display_name or clean_ticker,
        aliases=[symbol],  # Register original input as alias
        user_id=user_id
    )
    
    return security_id


def backfill_security_ids(user_id: int = None, auto_create: bool = False) -> dict:
    """
    Backfill security_id for transactions that have NULL security_id.
    
    This is a NON-DESTRUCTIVE operation that:
    1. Only updates transactions where security_id IS NULL
    2. Uses resolve_symbol_to_security() to find matching securities
    3. Optionally auto-creates securities for unmatched symbols
    4. Preserves ALL existing transaction data
    
    Args:
        user_id: Optional user ID to limit scope. If None, processes all users.
        auto_create: If True, creates new securities for unresolved symbols.
        
    Returns:
        dict with keys: resolved_count, unresolved_symbols, auto_created_count
    """
    result = {
        "resolved_count": 0,
        "unresolved_symbols": [],
        "auto_created_count": 0,
        "errors": []
    }
    
    # First, run the standard migration
    try:
        resolved, unresolved = migrate_transactions_to_security_id(user_id)
        result["resolved_count"] = resolved
        result["unresolved_symbols"] = list(unresolved)
        
        # If auto_create is enabled, create securities for unresolved symbols
        if auto_create and unresolved:
            for symbol in unresolved:
                try:
                    # Try to infer portfolio from transactions
                    conn = get_conn()
                    cur = conn.cursor()
                    db_execute(cur, """
                        SELECT DISTINCT portfolio FROM transactions 
                        WHERE stock_symbol = ? AND portfolio IS NOT NULL
                        LIMIT 1
                    """, (symbol,))
                    row = cur.fetchone()
                    portfolio = row[0] if row else None
                    conn.close()
                    
                    # Auto-create the security
                    new_security_id = auto_create_security_from_stock(symbol, portfolio, user_id=user_id or 1)
                    if new_security_id:
                        result["auto_created_count"] += 1
                        logger.info(f"âœ… Auto-created security for: {symbol}")
                except Exception as e:
                    result["errors"].append(f"{symbol}: {str(e)}")
            
            # Re-run migration to pick up newly created securities
            if result["auto_created_count"] > 0:
                resolved2, still_unresolved = migrate_transactions_to_security_id(user_id)
                result["resolved_count"] += resolved2
                result["unresolved_symbols"] = list(still_unresolved)
                
    except Exception as e:
        result["errors"].append(str(e))
        logger.error(f"âŒ Error in backfill_security_ids: {e}")
    
    return result


def seed_default_securities(user_id: int = 1):
    """
    Seed the securities master with common stocks from Kuwait, Bahrain, and US markets.
    
    This should be called during initial setup or migration.
    """
    # Kuwait Stock Exchange (KSE) securities
    kse_securities = [
        ("KRE", "Kuwait Real Estate Company"),
        ("OOREDOO", "Ooredoo Kuwait"),
        ("AGILITY", "Agility Logistics"),
        ("GFH", "GFH Financial Group"),
        ("NIH", "National Industries Group"),
        ("BPCC", "Boubyan Petrochemical"),
        ("MABANEE", "Mabanee Company"),
        ("HUMANSOFT", "HumanSoft"),
        ("KFH", "Kuwait Finance House"),
        ("KIB", "Kuwait International Bank"),
        ("SANAM", "Sanam Business Systems"),
        ("ALG", "Al Ahleia Circle"),
        ("ZAIN", "Zain Telecom"),
        ("NBK", "National Bank of Kuwait"),
        ("BOUBYAN", "Boubyan Bank"),
        ("WARBA", "Warba Bank"),
        ("BURGAN", "Burgan Bank"),
        ("ABK", "Al Ahli Bank of Kuwait"),
        ("CBK", "Commercial Bank of Kuwait"),
        ("KPROJ", "Kuwait Projects Company"),
        ("AAYAN", "Aayan Leasing"),
        ("MEZZAN", "Mezzan Holding"),
        ("AUB", "Ahli United Bank"),
        ("SHUAIBA", "Shuaiba Industrial"),
    ]
    
    # Bahrain Bourse (BSE) securities  
    bse_securities = [
        ("AGLTY", "Agility Bahrain"),
        ("GFH", "GFH Financial Group (Bahrain)"),
    ]
    
    # US securities (common examples)
    us_securities = [
        ("NASDAQ", "INCY", "Incyte Corporation"),
        ("NASDAQ", "AAPL", "Apple Inc"),
        ("NASDAQ", "TSLA", "Tesla Inc"),
        ("NASDAQ", "MSFT", "Microsoft Corporation"),
        ("NASDAQ", "GOOGL", "Alphabet Inc"),
        ("NASDAQ", "AMZN", "Amazon.com Inc"),
        ("NASDAQ", "META", "Meta Platforms Inc"),
        ("NASDAQ", "NVDA", "NVIDIA Corporation"),
        ("NYSE", "JNJ", "Johnson & Johnson"),
        ("NYSE", "JPM", "JPMorgan Chase"),
        ("NYSE", "V", "Visa Inc"),
        ("NYSE", "WMT", "Walmart Inc"),
        ("NYSE", "PG", "Procter & Gamble"),
        ("NYSE", "KO", "Coca-Cola Company"),
    ]
    
    created_count = 0
    
    # Create KSE securities
    for ticker, name in kse_securities:
        try:
            create_security(ticker, "KSE", name, user_id=user_id)
            created_count += 1
        except Exception:
            pass  # Already exists
    
    # Create BSE securities
    for ticker, name in bse_securities:
        try:
            create_security(ticker, "BSE", name, user_id=user_id)
            created_count += 1
        except Exception:
            pass
    
    # Create US securities
    for exchange, ticker, name in us_securities:
        try:
            create_security(ticker, exchange, name, user_id=user_id)
            created_count += 1
        except Exception:
            pass
    
    logger.info(f"âœ… Seeded {created_count} securities to master table")
    return created_count


def populate_aliases_from_transactions(user_id: int = None):
    """
    Scan transactions and stocks tables to auto-populate aliases.
    
    This helps with migration by learning all symbol variations in use.
    """
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        # Get all unique symbols from transactions (exclude soft-deleted if column exists)
        soft_del = _soft_delete_filter()
        if user_id:
            db_execute(cur, f"""
                SELECT DISTINCT stock_symbol, portfolio FROM transactions 
                WHERE user_id = ?{soft_del}
            """, (user_id,))
        else:
            db_execute(cur, f"SELECT DISTINCT stock_symbol, portfolio FROM transactions WHERE 1=1{soft_del}")
        
        symbols = cur.fetchall()
        
        aliases_created = 0
        for stock_symbol, portfolio in symbols:
            if not stock_symbol:
                continue
                
            # Try to find matching security
            security = resolve_symbol_to_security(stock_symbol, portfolio)
            
            if security:
                # Security exists, just register this as an alias
                register_alias(security["security_id"], stock_symbol, "legacy", user_id=user_id or 1)
                aliases_created += 1
            else:
                # Auto-create security from this symbol
                auto_create_security_from_stock(stock_symbol, portfolio, user_id=user_id or 1)
                aliases_created += 1
        
        logger.info(f"âœ… Processed {aliases_created} symbol aliases")
        return aliases_created
        
    finally:
        conn.close()


# =========================
# AUTH HELPER FUNCTIONS
# =========================
def hash_password(password: str) -> str:
    """Hash a password for storing."""
    try:
        import bcrypt
        salt = bcrypt.gensalt()
        hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
        return hashed.decode('utf-8')
    except ImportError:
        return password

def check_password(password: str, hashed: str) -> bool:
    """Check a password against a hash. No plain text fallback for security."""
    try:
        import bcrypt
        # checkpw raises ValueError if hashed is not a valid salt/hash
        if not hashed or not isinstance(hashed, (str, bytes)):
            return False
        
        # Ensure hashed is bytes
        if isinstance(hashed, str):
            hashed_bytes = hashed.encode('utf-8')
        else:
            hashed_bytes = hashed
            
        return bcrypt.checkpw(password.encode('utf-8'), hashed_bytes)
    except Exception:
        return False

def get_current_user_id() -> Optional[int]:
    """Get the currently logged in user ID."""
    return st.session_state.get('user_id')

def create_session_token(user_id: int, days: int = 30) -> str:
    """Create a new session token for the user."""
    token = str(uuid.uuid4())
    now = int(time.time())
    expires_at = now + (days * 24 * 60 * 60)
    
    conn = get_conn()
    cur = conn.cursor()
    # Ensure cleanup of old tokens for this user to avoid bloat
    db_execute(cur, "DELETE FROM user_sessions WHERE user_id = ?", (user_id,))
    
    db_execute(cur, "INSERT INTO user_sessions (token, user_id, expires_at, created_at) VALUES (?, ?, ?, ?)",
               (token, user_id, expires_at, now))
    conn.commit()
    conn.close()
    return token, expires_at

def get_user_from_token(token: str) -> Optional[dict]:
    """Validate token and return user info if valid."""
    try:
        conn = get_conn()
        cur = conn.cursor()
        now = int(time.time())
        
        # Clean expired sessions occasionally
        if np.random.random() < 0.1:
            try:
                db_execute(cur, "DELETE FROM user_sessions WHERE expires_at < ?", (now,))
                conn.commit()
            except Exception:
                pass
            
        db_execute(cur, """
            SELECT u.id, u.username, sess.expires_at 
            FROM user_sessions sess
            JOIN users u ON sess.user_id = u.id
            WHERE sess.token = ? AND sess.expires_at > ?
        """, (token, now))
        
        row = cur.fetchone()
        conn.close()
        
        if row:
            return {"id": row[0], "username": row[1]}
        return None
    except Exception as e:
        # Table may not exist yet during init
        logger.debug(f"get_user_from_token error (may be expected on first run): {e}")
        return None

def delete_session_token(token: str):
    """Delete a specific session token."""
    conn = get_conn()
    cur = conn.cursor()
    db_execute(cur, "DELETE FROM user_sessions WHERE token = ?", (token,))
    conn.commit()
    conn.close()


def get_yf_ticker(symbol: str):
    """Get the correct Yahoo Finance ticker for a symbol from KUWAIT_STOCKS mapping.
    Returns the yf_ticker if found, otherwise returns the symbol as-is.
    """
    for stock in KUWAIT_STOCKS:
        if stock["symbol"] == symbol:
            return stock.get("yf_ticker", symbol)
    return symbol


def fetch_price_yfinance(symbol: str, max_retries: int = 3, portfolio: str = None):
    """Fetch price using yfinance with correct Kuwait stock ticker mapping.
    
    Uses exponential backoff to avoid Yahoo Finance rate limits.
    Kuwait stock prices are divided by 1000 (fils to KWD conversion).
    Includes strict validation to reject obviously wrong prices.
    
    Now integrates with Securities Master for proper symbol resolution.
    
    Args:
        symbol: Stock symbol to fetch price for
        max_retries: Number of retry attempts
        portfolio: Optional portfolio name to infer exchange (KFH/BBYN â†’ KSE, USA â†’ NYSE/NASDAQ)
    
    Returns (price: float or None, used_ticker: str or None)
    """
    # Lazy-load yfinance
    if not _ensure_yfinance():
        return None, None
    
    import time
    import random
    
    # âœ… NEW: Try to resolve symbol through Securities Master first
    security = resolve_symbol_to_security(symbol, portfolio=portfolio)
    
    if security:
        # Get properly suffixed ticker for yfinance from Securities Master
        api_symbol, exchange, currency = get_price_fetch_symbol(security["security_id"])
        if api_symbol:
            yf_ticker = api_symbol
            is_kuwait_stock = exchange == "KSE"
        else:
            # Fallback if get_price_fetch_symbol fails
            yf_ticker = get_yf_ticker(symbol)
            is_kuwait_stock = yf_ticker.endswith('.KW')
    else:
        # Fallback to legacy mapping (for migration period or unregistered symbols)
        yf_ticker = get_yf_ticker(symbol)
        is_kuwait_stock = yf_ticker.endswith('.KW')
    
    # Only try the mapped ticker + one fallback
    variants = [yf_ticker]
    if yf_ticker == symbol:  # No mapping found
        variants.append(f"{symbol}.KW")
    
    for variant in variants:
        for attempt in range(1, max_retries + 1):
            try:
                # Use .download() - more reliable than .history()
                hist = yf.download(
                    variant,
                    period="5d",
                    interval="1d",
                    progress=False,
                    auto_adjust=False,
                )
                
                if hist is not None and not hist.empty and 'Close' in hist.columns:
                    close_series = hist["Close"].dropna()
                    if not close_series.empty:
                        # Handle both single-ticker (Series) and multi-ticker (DataFrame) cases
                        last_close = close_series.iloc[-1]
                        if isinstance(last_close, pd.Series):
                            # Multi-ticker case - get the first (and only) value
                            price = float(last_close.iloc[0])
                        else:
                            # Single value case
                            price = float(last_close)
                        
                        # âœ… VALIDATE PRICE LOGICALLY
                        if price <= 0:
                            continue  # Skip non-positive prices
                        
                        if is_kuwait_stock and price > 50:
                            # Kuwait stock prices are in Fils â†’ likely need /1000
                            price = normalize_kwd_price(price, 'KWD')
                        elif is_kuwait_stock and price < 0.01:
                            # Reject implausibly low prices (e.g., 0.0001)
                            continue
                        
                        return float(price), variant
                        
            except Exception as e:
                pass  # Silent fail â†’ try next variant
            
            # Exponential backoff for rate limits
            if attempt < max_retries:
                wait = (2 ** attempt) + random.uniform(0.3, 1.0)
                time.sleep(wait)
    
    return None, None  # All variants failed


@st.cache_data(ttl=3600)  # Cache for 1 hour
def cached_fetch_price(symbol: str):
    """Cached wrapper for fetch_price_yfinance to avoid repeated API calls."""
    return fetch_price_yfinance(symbol)


@st.cache_data(ttl=3600)  # Cache for 1 hour
def fetch_usd_kwd_rate(max_retries: int = 3):
    """Fetch USD to KWD exchange rate using yfinance.
    Returns rate as float. Falls back to hardcoded rate if API fails.
    """
    # Lazy-load yfinance
    if not _ensure_yfinance():
        return 0.307  # Fallback rate
    
    import time
    import random
    
    for attempt in range(1, max_retries + 1):
        try:
            # Use cached Ticker object
            ticker = _get_yf_ticker("KWD=X")
            if ticker is None:
                return 0.307  # Fallback
            # Use history only - no .info
            hist = ticker.history(period="5d", interval="1d", auto_adjust=False)
            
            if hist is not None and not hist.empty and 'Close' in hist.columns:
                rate = float(hist["Close"].dropna().iloc[-1])
                if rate > 0:
                    return rate
                    
        except Exception:
            if attempt < max_retries:
                wait = (2 ** attempt) + random.uniform(0.3, 1.0)
                time.sleep(wait)
            continue
    
    # Return fallback rate if all attempts fail
    return 0.307  # Approximate USD/KWD rate


def fetch_price_tradingview_by_tv_symbol(tv_exchange: str, tv_symbol: str, session=None):
    """Fetch price from TradingView using best-effort methods.
    Returns (price, debug_msg).
    """
    if not tv_symbol:
        return None, "No TradingView symbol provided"
    
    if session is None:
        session = session_tv() if requests else None
    
    tv_key = normalize_tv_key(tv_exchange, tv_symbol)
    debug_parts = []
    
    # 1) Try TradingView widget quotes endpoint (unofficial best-effort)
    try:
        q = urllib.parse.quote_plus(tv_key)
        url = f"https://tvc4.forexpros.com/quotes/?symbols={q}"
        if requests and session:
            r = session.get(url, timeout=15)
            if r.status_code == 200:
                try:
                    payload = r.json()
                    if isinstance(payload, list) and payload:
                        item = payload[0]
                        price = None
                        if "d" in item and isinstance(item["d"], list) and item["d"]:
                            d0 = item["d"][0]
                            price = d0.get("v") or d0.get("price") or d0.get("last")
                        elif "price" in item:
                            price = item.get("price")
                        if price is not None:
                            return float(price), None
                except Exception as e:
                    debug_parts.append(f"quotes JSON error: {e}")
    except Exception as e:
        debug_parts.append(f"quotes endpoint error: {e}")
    
    # 2) Try symbol-search result (some include price)
    try:
        results = tradingview_search(tv_symbol, exchange=tv_exchange, limit=5, session=session)
        if results and isinstance(results, tuple):
            results = results[0]
        if results:
            for ritem in results:
                ex = (ritem.get("exchange") or "").strip().upper()
                sym = (ritem.get("symbol") or "").strip().upper()
                if ex == tv_exchange.strip().upper() and sym == tv_symbol.strip().upper():
                    price = ritem.get("price") or ritem.get("p")
                    if price is not None:
                        return float(price), None
            # Try first result if no exact match
            price = results[0].get("price") or results[0].get("p")
            if price is not None:
                return float(price), None
    except Exception as e:
        debug_parts.append(f"symbol-search price error: {e}")
    
    # 3) Page scrape (fragile last resort)
    try:
        url_page = f"https://www.tradingview.com/symbols/{tv_exchange}-{tv_symbol}/"
        if requests and session:
            rpage = session.get(url_page, timeout=20)
            if rpage.status_code == 200:
                import re
                txt = rpage.text
                m = re.search(r'"last_price"\s*:\s*([0-9]+\.[0-9]+)', txt)
                if m:
                    return float(m.group(1)), None
    except Exception as e:
        debug_parts.append(f"page scrape error: {e}")
    
    return None, " | ".join(debug_parts) if debug_parts else "No price found"


def _ensure_securities_tables() -> None:
    """Ensure securities_master and security_aliases tables exist.
    
    This is called on every DB init to ensure these tables exist even for 
    databases created before the securities master feature was added.
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        if is_postgres():
            # PostgreSQL syntax
            cur.execute("""
                CREATE TABLE IF NOT EXISTS securities_master (
                    security_id TEXT PRIMARY KEY,
                    user_id INTEGER NOT NULL DEFAULT 1,
                    exchange TEXT NOT NULL,
                    canonical_ticker TEXT NOT NULL,
                    display_name TEXT,
                    isin TEXT,
                    currency TEXT NOT NULL DEFAULT 'KWD',
                    country TEXT NOT NULL DEFAULT 'KW',
                    status TEXT DEFAULT 'active' CHECK(status IN ('active', 'delisted', 'suspended')),
                    sector TEXT,
                    created_at INTEGER,
                    updated_at INTEGER,
                    UNIQUE(canonical_ticker, exchange, user_id)
                )
            """)
            
            cur.execute("""
                CREATE TABLE IF NOT EXISTS security_aliases (
                    id SERIAL PRIMARY KEY,
                    user_id INTEGER NOT NULL DEFAULT 1,
                    security_id TEXT NOT NULL,
                    alias_name TEXT NOT NULL,
                    alias_type TEXT DEFAULT 'user_input' CHECK(alias_type IN ('user_input', 'broker_format', 'official', 'legacy')),
                    valid_from TEXT,
                    valid_until TEXT,
                    created_at INTEGER,
                    FOREIGN KEY (security_id) REFERENCES securities_master(security_id),
                    UNIQUE(alias_name, security_id, user_id)
                )
            """)
            
            # Commit table creation first so column additions work on a clean state
            conn.commit()
            
            # Add columns BEFORE creating indexes (indexes on missing columns abort PostgreSQL transactions)
            add_column_if_missing("securities_master", "user_id", "INTEGER DEFAULT 1")
            add_column_if_missing("security_aliases", "user_id", "INTEGER DEFAULT 1")
            add_column_if_missing("transactions", "security_id", "TEXT")
            add_column_if_missing("transactions", "source", "TEXT DEFAULT 'MANUAL'")
            add_column_if_missing("transactions", "source_reference", "TEXT")
            add_column_if_missing("transactions", "is_deleted", "INTEGER DEFAULT 0")
            add_column_if_missing("transactions", "deleted_at", "INTEGER")
            add_column_if_missing("transactions", "deleted_by", "INTEGER")
            add_column_if_missing("transactions", "avg_cost_at_txn", "REAL")
            add_column_if_missing("transactions", "realized_pnl_at_txn", "REAL")
            add_column_if_missing("transactions", "cost_basis_at_txn", "REAL")
            add_column_if_missing("transactions", "shares_held_at_txn", "REAL")
            add_column_if_missing("transactions", "stock_master_id", "INTEGER")
            add_column_if_missing("transactions", "portfolio_id", "INTEGER")
            add_column_if_missing("transactions", "account_id", "INTEGER")
            add_column_if_missing("cash_deposits", "bank_name", "TEXT DEFAULT 'Cash Deposit'")
            add_column_if_missing("cash_deposits", "description", "TEXT")
            add_column_if_missing("cash_deposits", "comments", "TEXT")
            add_column_if_missing("cash_deposits", "source", "TEXT DEFAULT 'MANUAL'")
            add_column_if_missing("cash_deposits", "source_reference", "TEXT")
            add_column_if_missing("cash_deposits", "is_deleted", "INTEGER DEFAULT 0")
            add_column_if_missing("cash_deposits", "deleted_at", "INTEGER")
            add_column_if_missing("cash_deposits", "deleted_by", "INTEGER")
            add_column_if_missing("cash_deposits", "fx_rate_at_deposit", "REAL")
            add_column_if_missing("portfolio_snapshots", "twr_percent", "REAL")
            add_column_if_missing("portfolio_snapshots", "mwrr_percent", "REAL")
            add_column_if_missing("stocks", "last_updated", "INTEGER")
            add_column_if_missing("stocks", "price_source", "TEXT")
            
            # Now create indexes (columns guaranteed to exist)
            cur = conn.cursor()  # Fresh cursor after add_column commits
            cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_exchange ON securities_master(exchange)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_ticker ON securities_master(canonical_ticker)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_country ON securities_master(country)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_aliases_name ON security_aliases(LOWER(alias_name))")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_aliases_security ON security_aliases(security_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_security_id ON transactions(security_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_source ON transactions(source)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_deleted ON transactions(is_deleted)")
        else:
            # SQLite syntax
            cur.execute("""
                CREATE TABLE IF NOT EXISTS securities_master (
                    security_id TEXT PRIMARY KEY,
                    user_id INTEGER NOT NULL DEFAULT 1,
                    exchange TEXT NOT NULL,
                    canonical_ticker TEXT NOT NULL,
                    display_name TEXT,
                    isin TEXT,
                    currency TEXT NOT NULL DEFAULT 'KWD',
                    country TEXT NOT NULL DEFAULT 'KW',
                    status TEXT DEFAULT 'active' CHECK(status IN ('active', 'delisted', 'suspended')),
                    sector TEXT,
                    created_at INTEGER,
                    updated_at INTEGER,
                    UNIQUE(canonical_ticker, exchange, user_id)
                )
            """)
            
            cur.execute("""
                CREATE TABLE IF NOT EXISTS security_aliases (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL DEFAULT 1,
                    security_id TEXT NOT NULL,
                    alias_name TEXT NOT NULL,
                    alias_type TEXT DEFAULT 'user_input' CHECK(alias_type IN ('user_input', 'broker_format', 'official', 'legacy')),
                    valid_from TEXT,
                    valid_until TEXT,
                    created_at INTEGER,
                    FOREIGN KEY (security_id) REFERENCES securities_master(security_id),
                    UNIQUE(alias_name, security_id, user_id)
                )
            """)
            
            # SQLite indexes
            cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_exchange ON securities_master(exchange)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_ticker ON securities_master(canonical_ticker)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_country ON securities_master(country)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_aliases_name ON security_aliases(alias_name COLLATE NOCASE)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_aliases_security ON security_aliases(security_id)")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_security_id ON transactions(security_id)")
        
        # Add user_id column if missing (migration for existing tables)
        add_column_if_missing("securities_master", "user_id", "INTEGER DEFAULT 1")
        add_column_if_missing("security_aliases", "user_id", "INTEGER DEFAULT 1")
        
        # Add security_id column to transactions table for proper linking
        add_column_if_missing("transactions", "security_id", "TEXT")
        
        # =====================================================================
        # STEP 2: Upload Logic Enhancement - Add source tracking & soft delete
        # =====================================================================
        # Source tracking columns for transactions
        add_column_if_missing("transactions", "source", "TEXT DEFAULT 'MANUAL'")
        add_column_if_missing("transactions", "source_reference", "TEXT")
        
        # Soft delete columns for transactions (preserve data during re-upload)
        add_column_if_missing("transactions", "is_deleted", "INTEGER DEFAULT 0")
        add_column_if_missing("transactions", "deleted_at", "INTEGER")
        add_column_if_missing("transactions", "deleted_by", "INTEGER")
        
        # Same for cash_deposits table
        add_column_if_missing("cash_deposits", "source", "TEXT DEFAULT 'MANUAL'")
        add_column_if_missing("cash_deposits", "source_reference", "TEXT")
        add_column_if_missing("cash_deposits", "is_deleted", "INTEGER DEFAULT 0")
        add_column_if_missing("cash_deposits", "deleted_at", "INTEGER")
        add_column_if_missing("cash_deposits", "deleted_by", "INTEGER")
        
        # =====================================================================
        # STEP 3: Avg Cost Tracking - Store avg_cost at transaction time
        # =====================================================================
        # These columns store the weighted average cost at time of transaction
        # This ensures P&L can be calculated accurately even for closed positions
        add_column_if_missing("transactions", "avg_cost_at_txn", "REAL")  # WAC at time of this txn
        add_column_if_missing("transactions", "realized_pnl_at_txn", "REAL")  # Realized P&L for sells
        add_column_if_missing("transactions", "cost_basis_at_txn", "REAL")  # Total cost basis at txn time
        add_column_if_missing("transactions", "shares_held_at_txn", "REAL")  # Shares held after this txn
        
        # Create indexes for source tracking
        cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_source ON transactions(source)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_source_ref ON transactions(source_reference)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_deleted ON transactions(is_deleted)")
        
        conn.commit()
        conn.close()
        logger.debug("âœ… Securities tables verified/created")
    except Exception as e:
        logger.warning(f"Note ensuring securities tables: {e}")


def _ensure_normalized_schema() -> None:
    """
    Phase 1: Core Normalized Tables for proper data integrity.
    
    This implements a properly normalized database schema with:
    - stocks_master: Canonical stock reference (single source of truth)
    - portfolios: User portfolio grouping
    - external_accounts: Bank/brokerage accounts (KFH, BBYN, USD)
    - position_snapshots: Immutable position state after each transaction
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # 1. STOCKS_MASTER - Global stock reference (not user-specific)
        if is_postgres():
            cur.execute("""
                CREATE TABLE IF NOT EXISTS stocks_master (
                    id SERIAL PRIMARY KEY,
                    ticker VARCHAR(20) NOT NULL,
                    name VARCHAR(200),
                    exchange VARCHAR(50) DEFAULT 'KSE',
                    currency VARCHAR(3) DEFAULT 'KWD',
                    isin VARCHAR(12),
                    sector VARCHAR(50),
                    country VARCHAR(3) DEFAULT 'KW',
                    status VARCHAR(20) DEFAULT 'active',
                    created_at INTEGER,
                    updated_at INTEGER,
                    UNIQUE(ticker, exchange)
                )
            """)
        else:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS stocks_master (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ticker TEXT NOT NULL,
                    name TEXT,
                    exchange TEXT DEFAULT 'KSE',
                    currency TEXT DEFAULT 'KWD',
                    isin TEXT,
                    sector TEXT,
                    country TEXT DEFAULT 'KW',
                    status TEXT DEFAULT 'active',
                    created_at INTEGER,
                    updated_at INTEGER,
                    UNIQUE(ticker, exchange)
                )
            """)
        
        # 2. PORTFOLIOS - User portfolio grouping
        if is_postgres():
            cur.execute("""
                CREATE TABLE IF NOT EXISTS portfolios (
                    id SERIAL PRIMARY KEY,
                    user_id INTEGER NOT NULL,
                    name VARCHAR(100) NOT NULL,
                    base_currency VARCHAR(3) DEFAULT 'KWD',
                    description TEXT,
                    created_at INTEGER,
                    UNIQUE(user_id, name)
                )
            """)
        else:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS portfolios (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    name TEXT NOT NULL,
                    base_currency TEXT DEFAULT 'KWD',
                    description TEXT,
                    created_at INTEGER,
                    UNIQUE(user_id, name)
                )
            """)
        
        # 3. EXTERNAL_ACCOUNTS - Bank/brokerage accounts (KFH, BBYN, USD Cash)
        if is_postgres():
            cur.execute("""
                CREATE TABLE IF NOT EXISTS external_accounts (
                    id SERIAL PRIMARY KEY,
                    user_id INTEGER NOT NULL,
                    portfolio_id INTEGER REFERENCES portfolios(id),
                    name VARCHAR(100) NOT NULL,
                    account_number VARCHAR(50),
                    currency VARCHAR(3) DEFAULT 'KWD',
                    account_type VARCHAR(20) DEFAULT 'BROKERAGE',
                    current_balance DECIMAL(18,6) DEFAULT 0,
                    last_reconciled_date DATE,
                    created_at INTEGER,
                    UNIQUE(user_id, name)
                )
            """)
        else:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS external_accounts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    portfolio_id INTEGER,
                    name TEXT NOT NULL,
                    account_number TEXT,
                    currency TEXT DEFAULT 'KWD',
                    account_type TEXT DEFAULT 'BROKERAGE',
                    current_balance REAL DEFAULT 0,
                    last_reconciled_date TEXT,
                    created_at INTEGER,
                    UNIQUE(user_id, name),
                    FOREIGN KEY (portfolio_id) REFERENCES portfolios(id)
                )
            """)
        
        # 4. POSITION_SNAPSHOTS - Immutable position state after each transaction
        if is_postgres():
            cur.execute("""
                CREATE TABLE IF NOT EXISTS position_snapshots (
                    id SERIAL PRIMARY KEY,
                    user_id INTEGER NOT NULL,
                    stock_id INTEGER REFERENCES stocks_master(id),
                    portfolio_id INTEGER REFERENCES portfolios(id),
                    txn_id INTEGER,
                    snapshot_date DATE NOT NULL,
                    total_shares DECIMAL(15,6) DEFAULT 0,
                    total_cost DECIMAL(18,6) DEFAULT 0,
                    avg_cost DECIMAL(15,6) DEFAULT 0,
                    realized_pnl DECIMAL(18,6) DEFAULT 0,
                    cash_dividends_received DECIMAL(18,6) DEFAULT 0,
                    status VARCHAR(20) DEFAULT 'OPEN',
                    created_at INTEGER,
                    UNIQUE(stock_id, portfolio_id, user_id, snapshot_date)
                )
            """)
        else:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS position_snapshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    stock_id INTEGER,
                    portfolio_id INTEGER,
                    txn_id INTEGER,
                    snapshot_date TEXT NOT NULL,
                    total_shares REAL DEFAULT 0,
                    total_cost REAL DEFAULT 0,
                    avg_cost REAL DEFAULT 0,
                    realized_pnl REAL DEFAULT 0,
                    cash_dividends_received REAL DEFAULT 0,
                    status TEXT DEFAULT 'OPEN',
                    created_at INTEGER,
                    UNIQUE(stock_id, portfolio_id, user_id, snapshot_date),
                    FOREIGN KEY (stock_id) REFERENCES stocks_master(id),
                    FOREIGN KEY (portfolio_id) REFERENCES portfolios(id)
                )
            """)
        
        # 5. SYMBOL_MAPPINGS - Map user input variations to canonical symbols
        if is_postgres():
            cur.execute("""
                CREATE TABLE IF NOT EXISTS symbol_mappings (
                    id SERIAL PRIMARY KEY,
                    user_input TEXT NOT NULL,
                    canonical_ticker TEXT NOT NULL,
                    stock_id INTEGER REFERENCES stocks_master(id),
                    created_at INTEGER,
                    UNIQUE(user_input)
                )
            """)
        else:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS symbol_mappings (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_input TEXT NOT NULL COLLATE NOCASE,
                    canonical_ticker TEXT NOT NULL,
                    stock_id INTEGER,
                    created_at INTEGER,
                    UNIQUE(user_input),
                    FOREIGN KEY (stock_id) REFERENCES stocks_master(id)
                )
            """)
        
        # 6. CASH_FLOWS - Track all cash movements (Phase 2: Cash Flow Reconciliation)
        if is_postgres():
            cur.execute("""
                CREATE TABLE IF NOT EXISTS cash_flows (
                    id SERIAL PRIMARY KEY,
                    user_id INTEGER NOT NULL,
                    account_id INTEGER REFERENCES external_accounts(id),
                    flow_type VARCHAR(30) NOT NULL,
                    amount DECIMAL(18,6) NOT NULL,
                    currency VARCHAR(3) DEFAULT 'KWD',
                    related_txn_id INTEGER,
                    flow_date DATE NOT NULL,
                    description VARCHAR(200),
                    reconciled BOOLEAN DEFAULT FALSE,
                    created_at INTEGER
                )
            """)
        else:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS cash_flows (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    account_id INTEGER,
                    flow_type TEXT NOT NULL,
                    amount REAL NOT NULL,
                    currency TEXT DEFAULT 'KWD',
                    related_txn_id INTEGER,
                    flow_date TEXT NOT NULL,
                    description TEXT,
                    reconciled INTEGER DEFAULT 0,
                    created_at INTEGER,
                    FOREIGN KEY (account_id) REFERENCES external_accounts(id),
                    FOREIGN KEY (related_txn_id) REFERENCES transactions(id)
                )
            """)
        
        # 7. PORTFOLIO_TRANSACTIONS - Unified transaction table with source tracking
        # âœ… RECOMMENDED: Single table consolidating all transaction types
        if is_postgres():
            cur.execute("""
                CREATE TABLE IF NOT EXISTS portfolio_transactions (
                    id SERIAL PRIMARY KEY,
                    user_id INTEGER NOT NULL,
                    portfolio_id INTEGER NOT NULL REFERENCES portfolios(id),
                    txn_type VARCHAR(20) NOT NULL,
                    source VARCHAR(20) NOT NULL DEFAULT 'MANUAL',
                    source_reference VARCHAR(100),
                    stock_id INTEGER REFERENCES stocks_master(id),
                    account_id INTEGER REFERENCES external_accounts(id),
                    shares DECIMAL(15,6),
                    price DECIMAL(15,6),
                    amount DECIMAL(18,6) NOT NULL,
                    fees DECIMAL(15,6) DEFAULT 0,
                    txn_date DATE NOT NULL,
                    notes TEXT,
                    legacy_txn_id INTEGER,
                    created_at INTEGER,
                    created_by INTEGER,
                    is_deleted INTEGER DEFAULT 0
                )
            """)
        else:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS portfolio_transactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    portfolio_id INTEGER NOT NULL,
                    txn_type TEXT NOT NULL,
                    source TEXT NOT NULL DEFAULT 'MANUAL',
                    source_reference TEXT,
                    stock_id INTEGER,
                    account_id INTEGER,
                    shares REAL,
                    price REAL,
                    amount REAL NOT NULL,
                    fees REAL DEFAULT 0,
                    txn_date TEXT NOT NULL,
                    notes TEXT,
                    legacy_txn_id INTEGER,
                    created_at INTEGER,
                    created_by INTEGER,
                    is_deleted INTEGER DEFAULT 0,
                    FOREIGN KEY (portfolio_id) REFERENCES portfolios(id),
                    FOREIGN KEY (stock_id) REFERENCES stocks_master(id),
                    FOREIGN KEY (account_id) REFERENCES external_accounts(id)
                )
            """)
        
        # Add foreign key columns to transactions table (if not exists)
        add_column_if_missing("transactions", "stock_master_id", "INTEGER")
        add_column_if_missing("transactions", "portfolio_id", "INTEGER")
        add_column_if_missing("transactions", "account_id", "INTEGER")
        
        # Create indexes for performance
        cur.execute("CREATE INDEX IF NOT EXISTS idx_stocks_master_ticker ON stocks_master(ticker)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_portfolios_user ON portfolios(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_ext_accounts_user ON external_accounts(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_pos_snapshots_stock ON position_snapshots(stock_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_pos_snapshots_date ON position_snapshots(snapshot_date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_symbol_mappings_input ON symbol_mappings(user_input)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_cash_flows_account ON cash_flows(account_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_cash_flows_date ON cash_flows(flow_date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_cash_flows_type ON cash_flows(flow_type)")
        # Indexes for portfolio_transactions (unified table)
        cur.execute("CREATE INDEX IF NOT EXISTS idx_ptxn_portfolio_source ON portfolio_transactions(portfolio_id, source)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_ptxn_portfolio_type ON portfolio_transactions(portfolio_id, txn_type)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_ptxn_user ON portfolio_transactions(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_ptxn_date ON portfolio_transactions(txn_date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_ptxn_stock ON portfolio_transactions(stock_id)")
        
        # 8. DATABASE VIEWS - Aggregation views for reporting
        
        # View: Portfolio Deposit Summary
        # Always shows total deposits regardless of upload status
        cur.execute("DROP VIEW IF EXISTS portfolio_deposit_summary")
        cur.execute("""
            CREATE VIEW portfolio_deposit_summary AS
            SELECT 
                pt.user_id,
                pt.portfolio_id,
                p.name as portfolio_name,
                SUM(CASE WHEN pt.txn_type = 'DEPOSIT' THEN pt.amount ELSE 0 END) as total_deposits,
                SUM(CASE WHEN pt.txn_type = 'WITHDRAWAL' THEN pt.amount ELSE 0 END) as total_withdrawals,
                SUM(CASE WHEN pt.txn_type = 'DEPOSIT' THEN pt.amount ELSE 0 END) -
                SUM(CASE WHEN pt.txn_type = 'WITHDRAWAL' THEN pt.amount ELSE 0 END) as net_deposits,
                COUNT(CASE WHEN pt.txn_type = 'DEPOSIT' THEN 1 END) as deposit_count,
                COUNT(CASE WHEN pt.txn_type = 'WITHDRAWAL' THEN 1 END) as withdrawal_count,
                MIN(CASE WHEN pt.txn_type = 'DEPOSIT' THEN pt.txn_date END) as first_deposit_date,
                MAX(CASE WHEN pt.txn_type = 'DEPOSIT' THEN pt.txn_date END) as last_deposit_date
            FROM portfolio_transactions pt
            LEFT JOIN portfolios p ON pt.portfolio_id = p.id
            WHERE (pt.is_deleted = 0 OR pt.is_deleted IS NULL)
            GROUP BY pt.user_id, pt.portfolio_id, p.name
        """)
        
        # View: Portfolio Cash Summary (all cash movements)
        cur.execute("DROP VIEW IF EXISTS portfolio_cash_summary")
        cur.execute("""
            CREATE VIEW portfolio_cash_summary AS
            SELECT 
                pt.user_id,
                pt.portfolio_id,
                p.name as portfolio_name,
                SUM(CASE WHEN pt.txn_type = 'BUY' THEN pt.amount ELSE 0 END) as total_buys,
                SUM(CASE WHEN pt.txn_type = 'SELL' THEN pt.amount ELSE 0 END) as total_sells,
                SUM(CASE WHEN pt.txn_type = 'DIVIDEND' THEN pt.amount ELSE 0 END) as total_dividends,
                SUM(CASE WHEN pt.txn_type = 'DEPOSIT' THEN pt.amount ELSE 0 END) as total_deposits,
                SUM(CASE WHEN pt.txn_type = 'WITHDRAWAL' THEN pt.amount ELSE 0 END) as total_withdrawals,
                SUM(pt.amount) as cash_balance,
                SUM(COALESCE(pt.fees, 0)) as total_fees,
                COUNT(*) as transaction_count
            FROM portfolio_transactions pt
            LEFT JOIN portfolios p ON pt.portfolio_id = p.id
            WHERE (pt.is_deleted = 0 OR pt.is_deleted IS NULL)
            GROUP BY pt.user_id, pt.portfolio_id, p.name
        """)
        
        # View: Stock Position Summary
        cur.execute("DROP VIEW IF EXISTS stock_position_summary")
        cur.execute("""
            CREATE VIEW stock_position_summary AS
            SELECT 
                pt.user_id,
                pt.portfolio_id,
                p.name as portfolio_name,
                pt.stock_id,
                sm.ticker as stock_symbol,
                sm.name as stock_name,
                SUM(CASE WHEN pt.txn_type = 'BUY' THEN pt.shares ELSE 0 END) as shares_bought,
                SUM(CASE WHEN pt.txn_type = 'SELL' THEN pt.shares ELSE 0 END) as shares_sold,
                SUM(CASE WHEN pt.txn_type = 'BUY' THEN pt.shares ELSE 0 END) -
                SUM(CASE WHEN pt.txn_type = 'SELL' THEN pt.shares ELSE 0 END) as current_shares,
                SUM(CASE WHEN pt.txn_type = 'BUY' THEN -pt.amount ELSE 0 END) as total_cost,
                SUM(CASE WHEN pt.txn_type = 'SELL' THEN pt.amount ELSE 0 END) as total_proceeds,
                SUM(CASE WHEN pt.txn_type = 'DIVIDEND' THEN pt.amount ELSE 0 END) as total_dividends,
                COUNT(CASE WHEN pt.txn_type = 'BUY' THEN 1 END) as buy_count,
                COUNT(CASE WHEN pt.txn_type = 'SELL' THEN 1 END) as sell_count,
                MIN(pt.txn_date) as first_trade_date,
                MAX(pt.txn_date) as last_trade_date
            FROM portfolio_transactions pt
            LEFT JOIN portfolios p ON pt.portfolio_id = p.id
            LEFT JOIN stocks_master sm ON pt.stock_id = sm.id
            WHERE pt.stock_id IS NOT NULL 
            AND (pt.is_deleted = 0 OR pt.is_deleted IS NULL)
            GROUP BY pt.user_id, pt.portfolio_id, p.name, pt.stock_id, sm.ticker, sm.name
        """)
        
        conn.commit()
        conn.close()
        logger.debug("âœ… Normalized schema tables created/verified")
    except Exception as e:
        logger.warning(f"Note ensuring normalized schema: {e}")


def _migrate_to_normalized_schema(user_id: int) -> dict:
    """
    Migrate existing data to the normalized schema.
    
    This function:
    1. Creates portfolio records for KFH, BBYN, USA
    2. Creates external account records
    3. Populates stocks_master from unique symbols
    4. Creates symbol mappings for variations
    5. Links transactions to normalized tables
    
    Returns migration stats dict.
    """
    stats = {
        'portfolios_created': 0,
        'accounts_created': 0,
        'stocks_created': 0,
        'mappings_created': 0,
        'transactions_linked': 0,
        'errors': []
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        
        # 1. Create portfolio records
        portfolios_config = [
            ('KFH', 'KWD', 'Kuwait Finance House Portfolio'),
            ('BBYN', 'KWD', 'Boubyan Bank Portfolio'),
            ('USA', 'USD', 'US Stock Portfolio')
        ]
        
        portfolio_ids = {}
        for name, currency, desc in portfolios_config:
            try:
                db_execute(cur, """
                    INSERT INTO portfolios (user_id, name, base_currency, description, created_at)
                    VALUES (?, ?, ?, ?, ?)
                    ON CONFLICT(user_id, name) DO UPDATE SET description=excluded.description
                """, (user_id, name, currency, desc, ts))
                
                db_execute(cur, "SELECT id FROM portfolios WHERE user_id = ? AND name = ?", (user_id, name))
                row = cur.fetchone()
                if row:
                    portfolio_ids[name] = row[0]
                    stats['portfolios_created'] += 1
            except Exception as e:
                stats['errors'].append(f"Portfolio {name}: {e}")
        
        # 2. Create external accounts (linked to portfolios)
        accounts_config = [
            ('KFH Brokerage', 'KWD', 'BROKERAGE', 'KFH'),
            ('BBYN Brokerage', 'KWD', 'BROKERAGE', 'BBYN'),
            ('US Brokerage', 'USD', 'BROKERAGE', 'USA')
        ]
        
        account_ids = {}
        for name, currency, acct_type, portfolio_name in accounts_config:
            try:
                port_id = portfolio_ids.get(portfolio_name)
                db_execute(cur, """
                    INSERT INTO external_accounts (user_id, portfolio_id, name, currency, account_type, created_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                    ON CONFLICT(user_id, name) DO UPDATE SET portfolio_id=excluded.portfolio_id
                """, (user_id, port_id, name, currency, acct_type, ts))
                
                db_execute(cur, "SELECT id FROM external_accounts WHERE user_id = ? AND name = ?", (user_id, name))
                row = cur.fetchone()
                if row:
                    account_ids[portfolio_name] = row[0]
                    stats['accounts_created'] += 1
            except Exception as e:
                stats['errors'].append(f"Account {name}: {e}")
        
        # 3. Get all unique symbols from transactions and create stocks_master entries
        db_execute(cur, """
            SELECT DISTINCT stock_symbol, portfolio 
            FROM transactions 
            WHERE user_id = ? AND stock_symbol IS NOT NULL
        """, (user_id,))
        symbols = cur.fetchall()
        
        # Symbol normalization mapping (user input -> canonical)
        symbol_normalizations = {
            'mabanee': 'MABANEE',
            'Mabanee': 'MABANEE',
            'ooredoo': 'OOREDOO',
            'OOREDOO': 'OOREDOO',
            'agility kuwait': 'AGILITY',
            'agilityPLC': 'AGILITY',
            'AGLTY': 'AGILITY',
            'Sanam': 'SANAM',
            'sanam': 'SANAM',
        }
        
        stock_ids = {}
        for symbol, portfolio in symbols:
            try:
                # Normalize the symbol
                canonical = symbol_normalizations.get(symbol, symbol.upper().strip())
                exchange = 'NASDAQ' if portfolio == 'USA' else 'KSE'
                currency = 'USD' if portfolio == 'USA' else 'KWD'
                
                # Insert or get stocks_master record
                db_execute(cur, """
                    INSERT INTO stocks_master (ticker, name, exchange, currency, country, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                    ON CONFLICT(ticker, exchange) DO UPDATE SET updated_at=excluded.updated_at
                """, (canonical, canonical, exchange, currency, 'US' if portfolio == 'USA' else 'KW', ts, ts))
                
                db_execute(cur, "SELECT id FROM stocks_master WHERE ticker = ? AND exchange = ?", (canonical, exchange))
                row = cur.fetchone()
                if row:
                    stock_ids[symbol] = row[0]
                    stats['stocks_created'] += 1
                
                # Create symbol mapping
                if symbol != canonical:
                    db_execute(cur, """
                        INSERT INTO symbol_mappings (user_input, canonical_ticker, stock_id, created_at)
                        VALUES (?, ?, ?, ?)
                        ON CONFLICT(user_input) DO UPDATE SET canonical_ticker=excluded.canonical_ticker
                    """, (symbol, canonical, stock_ids.get(symbol), ts))
                    stats['mappings_created'] += 1
                    
            except Exception as e:
                stats['errors'].append(f"Stock {symbol}: {e}")
        
        # 4. Link transactions to normalized tables
        for symbol, stock_id in stock_ids.items():
            try:
                db_execute(cur, """
                    UPDATE transactions 
                    SET stock_master_id = ?
                    WHERE user_id = ? AND stock_symbol = ? AND stock_master_id IS NULL
                """, (stock_id, user_id, symbol))
                stats['transactions_linked'] += cur.rowcount
            except Exception as e:
                stats['errors'].append(f"Linking {symbol}: {e}")
        
        # Link portfolio_id based on portfolio column
        for portfolio_name, port_id in portfolio_ids.items():
            try:
                db_execute(cur, """
                    UPDATE transactions 
                    SET portfolio_id = ?
                    WHERE user_id = ? AND portfolio = ? AND portfolio_id IS NULL
                """, (port_id, user_id, portfolio_name))
            except Exception as e:
                stats['errors'].append(f"Linking portfolio {portfolio_name}: {e}")
        
        conn.commit()
        conn.close()
        logger.info(f"âœ… Migration completed: {stats}")
        
    except Exception as e:
        stats['errors'].append(f"Migration error: {e}")
        logger.error(f"Migration error: {e}")
    
    return stats


def migrate_to_unified_transactions(user_id: int) -> dict:
    """
    Migrate legacy transactions and cash_deposits to the unified portfolio_transactions table.
    
    This creates a single source of truth for all portfolio transactions:
    - BUY/SELL from transactions table
    - DIVIDEND from transactions (cash_dividend > 0)
    - DEPOSIT/WITHDRAWAL from cash_deposits table
    
    Source tracking:
    - source='LEGACY' for migrated records
    - legacy_txn_id preserves original ID for audit trail
    
    Args:
        user_id: User ID to migrate
        
    Returns:
        Migration stats dict
    """
    stats = {
        'buys_migrated': 0,
        'sells_migrated': 0,
        'dividends_migrated': 0,
        'deposits_migrated': 0,
        'withdrawals_migrated': 0,
        'skipped_duplicates': 0,
        'errors': []
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        soft_del = _soft_delete_filter()
        
        # Get portfolio and account mappings
        db_execute(cur, "SELECT id, name FROM portfolios WHERE user_id = ?", (user_id,))
        portfolio_map = {row[1]: row[0] for row in cur.fetchall()}
        
        db_execute(cur, "SELECT id, name FROM external_accounts WHERE user_id = ?", (user_id,))
        account_map = {row[1]: row[0] for row in cur.fetchall()}
        
        db_execute(cur, "SELECT id, ticker FROM stocks_master")
        stock_map = {row[1]: row[0] for row in cur.fetchall()}
        
        # 1. Migrate stock transactions (Buy/Sell)
        db_execute(cur, f"""
            SELECT id, stock_symbol, portfolio, txn_type, txn_date, shares, 
                   purchase_cost, sell_value, cash_dividend, fees, notes
            FROM transactions
            WHERE user_id = ? AND txn_type IN ('Buy', 'Sell') {soft_del}
            ORDER BY txn_date, id
        """, (user_id,))
        
        for row in cur.fetchall():
            txn_id, symbol, portfolio, txn_type, txn_date, shares, cost, proceeds, dividend, fees, notes = row
            
            portfolio_id = portfolio_map.get(portfolio)
            stock_id = stock_map.get(symbol)
            account_id = account_map.get(portfolio)
            
            if not portfolio_id:
                stats['errors'].append(f"Missing portfolio for txn {txn_id}: {portfolio}")
                continue
            
            # Check for duplicate (already migrated)
            db_execute(cur, """
                SELECT id FROM portfolio_transactions 
                WHERE legacy_txn_id = ? AND user_id = ?
            """, (txn_id, user_id))
            if cur.fetchone():
                stats['skipped_duplicates'] += 1
                continue
            
            # Calculate amount (cash impact)
            shares = float(shares or 0)
            cost = float(cost or 0)
            proceeds = float(proceeds or 0)
            fees = float(fees or 0)
            
            if txn_type == 'Buy':
                amount = -cost  # Cash outflow
                price = cost / shares if shares > 0 else 0
            else:  # Sell
                amount = proceeds  # Cash inflow
                price = proceeds / shares if shares > 0 else 0
            
            db_execute(cur, """
                INSERT INTO portfolio_transactions 
                (user_id, portfolio_id, txn_type, source, source_reference, 
                 stock_id, account_id, shares, price, amount, fees, 
                 txn_date, notes, legacy_txn_id, created_at, created_by)
                VALUES (?, ?, ?, 'LEGACY', 'transactions', ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (user_id, portfolio_id, txn_type.upper(), stock_id, account_id,
                  shares, price, amount, fees, txn_date, notes, txn_id, ts, user_id))
            
            if txn_type == 'Buy':
                stats['buys_migrated'] += 1
            else:
                stats['sells_migrated'] += 1
        
        # 2. Migrate dividends (separate entries from transactions with cash_dividend > 0)
        db_execute(cur, f"""
            SELECT id, stock_symbol, portfolio, txn_date, cash_dividend, notes
            FROM transactions
            WHERE user_id = ? AND COALESCE(cash_dividend, 0) > 0 {soft_del}
            ORDER BY txn_date, id
        """, (user_id,))
        
        for row in cur.fetchall():
            txn_id, symbol, portfolio, txn_date, dividend, notes = row
            
            portfolio_id = portfolio_map.get(portfolio)
            stock_id = stock_map.get(symbol)
            account_id = account_map.get(portfolio)
            
            if not portfolio_id:
                continue
            
            dividend = float(dividend or 0)
            
            # Check for duplicate dividend (check by source_reference containing 'div')
            db_execute(cur, """
                SELECT id FROM portfolio_transactions 
                WHERE legacy_txn_id = ? AND user_id = ? AND txn_type = 'DIVIDEND'
            """, (txn_id, user_id))
            if cur.fetchone():
                stats['skipped_duplicates'] += 1
                continue
            
            db_execute(cur, """
                INSERT INTO portfolio_transactions 
                (user_id, portfolio_id, txn_type, source, source_reference,
                 stock_id, account_id, shares, price, amount, fees,
                 txn_date, notes, legacy_txn_id, created_at, created_by)
                VALUES (?, ?, 'DIVIDEND', 'LEGACY', 'transactions_dividend', ?, ?, 0, 0, ?, 0, ?, ?, ?, ?, ?)
            """, (user_id, portfolio_id, stock_id, account_id, dividend, 
                  txn_date, notes, txn_id, ts, user_id))
            
            stats['dividends_migrated'] += 1
        
        # 3. Migrate cash deposits
        db_execute(cur, """
            SELECT id, portfolio, deposit_date, amount, notes
            FROM cash_deposits
            WHERE user_id = ?
            ORDER BY deposit_date, id
        """, (user_id,))
        
        for row in cur.fetchall():
            dep_id, portfolio, dep_date, amount, notes = row
            
            portfolio_id = portfolio_map.get(portfolio)
            account_id = account_map.get(portfolio)
            
            if not portfolio_id:
                stats['errors'].append(f"Missing portfolio for deposit {dep_id}: {portfolio}")
                continue
            
            amount = float(amount or 0)
            
            # Check for duplicate
            db_execute(cur, """
                SELECT id FROM portfolio_transactions 
                WHERE source_reference = ? AND user_id = ? AND txn_type IN ('DEPOSIT', 'WITHDRAWAL')
            """, (f'cash_deposits_{dep_id}', user_id))
            if cur.fetchone():
                stats['skipped_duplicates'] += 1
                continue
            
            txn_type = 'DEPOSIT' if amount >= 0 else 'WITHDRAWAL'
            
            db_execute(cur, """
                INSERT INTO portfolio_transactions 
                (user_id, portfolio_id, txn_type, source, source_reference,
                 stock_id, account_id, shares, price, amount, fees,
                 txn_date, notes, legacy_txn_id, created_at, created_by)
                VALUES (?, ?, ?, 'LEGACY', ?, NULL, ?, NULL, NULL, ?, 0, ?, ?, NULL, ?, ?)
            """, (user_id, portfolio_id, txn_type, f'cash_deposits_{dep_id}', account_id,
                  abs(amount), dep_date, notes, ts, user_id))
            
            if txn_type == 'DEPOSIT':
                stats['deposits_migrated'] += 1
            else:
                stats['withdrawals_migrated'] += 1
        
        conn.commit()
        conn.close()
        
        total = (stats['buys_migrated'] + stats['sells_migrated'] + 
                 stats['dividends_migrated'] + stats['deposits_migrated'] + 
                 stats['withdrawals_migrated'])
        logger.info(f"âœ… Unified transactions migration: {total} records migrated")
        
    except Exception as e:
        stats['errors'].append(str(e))
        logger.error(f"Unified transactions migration error: {e}")
    
    return stats


def add_portfolio_transaction(
    user_id: int,
    portfolio_id: int,
    txn_type: str,
    amount: float,
    txn_date: str,
    source: str = 'MANUAL',
    source_reference: str = None,
    stock_id: int = None,
    account_id: int = None,
    shares: float = None,
    price: float = None,
    fees: float = 0,
    notes: str = None
) -> dict:
    """
    Add a new transaction to the unified portfolio_transactions table.
    
    This is the primary entry point for all new transactions.
    
    Args:
        user_id: User ID
        portfolio_id: Portfolio ID (from portfolios table)
        txn_type: BUY, SELL, DIVIDEND, DEPOSIT, WITHDRAWAL
        amount: Cash impact (negative for BUY, positive for SELL/DEPOSIT)
        txn_date: Transaction date (YYYY-MM-DD)
        source: MANUAL, UPLOAD, API, BANK_FEED
        source_reference: File name, API ID, etc.
        stock_id: Stock ID (for BUY/SELL/DIVIDEND)
        account_id: Account ID (for DEPOSIT/WITHDRAWAL)
        shares: Number of shares (for BUY/SELL)
        price: Price per share (for BUY/SELL)
        fees: Transaction fees
        notes: Optional notes
        
    Returns:
        {'success': bool, 'txn_id': int, 'error': str}
    """
    result = {'success': False, 'txn_id': None}
    
    # Validate txn_type
    valid_types = {'BUY', 'SELL', 'DIVIDEND', 'DEPOSIT', 'WITHDRAWAL'}
    txn_type = txn_type.upper()
    if txn_type not in valid_types:
        result['error'] = f"Invalid txn_type: {txn_type}. Must be one of {valid_types}"
        return result
    
    # Validate source
    valid_sources = {'MANUAL', 'UPLOAD', 'API', 'BANK_FEED', 'LEGACY'}
    source = source.upper()
    if source not in valid_sources:
        result['error'] = f"Invalid source: {source}. Must be one of {valid_sources}"
        return result
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        ts = int(time.time())
        
        db_execute(cur, """
            INSERT INTO portfolio_transactions 
            (user_id, portfolio_id, txn_type, source, source_reference,
             stock_id, account_id, shares, price, amount, fees,
             txn_date, notes, created_at, created_by, is_deleted)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 0)
        """, (user_id, portfolio_id, txn_type, source, source_reference,
              stock_id, account_id, shares, price, amount, fees,
              txn_date, notes, ts, user_id))
        
        if is_postgres():
            cur.execute("SELECT lastval()")
        else:
            cur.execute("SELECT last_insert_rowid()")
        result['txn_id'] = cur.fetchone()[0]
        
        conn.commit()
        conn.close()
        
        result['success'] = True
        logger.info(f"Added {txn_type} transaction: {result['txn_id']}")
        
    except Exception as e:
        result['error'] = str(e)
        logger.error(f"Error adding transaction: {e}")
    
    return result


def get_portfolio_transactions(
    user_id: int,
    portfolio_id: int = None,
    txn_type: str = None,
    source: str = None,
    start_date: str = None,
    end_date: str = None,
    include_deleted: bool = False
) -> pd.DataFrame:
    """
    Query transactions from the unified portfolio_transactions table.
    
    Args:
        user_id: User ID
        portfolio_id: Optional filter by portfolio
        txn_type: Optional filter by type (BUY, SELL, DIVIDEND, DEPOSIT, WITHDRAWAL)
        source: Optional filter by source (MANUAL, UPLOAD, API, BANK_FEED, LEGACY)
        start_date: Optional start date filter
        end_date: Optional end date filter
        include_deleted: If True, include soft-deleted records
        
    Returns:
        DataFrame with transactions
    """
    try:
        conn = get_conn()
        
        query = """
            SELECT pt.id, pt.user_id, pt.portfolio_id, p.name as portfolio_name,
                   pt.txn_type, pt.source, pt.source_reference,
                   pt.stock_id, sm.ticker as stock_symbol, sm.name as stock_name,
                   pt.account_id, ea.name as account_name,
                   pt.shares, pt.price, pt.amount, pt.fees, pt.txn_date,
                   pt.notes, pt.legacy_txn_id, pt.created_at, pt.is_deleted
            FROM portfolio_transactions pt
            LEFT JOIN portfolios p ON pt.portfolio_id = p.id
            LEFT JOIN stocks_master sm ON pt.stock_id = sm.id
            LEFT JOIN external_accounts ea ON pt.account_id = ea.id
            WHERE pt.user_id = ?
        """
        params = [user_id]
        
        if not include_deleted:
            query += " AND (pt.is_deleted = 0 OR pt.is_deleted IS NULL)"
        
        if portfolio_id:
            query += " AND pt.portfolio_id = ?"
            params.append(portfolio_id)
        
        if txn_type:
            query += " AND pt.txn_type = ?"
            params.append(txn_type.upper())
        
        if source:
            query += " AND pt.source = ?"
            params.append(source.upper())
        
        if start_date:
            query += " AND pt.txn_date >= ?"
            params.append(start_date)
        
        if end_date:
            query += " AND pt.txn_date <= ?"
            params.append(end_date)
        
        query += " ORDER BY pt.txn_date DESC, pt.id DESC"
        
        df = pd.read_sql_query(convert_sql_placeholders(query), conn, params=params)
        conn.close()
        
        return df
        
    except Exception as e:
        logger.error(f"Error querying portfolio transactions: {e}")
        return pd.DataFrame()


def get_portfolio_cash_balance(user_id: int, portfolio_id: int = None) -> dict:
    """
    Calculate cash balance from unified portfolio_transactions.
    
    Cash balance = SUM(amount) where amount is:
    - Negative for BUY
    - Positive for SELL, DIVIDEND, DEPOSIT
    - Negative for WITHDRAWAL
    
    Args:
        user_id: User ID
        portfolio_id: Optional filter by portfolio
        
    Returns:
        {'total': float, 'by_portfolio': {name: balance}}
    """
    result = {'total': 0, 'by_portfolio': {}}
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        query = """
            SELECT p.name, SUM(pt.amount) as balance
            FROM portfolio_transactions pt
            JOIN portfolios p ON pt.portfolio_id = p.id
            WHERE pt.user_id = ? 
            AND (pt.is_deleted = 0 OR pt.is_deleted IS NULL)
        """
        params = [user_id]
        
        if portfolio_id:
            query += " AND pt.portfolio_id = ?"
            params.append(portfolio_id)
        
        query += " GROUP BY p.name"
        
        db_execute(cur, query, tuple(params))
        
        for row in cur.fetchall():
            portfolio_name, balance = row
            balance = float(balance or 0)
            result['by_portfolio'][portfolio_name] = balance
            result['total'] += balance
        
        conn.close()
        
    except Exception as e:
        logger.error(f"Error calculating cash balance: {e}")
        result['error'] = str(e)
    
    return result


def get_deposit_summary(user_id: int, portfolio_id: int = None) -> pd.DataFrame:
    """
    Get deposit summary from the portfolio_deposit_summary view.
    
    This view always shows accurate deposit totals regardless of upload status.
    
    Args:
        user_id: User ID
        portfolio_id: Optional filter by portfolio
        
    Returns:
        DataFrame with deposit summary per portfolio
    """
    try:
        conn = get_conn()
        
        query = """
            SELECT portfolio_id, portfolio_name, 
                   total_deposits, total_withdrawals, net_deposits,
                   deposit_count, withdrawal_count,
                   first_deposit_date, last_deposit_date
            FROM portfolio_deposit_summary
            WHERE user_id = ?
        """
        params = [user_id]
        
        if portfolio_id:
            query += " AND portfolio_id = ?"
            params.append(portfolio_id)
        
        df = pd.read_sql_query(convert_sql_placeholders(query), conn, params=params)
        conn.close()
        return df
        
    except Exception as e:
        logger.error(f"Error getting deposit summary: {e}")
        return pd.DataFrame()


def get_total_deposits_kwd(user_id: int) -> float:
    """
    Get total net deposits across all portfolios, converted to KWD.
    
    This is a convenience function that:
    1. Queries the portfolio_deposit_summary view
    2. Converts each portfolio's deposits to KWD based on portfolio currency
    3. Returns the sum
    
    Always returns accurate totals regardless of upload status.
    
    Args:
        user_id: User ID
        
    Returns:
        Total net deposits in KWD
    """
    try:
        deposit_summary = get_deposit_summary(user_id)
        
        if deposit_summary.empty:
            return 0.0
        
        total_kwd = 0.0
        for _, row in deposit_summary.iterrows():
            port_name = row['portfolio_name']
            net_deposits = float(row['net_deposits'] or 0)
            ccy = PORTFOLIO_CCY.get(port_name, 'KWD')
            total_kwd += convert_to_kwd(net_deposits, ccy)
        
        return total_kwd
        
    except Exception as e:
        logger.error(f"Error calculating total deposits KWD: {e}")
        return 0.0


# ============================================================================
# SOLUTION #3: UPLOAD PROCESS ENHANCEMENT
# ============================================================================

class TransactionUploader:
    """
    Enhanced transaction upload handler with:
    - Soft delete of previous uploads from same file
    - Source tracking for audit trail
    - Automatic cash balance reconciliation
    """
    
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.stats = {
            'uploaded': 0,
            'soft_deleted': 0,
            'errors': [],
            'reconciled': False
        }
    
    def upload(self, transactions: list, portfolio_id: int, source_reference: str, 
               source: str = 'UPLOAD') -> dict:
        """
        Upload transactions with proper source tracking and soft delete handling.
        
        Args:
            transactions: List of transaction dicts with keys:
                - txn_type: BUY, SELL, DIVIDEND, DEPOSIT, WITHDRAWAL
                - stock_symbol: Stock ticker (for trades)
                - shares: Number of shares
                - price: Price per share
                - amount: Cash impact (negative for BUY)
                - fees: Transaction fees
                - txn_date: Transaction date (YYYY-MM-DD)
                - notes: Optional notes
            portfolio_id: Target portfolio ID
            source_reference: File name or upload identifier
            source: Source type (UPLOAD, API, BANK_FEED)
            
        Returns:
            Result dict with stats and status
        """
        result = {
            'success': False,
            'uploaded_count': 0,
            'soft_deleted_count': 0,
            'errors': [],
            'debug_log': [],  # Debug log for troubleshooting
            'message': ''
        }
        
        # DEBUG: Log upload start
        debug_log = result['debug_log']
        debug_log.append(f"[UPLOAD START] user_id={self.user_id}, portfolio_id={portfolio_id}")
        debug_log.append(f"[UPLOAD] source={source}, source_reference={source_reference}")
        debug_log.append(f"[UPLOAD] transactions_count={len(transactions)}")
        logger.info(f"TransactionUploader.upload() started: user={self.user_id}, portfolio={portfolio_id}, source={source}, ref={source_reference}, txn_count={len(transactions)}")
        
        try:
            conn = get_conn()
            cur = conn.cursor()
            ts = int(time.time())
            
            # Get stock and account mappings
            db_execute(cur, "SELECT id, ticker FROM stocks_master")
            stock_map = {row[1]: row[0] for row in cur.fetchall()}
            
            db_execute(cur, "SELECT id, name FROM external_accounts WHERE user_id = ?", (self.user_id,))
            account_map = {row[1]: row[0] for row in cur.fetchall()}
            
            # Get account_id for this portfolio
            db_execute(cur, """
                SELECT ea.id FROM external_accounts ea
                JOIN portfolios p ON ea.portfolio_id = p.id
                WHERE p.id = ? AND ea.user_id = ?
            """, (portfolio_id, self.user_id))
            acc_row = cur.fetchone()
            default_account_id = acc_row[0] if acc_row else None
            
            # STEP 1: Soft delete previous uploads from same source_reference
            debug_log.append(f"[STEP 1] Soft-deleting previous uploads with source_reference='{source_reference}'")
            db_execute(cur, """
                UPDATE portfolio_transactions 
                SET is_deleted = 1
                WHERE portfolio_id = ? 
                AND user_id = ?
                AND source = ?
                AND source_reference = ?
                AND (is_deleted = 0 OR is_deleted IS NULL)
            """, (portfolio_id, self.user_id, source, source_reference))
            
            result['soft_deleted_count'] = cur.rowcount
            debug_log.append(f"[STEP 1] Soft-deleted {result['soft_deleted_count']} previous entries")
            logger.info(f"Soft-deleted {result['soft_deleted_count']} previous entries for source_reference={source_reference}")
            
            # STEP 2: Insert new transactions with source tracking
            debug_log.append(f"[STEP 2] Processing {len(transactions)} transactions...")
            for txn_idx, txn in enumerate(transactions):
                try:
                    txn_type = txn.get('txn_type', 'BUY').upper()
                    stock_symbol = txn.get('stock_symbol')
                    stock_id = stock_map.get(stock_symbol) if stock_symbol else None
                    account_id = txn.get('account_id', default_account_id)
                    
                    shares = float(txn.get('shares', 0) or 0)
                    price = float(txn.get('price', 0) or 0)
                    amount = float(txn.get('amount', 0) or 0)
                    fees = float(txn.get('fees', 0) or 0)
                    txn_date = txn.get('txn_date')
                    notes = txn.get('notes')
                    
                    # DEBUG: Log raw transaction data
                    if txn_idx < 5:  # Log first 5 transactions in detail
                        debug_log.append(f"  [TXN {txn_idx+1}] raw: type={txn_type}, symbol={stock_symbol}, shares={shares}, price={price}, date={txn_date}")
                    
                    # Auto-calculate amount if not provided
                    if amount == 0 and shares > 0 and price > 0:
                        if txn_type == 'BUY':
                            amount = -(shares * price + fees)
                        elif txn_type == 'SELL':
                            amount = shares * price - fees
                        if txn_idx < 5:
                            debug_log.append(f"  [TXN {txn_idx+1}] auto-calculated amount={amount:.2f}")
                    
                    db_execute(cur, """
                        INSERT INTO portfolio_transactions 
                        (user_id, portfolio_id, txn_type, source, source_reference,
                         stock_id, account_id, shares, price, amount, fees,
                         txn_date, notes, created_at, created_by, is_deleted)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 0)
                    """, (self.user_id, portfolio_id, txn_type, source, source_reference,
                          stock_id, account_id, shares, price, amount, fees,
                          txn_date, notes, ts, self.user_id))
                    
                    result['uploaded_count'] += 1
                    
                except Exception as e:
                    error_msg = f"Row {txn_idx+1} error: {e}"
                    result['errors'].append(error_msg)
                    debug_log.append(f"  [ERROR] {error_msg}")
                    logger.error(f"Transaction insert error: {e}")
            
            # STEP 3: Reconcile cash balances
            self._reconcile_cash_balances(cur, portfolio_id)
            
            conn.commit()
            conn.close()
            
            result['success'] = True
            result['message'] = f"Successfully uploaded {result['uploaded_count']} transactions"
            if result['soft_deleted_count'] > 0:
                result['message'] += f" (replaced {result['soft_deleted_count']} previous entries)"
            
            # DEBUG: Log completion
            debug_log.append(f"[UPLOAD COMPLETE] success=True, uploaded={result['uploaded_count']}, replaced={result['soft_deleted_count']}")
            logger.info(f"Upload complete: {result['uploaded_count']} uploaded, {result['soft_deleted_count']} replaced")
            
        except Exception as e:
            result['errors'].append(str(e))
            result['message'] = f"Upload failed: {e}"
            debug_log.append(f"[UPLOAD FAILED] {e}")
            logger.error(f"Transaction upload error: {e}")
        
        return result
    
    def _reconcile_cash_balances(self, cur, portfolio_id: int):
        """
        Reconcile cash balances after upload.
        
        Calculates net cash flow from all non-deleted transactions
        and updates the external_accounts balance.
        """
        try:
            # Calculate net cash flow per account
            db_execute(cur, """
                SELECT 
                    account_id,
                    SUM(CASE 
                        WHEN txn_type = 'DEPOSIT' THEN amount
                        WHEN txn_type = 'WITHDRAWAL' THEN -ABS(amount)
                        WHEN txn_type = 'BUY' THEN amount - COALESCE(fees, 0)
                        WHEN txn_type = 'SELL' THEN amount - COALESCE(fees, 0)
                        WHEN txn_type = 'DIVIDEND' THEN amount
                        ELSE 0 
                    END) as net_cash_flow
                FROM portfolio_transactions
                WHERE portfolio_id = ? 
                AND user_id = ?
                AND (is_deleted = 0 OR is_deleted IS NULL)
                AND account_id IS NOT NULL
                GROUP BY account_id
            """, (portfolio_id, self.user_id))
            
            today = time.strftime('%Y-%m-%d')
            
            for row in cur.fetchall():
                account_id, net_cash_flow = row
                net_cash_flow = float(net_cash_flow or 0)
                
                db_execute(cur, """
                    UPDATE external_accounts 
                    SET current_balance = ?,
                        last_reconciled_date = ?
                    WHERE id = ? AND user_id = ?
                """, (net_cash_flow, today, account_id, self.user_id))
            
            self.stats['reconciled'] = True
            
        except Exception as e:
            logger.error(f"Cash reconciliation error: {e}")
            self.stats['errors'].append(f"Reconciliation: {e}")
    
    def soft_delete_by_source(self, source: str, source_reference: str = None) -> int:
        """
        Soft delete transactions by source and optional reference.
        
        Args:
            source: Source type (UPLOAD, API, etc.)
            source_reference: Optional specific file/reference
            
        Returns:
            Number of records soft-deleted
        """
        try:
            conn = get_conn()
            cur = conn.cursor()
            
            if source_reference:
                db_execute(cur, """
                    UPDATE portfolio_transactions 
                    SET is_deleted = 1
                    WHERE user_id = ?
                    AND source = ?
                    AND source_reference = ?
                    AND (is_deleted = 0 OR is_deleted IS NULL)
                """, (self.user_id, source, source_reference))
            else:
                db_execute(cur, """
                    UPDATE portfolio_transactions 
                    SET is_deleted = 1
                    WHERE user_id = ?
                    AND source = ?
                    AND (is_deleted = 0 OR is_deleted IS NULL)
                """, (self.user_id, source))
            
            count = cur.rowcount
            conn.commit()
            conn.close()
            
            return count
            
        except Exception as e:
            logger.error(f"Soft delete error: {e}")
            return 0
    
    def restore_deleted(self, source_reference: str) -> int:
        """
        Restore soft-deleted transactions by source reference.
        
        Args:
            source_reference: File name or upload identifier
            
        Returns:
            Number of records restored
        """
        try:
            conn = get_conn()
            cur = conn.cursor()
            
            db_execute(cur, """
                UPDATE portfolio_transactions 
                SET is_deleted = 0
                WHERE user_id = ?
                AND source_reference = ?
                AND is_deleted = 1
            """, (self.user_id, source_reference))
            
            count = cur.rowcount
            conn.commit()
            conn.close()
            
            return count
            
        except Exception as e:
            logger.error(f"Restore error: {e}")
            return 0


# ============================================================================
# LEGACY TRANSACTIONS TABLE - SOFT DELETE HELPERS
# ============================================================================

def soft_delete_transactions(user_id: int, source: str = None, source_reference: str = None, 
                              preserve_manual: bool = True) -> int:
    """
    Soft delete transactions from the legacy transactions table.
    
    Args:
        user_id: User ID
        source: Source filter (UPLOAD, MANUAL, API, etc.) or None for all non-manual
        source_reference: Specific source_reference to filter (e.g., filename)
        preserve_manual: If True, never delete MANUAL entries
        
    Returns:
        Number of records soft-deleted
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        if source_reference:
            # Delete by specific source_reference
            db_execute(cur, """
                UPDATE transactions 
                SET is_deleted = 1,
                    deleted_at = ?,
                    deleted_by = ?
                WHERE user_id = ?
                AND source_reference = ?
                AND (is_deleted = 0 OR is_deleted IS NULL)
            """, (int(time.time()), user_id, user_id, source_reference))
        elif source:
            # Delete by source type
            db_execute(cur, """
                UPDATE transactions 
                SET is_deleted = 1,
                    deleted_at = ?,
                    deleted_by = ?
                WHERE user_id = ?
                AND source = ?
                AND (is_deleted = 0 OR is_deleted IS NULL)
            """, (int(time.time()), user_id, user_id, source))
        elif preserve_manual:
            # Delete all non-MANUAL entries
            db_execute(cur, """
                UPDATE transactions 
                SET is_deleted = 1,
                    deleted_at = ?,
                    deleted_by = ?
                WHERE user_id = ?
                AND (source != 'MANUAL' OR source IS NULL)
                AND (is_deleted = 0 OR is_deleted IS NULL)
            """, (int(time.time()), user_id, user_id))
        else:
            # Delete ALL (for full replace)
            db_execute(cur, """
                UPDATE transactions 
                SET is_deleted = 1,
                    deleted_at = ?,
                    deleted_by = ?
                WHERE user_id = ?
                AND (is_deleted = 0 OR is_deleted IS NULL)
            """, (int(time.time()), user_id, user_id))
        
        count = cur.rowcount
        conn.commit()
        conn.close()
        
        return count
        
    except Exception as e:
        logger.error(f"Soft delete transactions error: {e}")
        return 0


def restore_deleted_transactions(user_id: int, source_reference: str = None) -> int:
    """
    Restore soft-deleted transactions from the legacy transactions table.
    
    Args:
        user_id: User ID
        source_reference: Optional specific source_reference to restore
        
    Returns:
        Number of records restored
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        if source_reference:
            db_execute(cur, """
                UPDATE transactions 
                SET is_deleted = 0,
                    deleted_at = NULL,
                    deleted_by = NULL
                WHERE user_id = ?
                AND source_reference = ?
                AND is_deleted = 1
            """, (user_id, source_reference))
        else:
            db_execute(cur, """
                UPDATE transactions 
                SET is_deleted = 0,
                    deleted_at = NULL,
                    deleted_by = NULL
                WHERE user_id = ?
                AND is_deleted = 1
            """, (user_id,))
        
        count = cur.rowcount
        conn.commit()
        conn.close()
        
        return count
        
    except Exception as e:
        logger.error(f"Restore transactions error: {e}")
        return 0


def get_deleted_transactions_count(user_id: int) -> dict:
    """
    Get count of deleted transactions by source.
    
    Args:
        user_id: User ID
        
    Returns:
        Dict with counts by source
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        db_execute(cur, """
            SELECT source, COUNT(*) as count
            FROM transactions
            WHERE user_id = ?
            AND is_deleted = 1
            GROUP BY source
        """, (user_id,))
        
        results = {row['source'] or 'UNKNOWN': row['count'] for row in cur.fetchall()}
        conn.close()
        
        return results
        
    except Exception as e:
        logger.error(f"Get deleted count error: {e}")
        return {}


def upload_transactions_from_excel(
    user_id: int, 
    portfolio_id: int, 
    file_path: str,
    sheet_name: str = None
) -> dict:
    """
    Parse and upload transactions from an Excel file.
    
    Wrapper function that:
    1. Reads Excel file
    2. Normalizes column names
    3. Maps to transaction format
    4. Calls TransactionUploader.upload()
    
    Args:
        user_id: User ID
        portfolio_id: Target portfolio ID
        file_path: Path to Excel file
        sheet_name: Optional sheet name
        
    Returns:
        Upload result dict
    """
    import os
    
    result = {'success': False, 'errors': [], 'debug_log': []}
    debug_log = result['debug_log']
    
    # DEBUG: Log function start
    debug_log.append(f"[EXCEL UPLOAD START] user_id={user_id}, portfolio_id={portfolio_id}")
    debug_log.append(f"[EXCEL] file_path={file_path}, sheet_name={sheet_name}")
    logger.info(f"upload_transactions_from_excel() started: user={user_id}, portfolio={portfolio_id}, file={file_path}")
    
    try:
        # Read Excel file
        if sheet_name:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
        else:
            df = pd.read_excel(file_path)
        
        if df.empty:
            debug_log.append("[EXCEL] File is empty!")
            result['errors'].append("Excel file is empty")
            return result
        
        # Normalize column names
        original_cols = list(df.columns)
        df.columns = [str(c).strip().lower().replace(' ', '_') for c in df.columns]
        normalized_cols = list(df.columns)
        
        # DEBUG: Log column info
        debug_log.append(f"[EXCEL] Rows: {len(df)}, Original columns: {original_cols}")
        debug_log.append(f"[EXCEL] Normalized columns: {normalized_cols}")
        logger.info(f"Excel loaded: {len(df)} rows, columns: {normalized_cols}")
        
        # Map to transaction format
        transactions = []
        for idx, row in df.iterrows():
            try:
                # DEBUG: Log raw values for first few rows
                raw_date = row.get('txn_date') or row.get('date') or row.get('trade_date')
                raw_type = row.get('txn_type') or row.get('type') or row.get('transaction_type')
                parsed_date = _parse_date(raw_date)
                
                if idx < 3:  # Log first 3 rows in detail
                    debug_log.append(f"  [ROW {idx+2}] raw_date={raw_date!r} -> parsed={parsed_date}")
                    debug_log.append(f"  [ROW {idx+2}] raw_type={raw_type!r} -> mapped={_map_txn_type(raw_type)}")
                
                txn = {
                    'txn_type': _map_txn_type(raw_type),
                    # SYMBOL NORMALIZATION: Use normalize_stock_symbol for variations
                    'stock_symbol': normalize_stock_symbol(
                        str(row.get('stock_symbol') or row.get('symbol') or row.get('ticker') or '').strip()
                    ),
                    'shares': float(row.get('shares') or row.get('quantity') or row.get('qty') or 0),
                    'price': float(row.get('price') or row.get('unit_price') or 0),
                    'amount': float(row.get('amount') or row.get('total') or row.get('value') or 0),
                    'fees': float(row.get('fees') or row.get('commission') or row.get('brokerage') or 0),
                    'txn_date': parsed_date,
                    'notes': str(row.get('notes') or row.get('comments') or '') if row.get('notes') else None
                }
                
                # DEBUG: Log symbol normalization for first few rows
                if idx < 3:
                    raw_sym = str(row.get('stock_symbol') or row.get('symbol') or row.get('ticker') or '')
                    debug_log.append(f"  [ROW {idx+2}] symbol: {raw_sym!r} -> {txn['stock_symbol']}")
                
                # Skip rows with no meaningful data
                if not txn['stock_symbol'] and txn['txn_type'] in ['BUY', 'SELL']:
                    continue
                if txn['txn_type'] not in ['BUY', 'SELL', 'DIVIDEND', 'DEPOSIT', 'WITHDRAWAL']:
                    continue
                
                transactions.append(txn)
                
            except Exception as e:
                result['errors'].append(f"Row {idx + 2}: {e}")
        
        if not transactions:
            result['errors'].append("No valid transactions found in file")
            return result
        
        # Upload using TransactionUploader
        uploader = TransactionUploader(user_id)
        source_reference = os.path.basename(file_path)
        
        upload_result = uploader.upload(transactions, portfolio_id, source_reference, source='UPLOAD')
        
        result.update(upload_result)
        
    except Exception as e:
        result['errors'].append(str(e))
        logger.error(f"Excel upload error: {e}")
    
    return result


def _map_txn_type(raw_type) -> str:
    """Map various transaction type strings to standard format."""
    if not raw_type:
        return 'BUY'
    
    raw = str(raw_type).upper().strip()
    
    mappings = {
        'BUY': 'BUY',
        'PURCHASE': 'BUY',
        'B': 'BUY',
        'SELL': 'SELL',
        'SALE': 'SELL',
        'S': 'SELL',
        'DIVIDEND': 'DIVIDEND',
        'DIV': 'DIVIDEND',
        'CASH_DIVIDEND': 'DIVIDEND',
        'DEPOSIT': 'DEPOSIT',
        'DEP': 'DEPOSIT',
        'TRANSFER_IN': 'DEPOSIT',
        'WITHDRAWAL': 'WITHDRAWAL',
        'WITHDRAW': 'WITHDRAWAL',
        'TRANSFER_OUT': 'WITHDRAWAL'
    }
    
    return mappings.get(raw, 'BUY')


# Global flag to enable date parsing debug logging
_DATE_PARSE_DEBUG = False

def set_date_parse_debug(enabled: bool):
    """Enable/disable date parsing debug logging."""
    global _DATE_PARSE_DEBUG
    _DATE_PARSE_DEBUG = enabled


def _parse_date(raw_date, debug_log: list = None) -> str:
    """
    Parse various date formats to YYYY-MM-DD (ISO format).
    
    Handles:
    - ISO format: 2025-07-27
    - DD/MM/YYYY: 27/07/2025
    - MM/DD/YYYY: 07/27/2025
    - DD-MM-YYYY: 27-07-2025
    - DD-MMM-YY: 27-Jul-25
    - DD-MMM-YYYY: 27-Jul-2025
    - MM/DD/YY: 07/27/25
    - DD/MM/YY: 27/07/25
    - Excel serial dates: 45869 (days since 1899-12-30)
    - Pandas/numpy datetime objects
    """
    from datetime import datetime, timedelta
    
    if not raw_date:
        return time.strftime('%Y-%m-%d')
    
    # Handle None explicitly
    if raw_date is None or (isinstance(raw_date, float) and pd.isna(raw_date)):
        return time.strftime('%Y-%m-%d')
    
    # Handle pandas Timestamp or datetime objects directly
    if isinstance(raw_date, (datetime, pd.Timestamp)):
        return raw_date.strftime('%Y-%m-%d')
    
    # Handle Excel serial date numbers (float or int)
    if isinstance(raw_date, (int, float)) and not pd.isna(raw_date):
        # Excel serial date: days since 1899-12-30
        # Numbers > 30000 are likely Excel dates (year 1982+)
        if 30000 <= raw_date <= 100000:
            try:
                excel_epoch = datetime(1899, 12, 30)
                dt = excel_epoch + timedelta(days=int(raw_date))
                return dt.strftime('%Y-%m-%d')
            except:
                pass
    
    if isinstance(raw_date, str):
        raw_date = raw_date.strip()
        
        # Already in correct ISO format: YYYY-MM-DD
        if len(raw_date) == 10 and raw_date[4] == '-' and raw_date[7] == '-':
            try:
                # Validate it's a real date
                datetime.strptime(raw_date, '%Y-%m-%d')
                return raw_date
            except:
                pass
        
        # Try comprehensive list of formats
        date_formats = [
            '%Y-%m-%d',      # ISO: 2025-07-27
            '%d/%m/%Y',      # DD/MM/YYYY: 27/07/2025
            '%m/%d/%Y',      # MM/DD/YYYY: 07/27/2025
            '%d-%m-%Y',      # DD-MM-YYYY: 27-07-2025
            '%d-%b-%y',      # DD-MMM-YY: 27-Jul-25
            '%d-%b-%Y',      # DD-MMM-YYYY: 27-Jul-2025
            '%d-%B-%y',      # DD-Month-YY: 27-July-25
            '%d-%B-%Y',      # DD-Month-YYYY: 27-July-2025
            '%d %b %y',      # DD MMM YY: 27 Jul 25
            '%d %b %Y',      # DD MMM YYYY: 27 Jul 2025
            '%d %B %y',      # DD Month YY: 27 July 25
            '%d %B %Y',      # DD Month YYYY: 27 July 2025
            '%b %d, %Y',     # MMM DD, YYYY: Jul 27, 2025
            '%B %d, %Y',     # Month DD, YYYY: July 27, 2025
            '%m/%d/%y',      # MM/DD/YY: 07/27/25
            '%d/%m/%y',      # DD/MM/YY: 27/07/25
            '%Y/%m/%d',      # YYYY/MM/DD: 2025/07/27
            '%Y.%m.%d',      # YYYY.MM.DD: 2025.07.27
            '%d.%m.%Y',      # DD.MM.YYYY: 27.07.2025
        ]
        
        for fmt in date_formats:
            try:
                dt = datetime.strptime(raw_date, fmt)
                # Handle 2-digit years: if year < 100, assume 2000s for years < 50, 1900s otherwise
                if dt.year < 100:
                    dt = dt.replace(year=dt.year + 2000 if dt.year < 50 else dt.year + 1900)
                result = dt.strftime('%Y-%m-%d')
                # Debug log success
                if _DATE_PARSE_DEBUG or debug_log is not None:
                    msg = f"[DATE PARSE] '{raw_date}' matched format '{fmt}' -> {result}"
                    if debug_log is not None:
                        debug_log.append(msg)
                    if _DATE_PARSE_DEBUG:
                        logger.debug(msg)
                return result
            except ValueError:
                continue
    
    # Fallback: Try pandas Timestamp for any remaining edge cases
    try:
        ts = pd.Timestamp(raw_date)
        if not pd.isna(ts):
            result = ts.strftime('%Y-%m-%d')
            if _DATE_PARSE_DEBUG or debug_log is not None:
                msg = f"[DATE PARSE] '{raw_date}' parsed via pandas.Timestamp -> {result}"
                if debug_log is not None:
                    debug_log.append(msg)
                if _DATE_PARSE_DEBUG:
                    logger.debug(msg)
            return result
    except:
        pass
    
    # Last resort: return today's date with a warning logged
    result = time.strftime('%Y-%m-%d')
    warning_msg = f"[DATE PARSE WARNING] Could not parse: {raw_date!r} (type={type(raw_date).__name__}), using today: {result}"
    logger.warning(warning_msg)
    if debug_log is not None:
        debug_log.append(warning_msg)
    return result


# ============================================================================
# SOLUTION #2: POSITION CALCULATION HELPER
# ============================================================================
# Standardized SQL for calculating current holdings from transactions.
# This ensures consistency across all UI components.

def get_position_calculation_sql(user_id_param: str = "?", include_soft_delete: bool = True) -> str:
    """
    Generate standardized SQL for position calculation.
    
    CORRECT FORMULA: 
        net_shares = BUY shares + BONUS shares - SELL shares
    
    Args:
        user_id_param: SQL parameter placeholder (default "?")
        include_soft_delete: Whether to add soft-delete filter
        
    Returns:
        SQL subquery string that calculates positions per stock
    """
    soft_delete = ""
    if include_soft_delete:
        soft_delete = " AND (is_deleted IS NULL OR is_deleted = 0)"
    
    return f"""
        SELECT 
            portfolio,
            stock_symbol,
            SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(shares, 0) ELSE 0 END) AS total_bought,
            SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(shares, 0) ELSE 0 END) AS total_sold,
            SUM(COALESCE(bonus_shares, 0)) AS total_bonus,
            SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(shares, 0) ELSE 0 END) + 
            SUM(COALESCE(bonus_shares, 0)) - 
            SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(shares, 0) ELSE 0 END) AS current_holding
        FROM transactions
        WHERE user_id = {user_id_param}
        AND txn_type IN ('Buy', 'Sell', 'Bonus')
        {soft_delete}
        GROUP BY portfolio, stock_symbol
        HAVING (SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(shares, 0) ELSE 0 END) + 
            SUM(COALESCE(bonus_shares, 0)) - 
            SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(shares, 0) ELSE 0 END)) > 0.001
    """


def get_current_holdings(user_id: int, portfolio: str = None, include_closed: bool = False) -> pd.DataFrame:
    """
    Get current stock holdings calculated from transactions.
    
    This is the SINGLE SOURCE OF TRUTH for position calculations.
    
    Args:
        user_id: User ID
        portfolio: Optional portfolio filter (None = all)
        include_closed: If True, include positions with 0 shares
        
    Returns:
        DataFrame with columns: portfolio, stock_symbol, total_bought, total_sold, 
                                total_bonus, current_holding
    """
    soft_del = _soft_delete_filter()
    
    # PostgreSQL doesn't allow HAVING with column aliases - repeat full expression
    having_clause = """HAVING (SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(shares, 0) ELSE 0 END) + 
            SUM(COALESCE(bonus_shares, 0)) - 
            SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(shares, 0) ELSE 0 END)) > 0.001""" if not include_closed else ""
    portfolio_filter = f"AND portfolio = '{portfolio}'" if portfolio else ""
    
    sql = f"""
        SELECT 
            portfolio,
            stock_symbol,
            SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(shares, 0) ELSE 0 END) AS total_bought,
            SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(shares, 0) ELSE 0 END) AS total_sold,
            SUM(COALESCE(bonus_shares, 0)) AS total_bonus,
            SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(shares, 0) ELSE 0 END) + 
            SUM(COALESCE(bonus_shares, 0)) - 
            SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(shares, 0) ELSE 0 END) AS current_holding,
            -- Cost basis for open positions
            SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(purchase_cost, 0) ELSE 0 END) AS total_cost,
            -- Dividends received
            SUM(COALESCE(cash_dividend, 0)) AS total_dividends,
            -- Realized P&L from sells
            SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(sell_value, 0) ELSE 0 END) AS total_sell_value
        FROM transactions
        WHERE user_id = ?
        {portfolio_filter}
        {soft_del}
        GROUP BY portfolio, stock_symbol
        {having_clause}
        ORDER BY portfolio, stock_symbol
    """
    
    return query_df(sql, (user_id,))


def validate_position_integrity(user_id: int) -> dict:
    """
    Validate that position calculations are consistent.
    
    Returns:
        Dict with validation results and any discrepancies found
    """
    holdings = get_current_holdings(user_id, include_closed=True)
    
    issues = []
    
    for _, row in holdings.iterrows():
        # Check for negative holdings (should not happen)
        if row['current_holding'] < 0:
            issues.append({
                'type': 'NEGATIVE_POSITION',
                'portfolio': row['portfolio'],
                'symbol': row['stock_symbol'],
                'holding': row['current_holding'],
                'message': f"Negative position: {row['current_holding']:.4f} shares"
            })
        
        # Check for sells exceeding buys
        if row['total_sold'] > row['total_bought'] + row['total_bonus']:
            issues.append({
                'type': 'OVERSOLD',
                'portfolio': row['portfolio'],
                'symbol': row['stock_symbol'],
                'bought': row['total_bought'],
                'bonus': row['total_bonus'],
                'sold': row['total_sold'],
                'message': f"Sold more than owned: bought={row['total_bought']:.0f}, bonus={row['total_bonus']:.0f}, sold={row['total_sold']:.0f}"
            })
    
    return {
        'valid': len(issues) == 0,
        'issue_count': len(issues),
        'issues': issues,
        'total_positions': len(holdings),
        'open_positions': len(holdings[holdings['current_holding'] > 0.001]),
        'closed_positions': len(holdings[holdings['current_holding'] <= 0.001])
    }


# ============================================================================
# UI DISPLAY FIX #1: PORTFOLIO OVERVIEW QUERIES
# ============================================================================

def get_portfolio_overview(user_id: int, portfolio_id: int = None) -> dict:
    """
    Get comprehensive portfolio overview data from unified tables.
    
    This is the CORRECT query for the Overview tab - always shows accurate data
    regardless of upload status or data source.
    
    Args:
        user_id: User ID
        portfolio_id: Optional specific portfolio (None = all portfolios)
        
    Returns:
        Dict with:
        - total_deposits: Sum of all DEPOSIT transactions
        - total_withdrawals: Sum of all WITHDRAWAL transactions  
        - net_deposits: Deposits - Withdrawals
        - total_invested: Sum of BUY amounts (negative, so we negate)
        - total_divested: Sum of SELL amounts
        - total_dividends: Sum of DIVIDEND amounts
        - cash_balance: Net cash flow
        - by_portfolio: Breakdown per portfolio
    """
    result = {
        'total_deposits': 0.0,
        'total_withdrawals': 0.0,
        'net_deposits': 0.0,
        'total_invested': 0.0,
        'total_divested': 0.0,
        'total_dividends': 0.0,
        'cash_balance': 0.0,
        'total_fees': 0.0,
        'transaction_count': 0,
        'by_portfolio': {}
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # Build query with optional portfolio filter
        portfolio_filter = "AND pt.portfolio_id = ?" if portfolio_id else ""
        params = [user_id, portfolio_id] if portfolio_id else [user_id]
        
        # Query aggregated data per portfolio
        query = f"""
            SELECT 
                p.id as portfolio_id,
                p.name as portfolio_name,
                COALESCE(SUM(CASE WHEN pt.txn_type = 'DEPOSIT' THEN pt.amount ELSE 0 END), 0) as total_deposits,
                COALESCE(SUM(CASE WHEN pt.txn_type = 'WITHDRAWAL' THEN pt.amount ELSE 0 END), 0) as total_withdrawals,
                COALESCE(SUM(CASE WHEN pt.txn_type = 'BUY' THEN pt.amount ELSE 0 END), 0) as total_buys,
                COALESCE(SUM(CASE WHEN pt.txn_type = 'SELL' THEN pt.amount ELSE 0 END), 0) as total_sells,
                COALESCE(SUM(CASE WHEN pt.txn_type = 'DIVIDEND' THEN pt.amount ELSE 0 END), 0) as total_dividends,
                COALESCE(SUM(pt.amount), 0) as cash_balance,
                COALESCE(SUM(COALESCE(pt.fees, 0)), 0) as total_fees,
                COUNT(*) as txn_count
            FROM portfolios p
            LEFT JOIN portfolio_transactions pt ON p.id = pt.portfolio_id 
                AND pt.user_id = p.user_id
                AND (pt.is_deleted = 0 OR pt.is_deleted IS NULL)
            WHERE p.user_id = ? {portfolio_filter}
            GROUP BY p.id, p.name
        """
        
        db_execute(cur, query, tuple(params))
        
        for row in cur.fetchall():
            (port_id, port_name, deposits, withdrawals, buys, sells, 
             dividends, balance, fees, txn_count) = row
            
            deposits = float(deposits or 0)
            withdrawals = float(withdrawals or 0)
            buys = float(buys or 0)  # Negative value
            sells = float(sells or 0)
            dividends = float(dividends or 0)
            balance = float(balance or 0)
            fees = float(fees or 0)
            
            # Get portfolio currency
            ccy = PORTFOLIO_CCY.get(port_name, 'KWD')
            
            # Store per-portfolio data
            result['by_portfolio'][port_name] = {
                'portfolio_id': port_id,
                'currency': ccy,
                'total_deposits': deposits,
                'total_withdrawals': withdrawals,
                'net_deposits': deposits - withdrawals,
                'total_invested': -buys,  # Negate since buys are negative
                'total_divested': sells,
                'total_dividends': dividends,
                'cash_balance': balance,
                'total_fees': fees,
                'transaction_count': txn_count
            }
            
            # Aggregate totals (convert to KWD)
            result['total_deposits'] += convert_to_kwd(deposits, ccy)
            result['total_withdrawals'] += convert_to_kwd(withdrawals, ccy)
            result['total_invested'] += convert_to_kwd(-buys, ccy)
            result['total_divested'] += convert_to_kwd(sells, ccy)
            result['total_dividends'] += convert_to_kwd(dividends, ccy)
            result['cash_balance'] += convert_to_kwd(balance, ccy)
            result['total_fees'] += convert_to_kwd(fees, ccy)
            result['transaction_count'] += txn_count
        
        result['net_deposits'] = result['total_deposits'] - result['total_withdrawals']
        
        conn.close()
        
    except Exception as e:
        logger.error(f"Error getting portfolio overview: {e}")
        result['error'] = str(e)
    
    return result


def get_portfolio_value(user_id: int, portfolio_id: int = None) -> dict:
    """
    Get current portfolio value from holdings.
    
    Calculates market value based on current prices and share quantities.
    
    Args:
        user_id: User ID
        portfolio_id: Optional specific portfolio
        
    Returns:
        Dict with market values per portfolio and total
    """
    result = {
        'total_value_kwd': 0.0,
        'by_portfolio': {}
    }
    
    try:
        # Use existing build_portfolio_table function for consistency
        for port_name in PORTFOLIO_CCY.keys():
            df_port = build_portfolio_table(port_name)
            
            if not df_port.empty:
                ccy = PORTFOLIO_CCY.get(port_name, 'KWD')
                port_value = 0.0
                
                for _, row in df_port.iterrows():
                    if row.get('Shares Qty', 0) > 0:
                        market_val = float(row.get('Market Value', 0) or 0)
                        port_value += market_val
                
                result['by_portfolio'][port_name] = {
                    'currency': ccy,
                    'market_value': port_value,
                    'market_value_kwd': convert_to_kwd(port_value, ccy)
                }
                
                result['total_value_kwd'] += convert_to_kwd(port_value, ccy)
        
    except Exception as e:
        logger.error(f"Error getting portfolio value: {e}")
        result['error'] = str(e)
    
    return result


def get_account_balances(user_id: int, portfolio_id: int = None) -> dict:
    """
    Get current account balances from external_accounts table.
    
    Args:
        user_id: User ID
        portfolio_id: Optional specific portfolio
        
    Returns:
        Dict with account balances
    """
    result = {
        'total_cash_kwd': 0.0,
        'accounts': []
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        query = """
            SELECT ea.id, ea.name, ea.current_balance, ea.currency, 
                   ea.last_reconciled_date, p.name as portfolio_name
            FROM external_accounts ea
            LEFT JOIN portfolios p ON ea.portfolio_id = p.id
            WHERE ea.user_id = ?
        """
        params = [user_id]
        
        if portfolio_id:
            query += " AND ea.portfolio_id = ?"
            params.append(portfolio_id)
        
        db_execute(cur, query, tuple(params))
        
        for row in cur.fetchall():
            acc_id, acc_name, balance, ccy, reconciled_date, port_name = row
            balance = float(balance or 0)
            ccy = ccy or 'KWD'
            
            account_data = {
                'id': acc_id,
                'name': acc_name,
                'balance': balance,
                'currency': ccy,
                'balance_kwd': convert_to_kwd(balance, ccy),
                'last_reconciled': reconciled_date,
                'portfolio_name': port_name
            }
            
            result['accounts'].append(account_data)
            result['total_cash_kwd'] += convert_to_kwd(balance, ccy)
        
        conn.close()
        
    except Exception as e:
        logger.error(f"Error getting account balances: {e}")
        result['error'] = str(e)
    
    return result


def get_complete_overview(user_id: int) -> dict:
    """
    Get complete portfolio overview for UI display.
    
    This is the main entry point for the Overview tab.
    Combines all data sources into a single comprehensive dict.
    
    Args:
        user_id: User ID
        
    Returns:
        Complete overview data
    """
    # Get transaction-based overview
    overview = get_portfolio_overview(user_id)
    
    # Get current market values
    values = get_portfolio_value(user_id)
    
    # Get account cash balances
    accounts = get_account_balances(user_id)
    
    # Combine into complete result
    result = {
        # Transaction aggregates
        'total_deposits': overview['total_deposits'],
        'total_withdrawals': overview['total_withdrawals'],
        'net_deposits': overview['net_deposits'],
        'total_invested': overview['total_invested'],
        'total_divested': overview['total_divested'],
        'total_dividends': overview['total_dividends'],
        'total_fees': overview['total_fees'],
        'transaction_count': overview['transaction_count'],
        
        # Current values
        'portfolio_value': values['total_value_kwd'],
        'cash_balance': accounts['total_cash_kwd'],
        'total_value': values['total_value_kwd'] + accounts['total_cash_kwd'],
        
        # Calculated metrics
        'total_gain': values['total_value_kwd'] + accounts['total_cash_kwd'] - overview['net_deposits'],
        'roi_percent': (
            ((values['total_value_kwd'] + accounts['total_cash_kwd']) / overview['net_deposits'] - 1) * 100
            if overview['net_deposits'] > 0 else 0
        ),
        
        # Breakdown by portfolio
        'by_portfolio': {},
        'accounts': accounts['accounts']
    }
    
    # Combine portfolio data
    for port_name in PORTFOLIO_CCY.keys():
        port_data = overview['by_portfolio'].get(port_name, {})
        value_data = values['by_portfolio'].get(port_name, {})
        
        result['by_portfolio'][port_name] = {
            **port_data,
            'market_value': value_data.get('market_value', 0),
            'market_value_kwd': value_data.get('market_value_kwd', 0)
        }
    
    return result


# ============================================================================
# UI DISPLAY FIX #2: PORTFOLIO ANALYSIS QUERIES
# ============================================================================

def get_portfolio_monthly_breakdown(user_id: int, portfolio_id: int = None, 
                                    start_date: str = None, end_date: str = None) -> pd.DataFrame:
    """
    Get monthly transaction breakdown by type from portfolio_transactions.
    
    This is the CORRECT query for the Analysis tab - aggregates transactions
    by month and type (DEPOSIT, BUY, SELL, DIVIDEND, WITHDRAWAL).
    
    Args:
        user_id: User ID
        portfolio_id: Optional specific portfolio
        start_date: Optional start date (YYYY-MM-DD)
        end_date: Optional end date (YYYY-MM-DD)
        
    Returns:
        DataFrame with: month, txn_type, transaction_count, total_amount, total_fees
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # Build query with optional filters
        where_clauses = ["pt.user_id = ?", "(pt.is_deleted = 0 OR pt.is_deleted IS NULL)"]
        params = [user_id]
        
        if portfolio_id:
            where_clauses.append("pt.portfolio_id = ?")
            params.append(portfolio_id)
        
        if start_date:
            where_clauses.append("pt.txn_date >= ?")
            params.append(start_date)
        
        if end_date:
            where_clauses.append("pt.txn_date <= ?")
            params.append(end_date)
        
        where_sql = " AND ".join(where_clauses)
        
        # Cross-DB date formatting: use SUBSTRING for portability
        date_expr = "SUBSTRING(pt.txn_date FROM 1 FOR 7)" if is_postgres() else "strftime('%Y-%m', pt.txn_date)"
        query = f"""
            SELECT 
                {date_expr} as month,
                pt.txn_type,
                COUNT(*) as transaction_count,
                COALESCE(SUM(pt.amount), 0) as total_amount,
                COALESCE(SUM(pt.fees), 0) as total_fees,
                p.name as portfolio_name
            FROM portfolio_transactions pt
            LEFT JOIN portfolios p ON pt.portfolio_id = p.id
            WHERE {where_sql}
            GROUP BY {date_expr}, pt.txn_type, p.name
            ORDER BY month DESC, pt.txn_type
        """
        
        db_execute(cur, query, tuple(params))
        columns = ['month', 'txn_type', 'transaction_count', 'total_amount', 'total_fees', 'portfolio_name']
        rows = cur.fetchall()
        conn.close()
        
        if rows:
            return pd.DataFrame(rows, columns=columns)
        return pd.DataFrame(columns=columns)
        
    except Exception as e:
        logger.error(f"Error getting monthly breakdown: {e}")
        return pd.DataFrame()


def get_cumulative_deposits(user_id: int, portfolio_id: int = None,
                            start_date: str = None, end_date: str = None) -> pd.DataFrame:
    """
    Get cumulative deposits over time from portfolio_transactions.
    
    Uses window function to calculate running total of deposits.
    
    Args:
        user_id: User ID
        portfolio_id: Optional specific portfolio
        start_date: Optional start date
        end_date: Optional end date
        
    Returns:
        DataFrame with: txn_date, amount, cumulative_deposits, portfolio_name
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # Build query with optional filters
        where_clauses = [
            "pt.user_id = ?",
            "pt.txn_type = 'DEPOSIT'",
            "(pt.is_deleted = 0 OR pt.is_deleted IS NULL)"
        ]
        params = [user_id]
        
        if portfolio_id:
            where_clauses.append("pt.portfolio_id = ?")
            params.append(portfolio_id)
        
        if start_date:
            where_clauses.append("pt.txn_date >= ?")
            params.append(start_date)
        
        if end_date:
            where_clauses.append("pt.txn_date <= ?")
            params.append(end_date)
        
        where_sql = " AND ".join(where_clauses)
        
        # SQLite window function for running total
        query = f"""
            SELECT 
                pt.txn_date,
                pt.amount,
                SUM(pt.amount) OVER (ORDER BY pt.txn_date ROWS UNBOUNDED PRECEDING) as cumulative_deposits,
                p.name as portfolio_name
            FROM portfolio_transactions pt
            LEFT JOIN portfolios p ON pt.portfolio_id = p.id
            WHERE {where_sql}
            ORDER BY pt.txn_date
        """
        
        db_execute(cur, query, tuple(params))
        columns = ['txn_date', 'amount', 'cumulative_deposits', 'portfolio_name']
        rows = cur.fetchall()
        conn.close()
        
        if rows:
            df = pd.DataFrame(rows, columns=columns)
            df['txn_date'] = pd.to_datetime(df['txn_date'])
            return df
        return pd.DataFrame(columns=columns)
        
    except Exception as e:
        logger.error(f"Error getting cumulative deposits: {e}")
        return pd.DataFrame()


def get_cumulative_cash_flow(user_id: int, portfolio_id: int = None,
                              start_date: str = None, end_date: str = None) -> pd.DataFrame:
    """
    Get cumulative cash flow (all transaction types) over time.
    
    Shows running balance of: deposits + dividends + sells - buys - withdrawals - fees
    
    Args:
        user_id: User ID
        portfolio_id: Optional specific portfolio
        start_date: Optional start date
        end_date: Optional end date
        
    Returns:
        DataFrame with: txn_date, txn_type, amount, cumulative_cash_flow
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # Build query with optional filters
        where_clauses = [
            "pt.user_id = ?",
            "(pt.is_deleted = 0 OR pt.is_deleted IS NULL)"
        ]
        params = [user_id]
        
        if portfolio_id:
            where_clauses.append("pt.portfolio_id = ?")
            params.append(portfolio_id)
        
        if start_date:
            where_clauses.append("pt.txn_date >= ?")
            params.append(start_date)
        
        if end_date:
            where_clauses.append("pt.txn_date <= ?")
            params.append(end_date)
        
        where_sql = " AND ".join(where_clauses)
        
        # Get all transactions with running cash balance
        # amount is already signed correctly in portfolio_transactions
        query = f"""
            SELECT 
                pt.txn_date,
                pt.txn_type,
                pt.amount,
                SUM(pt.amount) OVER (ORDER BY pt.txn_date, pt.id ROWS UNBOUNDED PRECEDING) as cumulative_cash_flow,
                p.name as portfolio_name
            FROM portfolio_transactions pt
            LEFT JOIN portfolios p ON pt.portfolio_id = p.id
            WHERE {where_sql}
            ORDER BY pt.txn_date, pt.id
        """
        
        db_execute(cur, query, tuple(params))
        columns = ['txn_date', 'txn_type', 'amount', 'cumulative_cash_flow', 'portfolio_name']
        rows = cur.fetchall()
        conn.close()
        
        if rows:
            df = pd.DataFrame(rows, columns=columns)
            df['txn_date'] = pd.to_datetime(df['txn_date'])
            return df
        return pd.DataFrame(columns=columns)
        
    except Exception as e:
        logger.error(f"Error getting cumulative cash flow: {e}")
        return pd.DataFrame()


def get_portfolio_analysis_data(user_id: int, portfolio_id: int = None,
                                 start_date: str = None, end_date: str = None) -> dict:
    """
    Get comprehensive portfolio analysis data.
    
    Main entry point for Portfolio Analysis tab - combines all analysis queries.
    
    Args:
        user_id: User ID
        portfolio_id: Optional specific portfolio
        start_date: Optional start date
        end_date: Optional end date
        
    Returns:
        Dict with monthly_breakdown, cumulative_deposits, cumulative_cash_flow
    """
    return {
        'monthly_breakdown': get_portfolio_monthly_breakdown(user_id, portfolio_id, start_date, end_date),
        'cumulative_deposits': get_cumulative_deposits(user_id, portfolio_id, start_date, end_date),
        'cumulative_cash_flow': get_cumulative_cash_flow(user_id, portfolio_id, start_date, end_date)
    }


def get_cash_summary(user_id: int, portfolio_id: int = None) -> pd.DataFrame:
    """
    Get complete cash summary from the portfolio_cash_summary view.
    
    Returns all cash movements: buys, sells, dividends, deposits, withdrawals.
    
    Args:
        user_id: User ID
        portfolio_id: Optional filter by portfolio
        
    Returns:
        DataFrame with cash summary per portfolio
    """
    try:
        conn = get_conn()
        
        query = """
            SELECT portfolio_id, portfolio_name,
                   total_buys, total_sells, total_dividends,
                   total_deposits, total_withdrawals,
                   cash_balance, total_fees, transaction_count
            FROM portfolio_cash_summary
            WHERE user_id = ?
        """
        params = [user_id]
        
        if portfolio_id:
            query += " AND portfolio_id = ?"
            params.append(portfolio_id)
        
        df = pd.read_sql_query(convert_sql_placeholders(query), conn, params=params)
        conn.close()
        return df
        
    except Exception as e:
        logger.error(f"Error getting cash summary: {e}")
        return pd.DataFrame()


def get_stock_positions(user_id: int, portfolio_id: int = None, include_closed: bool = False) -> pd.DataFrame:
    """
    Get stock position summary from the stock_position_summary view.
    
    Args:
        user_id: User ID
        portfolio_id: Optional filter by portfolio
        include_closed: If True, include positions with 0 shares
        
    Returns:
        DataFrame with position details per stock/portfolio
    """
    try:
        conn = get_conn()
        
        query = """
            SELECT portfolio_id, portfolio_name, stock_id, stock_symbol, stock_name,
                   shares_bought, shares_sold, current_shares,
                   total_cost, total_proceeds, total_dividends,
                   buy_count, sell_count, first_trade_date, last_trade_date
            FROM stock_position_summary
            WHERE user_id = ?
        """
        params = [user_id]
        
        if portfolio_id:
            query += " AND portfolio_id = ?"
            params.append(portfolio_id)
        
        if not include_closed:
            query += " AND current_shares != 0"
        
        query += " ORDER BY portfolio_name, stock_symbol"
        
        df = pd.read_sql_query(convert_sql_placeholders(query), conn, params=params)
        conn.close()
        
        # Add calculated columns
        if not df.empty:
            df['avg_cost'] = df.apply(
                lambda r: r['total_cost'] / r['shares_bought'] if r['shares_bought'] > 0 else 0, 
                axis=1
            )
            df['realized_pnl'] = df['total_proceeds'] - (df['avg_cost'] * df['shares_sold'])
            df['status'] = df['current_shares'].apply(lambda x: 'CLOSED' if abs(x) < 0.001 else 'OPEN')
        
        return df
        
    except Exception as e:
        logger.error(f"Error getting stock positions: {e}")
        return pd.DataFrame()


def resolve_stock_symbol(user_input: str, user_id: int = None) -> dict:
    """
    Resolve a user-input stock symbol to canonical form.
    
    This provides referential integrity by:
    1. Checking symbol_mappings for known variations
    2. Checking stocks_master for exact match
    3. Returning normalized form with stock_id
    
    Returns:
        {
            'canonical_ticker': str,
            'stock_id': int or None,
            'exchange': str,
            'currency': str,
            'found': bool
        }
    """
    result = {
        'canonical_ticker': user_input.upper().strip(),
        'stock_id': None,
        'exchange': 'KSE',
        'currency': 'KWD',
        'found': False
    }
    
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        # 1. Check symbol_mappings first
        db_execute(cur, """
            SELECT canonical_ticker, stock_id 
            FROM symbol_mappings 
            WHERE UPPER(user_input) = UPPER(?)
        """, (user_input,))
        row = cur.fetchone()
        
        if row:
            result['canonical_ticker'] = row[0]
            result['stock_id'] = row[1]
            result['found'] = True
        else:
            # 2. Check stocks_master directly
            db_execute(cur, """
                SELECT id, ticker, exchange, currency 
                FROM stocks_master 
                WHERE UPPER(ticker) = UPPER(?)
            """, (user_input.upper().strip(),))
            row = cur.fetchone()
            
            if row:
                result['stock_id'] = row[0]
                result['canonical_ticker'] = row[1]
                result['exchange'] = row[2]
                result['currency'] = row[3]
                result['found'] = True
        
        conn.close()
    except Exception as e:
        logger.warning(f"Error resolving symbol {user_input}: {e}")
    
    return result


def init_db() -> None:
    """Initialize database schema. Handles both SQLite and PostgreSQL."""
    
    # ============================================
    # QUICK CHECK: Skip if already initialized
    # ============================================
    # This prevents re-running migrations/indexes on every restart
    try:
        if is_postgres():
            # For PostgreSQL, check if users table exists
            from db_layer import query_val
            result = query_val("SELECT 1 FROM information_schema.tables WHERE table_name = 'users' LIMIT 1")
            if result:
                _log_startup("PostgreSQL DB already initialized - skipping full setup")
                # Still ensure critical columns exist (fast operation)
                for tbl in ["stocks", "transactions", "portfolio_cash", "cash_deposits"]:
                    add_column_if_missing(tbl, "user_id", "INTEGER DEFAULT 1")
                # Ensure manual_override column exists on portfolio_cash
                add_column_if_missing("portfolio_cash", "manual_override", "INTEGER DEFAULT 0")
                # Ensure securities tables exist (added later in development)
                _ensure_securities_tables()
                _ensure_normalized_schema()
                return
        else:
            # For SQLite, check sqlite_master
            conn = get_conn()
            cur = conn.cursor()
            cur.execute("SELECT 1 FROM sqlite_master WHERE type='table' AND name='users'")
            if cur.fetchone():
                conn.close()
                _log_startup("SQLite DB already initialized - skipping full setup")
                # Ensure securities tables exist (added later in development)
                _ensure_securities_tables()
                _ensure_normalized_schema()
                return
            conn.close()
    except Exception as e:
        logger.debug(f"DB init check note: {e}")
        # Continue with full initialization if check fails
    
    # If PostgreSQL, schema is already created by db_layer.init_postgres_schema()
    if is_postgres():
        logger.info("ðŸ˜ Using PostgreSQL - schema already initialized")
        # Just ensure any missing columns are added
        for tbl in ["stocks", "transactions", "portfolio_cash", "cash_deposits"]:
            add_column_if_missing(tbl, "user_id", "INTEGER DEFAULT 1")
        add_column_if_missing("users", "email", "TEXT")
        add_column_if_missing("users", "name", "TEXT")
        add_column_if_missing("users", "gemini_api_key", "TEXT")
        add_column_if_missing("cash_deposits", "portfolio", "TEXT DEFAULT 'KFH'")
        add_column_if_missing("cash_deposits", "include_in_analysis", "INTEGER DEFAULT 1")
        add_column_if_missing("cash_deposits", "currency", "TEXT DEFAULT 'KWD'")
        add_column_if_missing("stocks", "current_price", "REAL DEFAULT 0")
        add_column_if_missing("stocks", "portfolio", "TEXT DEFAULT 'KFH'")
        add_column_if_missing("stocks", "currency", "TEXT DEFAULT 'KWD'")
        add_column_if_missing("stocks", "tradingview_symbol", "TEXT")
        add_column_if_missing("stocks", "tradingview_exchange", "TEXT")
        add_column_if_missing("transactions", "portfolio", "TEXT DEFAULT 'KFH'")
        add_column_if_missing("transactions", "category", "TEXT DEFAULT 'portfolio'")
        # Ensure manual_override column exists on portfolio_cash
        add_column_if_missing("portfolio_cash", "manual_override", "INTEGER DEFAULT 0")
        # Ensure securities tables exist (added later in development)
        _ensure_securities_tables()
        _ensure_normalized_schema()
        logger.info("âœ… PostgreSQL schema ready")
        return
    
    # SQLite initialization (original logic)
    conn = get_conn()
    cur = conn.cursor()
    
    logger.info("ðŸ”§ Initializing SQLite database...")

    # ============================================
    # STEP 1: CREATE USERS TABLE FIRST (Priority #1)
    # This MUST exist before any table with user_id FK
    # ============================================
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            email TEXT UNIQUE,
            username TEXT NOT NULL UNIQUE,
            password_hash TEXT NOT NULL,
            name TEXT,
            created_at INTEGER NOT NULL
        )
        """
    )
    conn.commit()  # Commit users table immediately
    
    # Verify users table exists
    cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='users'")
    if not cur.fetchone():
        raise Exception("CRITICAL: Failed to create users table!")
    logger.info("âœ… Step 1: Users table verified.")
    
    # Add missing columns to users (backwards compatibility)
    add_column_if_missing("users", "email", "TEXT")
    add_column_if_missing("users", "name", "TEXT")
    add_column_if_missing("users", "gemini_api_key", "TEXT")

    # ============================================
    # STEP 2: CREATE DEPENDENT TABLES (after users)
    # ============================================
    logger.info("ðŸ”§ Step 2: Creating dependent tables...")

    # Password Resets (OTP)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS password_resets (
            email TEXT NOT NULL,
            otp TEXT NOT NULL,
            expires_at INTEGER NOT NULL,
            created_at INTEGER NOT NULL
        )
        """
    )

    # User Sessions (for Keep me logged in)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS user_sessions (
            token TEXT PRIMARY KEY,
            user_id INTEGER NOT NULL,
            expires_at INTEGER NOT NULL,
            created_at INTEGER NOT NULL,
            FOREIGN KEY (user_id) REFERENCES users (id)
        )
        """
    )

    # Cash deposits
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS cash_deposits (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            portfolio TEXT DEFAULT 'KFH',
            bank_name TEXT NOT NULL,
            deposit_date TEXT NOT NULL,
            amount REAL NOT NULL,
            description TEXT,
            comments TEXT,
            created_at INTEGER NOT NULL
        )
        """
    )
    
    # Portfolio Cash (Manual Overrides)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS portfolio_cash (
            portfolio TEXT,
            user_id INTEGER,
            balance REAL,
            currency TEXT DEFAULT 'KWD',
            last_updated INTEGER,
            manual_override INTEGER DEFAULT 0,
            PRIMARY KEY (portfolio, user_id)
        )
        """
    )
    
    # Financial Audit Log (Compliance - immutable record of cash-affecting operations)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS financial_audit_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            operation TEXT NOT NULL,
            entity_type TEXT,
            entity_id INTEGER,
            old_value REAL,
            new_value REAL,
            delta REAL,
            portfolio TEXT,
            currency TEXT,
            reason TEXT,
            details TEXT,
            created_at INTEGER NOT NULL
        )
        """
    )
    cur.execute("CREATE INDEX IF NOT EXISTS idx_audit_user ON financial_audit_log(user_id)")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_audit_operation ON financial_audit_log(operation)")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_audit_created ON financial_audit_log(created_at)")
    
    # Add columns if they don't exist (Backwards compatibility)
    add_column_if_missing("cash_deposits", "user_id", "INTEGER")
    add_column_if_missing("cash_deposits", "portfolio", "TEXT DEFAULT 'KFH'")
    add_column_if_missing("cash_deposits", "include_in_analysis", "INTEGER DEFAULT 1")
    add_column_if_missing("cash_deposits", "currency", "TEXT DEFAULT 'KWD'")
    add_column_if_missing("cash_deposits", "source", "TEXT")  # New standardized column
    add_column_if_missing("cash_deposits", "notes", "TEXT")   # New standardized column
    add_column_if_missing("cash_deposits", "fx_rate_at_deposit", "REAL DEFAULT NULL")  # Historical FX rate
    # Soft-delete columns (Undo/Redo support)
    add_column_if_missing("cash_deposits", "is_deleted", "INTEGER DEFAULT 0")
    add_column_if_missing("cash_deposits", "deleted_at", "INTEGER")  # Unix timestamp
    add_column_if_missing("cash_deposits", "deleted_by", "INTEGER")  # User ID who deleted
    
    # Add manual_override column to portfolio_cash (for respecting user edits)
    add_column_if_missing("portfolio_cash", "manual_override", "INTEGER DEFAULT 0")
    
    # Check if we need to migrate portfolio_cash (it was PK=portfolio, now needs PK=(portfolio, user_id))
    # We can't casually alter PK in SQLite. We might need to handle this if old table exists.
    # Simple check: does it have user_id?
    try:
        # Check if portfolio_cash table exists and has user_id
        cols = table_columns("portfolio_cash")
        if "user_id" not in cols:
            # Need migration: Drop and recreate (Assuming data is ephemeral or simple enough to drop for this specific table which is just manual cache)
            # Or better: Create new table, copy data with default user_id=1, swap.
            pass # We'll handle migration logic below
    except Exception:
        pass

    # Stocks - COMPLEX: Needs UNIQUE(symbol, user_id)
    # If old table exists, it has UNIQUE(symbol).
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS stocks (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER DEFAULT 1,
            symbol TEXT NOT NULL,
            name TEXT,
            current_price REAL DEFAULT 0,
            portfolio TEXT DEFAULT 'KFH',
            currency TEXT DEFAULT 'KWD',
            tradingview_symbol TEXT,
            tradingview_exchange TEXT,
            UNIQUE(symbol, user_id)
        )
        """
    )
    
    # Ensure stocks has all required columns immediately after creation
    # This handles case where table existed with old schema
    conn.commit()  # Commit the CREATE TABLE first
    add_column_if_missing("stocks", "current_price", "REAL DEFAULT 0")
    add_column_if_missing("stocks", "portfolio", "TEXT DEFAULT 'KFH'")
    add_column_if_missing("stocks", "currency", "TEXT DEFAULT 'KWD'")
    add_column_if_missing("stocks", "tradingview_symbol", "TEXT")
    add_column_if_missing("stocks", "tradingview_exchange", "TEXT")

    # Transactions - CREATE TABLE FIRST (for fresh DB)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS transactions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            portfolio TEXT DEFAULT 'KFH',
            stock_symbol TEXT NOT NULL,
            txn_date TEXT NOT NULL,
            txn_type TEXT NOT NULL, 
            purchase_cost REAL NOT NULL DEFAULT 0,
            sell_value REAL NOT NULL DEFAULT 0,
            shares REAL NOT NULL DEFAULT 0,
            bonus_shares REAL NOT NULL DEFAULT 0,
            cash_dividend REAL NOT NULL DEFAULT 0,
            reinvested_dividend REAL NOT NULL DEFAULT 0,
            price_override REAL,
            planned_cum_shares REAL,
            fees REAL DEFAULT 0,
            broker TEXT,
            reference TEXT,
            notes TEXT,
            category TEXT DEFAULT 'portfolio',
            created_at INTEGER NOT NULL
        )
        """
    )
    conn.commit()
    
    # Ensure transactions has user_id (auto-migration for existing DBs)
    add_column_if_missing("transactions", "user_id", "INTEGER")
    add_column_if_missing("transactions", "portfolio", "TEXT DEFAULT 'KFH'")
    add_column_if_missing("transactions", "category", "TEXT DEFAULT 'portfolio'")

    # Transactions MIGRATION: Check if we need to expand txn_type constraint
    cur.execute("PRAGMA table_info(transactions)")
    cols = [r[1] for r in cur.fetchall()]

    # Check if we need to remove the strict CHECK constraint on txn_type
    # We do this by checking if we can insert a 'Deposit' type.
    try:
        cur.execute("INSERT INTO transactions (stock_symbol, txn_date, txn_type, created_at, user_id) VALUES ('TEST_Check', '2000-01-01', 'Deposit', 0, -1)")
        cur.execute("DELETE FROM transactions WHERE stock_symbol='TEST_Check'")
        # If successful, constraint is gone or compatible
    except sqlite3.IntegrityError:
        # Constraint exists. We need to recreate the table.
        # Rename old
        cur.execute("ALTER TABLE transactions RENAME TO transactions_old")
        
        # Create new with WIDER types and PORTFOLIO column
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS transactions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                portfolio TEXT DEFAULT 'KFH',
                stock_symbol TEXT NOT NULL,
                txn_date TEXT NOT NULL,
                txn_type TEXT NOT NULL, 
                purchase_cost REAL NOT NULL DEFAULT 0,
                sell_value REAL NOT NULL DEFAULT 0,
                shares REAL NOT NULL DEFAULT 0,
                bonus_shares REAL NOT NULL DEFAULT 0,
                cash_dividend REAL NOT NULL DEFAULT 0,
                reinvested_dividend REAL NOT NULL DEFAULT 0,
                price_override REAL,
                planned_cum_shares REAL,
                fees REAL DEFAULT 0,
                broker TEXT,
                reference TEXT,
                notes TEXT,
                category TEXT,
                created_at INTEGER NOT NULL
            )
            """
        )
        
        # Copy data
        # Mapping old columns to new. 'portfolio' needs to be inferred from stocks table if possible
        # For now we default to KFH or try to join? 
        # Joining in an INSERT SELECT is possible.
        # NOTE: We avoid joining on stocks.user_id since it may not exist yet
        cur.execute("""
            INSERT INTO transactions (
                id, user_id, portfolio, stock_symbol, txn_date, txn_type, 
                purchase_cost, sell_value, shares, bonus_shares, 
                cash_dividend, reinvested_dividend, notes, created_at, category
            )
            SELECT 
                t.id, t.user_id, 'KFH', t.stock_symbol, t.txn_date, t.txn_type,
                t.purchase_cost, t.sell_value, t.shares, t.bonus_shares,
                t.cash_dividend, t.reinvested_dividend, t.notes, t.created_at, t.category
            FROM transactions_old t
        """)
        
        # Drop old
        cur.execute("DROP TABLE transactions_old")

    conn.commit()
    conn.close()

    # ---- MIGRATION TO MULTI-USER ----
    # 1. Add user_id to all tables if missing
    for tbl in ["stocks", "transactions", "portfolio_cash", "cash_deposits"]:
        add_column_if_missing(tbl, "user_id", "INTEGER DEFAULT 1") # Default 1 for legacy data

    # 2. Fix 'stocks' unique constraint (UNIQUE(symbol) -> UNIQUE(symbol, user_id))
    # Check if we need to migrate
    conn = get_conn()
    cur = conn.cursor()
    try:
        # Check if index is on just symbol
        cur.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name='stocks'")
        res = cur.fetchone()
        if res:
            schema = res[0]
            if "UNIQUE(symbol, user_id)" not in schema and "UNIQUE (symbol, user_id)" not in schema:
                 # It likely has UNIQUE(symbol) or similar.
                 # We should reconstruct the table.
                 # st.info("Upgrading 'stocks' table for multi-user support...")
                 cur.execute("ALTER TABLE stocks RENAME TO stocks_old")
                 cur.execute("""
                    CREATE TABLE stocks (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        user_id INTEGER DEFAULT 1,
                        symbol TEXT NOT NULL,
                        name TEXT,
                        current_price REAL DEFAULT 0,
                        portfolio TEXT DEFAULT 'KFH',
                        currency TEXT DEFAULT 'KWD',
                        tradingview_symbol TEXT,
                        tradingview_exchange TEXT,
                        UNIQUE(symbol, user_id)
                    )
                 """)
                 # Copy data - Handle potentially missing columns in old table gracefully if possible, but assuming standard schema here
                 # We just select known columns.
                 # Note: If cols missing in old table this might fail. But add_column_if_missing ran above so they should exist?
                 # Wait, add_column_if_missing runs on 'stocks' (the renamed one? No, we renamed it just now).
                 # Before rename, we haven't run add_column_if_missing on 'stocks' in THIS function run yet (it's below).
                 # So we rely on existing schema.
                 
                 # Better to select specific columns we know exist or use * if easy.
                 # Let's rely on add_column_if_missing having run in previous versions of the app.
                 cur.execute("INSERT INTO stocks (id, symbol, name) SELECT id, symbol, name FROM stocks_old")
                 
                 # Now update the other columns using UPDATE from old table, or just let them be default?
                 # If we just insert symbol/name, we lose prices/portfolio info!
                 # We must copy all data.
                 # PRAGMA table_info to get columns?
                 # Simpler: Just try to copy what we expect.
                 
                 cur.execute("UPDATE stocks SET current_price = (SELECT current_price FROM stocks_old WHERE stocks_old.id = stocks.id)")
                 cur.execute("UPDATE stocks SET portfolio = (SELECT portfolio FROM stocks_old WHERE stocks_old.id = stocks.id)")
                 cur.execute("UPDATE stocks SET currency = (SELECT currency FROM stocks_old WHERE stocks_old.id = stocks.id)")
                 cur.execute("UPDATE stocks SET tradingview_symbol = (SELECT tradingview_symbol FROM stocks_old WHERE stocks_old.id = stocks.id)")
                 
                 cur.execute("DROP TABLE stocks_old")
                 conn.commit()
    except Exception as e:
        # If migration fails, ensure we still have proper columns via add_column_if_missing
        try:
            conn.rollback()
        except:
            pass
        pass

    # Ensure stocks table has all needed columns (in case migration failed or table was created with old schema)
    add_column_if_missing("stocks", "current_price", "REAL DEFAULT 0")
    add_column_if_missing("stocks", "portfolio", "TEXT DEFAULT 'KFH'")
    add_column_if_missing("stocks", "currency", "TEXT DEFAULT 'KWD'")
    add_column_if_missing("stocks", "tradingview_symbol", "TEXT")
    add_column_if_missing("stocks", "tradingview_exchange", "TEXT")

    # 3. Fix 'portfolio_cash' PK (PK(portfolio) -> PK(portfolio, user_id))
    try:
        cur.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name='portfolio_cash'")
        res = cur.fetchone()
        if res:
            schema = res[0]
            if "PRIMARY KEY (portfolio, user_id)" not in schema and "PRIMARY KEY(portfolio, user_id)" not in schema:
                 # st.info("Upgrading 'portfolio_cash' table...")
                 cur.execute("ALTER TABLE portfolio_cash RENAME TO portfolio_cash_old")
                 cur.execute("""
                    CREATE TABLE IF NOT EXISTS portfolio_cash (
                        portfolio TEXT,
                        user_id INTEGER DEFAULT 1,
                        balance REAL,
                        currency TEXT DEFAULT 'KWD',
                        last_updated INTEGER,
                        manual_override INTEGER DEFAULT 0,
                        PRIMARY KEY (portfolio, user_id)
                    )
                 """)
                 cur.execute("INSERT INTO portfolio_cash (portfolio, balance, currency, last_updated) SELECT portfolio, balance, currency, last_updated FROM portfolio_cash_old")
                 cur.execute("UPDATE portfolio_cash SET user_id = 1")
                 cur.execute("DROP TABLE portfolio_cash_old")
                 conn.commit()
    except Exception as e:
         pass
    
    conn.close()

    # ---- Auto-upgrade (safe for existing DBs) ----
    add_column_if_missing("stocks", "current_price", "REAL DEFAULT 0")
    add_column_if_missing("stocks", "portfolio", "TEXT DEFAULT 'KFH'")   # âœ… KFH / BBYN / USA
    add_column_if_missing("stocks", "currency", "TEXT DEFAULT 'KWD'")    # âœ… KWD / USD
    add_column_if_missing("stocks", "tradingview_symbol", "TEXT")
    add_column_if_missing("stocks", "tradingview_exchange", "TEXT")

    add_column_if_missing("transactions", "price_override", "REAL DEFAULT NULL")
    add_column_if_missing("transactions", "planned_cum_shares", "REAL DEFAULT NULL")
    add_column_if_missing("transactions", "fees", "REAL DEFAULT 0")
    add_column_if_missing("transactions", "broker", "TEXT")
    add_column_if_missing("transactions", "reference", "TEXT")
    add_column_if_missing("transactions", "bonus_shares", "REAL DEFAULT 0")
    add_column_if_missing("transactions", "cash_dividend", "REAL DEFAULT 0")
    add_column_if_missing("transactions", "category", "TEXT DEFAULT 'portfolio'")  # 'portfolio' or 'trading'
    add_column_if_missing("transactions", "fx_rate_at_txn", "REAL DEFAULT NULL")  # Historical USD/KWD rate
    # Soft-delete columns (Undo/Redo support)
    add_column_if_missing("transactions", "is_deleted", "INTEGER DEFAULT 0")
    add_column_if_missing("transactions", "deleted_at", "INTEGER")  # Unix timestamp
    add_column_if_missing("transactions", "deleted_by", "INTEGER")  # User ID who deleted
    
    # Migrate CHECK constraint to allow DIVIDEND_ONLY (if needed)
    def migrate_transaction_type_constraint():
        """Update CHECK constraint to allow DIVIDEND_ONLY transaction type"""
        conn = get_conn()
        cur = conn.cursor()
        
        # Check if we need to migrate by testing if DIVIDEND_ONLY is allowed
        try:
            cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='transactions'")
            if cur.fetchone():
                # Get the current schema
                cur.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name='transactions'")
                schema = cur.fetchone()
                if schema and "DIVIDEND_ONLY" not in schema[0]:
                    # Need to migrate - recreate table with new constraint
                    cur.execute("PRAGMA foreign_keys=off")
                    cur.execute("BEGIN TRANSACTION")
                    
                    # Rename old table
                    cur.execute("ALTER TABLE transactions RENAME TO transactions_old")
                    
                    # Create new table with updated constraint
                    cur.execute("""
                        CREATE TABLE transactions (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            stock_symbol TEXT NOT NULL,
                            txn_date TEXT NOT NULL,
                            txn_type TEXT NOT NULL CHECK(txn_type IN ('Buy','Sell','DIVIDEND_ONLY')),
                            purchase_cost REAL NOT NULL DEFAULT 0,
                            sell_value REAL NOT NULL DEFAULT 0,
                            shares REAL NOT NULL DEFAULT 0,
                            reinvested_dividend REAL NOT NULL DEFAULT 0,
                            notes TEXT,
                            created_at INTEGER NOT NULL,
                            price_override REAL DEFAULT NULL,
                            planned_cum_shares REAL DEFAULT NULL,
                            fees REAL DEFAULT 0,
                            broker TEXT,
                            reference TEXT,
                            bonus_shares REAL DEFAULT 0,
                            cash_dividend REAL DEFAULT 0,
                            category TEXT DEFAULT 'portfolio'
                        )
                    """)
                    
                    # Copy data from old table
                    cur.execute("""
                        INSERT INTO transactions 
                        SELECT * FROM transactions_old
                    """)
                    
                    # Drop old table
                    cur.execute("DROP TABLE transactions_old")
                    cur.execute("COMMIT")
                    cur.execute("PRAGMA foreign_keys=on")
                    
                    conn.commit()
        except Exception as e:
            conn.rollback()
            logger.debug(f"Migration info: {e}")
        finally:
            conn.close()
    
    # NOTE: Migration disabled for performance - only needed once
    # migrate_transaction_type_constraint()
    
    # Portfolio tracker snapshots
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS portfolio_snapshots (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER DEFAULT 1,
            snapshot_date TEXT NOT NULL,
            portfolio_value REAL NOT NULL,
            daily_movement REAL DEFAULT 0,
            beginning_difference REAL DEFAULT 0,
            deposit_cash REAL DEFAULT 0,
            accumulated_cash REAL DEFAULT 0,
            net_gain REAL DEFAULT 0,
            change_percent REAL DEFAULT 0,
            roi_percent REAL DEFAULT 0,
            created_at INTEGER NOT NULL,
            UNIQUE(snapshot_date, user_id)
        )
        """
    )
    
    # Migration for portfolio_snapshots to multi-user (UNIQUE snapshot_date -> UNIQUE snapshot_date, user_id)
    try:
        cur.execute("SELECT sql FROM sqlite_master WHERE type='table' AND name='portfolio_snapshots'")
        res = cur.fetchone()
        if res:
            schema = res[0]
            if "UNIQUE(snapshot_date, user_id)" not in schema and "UNIQUE (snapshot_date, user_id)" not in schema:
                # Need to migrate
                cur.execute("ALTER TABLE portfolio_snapshots RENAME TO portfolio_snapshots_old")
                cur.execute("""
                    CREATE TABLE portfolio_snapshots (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        user_id INTEGER DEFAULT 1,
                        snapshot_date TEXT NOT NULL,
                        portfolio_value REAL NOT NULL,
                        daily_movement REAL DEFAULT 0,
                        beginning_difference REAL DEFAULT 0,
                        deposit_cash REAL DEFAULT 0,
                        accumulated_cash REAL DEFAULT 0,
                        net_gain REAL DEFAULT 0,
                        change_percent REAL DEFAULT 0,
                        roi_percent REAL DEFAULT 0,
                        created_at INTEGER NOT NULL,
                        UNIQUE(snapshot_date, user_id)
                    )
                """)
                # Copy columns explicitly to match schema
                cur.execute("""
                    INSERT INTO portfolio_snapshots (id, user_id, snapshot_date, portfolio_value, daily_movement, beginning_difference, deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at)
                    SELECT id, 1, snapshot_date, portfolio_value, daily_movement, beginning_difference, deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at 
                    FROM portfolio_snapshots_old
                """)
                cur.execute("DROP TABLE portfolio_snapshots_old")
                conn.commit()
    except Exception:
        pass

    conn.commit()
    conn.close()
    
    # ============================================
    # PFM (Personal Financial Management) TABLES
    # ============================================
    conn = get_conn()
    cur = conn.cursor()
    
    # PFM Snapshots - master table for each reporting date
    cur.execute("""
        CREATE TABLE IF NOT EXISTS pfm_snapshots (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            snapshot_date TEXT NOT NULL,
            notes TEXT,
            created_at INTEGER NOT NULL,
            UNIQUE(user_id, snapshot_date)
        )
    """)
    
    # PFM Income & Expense Items
    cur.execute("""
        CREATE TABLE IF NOT EXISTS pfm_income_expense_items (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            snapshot_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            kind TEXT NOT NULL CHECK(kind IN ('income', 'expense')),
            category TEXT NOT NULL,
            monthly_amount REAL NOT NULL DEFAULT 0,
            is_finance_cost INTEGER DEFAULT 0,
            is_gna INTEGER DEFAULT 0,
            sort_order INTEGER DEFAULT 0,
            FOREIGN KEY (snapshot_id) REFERENCES pfm_snapshots(id) ON DELETE CASCADE
        )
    """)
    
    # PFM Asset Items
    cur.execute("""
        CREATE TABLE IF NOT EXISTS pfm_asset_items (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            snapshot_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            asset_type TEXT NOT NULL CHECK(asset_type IN ('real_estate', 'shares', 'gold', 'cash', 'crypto', 'other')),
            category TEXT NOT NULL,
            name TEXT NOT NULL,
            quantity REAL,
            price REAL,
            currency TEXT DEFAULT 'KWD',
            value_kwd REAL NOT NULL DEFAULT 0,
            FOREIGN KEY (snapshot_id) REFERENCES pfm_snapshots(id) ON DELETE CASCADE
        )
    """)
    
    # PFM Liability Items
    cur.execute("""
        CREATE TABLE IF NOT EXISTS pfm_liability_items (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            snapshot_id INTEGER NOT NULL,
            user_id INTEGER NOT NULL,
            category TEXT NOT NULL,
            amount_kwd REAL NOT NULL DEFAULT 0,
            is_current INTEGER DEFAULT 0,
            is_long_term INTEGER DEFAULT 0,
            FOREIGN KEY (snapshot_id) REFERENCES pfm_snapshots(id) ON DELETE CASCADE
        )
    """)
    
    conn.commit()
    conn.close()
    logger.info("âœ… PFM tables created.")
    
    # ============================================
    # SECURITIES MASTER TABLES (Three-Layer Architecture)
    # Layer 1: Canonical Securities Master (Single Source of Truth)
    # Layer 2: Alias Resolution (Maps variations to canonical security_id)
    # Layer 3: Exchange-aware price fetching (implemented in functions)
    # ============================================
    conn = get_conn()
    cur = conn.cursor()
    
    # Layer 1: Securities Master - Canonical source of truth for all securities (per user)
    cur.execute("""
        CREATE TABLE IF NOT EXISTS securities_master (
            security_id TEXT PRIMARY KEY,
            user_id INTEGER NOT NULL DEFAULT 1,
            exchange TEXT NOT NULL,
            canonical_ticker TEXT NOT NULL,
            display_name TEXT,
            isin TEXT,
            currency TEXT NOT NULL DEFAULT 'KWD',
            country TEXT NOT NULL DEFAULT 'KW',
            status TEXT DEFAULT 'active' CHECK(status IN ('active', 'delisted', 'suspended')),
            sector TEXT,
            created_at INTEGER,
            updated_at INTEGER,
            UNIQUE(canonical_ticker, exchange, user_id)
        )
    """)
    
    # Add user_id column if missing (migration for existing tables)
    add_column_if_missing("securities_master", "user_id", "INTEGER DEFAULT 1")
    
    # Layer 2: Security Aliases - Maps raw symbols to security_id (per user)
    cur.execute("""
        CREATE TABLE IF NOT EXISTS security_aliases (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL DEFAULT 1,
            security_id TEXT NOT NULL,
            alias_name TEXT NOT NULL,
            alias_type TEXT DEFAULT 'user_input' CHECK(alias_type IN ('user_input', 'broker_format', 'official', 'legacy')),
            valid_from TEXT,
            valid_until TEXT,
            created_at INTEGER,
            FOREIGN KEY (security_id) REFERENCES securities_master(security_id),
            UNIQUE(alias_name, security_id, user_id)
        )
    """)
    
    # Add user_id column if missing (migration for existing tables)
    add_column_if_missing("security_aliases", "user_id", "INTEGER DEFAULT 1")
    
    # Add security_id column to transactions table for proper linking
    add_column_if_missing("transactions", "security_id", "TEXT")
    
    # Create indexes for securities lookup performance
    cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_exchange ON securities_master(exchange)")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_ticker ON securities_master(canonical_ticker)")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_securities_country ON securities_master(country)")
    if is_postgres():
        cur.execute("CREATE INDEX IF NOT EXISTS idx_aliases_name ON security_aliases(LOWER(alias_name))")
    else:
        cur.execute("CREATE INDEX IF NOT EXISTS idx_aliases_name ON security_aliases(alias_name COLLATE NOCASE)")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_aliases_security ON security_aliases(security_id)")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_security_id ON transactions(security_id)")
    
    conn.commit()
    conn.close()
    logger.info("âœ… Securities Master tables created.")
    
    # ============================================
    # DATABASE INDEXES FOR PERFORMANCE
    # ============================================
    conn = get_conn()
    cur = conn.cursor()
    try:
        # Index on user_id for fast filtering (critical for multi-user queries)
        cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_user ON transactions(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_stocks_user ON stocks(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_snapshots_user ON portfolio_snapshots(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_cash_deposits_user ON cash_deposits(user_id)")
        
        # Composite indexes for common query patterns
        cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_user_symbol ON transactions(user_id, stock_symbol)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_snapshots_user_date ON portfolio_snapshots(user_id, snapshot_date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_txn_user_date ON transactions(user_id, txn_date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_cash_deposits_user_date ON cash_deposits(user_id, deposit_date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_stocks_user_portfolio ON stocks(user_id, portfolio)")
        
        # PFM table indexes
        cur.execute("CREATE INDEX IF NOT EXISTS idx_pfm_snapshots_user ON pfm_snapshots(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_pfm_income_expense_user ON pfm_income_expense_items(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_pfm_assets_user ON pfm_asset_items(user_id)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_pfm_liabilities_user ON pfm_liability_items(user_id)")
        
        conn.commit()
        logger.info("âœ… Database indexes created for performance.")
    except Exception as e:
        logger.debug(f"Index creation skipped: {e}")
    finally:
        conn.close()
    
    # ============================================
    # FIX NULL/DEFAULT USER_IDs (after restore or legacy data import)
    # ============================================
    conn = get_conn()
    cur = conn.cursor()
    try:
        # Fix NULL/default user_ids by assigning to first active user with real data
        # First, find the main user (user with most transactions, typically user_id = 2)
        cur.execute("""
            SELECT user_id, COUNT(*) as cnt 
            FROM transactions 
            WHERE user_id > 1 
            GROUP BY user_id 
            ORDER BY cnt DESC 
            LIMIT 1
        """)
        row = cur.fetchone()
        if row:
            default_user_id = row[0]
        else:
            # Fallback: find first user > 1
            cur.execute("SELECT id FROM users WHERE id > 1 ORDER BY id LIMIT 1")
            row = cur.fetchone()
            default_user_id = row[0] if row else 2
        
        # Fix cash_deposits with NULL user_id
        db_execute(cur, "UPDATE cash_deposits SET user_id = ? WHERE user_id IS NULL", (default_user_id,))
        fixed_cash = cur.rowcount
        
        # Fix transactions with NULL user_id
        db_execute(cur, "UPDATE transactions SET user_id = ? WHERE user_id IS NULL", (default_user_id,))
        fixed_txn = cur.rowcount
        
        # Fix stocks with NULL user_id  
        db_execute(cur, "UPDATE stocks SET user_id = ? WHERE user_id IS NULL", (default_user_id,))
        fixed_stocks = cur.rowcount
        
        # Fix portfolio_snapshots with NULL user_id OR default user_id=1 when main user is different
        db_execute(cur, "UPDATE portfolio_snapshots SET user_id = ? WHERE user_id IS NULL", (default_user_id,))
        fixed_snapshots = cur.rowcount
        
        # Also migrate user_id=1 to main user if main user exists and has data
        if default_user_id > 1:
            cur.execute("SELECT COUNT(*) FROM portfolio_snapshots WHERE user_id = 1")
            old_user_count = cur.fetchone()[0]
            db_execute(cur, "SELECT COUNT(*) FROM portfolio_snapshots WHERE user_id = ?", (default_user_id,))
            new_user_count = cur.fetchone()[0]
            
            # If user_id=1 has snapshots but main user doesn't, migrate them
            if old_user_count > 0 and new_user_count == 0:
                db_execute(cur, "UPDATE portfolio_snapshots SET user_id = ? WHERE user_id = 1", (default_user_id,))
                fixed_snapshots += cur.rowcount
        
        conn.commit()
        
        total_fixed = fixed_cash + fixed_txn + fixed_stocks + fixed_snapshots
        if total_fixed > 0:
            logger.info(f"âœ… Fixed {total_fixed} records with NULL/default user_id (assigned to user {default_user_id})")
    except Exception as e:
        logger.debug(f"User ID fix skipped: {e}")
    finally:
        conn.close()
    
    # ============================================
    # STEP 3: PERFORMANCE INDEXES
    # ============================================
    conn = get_conn()
    cur = conn.cursor()
    try:
        # Create indexes for faster lookups
        if is_postgres():
            cur.execute("CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_users_username ON users(username);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_transactions_user ON transactions(user_id);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_stocks_user ON stocks(user_id);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_snapshots_user ON portfolio_snapshots(user_id);")
        else:
            # SQLite syntax
            cur.execute("CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_users_username ON users(username);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_transactions_user ON transactions(user_id);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_stocks_user ON stocks(user_id);")
            cur.execute("CREATE INDEX IF NOT EXISTS idx_snapshots_user ON portfolio_snapshots(user_id);")
        conn.commit()
        logger.info("âœ… Performance indexes created.")
    except Exception as e:
        logger.debug(f"Index creation note: {e}")
    finally:
        conn.close()
    
    # ============================================
    # STEP 4: NORMALIZED SCHEMA (Phase 1)
    # ============================================
    _ensure_normalized_schema()
    logger.info("âœ… Step 4: Normalized schema tables created.")
    
    # ============================================
    # STEP 5: VERIFICATION
    # ============================================
    logger.info("âœ… Step 5: Database initialized. Users table verified.")
    logger.info("ðŸ”§ All tables created successfully.")
    
    # ============================================
    # SEED DEFAULT ADMIN USER (for cloud deployment)
    # ============================================
    seed_default_admin()


def seed_default_admin():
    """
    Create a default admin user if the users table is empty.
    
    SECURITY: Only seeds admin in development mode or when
    INIT_ADMIN_USER env var is set. This prevents backdoors in production.
    """
    import os
    
    # Security check: Don't seed admin in production unless explicitly requested
    if IS_PRODUCTION and not os.getenv("INIT_ADMIN_USER"):
        logger.info("âš ï¸ Skipping admin seed in production (set INIT_ADMIN_USER=1 to override)")
        return
    
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        cur.execute("SELECT count(*) FROM users")
        user_count = cur.fetchone()[0]
        
        if user_count == 0:
            import time
            
            # Hash the password with bcrypt
            try:
                import bcrypt
                hashed_pw = bcrypt.hashpw("admin123".encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
            except ImportError:
                # Fallback if bcrypt not available (plain text - not recommended for production)
                hashed_pw = "admin123"
                logger.warning("âš ï¸ WARNING: bcrypt not available, using plain text password")
            
            db_execute(cur,
                "INSERT INTO users (username, email, password_hash, created_at) VALUES (?, ?, ?, ?)",
                ('admin', 'admin@cloud.com', hashed_pw, int(time.time()))
            )
            conn.commit()
            logger.info("âœ… Default Admin User Created: admin / admin123")
            logger.warning("âš ï¸ IMPORTANT: Change this password after first login!")
    except Exception as e:
        logger.error(f"Admin seed error: {e}")
    finally:
        conn.close()


# =========================
# UTIL
# =========================
def safe_float(v, default: float = 0.0) -> float:
    """Safely convert a value to float, returning default on failure."""
    try:
        if v is None or v == "":
            return default
        return float(v)
    except Exception:
        return default


def convert_to_kwd(amount: float, ccy: str) -> float:
    """Convert amount from given currency to KWD.
    
    Rate Source Hierarchy (for USDâ†’KWD):
    1. st.session_state.usd_to_kwd (updated on page load via fetch_usd_kwd_rate)
    2. DEFAULT_USD_TO_KWD constant (fallback if session state unavailable)
    
    Safe for use both within Streamlit and standalone scripts.
    """
    if amount is None:
        return 0.0
    try:
        amount = float(amount)
    except (TypeError, ValueError):
        return 0.0
        
    if ccy is None:
        ccy = "KWD"  # Default to KWD if currency not specified
        
    if ccy == "KWD":
        return amount
    if ccy == "USD":
        # Safe access to session state with fallback to default
        try:
            rate = st.session_state.get("usd_to_kwd", DEFAULT_USD_TO_KWD)
            if rate is None:
                rate = DEFAULT_USD_TO_KWD
        except (AttributeError, RuntimeError):
            rate = DEFAULT_USD_TO_KWD
        return amount * float(rate)
    return amount  # fallback for other currencies


def get_current_fx_rate() -> float:
    """Get the current USDâ†’KWD exchange rate for storage in transactions/deposits.
    
    This rate should be stored with each transaction/deposit to enable accurate
    historical reporting (vs. using today's rate for all historical data).
    
    Returns:
        float: Current USD/KWD rate (e.g., 0.3072)
    """
    try:
        rate = st.session_state.get("usd_to_kwd", None)
        if rate is not None and rate > 0:
            return float(rate)
    except (AttributeError, RuntimeError):
        pass
    
    # Fallback: try to fetch fresh rate
    try:
        rate = fetch_usd_kwd_rate(max_retries=1)
        if rate and rate > 0:
            return float(rate)
    except Exception:
        pass
    
    return DEFAULT_USD_TO_KWD


def fmt_money(amount: float, ccy: str) -> str:
    """Format money with appropriate decimals for currency."""
    if st.session_state.get("privacy_mode", False):
        return "*****"
    if amount is None:
        amount = 0.0
    if ccy == "KWD":
        return f"{ccy} {amount:,.3f}"
    elif ccy == "USD":
        return f"{ccy} {amount:,.2f}"
    else:
        return f"{ccy} {amount:,.2f}"


def fmt_money_plain(x, d=0):
    """Format money without currency prefix. Default 0 decimals for money values."""
    if st.session_state.get("privacy_mode", False):
        return "*****"
    try:
        return f"{float(x):,.{d}f}"
    except Exception:
        return f"{0:,.{d}f}"


def fmt_kwd(amount):
    """Format amount as KWD (for use with .map())."""
    return fmt_money(amount, "KWD")


def format_financial(value, type_hint: str, for_html: bool = True) -> str:
    """
    Central formatter for all financial values.
    
    Args:
        value: The numeric value to format
        type_hint: One of "quantity", "money", "price", "percent"
        for_html: If True, returns HTML with color spans. If False, returns plain text.
    
    Returns:
        Formatted string with appropriate styling
    
    Examples:
        format_financial(13628, "quantity")     â†’ "13,628"
        format_financial(7399.82, "money")      â†’ '<span style="color:#10b981">7,400</span>'
        format_financial(-899.09, "money")      â†’ '<span style="color:#ef4444">(899)</span>'
        format_financial(2.65, "price")         â†’ "2.650"
        format_financial(-0.5376, "percent")    â†’ '<span style="color:#ef4444">-0.54%</span>'
    """
    # Handle None/NaN
    if value is None or (isinstance(value, float) and pd.isna(value)):
        return "-"
    
    # Try to convert to float
    try:
        if isinstance(value, str):
            # Clean string values
            clean_str = value.replace(',', '').replace('%', '').replace(' KWD', '').replace('(', '-').replace(')', '')
            num = float(clean_str)
        else:
            num = float(value)
    except (ValueError, TypeError):
        return str(value)  # Return as-is if not numeric
    
    # Colors
    c_pos = "#10b981"  # Emerald Green
    c_neg = "#ef4444"  # Red
    
    if type_hint == "quantity":
        # Thousands separator, no decimals, default color
        return f"{num:,.0f}"
    
    elif type_hint == "money":
        # Monetary values: Green/Red, no decimals, thousands separator
        if num > 0:
            formatted = f"{num:,.0f}"
            if for_html:
                return f'<span style="color:{c_pos}">{formatted}</span>'
            return formatted
        elif num < 0:
            formatted = f"({abs(num):,.0f})"
            if for_html:
                return f'<span style="color:{c_neg}">{formatted}</span>'
            return formatted
        else:
            return "0"
    
    elif type_hint == "price":
        # Prices: 3 decimal places, default color
        if num == 0:
            return "-"
        return f"{num:,.3f}"
    
    elif type_hint == "percent":
        # Percentages: 2 decimals with % sign, Green/Red
        formatted = f"{num:.2f}%"
        if num > 0:
            if for_html:
                return f'<span style="color:{c_pos}">{formatted}</span>'
            return formatted
        elif num < 0:
            if for_html:
                return f'<span style="color:{c_neg}">{formatted}</span>'
            return formatted
        else:
            return "0.00%"
    
    else:
        # Fallback: return as-is with 2 decimals
        return f"{num:,.2f}"


def detect_column_type(col_name: str) -> str:
    """
    Detect the type of a column based on its name.
    
    Returns: "quantity", "money", "price", "percent", or "text"
    """
    col_lower = str(col_name).lower()
    
    # Quantity columns
    if any(k in col_lower for k in ['qty', 'quantity', 'shares', 'volume', 'units', 'bonus']):
        return "quantity"
    
    # Percentage columns
    if any(k in col_lower for k in ['%', 'percent', 'yield', 'roi', 'margin', 'rate', 'change', 'pnl %', 'weight']):
        return "percent"
    
    # Specific price columns (per-share prices - 3 decimals)
    # Must check exact patterns to distinguish from monetary values
    price_patterns = ['market price', 'avg cost', 'avg. cost', 'average cost', 'price cost', 
                      'sale price', 'current price', 'buy price', 'sell price', 'unit price',
                      'price per']
    if any(k in col_lower for k in price_patterns):
        return "price"
    
    # Money/Value columns - monetary totals (no decimals)
    if any(k in col_lower for k in ['value', 'total', 'gain', 'loss', 'profit', 'income', 
                                     'div', 'movement', 'amount', 'diff', 'balance', 
                                     'deposit', 'cash', 'market', 'unrealized', 'realized',
                                     'appreciation', 'net', 'pnl', 'cost']):
        return "money"
    
    # Fallback price check for standalone "price" 
    if 'price' in col_lower:
        return "price"
    
    return "text"


# =========================
# PORTFOLIO CALCULATOR
# =========================
class PortfolioCalculator:
    """Calculate advanced portfolio metrics: TWR, MWRR, CAGR."""
    
    @staticmethod
    def calculate_twr_detailed(
        start_date: str,
        end_date: str,
        transactions_df: pd.DataFrame,
        cash_deposits_df: pd.DataFrame,
        daily_mv_df: pd.DataFrame
    ) -> dict:
        """
        Calculate Time-Weighted Return (TWR) - Full CFA/GIPS Compliant Implementation.
        
        GIPS COMPLIANCE NOTES:
        - External flows (deposits/withdrawals) split performance periods
        - Buys/sells/dividends are EXCLUDED (internal reallocations)
        - Midpoint weighting (0.5) applied for daily-level data without intra-day timing
        - Geometric linking of subperiod returns: TWR = âˆ(1 + Ráµ¢) - 1
        
        Args:
            start_date: Period start date (ISO format 'YYYY-MM-DD')
            end_date: Period end date (ISO format 'YYYY-MM-DD')
            transactions_df: DataFrame with columns [timestamp/txn_date, txn_type, amount]
                            txn_type in ['deposit', 'withdrawal', 'buy', 'sell', 'dividend']
            cash_deposits_df: DataFrame with columns [deposit_date/timestamp, amount]
                             Supplemental source for deposits outside transactions table
            daily_mv_df: DataFrame with columns [date, portfolio_value/balance]
                        Daily end-of-day market valuations
        
        Returns:
            dict with keys:
                twr_decimal: float - TWR as decimal (e.g., 0.0823)
                twr_percent: str - TWR as percentage string (e.g., "8.23%")
                period_start: str - Start date
                period_end: str - End date
                subperiods: list - Detailed subperiod breakdown
                external_flows_detected: int - Count of external flows
                cash_deposits_included: bool - Whether cash_deposits table was used
                methodology: str - Description of methodology
                warnings: list - Any warnings about data quality
        """
        import logging
        warnings_list = []
        
        try:
            # Parse dates
            period_start = pd.to_datetime(start_date)
            period_end = pd.to_datetime(end_date)
            
            # Validate inputs
            if daily_mv_df is None or daily_mv_df.empty:
                return {
                    'twr_decimal': None,
                    'twr_percent': 'N/A',
                    'period_start': str(start_date),
                    'period_end': str(end_date),
                    'subperiods': [],
                    'external_flows_detected': 0,
                    'cash_deposits_included': False,
                    'methodology': 'GIPS daily rebalanced with midpoint weighting',
                    'warnings': ['No market value data available']
                }
            
            # Normalize daily_mv_df columns
            daily_mv = daily_mv_df.copy()
            if 'date' not in daily_mv.columns and 'snapshot_date' in daily_mv.columns:
                daily_mv = daily_mv.rename(columns={'snapshot_date': 'date'})
            if 'balance' not in daily_mv.columns and 'portfolio_value' in daily_mv.columns:
                daily_mv = daily_mv.rename(columns={'portfolio_value': 'balance'})
            
            daily_mv['date'] = pd.to_datetime(daily_mv['date'])
            daily_mv = daily_mv.sort_values('date').reset_index(drop=True)
            
            # Filter to period
            daily_mv = daily_mv[(daily_mv['date'] >= period_start) & (daily_mv['date'] <= period_end)]
            if daily_mv.empty:
                return {
                    'twr_decimal': None,
                    'twr_percent': 'N/A',
                    'period_start': str(start_date),
                    'period_end': str(end_date),
                    'subperiods': [],
                    'external_flows_detected': 0,
                    'cash_deposits_included': False,
                    'methodology': 'GIPS daily rebalanced with midpoint weighting',
                    'warnings': ['No market value data in specified period']
                }
            
            # STEP 1: Consolidate ALL external flows from both sources
            external_flows = []
            has_time_precision = True
            
            # 1A. From transactions table - ONLY deposits and withdrawals
            if transactions_df is not None and not transactions_df.empty:
                txn_df = transactions_df.copy()
                
                # Normalize column names
                ts_col = None
                for col in ['timestamp', 'txn_date', 'date']:
                    if col in txn_df.columns:
                        ts_col = col
                        break
                
                type_col = None
                for col in ['type', 'txn_type']:
                    if col in txn_df.columns:
                        type_col = col
                        break
                
                amt_col = None
                for col in ['amount', 'purchase_cost', 'sell_value']:
                    if col in txn_df.columns:
                        amt_col = col
                        break
                
                if ts_col and type_col:
                    txn_df['_ts'] = pd.to_datetime(txn_df[ts_col])
                    
                    # Check for time precision
                    sample_ts = txn_df['_ts'].iloc[0] if len(txn_df) > 0 else None
                    if sample_ts and sample_ts.hour == 0 and sample_ts.minute == 0 and sample_ts.second == 0:
                        has_time_precision = False
                        warnings_list.append(
                            "WARNING: Using daily midpoint weighting due to missing intra-day timestampsâ€”accuracy reduced per GIPS guidance."
                        )
                    
                    for _, row in txn_df.iterrows():
                        txn_type = str(row[type_col]).lower().strip()
                        
                        # CRITICAL: Only deposits and withdrawals are external flows
                        # Buys, sells, dividends are internal reallocations - EXCLUDE
                        if txn_type in ['deposit', 'withdrawal']:
                            flow_ts = row['_ts']
                            
                            # Skip flows outside period
                            if flow_ts < period_start or flow_ts > period_end:
                                continue
                            
                            flow_amount = float(row.get(amt_col, 0) or 0)
                            if abs(flow_amount) < 0.01:
                                continue
                            
                            # Sign convention
                            if txn_type == 'withdrawal':
                                flow_amount = -abs(flow_amount)
                            else:
                                flow_amount = abs(flow_amount)
                            
                            external_flows.append({
                                'timestamp': flow_ts,
                                'amount': flow_amount,
                                'source': 'transactions',
                                'type': txn_type
                            })
            
            # 1B. From cash_deposits table (MUST BE INCLUDED per requirements)
            cash_deposits_included = False
            if cash_deposits_df is not None and not cash_deposits_df.empty:
                cash_deposits_included = True
                cd_df = cash_deposits_df.copy()
                
                # Normalize column names
                ts_col = None
                for col in ['deposit_timestamp', 'deposit_date', 'timestamp', 'date']:
                    if col in cd_df.columns:
                        ts_col = col
                        break
                
                if ts_col:
                    cd_df['_ts'] = pd.to_datetime(cd_df[ts_col])
                    
                    for _, row in cd_df.iterrows():
                        flow_ts = row['_ts']
                        
                        # Skip flows outside period
                        if flow_ts < period_start or flow_ts > period_end:
                            continue
                        
                        flow_amount = float(row.get('amount', 0) or 0)
                        if abs(flow_amount) < 0.01:
                            continue
                        
                        # Cash deposits are always positive inflows
                        flow_amount = abs(flow_amount)
                        
                        external_flows.append({
                            'timestamp': flow_ts,
                            'amount': flow_amount,
                            'source': 'cash_deposits',
                            'type': 'deposit'
                        })
            
            # Sort flows chronologically
            external_flows.sort(key=lambda x: x['timestamp'])
            
            # Aggregate flows on same timestamp (edge case handling)
            aggregated_flows = []
            if external_flows:
                current_ts = external_flows[0]['timestamp']
                current_amount = 0.0
                for flow in external_flows:
                    if flow['timestamp'] == current_ts:
                        current_amount += flow['amount']
                    else:
                        if abs(current_amount) >= 0.01:
                            aggregated_flows.append({
                                'timestamp': current_ts,
                                'amount': current_amount
                            })
                        current_ts = flow['timestamp']
                        current_amount = flow['amount']
                # Don't forget last flow
                if abs(current_amount) >= 0.01:
                    aggregated_flows.append({
                        'timestamp': current_ts,
                        'amount': current_amount
                    })
            
            external_flows = aggregated_flows
            
            # STEP 2: Build subperiod boundaries
            mv_start = daily_mv.iloc[0]['date']
            mv_end = daily_mv.iloc[-1]['date']
            
            boundaries = [mv_start]
            for flow in external_flows:
                flow_date = flow['timestamp']
                # Normalize to date for boundary (daily granularity per GIPS)
                flow_date_only = pd.Timestamp(flow_date.date())
                if mv_start < flow_date_only < mv_end:
                    boundaries.append(flow_date_only)
            boundaries.append(mv_end)
            boundaries = sorted(set(boundaries))
            
            # STEP 3: Calculate subperiod returns
            subperiods = []
            subperiod_returns = []
            
            # No external flows case - single subperiod
            if len(external_flows) == 0:
                mv_begin_val = float(daily_mv.iloc[0]['balance'])
                mv_end_val = float(daily_mv.iloc[-1]['balance'])
                
                if mv_begin_val <= 0:
                    return {
                        'twr_decimal': None,
                        'twr_percent': 'N/A',
                        'period_start': str(start_date),
                        'period_end': str(end_date),
                        'subperiods': [],
                        'external_flows_detected': 0,
                        'cash_deposits_included': cash_deposits_included,
                        'methodology': 'GIPS daily rebalanced with midpoint weighting',
                        'warnings': ['Zero or negative starting market value']
                    }
                
                simple_return = (mv_end_val - mv_begin_val) / mv_begin_val
                
                subperiods.append({
                    'start': str(mv_start),
                    'end': str(mv_end),
                    'mv_begin': mv_begin_val,
                    'mv_end': mv_end_val,
                    'net_flow': 0.0,
                    'return': round(simple_return, 6)
                })
                
                return {
                    'twr_decimal': round(simple_return, 6),
                    'twr_percent': f"{simple_return * 100:.2f}%",
                    'period_start': str(start_date),
                    'period_end': str(end_date),
                    'subperiods': subperiods,
                    'external_flows_detected': 0,
                    'cash_deposits_included': cash_deposits_included,
                    'methodology': 'GIPS daily rebalanced with midpoint weighting',
                    'warnings': warnings_list
                }
            
            # Calculate each subperiod return
            for i in range(len(boundaries) - 1):
                t_begin = boundaries[i]
                t_end = boundaries[i + 1]
                
                # Get MV at beginning (EOD of t_begin or closest before)
                mv_begin_rows = daily_mv[daily_mv['date'] <= t_begin]
                if mv_begin_rows.empty:
                    mv_begin_val = float(daily_mv.iloc[0]['balance'])
                else:
                    mv_begin_val = float(mv_begin_rows.iloc[-1]['balance'])
                
                # Get MV at end (EOD of t_end or closest at/before)
                mv_end_rows = daily_mv[daily_mv['date'] <= t_end]
                if mv_end_rows.empty:
                    continue
                mv_end_val = float(mv_end_rows.iloc[-1]['balance'])
                
                # Sum flows DURING this subperiod (t_begin < flow <= t_end)
                cf_net = 0.0
                for flow in external_flows:
                    flow_date = pd.Timestamp(flow['timestamp'].date()) if hasattr(flow['timestamp'], 'date') else pd.Timestamp(flow['timestamp'])
                    if t_begin < flow_date <= t_end:
                        cf_net += flow['amount']
                
                # MIDPOINT WEIGHTING (GIPS standard)
                # R = (MV_end - MV_begin - CF) / (MV_begin + CF * 0.5)
                weighted_cf = cf_net * 0.5
                denominator = mv_begin_val + weighted_cf
                
                if abs(denominator) < 0.01:
                    subperiod_return = 0.0
                else:
                    subperiod_return = (mv_end_val - mv_begin_val - cf_net) / denominator
                
                subperiod_returns.append(subperiod_return)
                
                subperiods.append({
                    'start': str(t_begin),
                    'end': str(t_end),
                    'mv_begin': round(mv_begin_val, 2),
                    'mv_end': round(mv_end_val, 2),
                    'net_flow': round(cf_net, 2),
                    'return': round(subperiod_return, 6)
                })
            
            # STEP 4: Geometric linking - TWR = âˆ(1 + Ráµ¢) - 1
            if not subperiod_returns:
                return {
                    'twr_decimal': None,
                    'twr_percent': 'N/A',
                    'period_start': str(start_date),
                    'period_end': str(end_date),
                    'subperiods': subperiods,
                    'external_flows_detected': len(external_flows),
                    'cash_deposits_included': cash_deposits_included,
                    'methodology': 'GIPS daily rebalanced with midpoint weighting',
                    'warnings': ['No valid subperiod returns calculated']
                }
            
            twr_factor = 1.0
            for r in subperiod_returns:
                twr_factor *= (1.0 + r)
            
            twr_decimal = twr_factor - 1.0
            
            return {
                'twr_decimal': round(twr_decimal, 6),
                'twr_percent': f"{twr_decimal * 100:.2f}%",
                'period_start': str(start_date),
                'period_end': str(end_date),
                'subperiods': subperiods,
                'external_flows_detected': len(external_flows),
                'cash_deposits_included': cash_deposits_included,
                'methodology': 'GIPS daily rebalanced with midpoint weighting',
                'warnings': warnings_list
            }
            
        except Exception as e:
            return {
                'twr_decimal': None,
                'twr_percent': 'N/A',
                'period_start': str(start_date),
                'period_end': str(end_date),
                'subperiods': [],
                'external_flows_detected': 0,
                'cash_deposits_included': False,
                'methodology': 'GIPS daily rebalanced with midpoint weighting',
                'warnings': [f'Calculation error: {str(e)}']
            }
    
    @staticmethod
    def validate_twr_implementation() -> dict:
        """
        Run validation test suite for TWR implementation.
        
        Tests:
        1. Basic 2-subperiod case (CFA validation case)
        2. Cash deposit table integration
        3. Security trade exclusion
        
        Returns:
            dict with test results
        """
        results = {'passed': 0, 'failed': 0, 'tests': []}
        
        # TEST 1: Basic 2-subperiod case
        # Day 1: Start with 100,000
        # Day 2: Deposit 10,000, end at 115,500
        # Day 3: Withdraw 5,000, end at 108,000
        # 
        # Subperiod 1 (Day 1 -> Day 2):
        #   MV_begin = 100,000, MV_end = 115,500, CF = +10,000
        #   R1 = (115,500 - 100,000 - 10,000) / (100,000 + 10,000*0.5)
        #   R1 = 5,500 / 105,000 = 0.05238
        #
        # Subperiod 2 (Day 2 -> Day 3):
        #   MV_begin = 115,500, MV_end = 108,000, CF = -5,000
        #   R2 = (108,000 - 115,500 - (-5,000)) / (115,500 + (-5,000)*0.5)
        #   R2 = (108,000 - 115,500 + 5,000) / (115,500 - 2,500)
        #   R2 = -2,500 / 113,000 = -0.02212
        #
        # TWR = (1 + 0.05238) * (1 - 0.02212) - 1 = 0.02910 = 2.91%
        
        test1_mv = pd.DataFrame({
            'date': ['2026-01-01', '2026-01-02', '2026-01-03'],
            'balance': [100000, 115500, 108000]
        })
        
        test1_txn = pd.DataFrame({
            'timestamp': ['2026-01-02 10:00:00', '2026-01-03 14:00:00'],
            'type': ['deposit', 'withdrawal'],
            'amount': [10000, 5000]
        })
        
        test1_result = PortfolioCalculator.calculate_twr_detailed(
            '2026-01-01', '2026-01-03',
            test1_txn, pd.DataFrame(), test1_mv
        )
        
        expected_twr_1 = 0.0291  # ~2.91%
        actual_twr_1 = test1_result.get('twr_decimal')
        
        test1_pass = actual_twr_1 is not None and abs(actual_twr_1 - expected_twr_1) < 0.005
        results['tests'].append({
            'name': 'TEST 1: Basic 2-subperiod case',
            'passed': test1_pass,
            'expected': f"{expected_twr_1*100:.2f}%",
            'actual': f"{actual_twr_1*100:.2f}%" if actual_twr_1 else 'N/A',
            'subperiods': test1_result.get('subperiods', [])
        })
        if test1_pass:
            results['passed'] += 1
        else:
            results['failed'] += 1
        
        # TEST 2: Cash deposit table integration
        test2_mv = pd.DataFrame({
            'date': ['2026-01-04', '2026-01-05', '2026-01-06'],
            'balance': [100000, 127000, 128000]
        })
        
        # No transactions, but deposit via cash_deposits table
        test2_cash_deposits = pd.DataFrame({
            'deposit_date': ['2026-01-05 09:00:00'],
            'amount': [25000]
        })
        
        test2_result = PortfolioCalculator.calculate_twr_detailed(
            '2026-01-04', '2026-01-06',
            pd.DataFrame(), test2_cash_deposits, test2_mv
        )
        
        # Should detect the deposit as external flow
        test2_pass = (
            test2_result.get('external_flows_detected', 0) >= 1 and
            test2_result.get('cash_deposits_included', False) == True
        )
        results['tests'].append({
            'name': 'TEST 2: Cash deposit table integration',
            'passed': test2_pass,
            'expected': 'external_flows >= 1, cash_deposits_included = True',
            'actual': f"external_flows={test2_result.get('external_flows_detected')}, cash_deposits_included={test2_result.get('cash_deposits_included')}",
            'subperiods': test2_result.get('subperiods', [])
        })
        if test2_pass:
            results['passed'] += 1
        else:
            results['failed'] += 1
        
        # TEST 3: Security trade exclusion
        # Buy transaction should NOT create a subperiod split
        test3_mv = pd.DataFrame({
            'date': ['2026-01-09', '2026-01-10', '2026-01-11'],
            'balance': [100000, 102000, 104000]
        })
        
        test3_txn = pd.DataFrame({
            'timestamp': ['2026-01-10 10:00:00'],
            'type': ['buy'],  # Buy - should be IGNORED
            'amount': [10000]
        })
        
        test3_result = PortfolioCalculator.calculate_twr_detailed(
            '2026-01-09', '2026-01-11',
            test3_txn, pd.DataFrame(), test3_mv
        )
        
        # Buy should NOT be detected as external flow
        test3_pass = test3_result.get('external_flows_detected', 0) == 0
        results['tests'].append({
            'name': 'TEST 3: Security trade exclusion (buy/sell ignored)',
            'passed': test3_pass,
            'expected': 'external_flows = 0',
            'actual': f"external_flows = {test3_result.get('external_flows_detected')}",
            'subperiods': test3_result.get('subperiods', [])
        })
        if test3_pass:
            results['passed'] += 1
        else:
            results['failed'] += 1
        
        # TEST 4: Dividend exclusion
        test4_mv = pd.DataFrame({
            'date': ['2026-01-15', '2026-01-16'],
            'balance': [100000, 101000]
        })
        
        test4_txn = pd.DataFrame({
            'timestamp': ['2026-01-16 09:00:00'],
            'type': ['dividend'],  # Dividend - should be IGNORED
            'amount': [500]
        })
        
        test4_result = PortfolioCalculator.calculate_twr_detailed(
            '2026-01-15', '2026-01-16',
            test4_txn, pd.DataFrame(), test4_mv
        )
        
        test4_pass = test4_result.get('external_flows_detected', 0) == 0
        results['tests'].append({
            'name': 'TEST 4: Dividend exclusion (dividends are returns, not flows)',
            'passed': test4_pass,
            'expected': 'external_flows = 0',
            'actual': f"external_flows = {test4_result.get('external_flows_detected')}",
            'subperiods': test4_result.get('subperiods', [])
        })
        if test4_pass:
            results['passed'] += 1
        else:
            results['failed'] += 1
        
        # TEST 5: Zero denominator edge case
        test5_mv = pd.DataFrame({
            'date': ['2026-01-20', '2026-01-21'],
            'balance': [0, 10000]
        })
        
        test5_txn = pd.DataFrame({
            'timestamp': ['2026-01-21 09:00:00'],
            'type': ['deposit'],
            'amount': [10000]
        })
        
        test5_result = PortfolioCalculator.calculate_twr_detailed(
            '2026-01-20', '2026-01-21',
            test5_txn, pd.DataFrame(), test5_mv
        )
        
        # Should handle gracefully without error
        test5_pass = 'error' not in str(test5_result.get('warnings', [])).lower() or test5_result.get('twr_decimal') is not None
        results['tests'].append({
            'name': 'TEST 5: Zero denominator edge case',
            'passed': test5_pass,
            'expected': 'No crash, graceful handling',
            'actual': f"twr={test5_result.get('twr_percent')}, warnings={test5_result.get('warnings')}",
            'subperiods': test5_result.get('subperiods', [])
        })
        if test5_pass:
            results['passed'] += 1
        else:
            results['failed'] += 1
        
        results['summary'] = f"Passed: {results['passed']}/{results['passed']+results['failed']}"
        return results
    
    @staticmethod
    def calculate_twr(portfolio_history: pd.DataFrame, cash_flows: pd.DataFrame) -> Optional[float]:
        """
        Calculate Time-Weighted Return (TWR) - CFA/GIPS Compliant (Simplified API).
        
        This is the simplified wrapper for backward compatibility.
        For detailed output with subperiod breakdown, use calculate_twr_detailed().
        
        GIPS COMPLIANCE:
        - Only deposit/withdrawal split subperiods (buy/sell/dividend excluded)
        - Midpoint weighting (0.5) for daily-level data
        - Geometric linking: TWR = âˆ(1 + Ráµ¢) - 1
        
        Args:
            portfolio_history: DataFrame with columns [date, balance]
            cash_flows: DataFrame with columns [date, amount, type]
                       type should be 'DEPOSIT' or 'WITHDRAWAL' only
        
        Returns:
            TWR as decimal (e.g., 0.0823 = 8.23%) or None if calculation fails
        """
        try:
            if portfolio_history.empty:
                return None
            
            # Use the detailed implementation
            ph = portfolio_history.copy()
            if 'date' not in ph.columns and 'snapshot_date' in ph.columns:
                ph = ph.rename(columns={'snapshot_date': 'date'})
            
            ph['date'] = pd.to_datetime(ph['date'])
            start_date = ph['date'].min().strftime('%Y-%m-%d')
            end_date = ph['date'].max().strftime('%Y-%m-%d')
            
            # Prepare cash flows as transactions format
            cf_formatted = pd.DataFrame()
            if not cash_flows.empty:
                cf = cash_flows.copy()
                cf_formatted = pd.DataFrame({
                    'timestamp': pd.to_datetime(cf['date']),
                    'type': cf['type'].str.lower(),
                    'amount': cf['amount']
                })
            
            result = PortfolioCalculator.calculate_twr_detailed(
                start_date, end_date,
                cf_formatted, pd.DataFrame(), ph
            )
            
            return result.get('twr_decimal')
            
        except Exception as e:
            logging.error(f"TWR calculation error: {e}")
            return None
    
    @staticmethod
    def calculate_mwrr(cash_flows: pd.DataFrame, current_value: float, start_date: date) -> Optional[float]:
        """
        CFA-compliant XIRR (Money-Weighted Return) with robust convergence.
        
        Uses Newton-Raphson with bisection fallback.
        Cash flows must have columns [date, amount, type] where:
          - type='DEPOSIT'    â†’ sign forced negative  (money OUT of investor)
          - type='DIVIDEND'   â†’ sign forced positive  (money IN to investor)
          - type='WITHDRAWAL' â†’ sign forced positive  (money IN to investor)
        Final portfolio value is appended automatically as a positive terminal flow.
        
        Args:
            cash_flows: DataFrame with columns [date, amount, type]
            current_value: Current portfolio value (must be > 0)
            start_date: Portfolio inception date (used for validation only;
                        actual dates come from the DataFrame)
        Returns:
            Annualized IRR as decimal (e.g. 0.1174 = 11.74%) or None
        """
        try:
            # â”€â”€ validate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if current_value is None or current_value <= 0:
                return None

            # â”€â”€ 1. build signed cashâ€‘flow list â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            cf_dates: list = []
            cf_amounts: list = []

            if not cash_flows.empty:
                _cf = cash_flows.copy()
                _cf['date'] = pd.to_datetime(_cf['date'])

                for _, row in _cf.iterrows():
                    amt = float(row['amount'])
                    if amt == 0:
                        continue
                    cf_type = str(row['type']).upper()

                    if cf_type == 'DEPOSIT':
                        cf_amounts.append(-abs(amt))      # money leaving investor
                    elif cf_type in ('DIVIDEND', 'WITHDRAWAL'):
                        cf_amounts.append(abs(amt))        # money returning
                    else:
                        continue
                    cf_dates.append(pd.to_datetime(row['date']))

            # â”€â”€ 2. terminal value (simulated full liquidation today) â”€â”€
            today = pd.Timestamp.now()
            cf_dates.append(today)
            cf_amounts.append(abs(current_value))

            if len(cf_dates) < 2:
                return None

            # Must have at least one negative AND one positive
            if not (any(c < 0 for c in cf_amounts) and any(c > 0 for c in cf_amounts)):
                return None

            # â”€â”€ 3. sort & combine sameâ€‘day flows â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            pairs = sorted(zip(cf_dates, cf_amounts), key=lambda x: x[0])
            combined_dates: list = []
            combined_amounts: list = []
            prev_dt = None
            running = 0.0
            for dt, a in pairs:
                if prev_dt is None:
                    prev_dt, running = dt, a
                elif dt == prev_dt:
                    running += a
                else:
                    combined_dates.append(prev_dt)
                    combined_amounts.append(running)
                    prev_dt, running = dt, a
            if prev_dt is not None:
                combined_dates.append(prev_dt)
                combined_amounts.append(running)

            cf_dates = combined_dates
            cf_amounts = combined_amounts

            # â”€â”€ 4. yearâ€‘fraction helper (ACT/365.25) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            t0 = cf_dates[0]
            year_fracs = [(dt - t0).days / 365.25 for dt in cf_dates]

            # â”€â”€ 5. NPV & derivative â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            def _npv(rate):
                if rate <= -1.0:
                    return float('inf')
                s = 0.0
                for amt, tau in zip(cf_amounts, year_fracs):
                    s += amt / ((1.0 + rate) ** tau)
                return s

            def _d_npv(rate):
                if rate <= -1.0:
                    return float('inf')
                s = 0.0
                for amt, tau in zip(cf_amounts, year_fracs):
                    s += -tau * amt / ((1.0 + rate) ** (tau + 1.0))
                return s

            # â”€â”€ 6. Newtonâ€‘Raphson (primary solver) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            r = 0.10
            converged = False
            for _ in range(200):
                f_val = _npv(r)
                fp_val = _d_npv(r)

                if abs(fp_val) < 1e-14:
                    break

                r_next = r - f_val / fp_val
                # clamp to reasonable range
                r_next = max(-0.9999, min(r_next, 100.0))

                if abs(r_next - r) < 1e-10:
                    if abs(_npv(r_next)) < 0.01:
                        converged = True
                        r = r_next
                    break
                r = r_next

            if converged:
                return r

            # â”€â”€ 7. Bisection fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            lo, hi = -0.9999, 10.0
            npv_lo = _npv(lo)
            npv_hi = _npv(hi)

            # Widen range if needed
            if npv_lo * npv_hi > 0:
                for test_hi in [20.0, 50.0, 100.0]:
                    if _npv(lo) * _npv(test_hi) < 0:
                        hi = test_hi
                        break
                else:
                    # Check if Newton result is at least close
                    if abs(_npv(r)) < 1.0 and -0.99 < r < 100:
                        return r
                    return None

            for _ in range(1000):
                mid = (lo + hi) / 2.0
                npv_mid = _npv(mid)

                if abs(npv_mid) < 1e-8:
                    return mid

                if _npv(lo) * npv_mid < 0:
                    hi = mid
                else:
                    lo = mid

            return mid  # best estimate after max iterations

        except Exception as e:
            logger.error(f"MWRR/XIRR calculation error: {e}", exc_info=True)
            return None
    
    @staticmethod
    def calculate_cagr(v_start: float, v_end: float, date_start: date, date_end: date) -> Optional[float]:
        """
        Calculate Compound Annual Growth Rate (CAGR).

        âš ï¸  CAGR is NOT a performance metric per CFA/GIPS standards.
        It ignores ALL intermediate cash flows (deposits & withdrawals).
        Later deposits inflate V_end without affecting V_start â†’ misleading.

        Use TWR for investment skill, IRR for personal wealth growth.
        CAGR is a simple descriptive statistic ONLY.

        Args:
            v_start: First deposit amount (NOT accumulated_cash from snapshots)
            v_end:   Current portfolio market value
            date_start: Date of first deposit
            date_end:   Date of latest valuation

        Returns:
            CAGR as decimal (e.g., 0.125 = 12.5%) or None if calculation fails
        """
        try:
            if v_start <= 0:
                return None

            days = (date_end - date_start).days
            years = days / 365.25

            if years <= 0:
                return None

            cagr = (v_end / v_start) ** (1 / years) - 1
            return cagr

        except Exception as e:
            logging.error(f"CAGR calculation error: {e}")
            return None

    @staticmethod
    def calculate_win_rate(conn, user_id: int) -> dict:
        """
        Calculate win rate from completed sell transactions.
        Uses realized_pnl_at_txn for P&L (already computed at trade time).

        Returns dict with win_rate, counts, and insights.
        """
        try:
            sells = pd.read_sql(
                convert_sql_placeholders("""
                SELECT stock_symbol, txn_date, shares, sell_value,
                       realized_pnl_at_txn, avg_cost_at_txn, fees
                FROM transactions
                WHERE txn_type = 'Sell'
                  AND (is_deleted IS NULL OR is_deleted = 0)
                  AND realized_pnl_at_txn IS NOT NULL
                  AND user_id = ?
                ORDER BY txn_date
                """),
                conn,
                params=(user_id,),
            )

            if sells.empty:
                return {
                    'win_rate': None,
                    'total_trades': 0,
                    'winning_trades': 0,
                    'losing_trades': 0,
                    'breakeven_trades': 0,
                    'status': 'no_data',
                }

            sells['pnl'] = pd.to_numeric(sells['realized_pnl_at_txn'], errors='coerce').fillna(0)

            winning = sells[sells['pnl'] > 0]
            losing = sells[sells['pnl'] < 0]
            breakeven = sells[sells['pnl'] == 0]

            total_trades = len(sells)
            win_rate = (len(winning) / total_trades * 100) if total_trades > 0 else 0

            avg_win = float(winning['pnl'].mean()) if len(winning) > 0 else 0.0
            avg_loss = float(losing['pnl'].mean()) if len(losing) > 0 else 0.0
            total_profit = float(winning['pnl'].sum()) if len(winning) > 0 else 0.0
            total_loss = abs(float(losing['pnl'].sum())) if len(losing) > 0 else 0.0
            profit_factor = total_profit / total_loss if total_loss > 0 else float('inf')

            return {
                'win_rate': round(win_rate, 1),
                'total_trades': total_trades,
                'winning_trades': len(winning),
                'losing_trades': len(losing),
                'breakeven_trades': len(breakeven),
                'avg_win_kwd': round(avg_win, 2),
                'avg_loss_kwd': round(abs(avg_loss), 2),
                'total_profit_kwd': round(total_profit, 2),
                'total_loss_kwd': round(total_loss, 2),
                'profit_factor': round(profit_factor, 2),
                'status': 'success',
            }
        except Exception as e:
            logging.error(f"Win rate calculation error: {e}")
            return {
                'win_rate': None,
                'total_trades': 0,
                'winning_trades': 0,
                'losing_trades': 0,
                'breakeven_trades': 0,
                'status': 'error',
            }


def fmt_price(x, d=6):
    if st.session_state.get("privacy_mode", False):
        return "*****"
    try:
        return f"{float(x):.{d}f}"
    except Exception:
        return f"{0:.{d}f}"


def fmt_int(x):
    try:
        return f"{float(x):,.0f}"
    except Exception:
        return "0"


def pct(x, d=2):
    try:
        return f"{float(x)*100:.{d}f}%"
    except Exception:
        return "0.00%"

def _norm_col(c: str) -> str:
    return (
        str(c).strip().lower()
        .replace(" ", "_")
        .replace("-", "_")
        .replace("/", "_")
        .replace("__", "_")
    )

def _to_iso_date(x) -> str:
    if x is None or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and x.strip() == ""):
        return ""
    try:
        dt = pd.to_datetime(x)
        return dt.date().isoformat()
    except Exception:
        return ""


def _safe_str(x) -> str:
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    return str(x).strip()


def _safe_num(x, default=0.0) -> float:
    try:
        if x is None or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and x.strip() == ""):
            return float(default)
        return float(x)
    except Exception:
        return float(default)


from typing import Optional, List
def _pick_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:

    cols = set(df.columns)
    for c in candidates:
        if c in cols:
            return c
    return None

def compute_stock_metrics(tx_df: pd.DataFrame):
    if tx_df.empty:
        return {
            "total_buy_cost": 0.0,
            "total_buy_shares": 0.0,
            "current_shares": 0.0,
            "avg_cost": 0.0,
            "total_sell_value": 0.0,
            "total_reinvested": 0.0,
        }

    buy = tx_df[tx_df["txn_type"] == "Buy"]
    sell = tx_df[tx_df["txn_type"] == "Sell"]

    total_buy_cost = float(buy["purchase_cost"].sum())
    total_buy_shares = float(buy["shares"].sum())
    total_sell_value = float(sell["sell_value"].sum())
    total_reinvested = float(tx_df["reinvested_dividend"].sum())

    current_shares = float(buy["shares"].sum() - sell["shares"].sum() + tx_df.get("bonus_shares", 0).sum())
    avg_cost = (total_buy_cost / current_shares) if current_shares > 0 else 0.0

    return {
        "total_buy_cost": total_buy_cost,
        "total_buy_shares": total_buy_shares,
        "current_shares": current_shares,
        "avg_cost": float(avg_cost),
        "total_sell_value": total_sell_value,
        "total_reinvested": total_reinvested,
    }


def compute_transactions_view(tx_df: pd.DataFrame) -> pd.DataFrame:
    if tx_df.empty:
        return pd.DataFrame(columns=[
            "Serial", "id", "txn_date", "txn_type", "purchase_cost", "sell_value", "shares",
            "Price", "CUM shares", "planned_cum_shares", "Difference Shares",
            "bonus_shares", "cash_dividend", "reinvested_dividend",
            "fees", "broker", "reference", "notes", "created_at"
        ])

    df = tx_df.copy()
    df["txn_date"] = df["txn_date"].fillna("")
    df["created_at"] = df["created_at"].fillna(0)

    df = df.sort_values(["txn_date", "created_at", "id"], ascending=[True, True, True]).reset_index(drop=True)

    serial = []
    price_list = []
    cum_list = []
    diff_list = []

    running = 0.0

    for i, r in df.iterrows():
        serial.append(i + 1)

        shares = safe_float(r.get("shares", 0), 0)
        bonus = safe_float(r.get("bonus_shares", 0), 0)
        ttype = r.get("txn_type", "")
        pcost = safe_float(r.get("purchase_cost", 0), 0)
        svalue = safe_float(r.get("sell_value", 0), 0)
        override = r.get("price_override", None)
        planned = r.get("planned_cum_shares", None)

        # Auto price unless override exists
        if override is not None and str(override) != "" and pd.notna(override):
            p = safe_float(override, 0)
        else:
            if shares > 0 and ttype == "Buy":
                p = pcost / shares
            elif shares > 0 and ttype == "Sell":
                p = svalue / shares
            else:
                p = 0.0

        price_list.append(float(p))

        # cumulative shares
        if ttype == "Buy":
            running += shares
        elif ttype == "Sell":
            running -= shares

        # bonus shares always increase holdings
        running += bonus
        cum_list.append(float(running))

        # difference shares (if planned exists)
        if planned is None or str(planned) == "" or pd.isna(planned):
            diff_list.append(None)
        else:
            diff_list.append(float(safe_float(planned, 0) - running))

    df["Serial"] = serial
    df["Price"] = price_list
    df["CUM shares"] = cum_list
    df["Difference Shares"] = diff_list
    return df


# =========================
# PORTFOLIO ANALYSIS (FINANCE LOGIC)
# =========================
def compute_holdings_avg_cost(tx: pd.DataFrame):
    """
    CFA/IFRS-Compliant Weighted Average Cost Method:
    
    Core State Variables:
    - total_shares: Shares currently held
    - total_cost: Remaining cost basis of held shares
    - avg_cost: Weighted average cost per share (total_cost / total_shares)
    - realized_pnl: Cumulative realized P&L from all sells
    - dividends_received: Total cash dividends received
    
    Transaction Rules:
    - Buy: cost += purchase_cost + fees, shares += shares
    - Sell: realized_pnl += (proceeds - avg_cost Ã— shares), reduce cost proportionally
    - Bonus shares: shares += bonus_shares (no cost, dilutes avg_cost)
    - Dividends: Income only, no cost basis adjustment
    """
    if tx.empty:
        return {
            "shares": 0.0,
            "cost_basis": 0.0,
            "avg_cost": 0.0,
            "cash_div": 0.0,
            "bonus_shares": 0.0,
            "reinv": 0.0,
            "realized_pnl": 0.0,
        }

    t = tx.copy()
    t["txn_date"] = t["txn_date"].fillna("")
    t["created_at"] = t["created_at"].fillna(0)
    t = t.sort_values(["txn_date", "created_at", "id"], ascending=[True, True, True])

    shares = 0.0
    cost = 0.0
    realized_pnl = 0.0

    cash_div = float(t.get("cash_dividend", 0).fillna(0).sum())
    bonus_total = float(t.get("bonus_shares", 0).fillna(0).sum())
    reinv = float(t.get("reinvested_dividend", 0).fillna(0).sum())

    for _, r in t.iterrows():
        typ = str(r.get("txn_type", ""))
        sh = safe_float(r.get("shares", 0), 0.0)
        fees = safe_float(r.get("fees", 0), 0.0)
        buy_cost = safe_float(r.get("purchase_cost", 0), 0.0)
        sell_value = safe_float(r.get("sell_value", 0), 0.0)
        bonus = safe_float(r.get("bonus_shares", 0), 0.0)

        if typ == "Buy":
            # BUY: Add shares and cost (fees increase cost basis)
            shares += sh
            cost += (buy_cost + fees)
            
        elif typ == "Sell":
            # SELL: Weighted Average Cost Method
            if shares > 0 and sh > 0:
                avg = cost / shares
                # Proceeds = sell_value - fees
                proceeds = sell_value - fees
                # Cost of shares sold = avg_cost Ã— shares_sold
                cost_of_shares_sold = avg * sh
                # Realized P&L = proceeds - cost of shares sold
                realized_pnl += (proceeds - cost_of_shares_sold)
                # Reduce state proportionally
                cost -= cost_of_shares_sold
                shares -= sh

        # Bonus shares: increase shares with zero cost (dilutes avg_cost)
        if bonus > 0:
            shares += bonus

    shares = max(shares, 0.0)
    
    # CRITICAL: Position closure state management
    # Once total_shares = 0, the position is CLOSED
    # - avg_cost and total_cost reset to 0
    # - unrealized_pnl will be 0 (calculated by caller)
    # - realized_pnl is permanent historical record
    if shares <= 0:
        shares = 0.0
        cost = 0.0
        avg_cost = 0.0
        position_open = False
    else:
        cost = max(cost, 0.0)
        avg_cost = cost / shares
        position_open = True

    return {
        "shares": float(shares),
        "cost_basis": float(cost),
        "avg_cost": float(avg_cost),
        "cash_div": float(cash_div),
        "bonus_shares": float(bonus_total),
        "reinv": float(reinv),
        "realized_pnl": float(realized_pnl),
        "position_open": position_open,  # True if shares > 0, False if fully closed
    }


@st.cache_data(ttl=300, show_spinner=False)  # Cache for 5 minutes - manual refresh via button
def build_portfolio_table(portfolio_name: str, user_id: Optional[int] = None) -> pd.DataFrame:
    """Build portfolio table directly from transactions (master storage).
    
    Args:
        portfolio_name: Name of the portfolio ('KFH', 'BBYN', 'USA')
        user_id: Optional user ID. If None, uses st.session_state.user_id.
                 Pass explicitly when running outside Streamlit (e.g., cron jobs).
    
    Note: Stocks list is derived from transactions table. The stocks table is used
    only to get current_price and currency metadata. Missing stocks are auto-created.
    """
    if user_id is None:
        user_id = st.session_state.get('user_id')
    
    # 1. Bulk Fetch All Transactions for this user AND this portfolio (Master Storage - Source of Truth)
    # CRITICAL: Filter by portfolio in the SQL query to properly handle stocks in multiple portfolios
    soft_delete_clause = _soft_delete_filter()
    all_txs = query_df(
        f"""
        SELECT
            id, TRIM(stock_symbol) AS stock_symbol, txn_date, txn_type,
            purchase_cost, sell_value, shares,
            bonus_shares, cash_dividend,
            price_override, planned_cum_shares,
            reinvested_dividend, fees,
            broker, reference, notes, created_at,
            portfolio
        FROM transactions
        WHERE user_id = ? AND COALESCE(category, 'portfolio') = 'portfolio'
              AND portfolio = ?
              {soft_delete_clause}
        ORDER BY txn_date ASC, created_at ASC, id ASC
        """,
        (user_id, portfolio_name)
    )
    
    if all_txs.empty:
        return pd.DataFrame()
    
    # 2. Get unique stock symbols from transactions for THIS portfolio only
    # Since we already filtered by portfolio in SQL, all symbols here belong to this portfolio
    unique_symbols = [sym.strip() for sym in all_txs['stock_symbol'].str.strip().unique()]
    
    # 3. Fetch stock metadata (current_price, currency, portfolio assignment)
    # Use placeholders for IN clause
    if unique_symbols:
        placeholders = ','.join(['?' for _ in unique_symbols])
        stocks_meta = query_df(
            f"""
            SELECT
                TRIM(symbol) AS symbol,
                COALESCE(name,'') AS name,
                COALESCE(current_price,0) AS current_price,
                COALESCE(portfolio,'KFH') AS portfolio,
                COALESCE(currency,'KWD') AS currency,
                tradingview_symbol,
                tradingview_exchange
            FROM stocks
            WHERE TRIM(symbol) IN ({placeholders}) AND user_id = ?
            """,
            tuple(unique_symbols) + (user_id,),
        )
    else:
        stocks_meta = pd.DataFrame()
    
    # 4. Create a lookup dict for stock metadata
    stock_lookup = {}
    if not stocks_meta.empty:
        for _, srow in stocks_meta.iterrows():
            stock_lookup[srow['symbol'].strip()] = {
                'name': srow['name'],
                'current_price': srow['current_price'],
                'portfolio': srow['portfolio'],
                'currency': srow['currency'],
            }

    rows = []
    for sym in unique_symbols:
        sym = sym.strip()
        
        # Get stock metadata for price/currency (or use defaults)
        # Since we already filtered by portfolio in SQL, all transactions here belong to this portfolio
        meta = stock_lookup.get(sym, {
            'name': sym,
            'current_price': 0.0,
            'portfolio': portfolio_name,
            'currency': 'USD' if portfolio_name == 'USA' else 'KWD',
        })
        
        cp = safe_float(meta.get('current_price', 0), 0.0)
        currency = meta.get('currency', 'KWD')
        # Override currency based on portfolio
        if portfolio_name == 'USA':
            currency = 'USD'

        # Filter transactions for this stock (already filtered by portfolio in SQL)
        tx = all_txs[all_txs['stock_symbol'].str.strip() == sym].copy()

        # Calculate metrics (CFA/IFRS-compliant WAC method)
        h = compute_holdings_avg_cost(tx)

        qty = h["shares"]
        
        # CRITICAL: Only include stocks with quantity > 0 (active holdings)
        if qty <= 0.001:
            continue

        # --- Rounding to 3 decimals to prevent 1 fils errors ---
        total_cost = round(h["cost_basis"], 3)
        avg_cost = round(h["avg_cost"], 6)  # Use pre-calculated avg_cost from WAC

        # Market Price = current_price (possibly just updated)
        mkt_price = cp
        
        mkt_value = round(qty * mkt_price, 3)
        
        # CFA-Compliant P&L Calculations:
        # Unrealized P&L = (Current Price - Avg Cost) Ã— Shares (for open positions)
        unreal = round((mkt_price - avg_cost) * qty, 3) if qty > 0 and mkt_price > 0 else 0.0
        
        # Realized P&L from closed positions (WAC method)
        realized_pnl = round(h["realized_pnl"], 3)

        cash_div = round(h["cash_div"], 3)
        bonus_sh = h["bonus_shares"]
        reinv_div = round(h["reinv"], 3)

        yield_pct = (cash_div / total_cost) if total_cost > 0 else 0.0
        
        # Total P&L = Unrealized + Realized + Dividends (comprehensive return)
        total_pnl = round(unreal + realized_pnl + cash_div, 3)
        pnl_pct = (total_pnl / (total_cost + abs(realized_pnl))) if (total_cost + abs(realized_pnl)) > 0 else 0.0
        
        display_name = meta.get('name') if meta.get('name') else sym
        
        rows.append({
            "Company": f"{display_name} - {sym}".strip(),
            "Symbol": sym,
            "Shares Qty": qty,
            "Avg Cost": avg_cost,
            "Total Cost": total_cost,
            "Market Price": mkt_price,
            "Market Value": mkt_value,
            "Unrealized P/L": unreal,
            "Realized P/L": realized_pnl,
            "Cash Dividends": cash_div,
            "Reinvested Dividends": reinv_div,
            "Bonus Dividend Shares": bonus_sh,
            "Dividend Yield on Cost %": yield_pct,
            "Total PNL": total_pnl,
            "PNL %": pnl_pct,
            "Currency": currency,
        })

    df = pd.DataFrame(rows)
    
    if not df.empty:
        # Calculate weights
        total_cost_sum = float(df["Total Cost"].sum())
        df["Weight by Cost"] = df["Total Cost"].apply(lambda x: (x / total_cost_sum) if total_cost_sum > 0 else 0.0)
        df["Weighted Dividend Yield on Cost"] = df["Dividend Yield on Cost %"] * df["Weight by Cost"]
        df = df.sort_values(["Total Cost"], ascending=[False]).reset_index(drop=True)
        
    return df


def render_portfolio_table(title: str, df: pd.DataFrame, fx_usdkwd: Optional[float] = None):
    if df.empty:
        st.markdown('<div style="text-align: center; padding: 2rem; color: #9ca3af;">No stocks in this portfolio yet.</div>', unsafe_allow_html=True)
        return

    # --- PREPARE DATA FOR EXCEL-STYLE TABLE ---
    # 1. Calculate Total Portfolio Cost for Weighting
    total_portfolio_cost = df["Total Cost"].sum()
    
    # Fetch P/E Ratios
    if not df.empty and "Symbol" in df.columns:
        items = tuple(zip(df["Symbol"], df["Currency"]))  # tuple for cache hashability
        pe_map = get_pe_ratios(items)
        df["P/E Ratio"] = df["Symbol"].map(pe_map)
    else:
        df["P/E Ratio"] = None

    # 2. Create the exact columns requested
    view_df = pd.DataFrame()
    view_df["Company"] = df["Company"]
    view_df["P/E Ratio"] = pd.to_numeric(df["P/E Ratio"], errors='coerce')
    view_df["Quantity"] = df["Shares Qty"]
    view_df["Avg. Cost Per Share"] = df["Avg Cost"]
    view_df["Total cost"] = df["Total Cost"]
    view_df["Market price"] = df["Market Price"]
    view_df["Market value"] = df["Market Value"]
    
    # Appreciation income = Market Value - Total Cost (Unrealized P/L)
    view_df["Unrealized P/L"] = df["Unrealized P/L"]
    
    # Realized P/L from closed positions (CFA/IFRS compliant)
    view_df["Realized P/L"] = df["Realized P/L"] if "Realized P/L" in df.columns else 0.0
    
    view_df["Cash dividends"] = df["Cash Dividends"]
    view_df["amount reinvested from dividends"] = df["Reinvested Dividends"]
    view_df["Bonus dividend shares"] = df["Bonus Dividend Shares"]
    
    # Bonus share value = Bonus Shares * Market Price
    view_df["Bonus share value"] = view_df["Bonus dividend shares"] * view_df["Market price"]
    
    # Weight by Cost
    view_df["weight by Cost"] = (view_df["Total cost"] / total_portfolio_cost) if total_portfolio_cost > 0 else 0.0
    
    # Yield (%) = Cash Dividends / Total Cost
    view_df["Yield"] = view_df.apply(lambda x: (x["Cash dividends"] / x["Total cost"]) if x["Total cost"] > 0 else 0.0, axis=1)
    
    # Yield Amount = Cash Dividends
    view_df["Yield Amount"] = view_df["Cash dividends"]
    
    # Weighted yield = Weight * Yield
    view_df["Weighted yield"] = view_df["weight by Cost"] * view_df["Yield"]
    
    # Total P/L = Unrealized + Realized + Dividends (CFA-compliant)
    view_df["Total P/L"] = view_df["Unrealized P/L"] + view_df["Realized P/L"] + view_df["Cash dividends"]
    
    # % = Total P/L / Total cost
    view_df["P/L %"] = view_df.apply(lambda x: (x["Total P/L"] / x["Total cost"]) if x["Total cost"] > 0 else 0.0, axis=1)

    # --- TOTAL ROW ---
    total_row = {
        "Company": "TOTAL",
        "P/E Ratio": None,
        "Quantity": view_df["Quantity"].sum(),
        "Avg. Cost Per Share": 0,     # Placeholder, hidden by formatter
        "Total cost": view_df["Total cost"].sum(),
        "Market price": 0,            # Placeholder, hidden by formatter
        "Market value": view_df["Market value"].sum(),
        "Unrealized P/L": view_df["Unrealized P/L"].sum(),
        "Realized P/L": view_df["Realized P/L"].sum(),
        "Cash dividends": view_df["Cash dividends"].sum(),
        "amount reinvested from dividends": view_df["amount reinvested from dividends"].sum(),
        "Bonus dividend shares": view_df["Bonus dividend shares"].sum(),
        "Bonus share value": view_df["Bonus share value"].sum(),
        "weight by Cost": 1.0, # 100%
        "Yield": (view_df["Cash dividends"].sum() / view_df["Total cost"].sum()) if view_df["Total cost"].sum() > 0 else 0.0,
        "Yield Amount": view_df["Yield Amount"].sum(),
        "Weighted yield": view_df["Weighted yield"].sum(),
        "Total P/L": view_df["Total P/L"].sum(),
        "P/L %": (view_df["Total P/L"].sum() / view_df["Total cost"].sum()) if view_df["Total cost"].sum() > 0 else 0.0
    }
    
    # Append Total Row
    view_df = pd.concat([view_df, pd.DataFrame([total_row])], ignore_index=True)

    # --- STYLING ---
    def color_positive_negative(val):
        """Color positive green, negative red, zero/neutral default."""
        if not isinstance(val, (int, float)):
            return ''
        if val > 0:
            return 'color: #10B981; font-weight: 600;' # Green
        elif val < 0:
            return 'color: #EF4444; font-weight: 600;' # Red
        return 'color: var(--text-color); opacity: 0.6;'

    # Formatters
    is_privacy = st.session_state.get("privacy_mode", False)
    
    def fmt_val(x, fmt_str):
        if is_privacy:
            return "*****"
        if x is None:
            return "-"
        try:
            return fmt_str.format(x)
        except:
            return str(x) if x is not None else "-"

    format_dict = {
        "Quantity": lambda x: fmt_val(x, "{:,.0f}"),
        # Prices: 6 decimals for Avg Cost, 3 decimals for Market Price
        "Avg. Cost Per Share": lambda x: fmt_val(x, "{:,.6f}") if x and x != 0 else "-",
        "Market price": lambda x: fmt_val(x, "{:,.3f}") if x and x != 0 else "-",
        "P/E Ratio": lambda x: fmt_val(x, "{:.2f}") if x and x != 0 else "-",
        # Money/Values: No decimals (rounded)
        "Total cost": lambda x: fmt_val(x, "{:,.0f}"),
        "Market value": lambda x: fmt_val(x, "{:,.0f}"),
        "Unrealized P/L": lambda x: fmt_val(x, "{:,.0f}"),
        "Realized P/L": lambda x: fmt_val(x, "{:,.0f}"),
        "Cash dividends": lambda x: fmt_val(x, "{:,.0f}"),
        "amount reinvested from dividends": lambda x: fmt_val(x, "{:,.0f}"),
        "Bonus dividend shares": lambda x: fmt_val(x, "{:,.0f}"),
        "Bonus share value": lambda x: fmt_val(x, "{:,.0f}"),
        "Yield Amount": lambda x: fmt_val(x, "{:,.0f}"),
        "Total P/L": lambda x: fmt_val(x, "{:,.0f}"),
        # Percentages: 2 decimals
        "weight by Cost": lambda x: fmt_val(x, "{:.2%}") if x is not None else "-",
        "Yield": lambda x: fmt_val(x, "{:.2%}") if x is not None else "-",
        "Weighted yield": lambda x: fmt_val(x, "{:.2%}") if x is not None else "-",
        "P/L %": lambda x: fmt_val(x, "{:.2%}") if x is not None else "-"
    }

    # Apply Styling
    st.dataframe(
        view_df.style
        .format(format_dict)
        .map(color_positive_negative, subset=["Unrealized P/L", "Realized P/L", "Total P/L", "P/L %"])
        .apply(lambda x: ['font-weight: bold; background-color: rgba(128,128,128,0.1); border-top: 2px solid gray' if x.name == len(view_df)-1 else '' for i in x], axis=1), # Style Total Row
        width="stretch",
        height=(len(view_df) + 1) * 35 + 3
    )
    
    st.markdown('</div>', unsafe_allow_html=True)


# =========================
# UI - CASH DEPOSITS
# =========================
def ui_cash_deposits():
    user_id = st.session_state.get('user_id')
    st.subheader("ðŸ’° Cash Deposits")
    
    # Clean up any deposits from year 1970 (likely corrupt data)
    try:
        corrupt_deposits = query_df(
            "SELECT COUNT(*) as count FROM cash_deposits WHERE deposit_date LIKE '1970%%' AND user_id=?", (user_id,)
        )
        if not corrupt_deposits.empty and corrupt_deposits["count"].iloc[0] > 0:
            count = corrupt_deposits["count"].iloc[0]
            exec_sql("DELETE FROM cash_deposits WHERE deposit_date LIKE '1970%%' AND user_id=?", (user_id,))
            st.success(f"ðŸ§¹ Cleaned up {count:,} corrupt deposit(s) from year 1970")
    except:
        pass  # Silently continue if cleanup fails

    # Tabs for Manual Entry and Excel Upload
    tab1, tab2 = st.tabs(["âž• Manual Entry", "ðŸ“¥ Upload Excel"])
    
    with tab1:
        with st.expander("Add Deposit Manually", expanded=True):
            c1, c2, c3, c4, c5 = st.columns([1, 1, 1, 1, 0.8])
            portfolio = c1.selectbox("Portfolio", options=["KFH", "BBYN", "USA"], key="deposit_portfolio")
            bank_name = c2.text_input("Bank name", placeholder="e.g. KFH, NBK, KIB")
            deposit_date = c3.date_input("Date", value=date.today())
            amount = c4.number_input("Amount", min_value=0.0, step=10.0, format="%.3f")
            currency = c5.selectbox("Currency", options=["KWD", "USD"], key="deposit_currency")
            description = st.text_input("Description", placeholder="e.g. Salary, Transfer, Top-up")
            comments = st.text_area("Comments (optional)")
            include_in_analysis = st.checkbox("Include in Portfolio Analysis", value=True, 
                                            help="If checked, this deposit will be added to portfolio analysis. If unchecked, it will only be kept as a record.")

            if st.button("Save Deposit", type="primary"):
                if bank_name.strip() == "":
                    st.error("Bank name is required.")
                elif amount <= 0:
                    st.error("Amount must be > 0.")
                else:
                    deposit_date_str = deposit_date.isoformat()
                    
                    # Save to cash_deposits table (with historical FX rate)
                    current_fx = get_current_fx_rate()
                    exec_sql(
                        """
                        INSERT INTO cash_deposits (user_id, portfolio, bank_name, deposit_date, amount, currency, description, comments, include_in_analysis, fx_rate_at_deposit, created_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """,
                        (
                            user_id,
                            portfolio,
                            bank_name.strip(),
                            deposit_date_str,
                            float(amount),
                            currency,
                            description.strip(),
                            comments.strip(),
                            1 if include_in_analysis else 0,
                            current_fx,
                            int(time.time()),
                        ),
                    )
                    
                    # Audit log: Deposit created
                    log_audit_event(
                        user_id=user_id,
                        operation='DEPOSIT',
                        entity_type='deposit',
                        new_value=float(amount),
                        delta=float(amount) if include_in_analysis else 0,
                        portfolio=portfolio,
                        currency=currency,
                        reason='USER_ACTION',
                        details=f"Bank: {bank_name.strip()}, Date: {deposit_date_str}"
                    )
                    
                    # Update portfolio cash: DEPOSIT increases cash
                    if include_in_analysis:
                        update_portfolio_cash(user_id, portfolio, float(amount), currency)
                    
                    # Only sync to portfolio_snapshots if include_in_analysis is True
                    if include_in_analysis:
                        # Check if snapshot already exists for this date
                        existing = query_df("SELECT * FROM portfolio_snapshots WHERE snapshot_date = ? AND user_id = ?", (deposit_date_str, user_id))
                        
                        if not existing.empty:
                            # Update existing snapshot: add deposit to deposit_cash and accumulated_cash
                            current_acc = float(existing["accumulated_cash"].iloc[0]) if pd.notna(existing["accumulated_cash"].iloc[0]) else 0
                            new_accumulated = current_acc + convert_to_kwd(float(amount), currency)
                            
                            # Recalculate net_gain and ROI with new accumulated cash
                            current_beginning_diff = float(existing["beginning_difference"].iloc[0]) if pd.notna(existing["beginning_difference"].iloc[0]) else 0
                            new_net_gain = current_beginning_diff - new_accumulated
                            
                            # Get net invested capital for ROI (exclude soft-deleted deposits)
                            _soft_del_dep = _soft_delete_filter_deposits()
                            total_deps = query_df(f"SELECT SUM(amount) as total FROM cash_deposits WHERE user_id = ? AND include_in_analysis = 1{_soft_del_dep}", (user_id,))
                            total_deps_kwd = float(total_deps["total"].iloc[0]) if not total_deps.empty and pd.notna(total_deps["total"].iloc[0]) else 0
                            new_roi = (new_net_gain / total_deps_kwd * 100) if total_deps_kwd > 0 else 0
                            
                            exec_sql(
                                """UPDATE portfolio_snapshots 
                                   SET deposit_cash = deposit_cash + ?, accumulated_cash = ?, net_gain = ?, roi_percent = ?
                                   WHERE snapshot_date = ? AND user_id = ?""",
                                (convert_to_kwd(float(amount), currency), new_accumulated, new_net_gain, new_roi, deposit_date_str, user_id)
                            )
                        else:
                            # TWR FIX: Create a proper snapshot with LIVE portfolio value
                            # This ensures TWR has accurate valuation on cash flow dates
                            
                            # 1. Calculate LIVE portfolio value (Stock Market Values)
                            live_stock_value = 0.0
                            for port_name in PORTFOLIO_CCY.keys():
                                df_port = build_portfolio_table(port_name)
                                if not df_port.empty:
                                    for _, row in df_port.iterrows():
                                        live_stock_value += convert_to_kwd(row['Market Value'], row['Currency'])
                            
                            # Add Manual Cash from portfolio_cash table
                            manual_cash_kwd = 0.0
                            cash_recs = query_df("SELECT balance, currency FROM portfolio_cash WHERE user_id=?", (user_id,))
                            if not cash_recs.empty:
                                for _, cr in cash_recs.iterrows():
                                    manual_cash_kwd += convert_to_kwd(cr["balance"], cr["currency"])
                            
                            live_portfolio_value = live_stock_value + manual_cash_kwd
                            
                            # 2. Get previous snapshot for calculations
                            prev_snap = query_df(
                                "SELECT portfolio_value FROM portfolio_snapshots WHERE snapshot_date < ? AND user_id = ? ORDER BY snapshot_date DESC LIMIT 1",
                                (deposit_date_str, user_id)
                            )
                            
                            prev_value = 0.0
                            if not prev_snap.empty:
                                prev_value = float(prev_snap["portfolio_value"].iloc[0]) if pd.notna(prev_snap["portfolio_value"].iloc[0]) else 0
                            
                            # 3. Calculate accumulated cash DIRECTLY from deposits (no carry-forward drift)
                            deposit_in_kwd = convert_to_kwd(float(amount), currency)
                            accumulated_cash = calculate_accumulated_cash(user_id, deposit_date_str)
                            
                            # 4. Calculate metrics
                            daily_movement = live_portfolio_value - prev_value if prev_value > 0 else 0.0
                            
                            # Beginning diff = Current Value - First Value
                            first_snap = query_df("SELECT portfolio_value FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date ASC LIMIT 1", (user_id,))
                            if not first_snap.empty:
                                baseline = float(first_snap["portfolio_value"].iloc[0])
                                beginning_diff = live_portfolio_value - baseline
                            else:
                                beginning_diff = 0.0
                            
                            net_gain = beginning_diff - accumulated_cash
                            
                            # Get net invested capital for ROI (exclude soft-deleted)
                            _soft_del_dep = _soft_delete_filter_deposits()
                            total_deps = query_df(f"SELECT SUM(amount) as total FROM cash_deposits WHERE user_id = ? AND include_in_analysis = 1{_soft_del_dep}", (user_id,))
                            total_deps_kwd = float(total_deps["total"].iloc[0]) if not total_deps.empty and pd.notna(total_deps["total"].iloc[0]) else 0
                            roi_percent = (net_gain / total_deps_kwd * 100) if total_deps_kwd > 0 else 0
                            
                            change_percent = ((live_portfolio_value - prev_value) / prev_value * 100) if prev_value > 0 else 0.0
                            
                            exec_sql(
                                """
                                INSERT INTO portfolio_snapshots 
                                (user_id, snapshot_date, portfolio_value, daily_movement, beginning_difference, 
                                 deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                """,
                                (user_id, deposit_date_str, live_portfolio_value, daily_movement, beginning_diff, 
                                 deposit_in_kwd, accumulated_cash, net_gain, change_percent, roi_percent, int(time.time()))
                            )
                    
                    success_msg = "Deposit saved!"
                    if include_in_analysis:
                        success_msg += " âœ… Added to Portfolio Analysis."
                    else:
                        success_msg += " ðŸ“ Saved as record only (not in analysis)."
                    st.success(success_msg)
                    try:
                        st.rerun()
                    except:
                        pass
    
    with tab2:
        st.markdown("### ðŸ“¥ Upload Cash Deposits from Excel")
        st.caption("Upload an Excel file with columns: **deposit_date**, **amount**, **currency**, **portfolio**, **include_in_analysis**, **bank_name**, **description**, **comments**")
        st.caption("ðŸ“Œ **include_in_analysis**: Use 'Yes' or 'Portfolio' to add to portfolio analysis, 'No' or 'Record' for record only")
        
        # Provide sample Excel template
        sample_deposits = pd.DataFrame([
            {
                "deposit_date": date.today().isoformat(),
                "amount": 1000.0,
                "currency": "KWD",
                "portfolio": "KFH",
                "include_in_analysis": "Yes",
                "bank_name": "KFH Bank",
                "description": "Monthly Salary",
                "comments": "Regular deposit",
            },
            {
                "deposit_date": date.today().isoformat(),
                "amount": 500.0,
                "currency": "USD",
                "portfolio": "USA",
                "include_in_analysis": "No",
                "bank_name": "US Bank",
                "description": "Transfer",
                "comments": "Record only",
            }
        ])
        
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as writer:
            sample_deposits.to_excel(writer, sheet_name="Deposits", index=False)
        buf.seek(0)
        
        st.download_button(
            label="ðŸ“¥ Download Sample Template",
            data=buf,
            file_name="cash_deposits_template.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        
        uploaded_file = st.file_uploader("Choose an Excel file", type=["xlsx"], key="cash_deposits_excel")
        
        if uploaded_file is not None:
            try:
                # Read and preview the file
                df = pd.read_excel(uploaded_file, sheet_name=0)
                
                # Normalize column names
                df.columns = [str(c).strip().lower().replace(" ", "_") for c in df.columns]
                
                # Validate required columns
                required_cols = ["deposit_date", "amount"]
                missing = [c for c in required_cols if c not in df.columns]
                
                if missing:
                    st.error(f"âŒ Missing required columns: {', '.join(missing)}")
                    st.info("Required columns: deposit_date, amount. Optional: currency, portfolio, include_in_analysis, bank_name, description, comments")
                else:
                    # Show preview
                    st.markdown("#### ðŸ“‹ Preview (first 10 rows)")
                    st.dataframe(df.head(10), width="stretch")
                    st.info(f"ðŸ“Š Found **{len(df):,}** deposits to import")
                    
                    # Import button
                    col_btn1, col_btn2 = st.columns([1, 3])
                    with col_btn1:
                        if st.button("âœ… Import All Deposits", type="primary", width="stretch"):
                            # Process the upload
                            success_count = 0
                            error_count = 0
                            in_analysis_count = 0
                            record_only_count = 0
                            error_messages = []
                            
                            # Add default values for optional columns
                            if "currency" not in df.columns:
                                df["currency"] = "KWD"
                            if "portfolio" not in df.columns:
                                df["portfolio"] = "KFH"
                            if "include_in_analysis" not in df.columns:
                                df["include_in_analysis"] = "Yes"
                            if "bank_name" not in df.columns:
                                df["bank_name"] = "N/A"
                            if "description" not in df.columns:
                                df["description"] = ""
                            if "comments" not in df.columns:
                                df["comments"] = ""
                            
                            progress_bar = st.progress(0, text="Importing deposits...")
                            
                            for idx, row in df.iterrows():
                                try:
                                    # Parse deposit date
                                    deposit_date_val = row["deposit_date"]
                                    if pd.isna(deposit_date_val):
                                        raise ValueError("deposit_date is empty")
                                    
                                    if isinstance(deposit_date_val, str):
                                        deposit_date_str = deposit_date_val.strip()
                                    else:
                                        deposit_date_str = pd.to_datetime(deposit_date_val).strftime("%Y-%m-%d")
                                    
                                    # Parse amount
                                    amount_val = row["amount"]
                                    if pd.isna(amount_val):
                                        raise ValueError("amount is empty")
                                    amount_val = float(amount_val)
                                    
                                    # Parse other fields with defaults
                                    currency_val = str(row.get("currency", "KWD")).strip().upper() if pd.notna(row.get("currency")) else "KWD"
                                    portfolio_val = str(row.get("portfolio", "KFH")).strip() if pd.notna(row.get("portfolio")) else "KFH"
                                    bank_name_val = str(row.get("bank_name", "N/A")).strip() if pd.notna(row.get("bank_name")) else "N/A"
                                    description_val = str(row.get("description", "")).strip() if pd.notna(row.get("description")) else ""
                                    comments_val = str(row.get("comments", "")).strip() if pd.notna(row.get("comments")) else ""
                                    
                                    # Parse include_in_analysis
                                    include_raw = row.get("include_in_analysis", "Yes")
                                    if pd.isna(include_raw):
                                        include_in_analysis = True
                                    else:
                                        include_val = str(include_raw).strip().lower()
                                        include_in_analysis = include_val in ["yes", "y", "true", "1", "portfolio"]
                                    
                                    if include_in_analysis:
                                        in_analysis_count += 1
                                    else:
                                        record_only_count += 1
                                    
                                    # Insert into database with user_id (with historical FX rate)
                                    current_fx = get_current_fx_rate()
                                    exec_sql(
                                        """
                                        INSERT INTO cash_deposits 
                                        (user_id, portfolio, bank_name, deposit_date, amount, currency, description, comments, include_in_analysis, fx_rate_at_deposit, created_at)
                                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                        """,
                                        (
                                            user_id,
                                            portfolio_val,
                                            bank_name_val,
                                            deposit_date_str,
                                            amount_val,
                                            currency_val,
                                            description_val,
                                            comments_val,
                                            1 if include_in_analysis else 0,
                                            current_fx,
                                            int(time.time()),
                                        ),
                                    )
                                    
                                    # Sync to portfolio_snapshots if include_in_analysis is True
                                    if include_in_analysis:
                                        existing = query_df(
                                            "SELECT * FROM portfolio_snapshots WHERE snapshot_date = ? AND user_id = ?", 
                                            (deposit_date_str, user_id)
                                        )
                                        
                                        # Convert deposit to KWD for consistent tracking
                                        deposit_in_kwd = convert_to_kwd(amount_val, currency_val)
                                        
                                        if not existing.empty:
                                            # Update existing snapshot - calculate accumulated_cash DIRECTLY from deposits
                                            new_accumulated = calculate_accumulated_cash(user_id, deposit_date_str)
                                            
                                            current_beginning_diff = float(existing["beginning_difference"].iloc[0]) if pd.notna(existing["beginning_difference"].iloc[0]) else 0
                                            new_net_gain = current_beginning_diff - new_accumulated
                                            
                                            exec_sql(
                                                """UPDATE portfolio_snapshots 
                                                   SET deposit_cash = deposit_cash + ?, accumulated_cash = ?, net_gain = ?
                                                   WHERE snapshot_date = ? AND user_id = ?""",
                                                (deposit_in_kwd, new_accumulated, new_net_gain, deposit_date_str, user_id)
                                            )
                                        else:
                                            # For historical deposits, create a placeholder snapshot
                                            # Calculate accumulated_cash DIRECTLY from deposits (no carry-forward drift)
                                            accumulated_cash = calculate_accumulated_cash(user_id, deposit_date_str)
                                            
                                            net_gain = 0 - accumulated_cash
                                            
                                            exec_sql(
                                                """
                                                INSERT INTO portfolio_snapshots 
                                                (user_id, snapshot_date, portfolio_value, daily_movement, beginning_difference, 
                                                 deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at)
                                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                                """,
                                                (user_id, deposit_date_str, 0, 0, 0, deposit_in_kwd, accumulated_cash, net_gain, 0, 0, int(time.time()))
                                            )
                                    
                                    success_count += 1
                                    
                                except Exception as e:
                                    error_count += 1
                                    error_messages.append(f"Row {idx + 2}: {str(e)[:80]}")
                                
                                # Update progress
                                progress_bar.progress((idx + 1) / len(df), text=f"Importing... {idx + 1}/{len(df)}")
                            
                            progress_bar.empty()
                            
                            # Show results
                            if success_count > 0:
                                status_parts = [f"âœ… Successfully imported **{success_count:,}** deposits!"]
                                if in_analysis_count > 0:
                                    status_parts.append(f"ðŸ“Š {in_analysis_count:,} added to portfolio analysis")
                                if record_only_count > 0:
                                    status_parts.append(f"ðŸ“ {record_only_count:,} saved as records only")
                                st.success(" | ".join(status_parts))
                            
                            if error_count > 0:
                                st.error(f"âŒ {error_count:,} deposits failed to import.")
                                with st.expander("View Error Details"):
                                    for msg in error_messages[:20]:  # Show first 20 errors
                                        st.text(msg)
                                    if len(error_messages) > 20:
                                        st.text(f"... and {len(error_messages) - 20} more errors")
                            
                            if success_count > 0:
                                time.sleep(1)
                                st.rerun()
                    
                    with col_btn2:
                        st.caption("This will import all deposits from the uploaded file.")
                        
            except Exception as e:
                st.error(f"âŒ Error reading Excel file: {e}")
                st.info("Please ensure the file is a valid Excel file (.xlsx) with the correct column names.")


    st.divider()
    
    st.subheader("ðŸ’° Deposits History")
    
    # Filter and sort options
    col1, col2 = st.columns([1, 1])
    with col1:
        filter_option = st.selectbox(
            "Filter",
            ["All Deposits", "In Portfolio Analysis", "Records Only"],
            key="deposits_filter"
        )
    with col2:
        sort_option = st.selectbox(
            "Sort By",
            ["Newest First", "Oldest First"],
            key="deposits_sort"
        )
    
    sort_order = "DESC" if sort_option == "Newest First" else "ASC"
    
    # Build query based on filter (exclude soft-deleted if column exists)
    soft_del = _soft_delete_filter_deposits()
    
    if filter_option == "In Portfolio Analysis":
        deposits = query_df(
            f"""
            SELECT id, portfolio, bank_name, deposit_date, amount, currency, description, comments, include_in_analysis
            FROM cash_deposits
            WHERE include_in_analysis = 1 AND user_id = ?{soft_del}
            ORDER BY deposit_date {sort_order}, id {sort_order}
            """, (user_id,)
        )
    elif filter_option == "Records Only":
        deposits = query_df(
            f"""
            SELECT id, portfolio, bank_name, deposit_date, amount, currency, description, comments, include_in_analysis
            FROM cash_deposits
            WHERE include_in_analysis = 0 AND user_id = ?{soft_del}
            ORDER BY deposit_date {sort_order}, id {sort_order}
            """, (user_id,)
        )
    else:
        deposits = query_df(
            f"""
            SELECT id, portfolio, bank_name, deposit_date, amount, currency, description, comments, include_in_analysis
            FROM cash_deposits
            WHERE user_id = ?{soft_del}
            ORDER BY deposit_date {sort_order}, id {sort_order}
            """, (user_id,)
        )

    if deposits.empty:
        st.info("No deposits yet.")
        return
    
    # Add human-readable status column
    deposits["Status"] = deposits["include_in_analysis"].apply(
        lambda x: "âœ… In Analysis" if x == 1 else "ðŸ“‹ Record Only"
    )
    
    # Convert all amounts to KWD for total calculation
    deposits["amount_in_kwd"] = deposits.apply(
        lambda row: convert_to_kwd(row["amount"], row.get("currency", "KWD")),
        axis=1
    )
    
    # Summary cards (all in KWD)
    total_deposits = deposits["amount_in_kwd"].sum()
    total_in_analysis = deposits[deposits["include_in_analysis"] == 1]["amount_in_kwd"].sum()
    total_records_only = deposits[deposits["include_in_analysis"] == 0]["amount_in_kwd"].sum()
    
    # Group by portfolio for summary
    portfolios = deposits["portfolio"].unique()
    
    # Create columns: Total card + portfolio cards
    num_cols = len(portfolios) + 1
    cols = st.columns(num_cols)
    
    # Total card (in KWD)
    with cols[0]:
        st.metric("ðŸ’° Total Cash Deposits (KWD)", fmt_money_plain(total_deposits))
        st.caption(f"In Analysis: {fmt_money_plain(total_in_analysis)} | Records: {fmt_money_plain(total_records_only)}")
    
    # Portfolio cards
    for idx, port in enumerate(portfolios):
        port_deposits = deposits[deposits["portfolio"] == port]
        port_total = port_deposits["amount"].sum()
        port_in_analysis = port_deposits[port_deposits["include_in_analysis"] == 1]["amount"].sum()
        with cols[idx + 1]:
            st.metric(f"{port} Total", fmt_money_plain(port_total))
            st.caption(f"In Analysis: {fmt_money_plain(port_in_analysis)}")
    
    st.divider()
    
    # Delete options
    col1, col2, col3 = st.columns([2, 1, 1])
    
    if not st.session_state.get("confirm_delete_all"):
        with col2:
            if st.button("ðŸ—‘ï¸ Delete All Deposits", type="secondary", width="stretch", key="delete_all_btn"):
                st.session_state.confirm_delete_all = True
                st.rerun()
    else:
        with col2:
            if st.button("âŒ Cancel", type="secondary", width="stretch", key="cancel_delete_btn"):
                st.session_state.confirm_delete_all = False
                st.rerun()
        
        with col3:
            if st.button("âœ… Confirm Delete All", type="primary", width="stretch", key="confirm_delete_btn"):
                # Hard delete all deposits for current user only
                conn = get_conn()
                cur = conn.cursor()
                user_id = st.session_state.get('user_id', 1)
                db_execute(cur, "DELETE FROM cash_deposits WHERE user_id = ?", (user_id,))
                conn.commit()
                conn.close()
                build_portfolio_table.clear()  # Clear cache to show updated data
                st.session_state.confirm_delete_all = False
                st.rerun()
        
        st.warning("âš ï¸ Are you sure? This will permanently delete ALL deposits and cannot be undone!")
    
    # Show total count
    st.info(f"ðŸ“Š Total: **{len(deposits)}** cash deposit transactions")
    
    # Column headers
    header_cols = st.columns([0.5, 1.5, 1.5, 1.8, 1.2, 0.8, 1.2, 2, 2, 1.2])
    with header_cols[0]:
        st.markdown("**#**")
    with header_cols[1]:
        st.markdown("**Date**")
    with header_cols[2]:
        st.markdown("**Portfolio**")
    with header_cols[3]:
        st.markdown("**Bank**")
    with header_cols[4]:
        st.markdown("**Amount**")
    with header_cols[5]:
        st.markdown("**Ccy**")
    with header_cols[6]:
        st.markdown("**Status**")
    with header_cols[7]:
        st.markdown("**Description**")
    with header_cols[8]:
        st.markdown("**Comments**")
    with header_cols[9]:
        st.markdown("**Actions**")
    
    st.divider()
    
    # Display deposits table with edit and delete buttons
    for row_num, (idx, row) in enumerate(deposits.iterrows(), start=1):
        deposit_id = int(row["id"])
        
        # Check if this deposit is being edited
        edit_key = f"edit_deposit_{deposit_id}"
        is_editing = st.session_state.get(edit_key, False)
        
        if is_editing:
            # Show edit form (without sequence number column in edit mode)
            with st.container():
                st.markdown(f"**âœï¸ Editing Deposit #{row_num} (ID: {deposit_id})**")
                
                edit_cols = st.columns([2, 2, 2, 2])
                
                with edit_cols[0]:
                    new_date = st.date_input(
                        "Date", 
                        value=pd.to_datetime(row["deposit_date"]).date(),
                        key=f"edit_date_{deposit_id}"
                    )
                
                with edit_cols[1]:
                    new_portfolio = st.selectbox(
                        "Portfolio",
                        ["KFH", "BBYN", "USA"],
                        index=["KFH", "BBYN", "USA"].index(row["portfolio"]) if row["portfolio"] in ["KFH", "BBYN", "USA"] else 0,
                        key=f"edit_portfolio_{deposit_id}"
                    )
                
                with edit_cols[2]:
                    new_bank = st.text_input(
                        "Bank Name",
                        value=row["bank_name"],
                        key=f"edit_bank_{deposit_id}"
                    )
                
                with edit_cols[3]:
                    new_amount = st.number_input(
                        "Amount",
                        value=float(row["amount"]),
                        min_value=0.0,
                        step=0.001,
                        format="%.3f",
                        key=f"edit_amount_{deposit_id}"
                    )
                
                edit_cols2 = st.columns([2, 2, 4])
                
                with edit_cols2[0]:
                    new_currency = st.selectbox(
                        "Currency",
                        [BASE_CCY, USD_CCY],
                        index=0 if row.get("currency", "KWD") == BASE_CCY else 1,
                        key=f"edit_currency_{deposit_id}"
                    )
                
                with edit_cols2[1]:
                    new_include = st.checkbox(
                        "Include in Portfolio Analysis",
                        value=bool(row["include_in_analysis"]),
                        key=f"edit_include_{deposit_id}"
                    )
                
                new_description = st.text_input(
                    "Description",
                    value=row["description"] if pd.notna(row["description"]) else "",
                    key=f"edit_description_{deposit_id}"
                )
                
                new_comments = st.text_area(
                    "Comments",
                    value=row["comments"] if pd.notna(row["comments"]) else "",
                    key=f"edit_comments_{deposit_id}",
                    height=80
                )
                
                # Action buttons
                action_cols = st.columns([1, 1, 4])
                with action_cols[0]:
                    if st.button("ðŸ’¾ Save", key=f"save_{deposit_id}", type="primary"):
                        # Update the deposit
                        exec_sql(
                            """
                            UPDATE cash_deposits 
                            SET deposit_date = ?, portfolio = ?, bank_name = ?, amount = ?, 
                                currency = ?, description = ?, comments = ?, include_in_analysis = ?
                            WHERE id = ?
                            """,
                            (
                                new_date.strftime("%Y-%m-%d"),
                                new_portfolio,
                                new_bank,
                                new_amount,
                                new_currency,
                                new_description,
                                new_comments,
                                1 if new_include else 0,
                                deposit_id
                            )
                        )
                        st.session_state[edit_key] = False
                        st.success("âœ… Deposit updated successfully!")
                        st.rerun()
                
                with action_cols[1]:
                    if st.button("âŒ Cancel", key=f"cancel_edit_{deposit_id}"):
                        st.session_state[edit_key] = False
                        st.rerun()
                
                st.divider()
        
        else:
            # Show normal row view
            with st.container():
                cols = st.columns([0.5, 1.5, 1.5, 1.8, 1.2, 0.8, 1.2, 2, 2, 1.2])
                
                with cols[0]:
                    st.text(f"{row_num}")
                with cols[1]:
                    st.text(row["deposit_date"])
                with cols[2]:
                    st.text(row["portfolio"])
                with cols[3]:
                    st.text(row["bank_name"])
                with cols[4]:
                    st.text(fmt_money_plain(row["amount"]))
                with cols[5]:
                    st.text(row.get("currency", "KWD"))
                with cols[6]:
                    st.text(row["Status"])
                with cols[7]:
                    st.text(row["description"] if pd.notna(row["description"]) else "")
                with cols[8]:
                    st.text(row["comments"] if pd.notna(row["comments"]) else "")
                with cols[9]:
                    action_cols = st.columns(2)
                    with action_cols[0]:
                        if st.button("âœï¸", key=f"edit_{deposit_id}", help="Edit this deposit"):
                            st.session_state[edit_key] = True
                            st.rerun()
                    with action_cols[1]:
                        if st.button("ðŸ—‘ï¸", key=f"delete_{deposit_id}", help="Delete this deposit"):
                            # Audit log before delete
                            old_amount = float(row.get("amount", 0))
                            old_portfolio = row.get("portfolio", "KFH")
                            old_currency = row.get("currency", "KWD")
                            log_audit_event(
                                user_id=user_id,
                                operation='DEPOSIT_DELETE',
                                entity_type='deposit',
                                entity_id=deposit_id,
                                old_value=old_amount,
                                delta=-old_amount,
                                portfolio=old_portfolio,
                                currency=old_currency,
                                reason='USER_ACTION',
                                details=f"Deleted deposit from {row.get('deposit_date', 'unknown date')}"
                            )
                            
                            # Soft-delete deposit (can be restored within 30 days)
                            soft_delete_deposit(user_id, deposit_id)
                            build_portfolio_table.clear()  # Clear cache to show updated data
                            st.success("Deposit deleted. Use 'Trash' to undo if needed.")
                            st.rerun()
                
                st.divider()
    
    # Add Trash expander at the bottom
    with st.expander("ðŸ—‘ï¸ View Trash (Recently Deleted)", expanded=False):
        ui_trash_bin()


# =============================================================================
# ACCUMULATED CASH CALCULATION - DIRECT FROM DEPOSITS (NO CARRY-FORWARD DRIFT)
# =============================================================================

def calculate_accumulated_cash(user_id: int, as_of_date: str = None) -> float:
    """
    Calculate accumulated cash from portfolio_cash table (the source of truth).
    
    This returns the current cash balance held across all portfolios,
    which properly accounts for deposits, withdrawals, buys, sells, dividends, and fees.
    
    The portfolio_cash table can be either:
    1. Manually set (manual_override=1) to match brokerage statements
    2. Auto-calculated from transactions (manual_override=0)
    
    Args:
        user_id: User ID
        as_of_date: Not used currently, kept for API compatibility
        
    Returns:
        Total accumulated cash in KWD (converted from original currencies)
    """
    # Use portfolio_cash table which has the correct cash balances
    cash_df = query_df("""
        SELECT balance, COALESCE(currency, 'KWD') as currency
        FROM portfolio_cash 
        WHERE user_id = ?
    """, (user_id,))
    
    if cash_df.empty:
        return 0.0
    
    total_kwd = 0.0
    for _, row in cash_df.iterrows():
        balance = float(row['balance']) if pd.notna(row['balance']) else 0.0
        currency = row['currency'] if pd.notna(row['currency']) else 'KWD'
        total_kwd += convert_to_kwd(balance, currency)
    
    return total_kwd


# =============================================================================
# CASH LEDGER RECALCULATION - SINGLE SOURCE OF TRUTH
# =============================================================================

def recalc_portfolio_cash(user_id: int, conn=None, force_override: bool = False):
    """
    Recalculates the absolute cash balance for portfolios of a user.
    
    RESPECTS MANUAL OVERRIDES: If a portfolio has manual_override=1, its balance
    is preserved unless force_override=True. This prevents user edits from being
    overwritten when transactions are modified.
    
    The calculation aggregates:
    - Deposits/Withdrawals from cash_deposits (where include_in_analysis=1)
    - Sell proceeds (+sell_value)
    - Buy costs (-purchase_cost)
    - Fees (-fees on all transactions)
    - Dividends (+cash_dividend)
    
    Args:
        user_id: The user ID to recalculate cash for
        conn: Optional database connection. If None, creates new connection.
        force_override: If True, recalculate even for portfolios with manual_override=1
    """
    close_conn = False
    if conn is None:
        conn = get_conn()
        close_conn = True
    
    try:
        cur = conn.cursor()
        
        # Step A: Get list of portfolios with manual overrides (to preserve them)
        manual_override_portfolios = set()
        if not force_override:
            db_execute(cur, """
                SELECT portfolio FROM portfolio_cash 
                WHERE user_id = ? AND manual_override = 1
            """, (user_id,))
            manual_override_portfolios = {row[0] for row in cur.fetchall()}
        
        # Step A2: Reset balances only for NON-manual-override portfolios
        if manual_override_portfolios:
            # Only reset portfolios that are NOT manually overridden
            db_execute(cur, """
                UPDATE portfolio_cash 
                SET balance = 0, last_updated = ? 
                WHERE user_id = ? AND (manual_override = 0 OR manual_override IS NULL)
            """, (int(time.time()), user_id))
        else:
            # No manual overrides - reset all
            db_execute(cur, "UPDATE portfolio_cash SET balance = 0, last_updated = ? WHERE user_id = ?",
                       (int(time.time()), user_id))
        
        # Step B: Aggregation Query using UNION ALL
        # NOTE: Use t.portfolio directly from transactions table
        # This properly handles stocks that appear in multiple portfolios
        # IMPORTANT: PostgreSQL requires alias for derived tables
        aggregation_sql = """
            SELECT portfolio, SUM(net_change) as total_change
            FROM (
                -- 1. Deposits & Withdrawals (amount can be + or -)
                SELECT portfolio, COALESCE(amount, 0) as net_change
                FROM cash_deposits
                WHERE user_id = ? AND include_in_analysis = 1 AND COALESCE(is_deleted, 0) = 0

                UNION ALL

                -- 2. Buys (Outflow - negative) - Use portfolio from transaction directly
                SELECT t.portfolio, -1 * COALESCE(t.purchase_cost, 0) as net_change
                FROM transactions t
                WHERE t.user_id = ? AND t.txn_type = 'Buy' AND COALESCE(t.category, 'portfolio') = 'portfolio'
                AND COALESCE(t.is_deleted, 0) = 0

                UNION ALL

                -- 3. Sells (Inflow - positive) - Use portfolio from transaction directly
                SELECT t.portfolio, COALESCE(t.sell_value, 0) as net_change
                FROM transactions t
                WHERE t.user_id = ? AND t.txn_type = 'Sell' AND COALESCE(t.category, 'portfolio') = 'portfolio'
                AND COALESCE(t.is_deleted, 0) = 0

                UNION ALL

                -- 4. Dividends (Inflow - positive) - Use portfolio from transaction directly
                SELECT t.portfolio, COALESCE(t.cash_dividend, 0) as net_change
                FROM transactions t
                WHERE t.user_id = ? AND COALESCE(t.cash_dividend, 0) > 0 AND COALESCE(t.category, 'portfolio') = 'portfolio'
                AND COALESCE(t.is_deleted, 0) = 0

                UNION ALL

                -- 5. Fees (Outflow - negative) - Use portfolio from transaction directly
                SELECT t.portfolio, -1 * COALESCE(t.fees, 0) as net_change
                FROM transactions t
                WHERE t.user_id = ? AND COALESCE(t.fees, 0) > 0 AND COALESCE(t.category, 'portfolio') = 'portfolio'
                AND COALESCE(t.is_deleted, 0) = 0
            ) AS cash_movements
            GROUP BY portfolio
        """
        
        db_execute(cur, aggregation_sql, (user_id, user_id, user_id, user_id, user_id))
        results = cur.fetchall()
        
        # Step C: Upsert balances for each portfolio
        for row in results:
            portfolio = row[0]
            total_balance = float(row[1]) if row[1] else 0.0
            
            if portfolio is None:
                continue  # Skip null portfolios
            
            # Skip portfolios with manual override (user explicitly set the balance)
            if portfolio in manual_override_portfolios:
                continue
            
            # Check if record exists
            db_execute(cur, "SELECT 1 FROM portfolio_cash WHERE user_id = ? AND portfolio = ?",
                       (user_id, portfolio))
            exists = cur.fetchone()
            
            if exists:
                db_execute(cur, 
                    "UPDATE portfolio_cash SET balance = ?, last_updated = ? WHERE user_id = ? AND portfolio = ?",
                    (total_balance, int(time.time()), user_id, portfolio))
            else:
                db_execute(cur,
                    "INSERT INTO portfolio_cash (user_id, portfolio, balance, currency, last_updated, manual_override) VALUES (?, ?, ?, 'KWD', ?, 0)",
                    (user_id, portfolio, total_balance, int(time.time())))
        
        conn.commit()
        if manual_override_portfolios:
            logger.info(f"âœ… Cash ledger recalculated for user {user_id}: {len(results)} portfolios updated (preserved {len(manual_override_portfolios)} manual overrides)")
        else:
            logger.info(f"âœ… Cash ledger recalculated for user {user_id}: {len(results)} portfolios updated")
        
    except Exception as e:
        logger.error(f"Error recalculating cash ledger for user {user_id}: {e}")
        raise
    finally:
        if close_conn:
            conn.close()


# =============================================================================
# FINANCIAL AUDIT LOG - Compliance tracking for cash-affecting operations
# =============================================================================

def log_audit_event(
    user_id: int,
    operation: str,
    entity_type: str = None,
    entity_id: int = None,
    old_value: float = None,
    new_value: float = None,
    delta: float = None,
    portfolio: str = None,
    currency: str = None,
    reason: str = None,
    details: str = None
) -> None:
    """
    Log a financial event to the immutable audit trail.
    
    This provides CFA-compliant audit logging for all cash-affecting operations.
    Records are never deleted or modified - only new entries are added.
    
    Args:
        user_id: User performing the action
        operation: Type of operation:
            - 'DEPOSIT' - Cash deposit added
            - 'DEPOSIT_DELETE' - Cash deposit removed
            - 'DEPOSIT_EDIT' - Cash deposit modified
            - 'BUY' - Stock purchase (cash decreased)
            - 'SELL' - Stock sale (cash increased)
            - 'DIVIDEND' - Dividend received
            - 'TRANSACTION_DELETE' - Transaction removed
            - 'TRANSACTION_EDIT' - Transaction modified
            - 'MANUAL_CASH_ADJUST' - Manual cash balance override
            - 'SNAPSHOT_CREATE' - Portfolio snapshot created
            - 'SNAPSHOT_UPDATE' - Portfolio snapshot modified
        entity_type: 'transaction', 'deposit', 'snapshot', 'cash_balance'
        entity_id: ID of the affected record
        old_value: Previous value (for edits/deletes)
        new_value: New value (for creates/edits)
        delta: Change in cash balance
        portfolio: Affected portfolio (KFH, BBYN, USA)
        currency: Currency code
        reason: Why the change was made ('USER_ACTION', 'SYSTEM_RECALC', 'RESTORE')
        details: Additional context (JSON string or description)
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        
        db_execute(cur, """
            INSERT INTO financial_audit_log 
            (user_id, operation, entity_type, entity_id, old_value, new_value, delta,
             portfolio, currency, reason, details, created_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            user_id,
            operation,
            entity_type,
            entity_id,
            old_value,
            new_value,
            delta,
            portfolio,
            currency,
            reason or 'USER_ACTION',
            details,
            int(time.time())
        ))
        
        conn.commit()
        conn.close()
        
        logger.debug(f"ðŸ“‹ Audit: {operation} for user {user_id}, entity={entity_type}:{entity_id}, delta={delta}")
        
    except Exception as e:
        # Audit logging should never block the main operation
        logger.warning(f"Audit log failed (non-blocking): {e}")


# =============================================================================
# SOFT DELETE HELPERS (Undo/Redo Support)
# =============================================================================
# Retention period: 30 days (configurable)
SOFT_DELETE_RETENTION_DAYS = 30

# Note: _column_exists() and _soft_delete_filter() are defined earlier in the file
# for backward compatibility with databases that don't have soft-delete columns yet.


def soft_delete_transaction(user_id: int, txn_id: int) -> bool:
    """
    Soft-delete a transaction by setting is_deleted=1.
    The record remains in the database for SOFT_DELETE_RETENTION_DAYS.
    
    Returns True if successful, False otherwise.
    """
    try:
        exec_sql("""
            UPDATE transactions 
            SET is_deleted = 1, deleted_at = ?, deleted_by = ?
            WHERE id = ? AND user_id = ? AND COALESCE(is_deleted, 0) = 0
        """, (int(time.time()), user_id, txn_id, user_id))
        logger.info(f"Soft-deleted transaction {txn_id} for user {user_id}")
        return True
    except Exception as e:
        logger.error(f"Failed to soft-delete transaction {txn_id}: {e}")
        return False


def soft_delete_deposit(user_id: int, deposit_id: int) -> bool:
    """
    Soft-delete a cash deposit by setting is_deleted=1.
    The record remains in the database for SOFT_DELETE_RETENTION_DAYS.
    
    Returns True if successful, False otherwise.
    """
    try:
        exec_sql("""
            UPDATE cash_deposits 
            SET is_deleted = 1, deleted_at = ?, deleted_by = ?
            WHERE id = ? AND user_id = ? AND COALESCE(is_deleted, 0) = 0
        """, (int(time.time()), user_id, deposit_id, user_id))
        logger.info(f"Soft-deleted deposit {deposit_id} for user {user_id}")
        return True
    except Exception as e:
        logger.error(f"Failed to soft-delete deposit {deposit_id}: {e}")
        return False


def restore_deleted_transaction(user_id: int, txn_id: int) -> bool:
    """
    Restore a soft-deleted transaction.
    
    Returns True if successful, False otherwise.
    """
    try:
        exec_sql("""
            UPDATE transactions 
            SET is_deleted = 0, deleted_at = NULL, deleted_by = NULL
            WHERE id = ? AND user_id = ? AND is_deleted = 1
        """, (txn_id, user_id))
        
        # Log audit event
        log_audit_event(
            user_id=user_id,
            operation='TRANSACTION_RESTORE',
            entity_type='transaction',
            entity_id=txn_id,
            reason='USER_ACTION',
            details='Restored from trash'
        )
        
        logger.info(f"Restored transaction {txn_id} for user {user_id}")
        return True
    except Exception as e:
        logger.error(f"Failed to restore transaction {txn_id}: {e}")
        return False


def restore_deleted_deposit(user_id: int, deposit_id: int) -> bool:
    """
    Restore a soft-deleted cash deposit.
    
    Returns True if successful, False otherwise.
    """
    try:
        exec_sql("""
            UPDATE cash_deposits 
            SET is_deleted = 0, deleted_at = NULL, deleted_by = NULL
            WHERE id = ? AND user_id = ? AND is_deleted = 1
        """, (deposit_id, user_id))
        
        # Log audit event
        log_audit_event(
            user_id=user_id,
            operation='DEPOSIT_RESTORE',
            entity_type='deposit',
            entity_id=deposit_id,
            reason='USER_ACTION',
            details='Restored from trash'
        )
        
        logger.info(f"Restored deposit {deposit_id} for user {user_id}")
        return True
    except Exception as e:
        logger.error(f"Failed to restore deposit {deposit_id}: {e}")
        return False


def get_deleted_transactions(user_id: int, days: int = None) -> pd.DataFrame:
    """
    Get soft-deleted transactions within retention period.
    
    Args:
        user_id: User ID
        days: Number of days to look back (default: SOFT_DELETE_RETENTION_DAYS)
    
    Returns:
        DataFrame of deleted transactions
    """
    if days is None:
        days = SOFT_DELETE_RETENTION_DAYS
    
    cutoff = int(time.time()) - (days * 24 * 60 * 60)
    
    return query_df("""
        SELECT id, stock_symbol, txn_date, txn_type, shares, purchase_cost, sell_value,
               cash_dividend, bonus_shares, deleted_at,
               datetime(deleted_at, 'unixepoch', 'localtime') as deleted_date
        FROM transactions
        WHERE user_id = ? AND is_deleted = 1 AND deleted_at >= ?
        ORDER BY deleted_at DESC
    """, (user_id, cutoff))


def get_deleted_deposits(user_id: int, days: int = None) -> pd.DataFrame:
    """
    Get soft-deleted deposits within retention period.
    
    Args:
        user_id: User ID
        days: Number of days to look back (default: SOFT_DELETE_RETENTION_DAYS)
    
    Returns:
        DataFrame of deleted deposits
    """
    if days is None:
        days = SOFT_DELETE_RETENTION_DAYS
    
    cutoff = int(time.time()) - (days * 24 * 60 * 60)
    
    return query_df("""
        SELECT id, deposit_date, amount, portfolio, currency, bank_name, deleted_at,
               datetime(deleted_at, 'unixepoch', 'localtime') as deleted_date
        FROM cash_deposits
        WHERE user_id = ? AND is_deleted = 1 AND deleted_at >= ?
        ORDER BY deleted_at DESC
    """, (user_id, cutoff))


def purge_expired_soft_deletes(user_id: int = None):
    """
    Permanently delete records that have exceeded the retention period.
    This should be run periodically (e.g., daily cron job).
    
    Args:
        user_id: If provided, only purge for this user. Otherwise purge all.
    """
    cutoff = int(time.time()) - (SOFT_DELETE_RETENTION_DAYS * 24 * 60 * 60)
    
    try:
        if user_id:
            exec_sql("""
                DELETE FROM transactions 
                WHERE is_deleted = 1 AND deleted_at < ? AND user_id = ?
            """, (cutoff, user_id))
            exec_sql("""
                DELETE FROM cash_deposits 
                WHERE is_deleted = 1 AND deleted_at < ? AND user_id = ?
            """, (cutoff, user_id))
        else:
            exec_sql("""
                DELETE FROM transactions 
                WHERE is_deleted = 1 AND deleted_at < ?
            """, (cutoff,))
            exec_sql("""
                DELETE FROM cash_deposits 
                WHERE is_deleted = 1 AND deleted_at < ?
            """, (cutoff,))
        
        logger.info(f"Purged soft-deleted records older than {SOFT_DELETE_RETENTION_DAYS} days")
    except Exception as e:
        logger.error(f"Failed to purge expired soft-deletes: {e}")


def ui_trash_bin():
    """
    UI component for viewing and restoring soft-deleted transactions and deposits.
    Can be embedded in any tab or shown as a modal.
    """
    user_id = st.session_state.get('user_id')
    if not user_id:
        st.warning("Please log in to view deleted items.")
        return
    
    st.subheader("ðŸ—‘ï¸ Trash (Recently Deleted)")
    st.caption(f"Items are kept for {SOFT_DELETE_RETENTION_DAYS} days before permanent deletion.")
    
    # Tabs for transactions and deposits
    trash_tab1, trash_tab2 = st.tabs(["ðŸ“Š Transactions", "ðŸ’° Deposits"])
    
    with trash_tab1:
        deleted_txns = get_deleted_transactions(user_id)
        
        if deleted_txns.empty:
            st.info("No deleted transactions in the last 30 days.")
        else:
            st.write(f"**{len(deleted_txns)}** deleted transaction(s)")
            
            # Display as a table with restore buttons
            for idx, row in deleted_txns.iterrows():
                with st.container():
                    cols = st.columns([0.5, 1.2, 0.8, 0.6, 0.8, 0.8, 1.2, 0.5])
                    
                    cols[0].write(f"#{row['id']}")
                    cols[1].write(row['stock_symbol'])
                    cols[2].write(str(row['txn_date']))
                    cols[3].write(row['txn_type'])
                    cols[4].write(f"{row['shares']:.2f}" if row['shares'] else "-")
                    
                    # Show value
                    value = row['purchase_cost'] if row['purchase_cost'] else row['sell_value']
                    cols[5].write(f"{value:.3f}" if value else "-")
                    
                    cols[6].write(row['deleted_date'])
                    
                    if cols[7].button("ðŸ”„", key=f"restore_txn_{row['id']}", help="Restore this transaction"):
                        if restore_deleted_transaction(user_id, int(row['id'])):
                            st.success(f"Transaction #{row['id']} restored!")
                            build_portfolio_table.clear()
                            time.sleep(0.3)
                            st.rerun()
                        else:
                            st.error("Failed to restore transaction.")
                    
                    st.divider()
            
            # Bulk actions
            st.write("---")
            col1, col2, _ = st.columns([1, 1, 2])
            
            with col1:
                if st.button("ðŸ”„ Restore All Transactions", type="secondary"):
                    restored = 0
                    for _, row in deleted_txns.iterrows():
                        if restore_deleted_transaction(user_id, int(row['id'])):
                            restored += 1
                    st.success(f"Restored {restored} transactions!")
                    build_portfolio_table.clear()
                    time.sleep(0.3)
                    st.rerun()
            
            with col2:
                if st.button("âš ï¸ Permanently Delete All", type="primary"):
                    st.session_state['confirm_purge_txns'] = True
                
                if st.session_state.get('confirm_purge_txns'):
                    st.error("Are you sure? This cannot be undone!")
                    c1, c2 = st.columns(2)
                    if c1.button("Yes, Delete Forever"):
                        exec_sql("""
                            DELETE FROM transactions 
                            WHERE is_deleted = 1 AND user_id = ?
                        """, (user_id,))
                        st.session_state['confirm_purge_txns'] = False
                        st.success("All deleted transactions permanently removed.")
                        st.rerun()
                    if c2.button("Cancel"):
                        st.session_state['confirm_purge_txns'] = False
                        st.rerun()
    
    with trash_tab2:
        deleted_deps = get_deleted_deposits(user_id)
        
        if deleted_deps.empty:
            st.info("No deleted deposits in the last 30 days.")
        else:
            st.write(f"**{len(deleted_deps)}** deleted deposit(s)")
            
            # Display as a table with restore buttons
            for idx, row in deleted_deps.iterrows():
                with st.container():
                    cols = st.columns([0.5, 0.8, 0.8, 0.8, 1, 1.2, 0.5])
                    
                    cols[0].write(f"#{row['id']}")
                    cols[1].write(str(row['deposit_date']))
                    cols[2].write(f"{row['amount']:.3f}")
                    cols[3].write(row['currency'] or 'KWD')
                    cols[4].write(row['portfolio'] or '-')
                    cols[5].write(row['deleted_date'])
                    
                    if cols[6].button("ðŸ”„", key=f"restore_dep_{row['id']}", help="Restore this deposit"):
                        if restore_deleted_deposit(user_id, int(row['id'])):
                            st.success(f"Deposit #{row['id']} restored!")
                            build_portfolio_table.clear()
                            time.sleep(0.3)
                            st.rerun()
                        else:
                            st.error("Failed to restore deposit.")
                    
                    st.divider()
            
            # Bulk actions
            st.write("---")
            col1, col2, _ = st.columns([1, 1, 2])
            
            with col1:
                if st.button("ðŸ”„ Restore All Deposits", type="secondary"):
                    restored = 0
                    for _, row in deleted_deps.iterrows():
                        if restore_deleted_deposit(user_id, int(row['id'])):
                            restored += 1
                    st.success(f"Restored {restored} deposits!")
                    build_portfolio_table.clear()
                    time.sleep(0.3)
                    st.rerun()
            
            with col2:
                if st.button("âš ï¸ Permanently Delete All Deposits", type="primary"):
                    st.session_state['confirm_purge_deps'] = True
                
                if st.session_state.get('confirm_purge_deps'):
                    st.error("Are you sure? This cannot be undone!")
                    c1, c2 = st.columns(2)
                    if c1.button("Yes, Delete Deposits Forever"):
                        exec_sql("""
                            DELETE FROM cash_deposits 
                            WHERE is_deleted = 1 AND user_id = ?
                        """, (user_id,))
                        st.session_state['confirm_purge_deps'] = False
                        st.success("All deleted deposits permanently removed.")
                        st.rerun()
                    if c2.button("Cancel Deposit Delete"):
                        st.session_state['confirm_purge_deps'] = False
                        st.rerun()


# =============================================================================
# RECONCILIATION REPORT - Monthly cash and portfolio reconciliation
# =============================================================================

def calculate_monthly_reconciliation(user_id: int, year: int, month: int) -> dict:
    """
    Calculate reconciliation data for a given month.
    
    Returns dict with:
    - cash_starting: Starting cash balance
    - cash_deposits: Total deposits in period
    - cash_dividends: Total dividends received
    - cash_buys: Total spent on buys
    - cash_sells: Total received from sells
    - cash_ending_calc: Calculated ending balance
    - cash_ending_manual: Manual/actual ending balance
    - cash_reconciled: Boolean if reconciled
    
    - portfolio_starting: Starting portfolio value
    - portfolio_appreciation: Market value change
    - portfolio_new_buys: Cost of new purchases
    - portfolio_sells: Value of sales
    - portfolio_ending: Ending portfolio value
    - portfolio_reconciled: Boolean if reconciled
    """
    from calendar import monthrange
    
    # Date range for the month
    first_day = date(year, month, 1)
    last_day = date(year, month, monthrange(year, month)[1])
    prev_month_last = first_day - timedelta(days=1)
    
    first_day_str = first_day.isoformat()
    last_day_str = last_day.isoformat()
    prev_month_str = prev_month_last.isoformat()
    
    result = {
        'year': year,
        'month': month,
        'month_name': first_day.strftime('%B %Y'),
        'period_start': first_day_str,
        'period_end': last_day_str,
    }
    
    # --- CASH RECONCILIATION ---
    
    # Starting cash: Get from previous month's snapshot or calculate from deposits
    prev_snapshot = query_df("""
        SELECT portfolio_value, accumulated_cash 
        FROM portfolio_snapshots 
        WHERE user_id = ? AND snapshot_date <= ?
        ORDER BY snapshot_date DESC LIMIT 1
    """, (user_id, prev_month_str))
    
    if not prev_snapshot.empty:
        # Get actual cash from portfolio_cash at start of month (approximate)
        cash_recs = query_df("SELECT balance, currency FROM portfolio_cash WHERE user_id=?", (user_id,))
        starting_cash = 0.0
        for _, cr in cash_recs.iterrows():
            starting_cash += convert_to_kwd(float(cr["balance"]) if pd.notna(cr["balance"]) else 0, cr["currency"])
        # We'll estimate starting cash from deposits minus buys/sells before period
        # Actually, let's calculate from deposits accumulated up to prev month
        _soft_del_dep = _soft_delete_filter_deposits()
        deposits_before = query_df(f"""
            SELECT SUM(amount) as total FROM cash_deposits 
            WHERE user_id = ? AND deposit_date < ? AND include_in_analysis = 1{_soft_del_dep}
        """, (user_id, first_day_str))
        result['cash_starting'] = float(deposits_before['total'].iloc[0]) if not deposits_before.empty and pd.notna(deposits_before['total'].iloc[0]) else 0.0
    else:
        result['cash_starting'] = 0.0
    
    # Deposits in period
    _soft_del_dep = _soft_delete_filter_deposits()
    deposits_period = query_df(f"""
        SELECT SUM(amount) as total FROM cash_deposits 
        WHERE user_id = ? AND deposit_date >= ? AND deposit_date <= ? 
        {_soft_del_dep.replace(' AND ', '')} AND include_in_analysis = 1
    """.replace('\n         AND', '\n        AND'), (user_id, first_day_str, last_day_str))
    result['cash_deposits'] = float(deposits_period['total'].iloc[0]) if not deposits_period.empty and pd.notna(deposits_period['total'].iloc[0]) else 0.0
    
    # Dividends in period
    _soft_del_txn = _soft_delete_filter()
    dividends_period = query_df(f"""
        SELECT SUM(COALESCE(cash_dividend, 0)) as total FROM transactions 
        WHERE user_id = ? AND txn_date >= ? AND txn_date <= ?{_soft_del_txn}
    """, (user_id, first_day_str, last_day_str))
    result['cash_dividends'] = float(dividends_period['total'].iloc[0]) if not dividends_period.empty and pd.notna(dividends_period['total'].iloc[0]) else 0.0
    
    # Buys in period (money spent)
    buys_period = query_df(f"""
        SELECT SUM(COALESCE(purchase_cost, 0) + COALESCE(fees, 0)) as total FROM transactions 
        WHERE user_id = ? AND txn_date >= ? AND txn_date <= ?
        AND txn_type = 'Buy'{_soft_del_txn}
    """, (user_id, first_day_str, last_day_str))
    result['cash_buys'] = float(buys_period['total'].iloc[0]) if not buys_period.empty and pd.notna(buys_period['total'].iloc[0]) else 0.0
    
    # Sells in period (money received)
    sells_period = query_df(f"""
        SELECT SUM(COALESCE(sell_value, 0) - COALESCE(fees, 0)) as total FROM transactions 
        WHERE user_id = ? AND txn_date >= ? AND txn_date <= ?
        AND txn_type = 'Sell'{_soft_del_txn}
    """, (user_id, first_day_str, last_day_str))
    result['cash_sells'] = float(sells_period['total'].iloc[0]) if not sells_period.empty and pd.notna(sells_period['total'].iloc[0]) else 0.0
    
    # Calculate expected ending cash
    result['cash_ending_calc'] = (
        result['cash_starting'] 
        + result['cash_deposits'] 
        + result['cash_dividends'] 
        - result['cash_buys'] 
        + result['cash_sells']
    )
    
    # Actual ending cash from portfolio_cash
    cash_recs = query_df("SELECT balance, currency FROM portfolio_cash WHERE user_id=?", (user_id,))
    result['cash_ending_manual'] = 0.0
    for _, cr in cash_recs.iterrows():
        result['cash_ending_manual'] += convert_to_kwd(float(cr["balance"]) if pd.notna(cr["balance"]) else 0, cr["currency"])
    
    # Check reconciliation (allow for small rounding differences)
    result['cash_difference'] = abs(result['cash_ending_calc'] - result['cash_ending_manual'])
    result['cash_reconciled'] = result['cash_difference'] < 1.0  # Within 1 KWD
    
    # --- PORTFOLIO VALUE RECONCILIATION ---
    
    # Starting portfolio value from previous snapshot
    if not prev_snapshot.empty:
        result['portfolio_starting'] = float(prev_snapshot['portfolio_value'].iloc[0]) if pd.notna(prev_snapshot['portfolio_value'].iloc[0]) else 0.0
    else:
        result['portfolio_starting'] = 0.0
    
    # Current portfolio value (live)
    live_stock_value = 0.0
    for port_name in PORTFOLIO_CCY.keys():
        df_port = build_portfolio_table(port_name)
        if not df_port.empty:
            for _, row in df_port.iterrows():
                live_stock_value += convert_to_kwd(row['Market Value'], row['Currency'])
    
    # Add cash to get total portfolio value
    result['portfolio_ending'] = live_stock_value + result['cash_ending_manual']
    
    # New buys = total cost basis added
    result['portfolio_new_buys'] = result['cash_buys']
    
    # Sells = value removed
    result['portfolio_sells'] = result['cash_sells']
    
    # Market appreciation = Ending - Starting - Buys + Sells
    result['portfolio_appreciation'] = (
        result['portfolio_ending'] 
        - result['portfolio_starting'] 
        - result['portfolio_new_buys'] 
        + result['portfolio_sells']
    )
    
    # Expected ending value
    result['portfolio_ending_calc'] = (
        result['portfolio_starting'] 
        + result['portfolio_appreciation'] 
        + result['portfolio_new_buys'] 
        - result['portfolio_sells']
    )
    
    # Portfolio reconciliation (check if calculation matches)
    result['portfolio_difference'] = abs(result['portfolio_ending'] - result['portfolio_ending_calc'])
    result['portfolio_reconciled'] = result['portfolio_difference'] < 1.0
    
    return result


def generate_reconciliation_pdf(recon_data: dict) -> bytes:
    """
    Generate a professional PDF reconciliation report.
    
    Args:
        recon_data: Dictionary from calculate_monthly_reconciliation()
        
    Returns:
        PDF bytes
    """
    try:
        from reportlab.lib import colors
        from reportlab.lib.pagesizes import letter
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
        from reportlab.lib.enums import TA_CENTER, TA_RIGHT, TA_LEFT
    except ImportError:
        return None
    
    pdf_buffer = io.BytesIO()
    doc = SimpleDocTemplate(pdf_buffer, pagesize=letter, topMargin=0.5*inch, bottomMargin=0.5*inch)
    
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=20,
        textColor=colors.HexColor('#1e40af'),
        spaceAfter=5,
        alignment=TA_CENTER
    )
    subtitle_style = ParagraphStyle(
        'Subtitle',
        parent=styles['Normal'],
        fontSize=12,
        textColor=colors.HexColor('#6b7280'),
        spaceAfter=20,
        alignment=TA_CENTER
    )
    heading_style = ParagraphStyle(
        'SectionHeading',
        parent=styles['Heading2'],
        fontSize=14,
        textColor=colors.HexColor('#1e293b'),
        spaceBefore=25,
        spaceAfter=10
    )
    
    elements = []
    
    # Header
    elements.append(Paragraph("PORTFOLIO RECONCILIATION REPORT", title_style))
    elements.append(Paragraph(recon_data['month_name'], subtitle_style))
    elements.append(Paragraph(f"Generated: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}", 
                             ParagraphStyle('Gen', parent=styles['Normal'], fontSize=9, 
                                          textColor=colors.gray, alignment=TA_CENTER)))
    elements.append(Spacer(1, 20))
    
    # --- CASH RECONCILIATION SECTION ---
    elements.append(Paragraph("ðŸ’° CASH RECONCILIATION", heading_style))
    
    # Cash status indicator
    cash_status = "âœ… CASH RECONCILED" if recon_data['cash_reconciled'] else f"âš ï¸ VARIANCE: {recon_data['cash_difference']:.3f} KWD"
    cash_status_color = colors.HexColor('#10b981') if recon_data['cash_reconciled'] else colors.HexColor('#ef4444')
    
    def fmt_amt(val, prefix=""):
        """Format amount with proper sign."""
        if val >= 0:
            return f"{prefix}{val:,.3f} KWD"
        else:
            return f"({prefix}{abs(val):,.3f} KWD)"
    
    cash_data = [
        ["Description", "Amount"],
        [f"Starting Cash Balance ({recon_data['period_start'][:7]})", fmt_amt(recon_data['cash_starting'])],
        ["+ Cash Deposits", fmt_amt(recon_data['cash_deposits'], "+")],
        ["+ Dividends Received", fmt_amt(recon_data['cash_dividends'], "+")],
        ["- Buys", f"({recon_data['cash_buys']:,.3f} KWD)"],
        ["+ Sells", fmt_amt(recon_data['cash_sells'], "+")],
        ["â”€" * 30, "â”€" * 20],
        ["Ending Cash Balance (Calculated)", fmt_amt(recon_data['cash_ending_calc'])],
        ["Ending Cash Balance (Actual)", fmt_amt(recon_data['cash_ending_manual'])],
        ["", ""],
        [cash_status, ""],
    ]
    
    cash_table = Table(cash_data, colWidths=[4*inch, 2.5*inch])
    cash_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e40af')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('ALIGN', (0, 0), (0, -1), 'LEFT'),
        ('ALIGN', (1, 0), (1, -1), 'RIGHT'),
        ('TOPPADDING', (0, 0), (-1, -1), 8),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
        ('GRID', (0, 0), (-1, -3), 0.5, colors.HexColor('#e2e8f0')),
        ('BACKGROUND', (0, -4), (-1, -4), colors.HexColor('#f0f9ff')),
        ('BACKGROUND', (0, -3), (-1, -3), colors.HexColor('#f0f9ff')),
        ('FONTNAME', (0, -4), (-1, -3), 'Helvetica-Bold'),
        ('TEXTCOLOR', (0, -1), (0, -1), cash_status_color),
        ('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold'),
        ('FONTSIZE', (0, -1), (-1, -1), 11),
    ]))
    elements.append(cash_table)
    elements.append(Spacer(1, 30))
    
    # --- PORTFOLIO VALUE RECONCILIATION SECTION ---
    elements.append(Paragraph("ðŸ“ˆ PORTFOLIO VALUE RECONCILIATION", heading_style))
    
    portfolio_status = "âœ… PORTFOLIO RECONCILED" if recon_data['portfolio_reconciled'] else f"âš ï¸ VARIANCE: {recon_data['portfolio_difference']:.3f} KWD"
    portfolio_status_color = colors.HexColor('#10b981') if recon_data['portfolio_reconciled'] else colors.HexColor('#ef4444')
    
    portfolio_data = [
        ["Description", "Amount"],
        [f"Starting Portfolio Value", fmt_amt(recon_data['portfolio_starting'])],
        ["+ Market Appreciation", fmt_amt(recon_data['portfolio_appreciation'], "+") if recon_data['portfolio_appreciation'] >= 0 else f"({abs(recon_data['portfolio_appreciation']):,.3f} KWD)"],
        ["+ New Buys (Cost)", fmt_amt(recon_data['portfolio_new_buys'], "+")],
        ["- Sells", f"({recon_data['portfolio_sells']:,.3f} KWD)"],
        ["â”€" * 30, "â”€" * 20],
        ["Ending Portfolio Value", fmt_amt(recon_data['portfolio_ending'])],
        ["", ""],
        [portfolio_status, ""],
    ]
    
    portfolio_table = Table(portfolio_data, colWidths=[4*inch, 2.5*inch])
    portfolio_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#059669')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('ALIGN', (0, 0), (0, -1), 'LEFT'),
        ('ALIGN', (1, 0), (1, -1), 'RIGHT'),
        ('TOPPADDING', (0, 0), (-1, -1), 8),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
        ('GRID', (0, 0), (-1, -3), 0.5, colors.HexColor('#e2e8f0')),
        ('BACKGROUND', (0, -3), (-1, -3), colors.HexColor('#ecfdf5')),
        ('FONTNAME', (0, -3), (-1, -3), 'Helvetica-Bold'),
        ('TEXTCOLOR', (0, -1), (0, -1), portfolio_status_color),
        ('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold'),
        ('FONTSIZE', (0, -1), (-1, -1), 11),
    ]))
    elements.append(portfolio_table)
    elements.append(Spacer(1, 30))
    
    # --- SUMMARY SECTION ---
    elements.append(Paragraph("ðŸ“Š PERIOD SUMMARY", heading_style))
    
    # Calculate some summary metrics
    total_inflows = recon_data['cash_deposits'] + recon_data['cash_dividends'] + recon_data['cash_sells']
    total_outflows = recon_data['cash_buys']
    net_cash_flow = total_inflows - total_outflows
    
    summary_data = [
        ["Metric", "Value"],
        ["Period", f"{recon_data['period_start']} to {recon_data['period_end']}"],
        ["Total Cash Inflows", fmt_amt(total_inflows)],
        ["Total Cash Outflows", fmt_amt(total_outflows)],
        ["Net Cash Flow", fmt_amt(net_cash_flow)],
        ["Portfolio Change", fmt_amt(recon_data['portfolio_ending'] - recon_data['portfolio_starting'])],
    ]
    
    summary_table = Table(summary_data, colWidths=[3*inch, 3.5*inch])
    summary_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#6366f1')),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('ALIGN', (0, 0), (0, -1), 'LEFT'),
        ('ALIGN', (1, 0), (1, -1), 'RIGHT'),
        ('TOPPADDING', (0, 0), (-1, -1), 8),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
        ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
    ]))
    elements.append(summary_table)
    
    # Footer
    elements.append(Spacer(1, 40))
    footer_style = ParagraphStyle('Footer', parent=styles['Normal'], fontSize=8, 
                                   textColor=colors.gray, alignment=TA_CENTER)
    elements.append(Paragraph("This report is auto-generated for reconciliation purposes.", footer_style))
    elements.append(Paragraph("Figures are in Kuwaiti Dinars (KWD) unless otherwise specified.", footer_style))
    
    # Build PDF
    doc.build(elements)
    pdf_buffer.seek(0)
    return pdf_buffer.getvalue()


def update_portfolio_cash(user_id: int, portfolio: str, delta: float, currency="KWD"):
    """
    Updates cash balance by applying a delta (positive or negative).
    
    Cash Rules:
    - BUY: delta = -(quantity * price + fees)  [cash decreases]
    - SELL: delta = +(quantity * price - fees) [cash increases]
    - DIVIDEND: delta = +dividend_amount       [cash increases]
    - DEPOSIT: delta = +deposit_amount         [cash increases]
    - WITHDRAW: delta = -withdrawal_amount     [cash decreases]
    
    Args:
        user_id: User ID
        portfolio: Portfolio name (KFH, BBYN, USA)
        delta: Amount to add (positive) or subtract (negative)
        currency: Currency code (KWD, USD)
    """
    conn = get_conn()
    try:
        cur = conn.cursor()
        ts = int(time.time())
        
        # Check if record exists
        db_execute(cur, "SELECT balance FROM portfolio_cash WHERE user_id = ? AND portfolio = ?",
                   (user_id, portfolio))
        row = cur.fetchone()
        
        if row:
            # Update existing balance by adding delta
            new_balance = float(row[0]) + delta
            db_execute(cur, 
                "UPDATE portfolio_cash SET balance = ?, last_updated = ? WHERE user_id = ? AND portfolio = ?",
                (new_balance, ts, user_id, portfolio))
        else:
            # Insert new record with delta as initial balance
            db_execute(cur,
                "INSERT INTO portfolio_cash (user_id, portfolio, balance, currency, last_updated) VALUES (?, ?, ?, ?, ?)",
                (user_id, portfolio, delta, currency, ts))
        
        conn.commit()
        logger.info(f"ðŸ’° Cash updated for {portfolio}: delta={delta:+,.2f} {currency}")
        
    except Exception as e:
        logger.error(f"Error updating cash for {portfolio}: {e}")
        raise
    finally:
        conn.close()


@st.cache_data(ttl=300)
def load_stocks_master():
    """
    Loads distinct stored stocks from the database for the search dropdown.
    Returns a DataFrame with columns: symbol, name.
    """
    try:
        # We query the stocks table. 
        # The user has stocks stored here with symbol, name, portfolio, currency etc.
        # We'll use this as the master list.
        user_id = st.session_state.get('user_id', 1)
        df = query_df(
            "SELECT symbol, name, portfolio, currency FROM stocks WHERE user_id = ? ORDER BY symbol",
            (user_id,)
        )
        return df
    except Exception as e:
        logger.error(f"Error loading stocks master: {e}")
        return pd.DataFrame(columns=["symbol", "name", "portfolio", "currency"])


def generate_sample_transactions_excel():
    """Generate a sample Excel file for transaction imports."""
    import io
    
    # Sample data matching database schema
    sample_data = {
        'stock_symbol': ['NBK', 'ZAIN', 'AAPL', 'KFH', 'AGILITY'],
        'stock_name': ['National Bank of Kuwait', 'Zain Telecom', 'Apple Inc', 'Kuwait Finance House', 'Agility Public Warehousing'],
        'portfolio': ['KFH', 'KFH', 'USA', 'BBYN', 'KFH'],
        'currency': ['KWD', 'KWD', 'USD', 'KWD', 'KWD'],
        'txn_date': ['2024-01-15', '2024-02-20', '2024-03-10', '2024-04-05', '2024-05-15'],
        'txn_type': ['Buy', 'Buy', 'Buy', 'Buy', 'Sell'],
        'category': ['portfolio', 'portfolio', 'portfolio', 'portfolio', 'portfolio'],
        'shares': [1000, 500, 50, 2000, 300],
        'purchase_cost': [1050.000, 275.000, 8500.00, 1580.000, 0],
        'sell_value': [0, 0, 0, 0, 450.000],
        'cash_dividend': [0, 0, 0, 0, 0],
        'reinvested_dividend': [0, 0, 0, 0, 0],
        'bonus_shares': [0, 0, 0, 0, 0],
        'fees': [5.25, 2.75, 10.00, 7.90, 3.50],
        'broker': ['Markaz', 'NBK Capital', 'Interactive Brokers', 'KFH Capital', 'Markaz'],
        'reference': ['TXN-2024-001', 'TXN-2024-002', 'TXN-2024-003', 'TXN-2024-004', 'TXN-2024-005'],
        'notes': ['Initial purchase', 'Adding position', 'US market entry', 'Long term hold', 'Partial profit taking']
    }
    
    df = pd.DataFrame(sample_data)
    
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Transactions')
        
        workbook = writer.book
        worksheet = writer.sheets['Transactions']
        
        # Header format
        header_fmt = workbook.add_format({'bold': True, 'bg_color': '#4472C4', 'font_color': 'white', 'border': 1})
        for col_num, value in enumerate(df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)
            worksheet.set_column(col_num, col_num, 18)
        
        # Add instructions sheet
        instructions_sheet = workbook.add_worksheet('Instructions')
        instructions = [
            ['Column', 'Required', 'Description', 'Example Values'],
            ['stock_symbol', 'YES', 'Stock ticker symbol (uppercase)', 'NBK, ZAIN, AAPL'],
            ['stock_name', 'No', 'Full company name', 'National Bank of Kuwait'],
            ['portfolio', 'No', 'Portfolio group (default: KFH)', 'KFH, BBYN, USA'],
            ['currency', 'No', 'Currency code (default: KWD)', 'KWD, USD'],
            ['txn_date', 'YES', 'Transaction date (YYYY-MM-DD)', '2024-01-15'],
            ['txn_type', 'YES', 'Transaction type', 'Buy, Sell, DIVIDEND_ONLY'],
            ['category', 'No', 'Category (default: portfolio)', 'portfolio, record'],
            ['shares', 'YES', 'Number of shares', '1000'],
            ['purchase_cost', 'No', 'Total cost for Buy (in currency)', '1050.000'],
            ['sell_value', 'No', 'Total value for Sell (in currency)', '1200.000'],
            ['cash_dividend', 'No', 'Cash dividend received', '25.500'],
            ['reinvested_dividend', 'No', 'Dividend reinvested', '0'],
            ['bonus_shares', 'No', 'Bonus shares received', '50'],
            ['fees', 'No', 'Transaction fees/commission', '5.25'],
            ['broker', 'No', 'Broker name', 'Markaz, NBK Capital'],
            ['reference', 'No', 'Reference number', 'TXN-2024-001'],
            ['notes', 'No', 'Additional notes', 'Long term investment'],
        ]
        
        title_fmt = workbook.add_format({'bold': True, 'font_size': 14, 'bg_color': '#4472C4', 'font_color': 'white'})
        header_fmt2 = workbook.add_format({'bold': True, 'bg_color': '#D9E2F3', 'border': 1})
        cell_fmt = workbook.add_format({'border': 1, 'text_wrap': True})
        
        instructions_sheet.set_column(0, 0, 20)
        instructions_sheet.set_column(1, 1, 10)
        instructions_sheet.set_column(2, 2, 45)
        instructions_sheet.set_column(3, 3, 30)
        
        for row_num, row_data in enumerate(instructions):
            fmt = header_fmt2 if row_num == 0 else cell_fmt
            for col_num, value in enumerate(row_data):
                instructions_sheet.write(row_num, col_num, value, fmt)
    
    return buffer.getvalue()


def ui_transactions():
    st.subheader("Add Transactions (per stock)")
    
    # --- Sample Download ---
    with st.expander("ðŸ“¥ Download Sample Template"):
        st.markdown("""
        Download a sample Excel template to see the expected format for importing transactions.
        The template includes:
        - **Transactions sheet**: Sample data with all columns
        - **Instructions sheet**: Description of each column
        """)
        
        sample_data = generate_sample_transactions_excel()
        st.download_button(
            label="ðŸ“¥ Download Sample Template",
            data=sample_data,
            file_name="transactions_sample_template.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            width="stretch"
        )
    
    # --- Import / Export All Transactions Option ---
    with st.expander("ðŸ” Import / Export All Transactions (Backup & Restore)"):
        col_export, col_import = st.columns(2)
        
        with col_export:
            st.markdown("### ðŸ“¤ Export (Backup)")
            st.caption("Download a complete list of all YOUR transactions.")
            
            # Fetch data - filter by user_id and exclude soft-deleted
            user_id = st.session_state.get('user_id', 1)
            soft_del = _soft_delete_filter("t")
            export_sql = f"""
                SELECT 
                    t.id, t.stock_symbol, s.name as stock_name, s.portfolio, s.currency,
                    t.txn_date, t.txn_type, t.category,
                    t.shares, t.purchase_cost, t.sell_value, 
                    t.cash_dividend, t.reinvested_dividend, t.bonus_shares,
                    t.fees, t.broker, t.reference, t.notes, t.created_at
                FROM transactions t
                LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND s.user_id = t.user_id
                WHERE t.user_id = ?{soft_del}
                ORDER BY t.txn_date DESC
            """
            df_export = query_df(export_sql, (user_id,))
            
            if not df_export.empty:
                # Convert to Excel buffer
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    df_export.to_excel(writer, index=False, sheet_name='Transactions')
                    
                    # Format columns
                    workbook = writer.book
                    worksheet = writer.sheets['Transactions']
                    header_fmt = workbook.add_format({'bold': True, 'bg_color': '#D9EAD3', 'border': 1})
                    for col_num, value in enumerate(df_export.columns.values):
                        worksheet.write(0, col_num, value, header_fmt)
                        worksheet.set_column(col_num, col_num, 15) # Set width
                
                st.download_button(
                    label="ðŸ“¥ Download All Transactions",
                    data=buffer.getvalue(),
                    file_name=f"portfolio_backup_{date.today().strftime('%Y-%m-%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    width="stretch"
                )
            else:
                st.info("No transactions found to export.")

        with col_import:
            st.markdown("### ðŸ” Import (Restore)")
            st.caption("Upload a previously exported Excel file to restore data.")
            
            restore_file = st.file_uploader("Upload Backup Excel", type=['xlsx'], key="restore_uploader")
            
            # Import mode selection
            import_mode = st.radio(
                "Import Mode:",
                ["ðŸ”„ Merge (Skip Duplicates)", "ðŸ—‘ï¸ Delete All & Replace"],
                index=0,
                key="import_mode",
                help="Merge: Adds new records, skips duplicates. Delete All: Removes ALL existing transactions before importing."
            )
            
            if restore_file:
                # Show preview of file
                try:
                    preview_df = pd.read_excel(restore_file)
                    restore_file.seek(0)  # Reset for later read
                    st.info(f"ðŸ“‹ File contains **{len(preview_df):,}** rows")
                except:
                    pass
                
                if import_mode == "ðŸ—‘ï¸ Delete All & Replace":
                    st.warning("âš ï¸ **WARNING:** This will soft-delete your existing transactions before importing!")
                    preserve_manual = st.checkbox(
                        "âœ… Preserve manually entered transactions", 
                        value=True, 
                        key="preserve_manual_entries",
                        help="If checked, transactions marked as 'MANUAL' source will NOT be deleted"
                    )
                    confirm_delete = st.checkbox("I understand this will delete my imported transactions", key="confirm_full_replace")
                else:
                    confirm_delete = True  # No confirmation needed for merge
                    preserve_manual = True  # Default to preserve in merge mode
                
                if st.button("âš¡ Restore / Import Data", type="primary", width="stretch", disabled=(import_mode == "ðŸ—‘ï¸ Delete All & Replace" and not confirm_delete)):
                    try:
                        restore_df = pd.read_excel(restore_file)
                        
                        # Column name normalization (handle both old and new formats)
                        col_mapping = {
                            'symbol': 'stock_symbol',
                            'date': 'txn_date',
                            'type': 'txn_type',
                            'quantity': 'shares',
                            'dividend': 'cash_dividend'
                        }
                        restore_df = restore_df.rename(columns=col_mapping)
                        
                        # Basic validation - flexible column detection
                        has_symbol = 'stock_symbol' in restore_df.columns
                        has_date = 'txn_date' in restore_df.columns
                        has_type = 'txn_type' in restore_df.columns
                        
                        if not (has_symbol and has_date and has_type):
                            st.error(f"âŒ Invalid file format. Required columns: stock_symbol (or symbol), txn_date (or date), txn_type (or type)")
                        else:
                            conn = get_conn()
                            cur = conn.cursor()
                            user_id = st.session_state.get('user_id', 1)
                            restored_count = 0
                            skipped_count = 0
                            new_stocks = 0
                            deleted_count = 0
                            deposits_imported = 0  # Track deposits separately
                            
                            # Generate source_reference from filename
                            source_reference = f"restore:{restore_file.name}:{int(time.time())}"
                            
                            # DELETE ALL MODE: Soft delete existing transactions first
                            if import_mode == "ðŸ—‘ï¸ Delete All & Replace":
                                # Build query based on preserve_manual setting
                                if preserve_manual:
                                    # Count only non-manual transactions
                                    db_execute(cur, """
                                        SELECT COUNT(*) FROM transactions 
                                        WHERE user_id = ? 
                                        AND (is_deleted = 0 OR is_deleted IS NULL)
                                        AND (source != 'MANUAL' OR source IS NULL)
                                    """, (user_id,))
                                    deleted_count = cur.fetchone()[0]
                                    # Soft delete non-manual only
                                    db_execute(cur, """
                                        UPDATE transactions 
                                        SET is_deleted = 1, 
                                            deleted_at = ?, 
                                            deleted_by = ?
                                        WHERE user_id = ? 
                                        AND (is_deleted = 0 OR is_deleted IS NULL)
                                        AND (source != 'MANUAL' OR source IS NULL)
                                    """, (int(time.time()), user_id, user_id))
                                    st.info(f"ðŸ—‘ï¸ Soft-deleted {deleted_count:,} imported transactions (manual entries preserved).")
                                else:
                                    # Delete all transactions
                                    db_execute(cur, """
                                        SELECT COUNT(*) FROM transactions 
                                        WHERE user_id = ? 
                                        AND (is_deleted = 0 OR is_deleted IS NULL)
                                    """, (user_id,))
                                    deleted_count = cur.fetchone()[0]
                                    db_execute(cur, """
                                        UPDATE transactions 
                                        SET is_deleted = 1, 
                                            deleted_at = ?, 
                                            deleted_by = ?
                                        WHERE user_id = ? 
                                        AND (is_deleted = 0 OR is_deleted IS NULL)
                                    """, (int(time.time()), user_id, user_id))
                                    st.info(f"ðŸ—‘ï¸ Soft-deleted {deleted_count:,} existing transactions.")
                                
                                # Also clear cash_deposits if doing full replace
                                db_execute(cur, "DELETE FROM cash_deposits WHERE user_id = ?", (user_id,))
                                conn.commit()
                            
                            progress_bar = st.progress(0, text="Restoring data...")
                            
                            total_rows = len(restore_df)
                            skipped_invalid = 0
                            for idx, row in restore_df.iterrows():
                                # Progress update
                                if idx % 10 == 0:
                                    progress_bar.progress((idx + 1) / total_rows, text=f"Processing row {idx+1}/{total_rows}")

                                # 2. Extract common data first
                                t_date = pd.to_datetime(row['txn_date']).strftime('%Y-%m-%d')
                                t_type = str(row['txn_type']).strip()
                                t_portfolio = str(row.get('portfolio', 'KFH') or 'KFH')
                                
                                # ========== HANDLE DEPOSITS SEPARATELY ==========
                                # Check if this is a deposit transaction (case-insensitive)
                                if t_type.lower() in ['deposit', 'cash_deposit', 'cash deposit', 'flow_in']:
                                    # Get deposit amount from purchase_cost or amount column
                                    deposit_amount = float(row.get('purchase_cost', 0) or row.get('amount', 0) or 0)
                                    if deposit_amount <= 0:
                                        skipped_invalid += 1
                                        continue
                                    
                                    deposit_currency = str(row.get('currency', 'KWD') or 'KWD').upper()
                                    deposit_notes = str(row.get('notes', '') or '')
                                    deposit_ref = str(row.get('reference', '') or '')
                                    
                                    # Check for duplicate deposit (in Merge mode)
                                    if import_mode == "ðŸ”„ Merge (Skip Duplicates)":
                                        db_execute(cur, """
                                            SELECT id FROM cash_deposits 
                                            WHERE deposit_date=? AND amount=? AND user_id=?
                                        """, (t_date, deposit_amount, user_id))
                                        if cur.fetchone():
                                            skipped_count += 1
                                            continue
                                    
                                    # Insert into cash_deposits table
                                    current_fx = get_current_fx_rate()
                                    db_execute(cur, """
                                        INSERT INTO cash_deposits 
                                        (user_id, portfolio, bank_name, deposit_date, amount, currency, 
                                         description, comments, include_in_analysis, fx_rate_at_deposit, created_at)
                                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                    """, (
                                        user_id,
                                        t_portfolio,
                                        deposit_ref if deposit_ref else 'Imported',
                                        t_date,
                                        deposit_amount,
                                        deposit_currency,
                                        deposit_notes,
                                        f"Imported from transactions Excel",
                                        1,  # include_in_analysis = True
                                        current_fx,
                                        int(time.time())
                                    ))
                                    deposits_imported += 1
                                    continue  # Skip to next row, don't process as stock transaction
                                # ========== END DEPOSIT HANDLING ==========

                                # SYMBOL NORMALIZATION: Resolve user input to canonical ticker
                                raw_symbol = str(row['stock_symbol']).strip()
                                symbol = normalize_stock_symbol(raw_symbol, t_portfolio)
                                
                                # Validate symbol format after normalization
                                is_valid, _ = validate_stock_symbol(symbol, allow_new=True)
                                if not is_valid:
                                    skipped_invalid += 1
                                    continue
                                
                                # Auto-register new mapping if normalized differently
                                if raw_symbol.upper() != symbol and raw_symbol.lower() not in ['deposit', 'cash_deposit']:
                                    add_symbol_mapping(raw_symbol, symbol)
                                
                                # 1. Ensure Stock Exists for this user
                                db_execute(cur, "SELECT id FROM stocks WHERE symbol = ? AND user_id = ?", (symbol, user_id))
                                if not cur.fetchone():
                                    # Create stock if missing (use backup data if available)
                                    s_name = row.get('stock_name', symbol)
                                    s_port = row.get('portfolio', 'KFH')
                                    s_curr = row.get('currency', 'KWD')
                                    db_execute(cur, "INSERT INTO stocks (symbol, name, portfolio, currency, user_id) VALUES (?, ?, ?, ?, ?)", 
                                                (symbol, s_name, s_port, s_curr, user_id))
                                    _VALID_SYMBOLS_CACHE.add(symbol.upper())  # Update cache
                                    new_stocks += 1
                                
                                # Extract remaining transaction data
                                t_cat = row.get('category', 'portfolio')
                                t_shares = float(row.get('shares', 0) or 0)
                                t_cost = float(row.get('purchase_cost', 0) or 0)
                                t_sell = float(row.get('sell_value', 0) or 0)
                                t_div = float(row.get('cash_dividend', 0) or 0)
                                t_reinv = float(row.get('reinvested_dividend', 0) or 0)
                                t_bonus = float(row.get('bonus_shares', 0) or 0)
                                t_fees = float(row.get('fees', 0) or 0)
                                t_broker = str(row.get('broker', '') or '')
                                t_ref = str(row.get('reference', '') or '')
                                t_notes = str(row.get('notes', '') or '')
                                t_created = int(row.get('created_at', time.time()) or time.time())
                                
                                # 3. Check Duplicate (only in Merge mode, excluding soft-deleted)
                                if import_mode == "ðŸ”„ Merge (Skip Duplicates)":
                                    db_execute(cur, """
                                        SELECT id FROM transactions 
                                        WHERE stock_symbol=? AND txn_date=? AND txn_type=? 
                                        AND shares=? AND purchase_cost=? AND sell_value=? AND user_id=?
                                        AND (is_deleted = 0 OR is_deleted IS NULL)
                                    """, (symbol, t_date, t_type, t_shares, t_cost, t_sell, user_id))
                                    
                                    if cur.fetchone():
                                        skipped_count += 1
                                        continue
                                
                                # 4. Insert record (with historical FX rate and source tracking)
                                t_fx_rate = float(row.get('fx_rate_at_txn', 0) or 0) if pd.notna(row.get('fx_rate_at_txn')) else get_current_fx_rate()
                                db_execute(cur, """
                                    INSERT INTO transactions 
                                    (stock_symbol, portfolio, txn_date, txn_type, category, shares, purchase_cost, 
                                     sell_value, cash_dividend, reinvested_dividend, bonus_shares, 
                                     fees, broker, reference, notes, fx_rate_at_txn, created_at, user_id,
                                     source, source_reference, is_deleted)
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                """, (symbol, t_portfolio, t_date, t_type, t_cat, t_shares, t_cost, t_sell, 
                                      t_div, t_reinv, t_bonus, t_fees, t_broker, t_ref, t_notes, t_fx_rate, t_created, user_id,
                                      'RESTORE', source_reference, 0))
                                restored_count += 1
                            
                            conn.commit()
                            
                            # AUTO-SYNC: Ensure all transaction symbols have corresponding stock entries
                            stocks_synced = 0
                            db_execute(cur, 'SELECT DISTINCT stock_symbol, portfolio FROM transactions WHERE user_id = ? AND (is_deleted = 0 OR is_deleted IS NULL)', (user_id,))
                            for sym, port in cur.fetchall():
                                if not sym or str(sym).strip().lower() in ['deposit', 'cash_deposit', 'cash deposit', 'flow_in']:
                                    continue
                                sym = str(sym).strip().upper()
                                db_execute(cur, 'SELECT id FROM stocks WHERE UPPER(symbol) = ? AND user_id = ?', (sym, user_id))
                                if not cur.fetchone():
                                    currency = 'USD' if port == 'USA' else 'KWD'
                                    db_execute(cur, 'INSERT INTO stocks (symbol, name, portfolio, currency, user_id) VALUES (?, ?, ?, ?, ?)', 
                                               (sym, sym, port or 'KFH', currency, user_id))
                                    stocks_synced += 1
                            conn.commit()
                            conn.close()
                            
                            progress_bar.empty()
                            build_portfolio_table.clear()  # Clear cache to show updated data
                            
                            if import_mode == "ðŸ—‘ï¸ Delete All & Replace":
                                st.success(f"âœ… Full Replace Complete: Deleted {deleted_count:,}, imported {restored_count:,} transactions.")
                            else:
                                st.success(f"âœ… Merge Complete: {restored_count:,} imported, {skipped_count:,} skipped (duplicates).")
                            
                            if deposits_imported > 0:
                                st.success(f"ðŸ’µ Imported **{deposits_imported:,}** cash deposits to portfolio analysis.")
                            
                            if new_stocks > 0 or stocks_synced > 0:
                                st.info(f"ðŸ†• Created {new_stocks + stocks_synced:,} stock entries.")
                            
                            if skipped_invalid > 0:
                                st.warning(f"âš ï¸ Skipped {skipped_invalid:,} rows with invalid data.")
                            
                            time.sleep(2)
                            st.rerun()
                            
                    except Exception as e:
                        st.error(f"Error restoring data: {e}")
    
    # Add stock section first
    with st.expander("âž• Add New Stock", expanded=True):
        # Market selection row
        market_col, stock_dropdown_col = st.columns([1, 3])
        
        with market_col:
            market = st.selectbox("Market", ["Kuwait Market", "US Market"], key="add_stock_market")
        
        # Get stock options based on selected market
        if market == "Kuwait Market":
            stock_options = get_kuwait_stock_options()
            default_portfolio = "KFH"
            default_currency = "KWD"
        else:
            stock_options = get_us_stock_options()
            default_portfolio = "USA"
            default_currency = "USD"
        
        with stock_dropdown_col:
            selected_stock = st.selectbox(
                "Search Stock", 
                stock_options, 
                key="add_stock_dropdown",
                help="Select a stock from the list or enter manually below"
            )
        
        # Parse selection to pre-fill fields
        market_key = "Kuwait" if market == "Kuwait Market" else "US"
        parsed_symbol, parsed_name, parsed_yf_ticker = parse_stock_selection(selected_stock, market_key)
        
        # Input fields row
        c1, c2, c3, c4, c5 = st.columns([1.3, 3.5, 1.2, 1.2, 1.2])
        
        # Use parsed values as defaults if available
        symbol = c1.text_input("Symbol", value=parsed_symbol or "", placeholder="e.g. AAPL, TSLA")
        name = c2.text_input("Name (optional)", value=parsed_name or "", placeholder="Stock full name (optional)")
        portfolio = c3.selectbox("Portfolio", ["KFH", "BBYN", "USA"], index=["KFH", "BBYN", "USA"].index(default_portfolio), key="manual_portfolio")
        currency = c4.selectbox("Currency", ["KWD", "USD"], index=["KWD", "USD"].index(default_currency), key="manual_currency")
        
        if c5.button("Add Stock", type="primary", key="add_manual_stock"):
            sym = symbol.strip().upper()
            if sym == "":
                st.error("Symbol is required.")
            else:
                # Validate symbol format and security
                is_valid, error_msg = validate_stock_symbol(sym, allow_new=True)
                if not is_valid:
                    st.error(f"Invalid symbol: {error_msg}")
                else:
                    try:
                        user_id = st.session_state.get('user_id', 1)
                        
                        # Auto-fetch price for new stock
                        initial_price = 0.0
                        with st.spinner(f"Fetching price for {sym}..."):
                            fetched_price, _ = fetch_price_yfinance(sym)
                            if fetched_price and fetched_price > 0:
                                initial_price = float(fetched_price)
                        
                        exec_sql(
                            "INSERT INTO stocks (symbol, name, current_price, portfolio, currency, user_id) VALUES (?, ?, ?, ?, ?, ?)",
                            (sym, name.strip(), initial_price, portfolio, currency, user_id),
                        )
                        # Add to valid symbols cache
                        _VALID_SYMBOLS_CACHE.add(sym.upper())
                        if initial_price > 0:
                            st.success(f"Stock {sym} added with price {initial_price:.4f}")
                        else:
                            st.success(f"Stock {sym} added. Click 'Fetch Current Price' to get latest price.")
                        build_portfolio_table.clear()
                        st.rerun()
                    except sqlite3.IntegrityError:
                        st.warning("This symbol already exists.")

    st.divider()

    # Load stored stocks from master (Cached)
    stocks_master = load_stocks_master()
    
    if stocks_master.empty:
        st.info("Add a stock first, then you can add transactions.")
        return

    st.markdown("### ðŸ”Ž Select Stock")
    
    # Prepare options for the dropdown
    # Format: "Name - Ticker"
    stock_options = [
        (f"{row['name']} - {row['symbol']}".strip() if row['name'] else row['symbol'])
        for _, row in stocks_master.iterrows()
    ]

    # Stock Dropdown (Selectbox with built-in search)
    current_selection_index = 0
    if "selected_stock_label" in st.session_state:
         if st.session_state.selected_stock_label in stock_options:
             current_selection_index = stock_options.index(st.session_state.selected_stock_label)
    
    selected_opt = st.selectbox(
        "Select stock from list", 
        stock_options, 
        index=current_selection_index,
        key="stock_selector_dropdown"
    )
    
    # Update session state when selection changes
    if selected_opt:
        st.session_state.selected_stock_label = selected_opt
        # Extract symbol
        selected_symbol = selected_opt.rsplit(" - ", 1)[-1].strip()
        
        # Store in session state as requested
        st.session_state["selected_stock_ticker"] = selected_symbol
        st.session_state["selected_stock_name"] = selected_opt.split(" - ")[0].strip()

    if not selected_opt:
        return

    # Use selected_symbol for the rest of the page logic
    # Re-query specific row to get current_price etc (or use master if it has all info)
    # The load_stocks_master returned symbol, name, portfolio, currency.
    # We might need current_price which wasn't in the minimal load_stocks_master query I wrote?
    # Actually, the original query had current_price.
    # Let's re-fetch the single row to ensure we have fresh price/data for the "Stock Details" panel
    # without reloading the full master table every time a price changes.
    
    # Or better: keep using the `stock_row` query pattern the original code had, but using `selected_symbol`
    
    # Original code logic continues here...
    
    # Fetch FRESH details for the single selected stock
    # This ensures if we update price, it reflects immediately without invalidating the huge master cache.
    user_id = st.session_state.get('user_id', 1)
    stock_row_df = query_df("SELECT * FROM stocks WHERE symbol = ? AND user_id = ?", (selected_symbol, user_id))
    if stock_row_df.empty:
        st.error(f"Stock {selected_symbol} not found in DB.")
        return
    
    stock_row = stock_row_df.iloc[0]
    current_price_db = safe_float(stock_row.get("current_price"), 0)

    st.markdown(f"#### Managing: {stock_row.get('name')} ({selected_symbol})")
    
    # Fetch current price section
    cpx1, cpx2, cpx3 = st.columns([1, 2, 1])
    with cpx1:
        st.metric("Current Price", f"{current_price_db:.6f}")
    with cpx2:
        if st.button("Fetch Current Price", type="primary"):
                with st.spinner(f"Fetching price for {selected_symbol}..."):
                    # âœ… Use Securities Master resolution for proper symbol mapping
                    portfolio = stock_row.get('portfolio') if 'portfolio' in stock_row.index else None
                    p, used_ticker = fetch_price_yfinance(selected_symbol, portfolio=portfolio)

                if p is None:
                    st.error("Price fetch failed from Yahoo Finance")
                    st.info("Check if ticker is registered in Securities Master or mapped in stock_data.py (e.g., KRE -> KRE.KW)")
                else:
                    try:
                        user_id = st.session_state.get('user_id', 1)
                        exec_sql("UPDATE stocks SET current_price = ? WHERE symbol = ? AND user_id = ?", (float(p), selected_symbol, user_id))
                        st.success(f"Price updated: {p:.6f} (from Yahoo: {used_ticker})")
                        # Clear cache to ensure fresh data displays
                        build_portfolio_table.clear()
                        time.sleep(0.3)
                        st.rerun()
                    except Exception as e:
                        st.error(f"Failed to save fetched price: {e}")
    
    with cpx3:
        st.write("")
        st.write("")
        if st.button("ðŸ—‘ï¸ Delete Stock", type="secondary", help="Permanently delete this stock and all its transactions"):
            # Confirmation using session state
            if 'confirm_delete_stock' not in st.session_state:
                st.session_state['confirm_delete_stock'] = selected_symbol
                st.warning(f"âš ï¸ Click 'Confirm Delete' below to permanently remove {selected_symbol} and all its transactions")
                st.rerun()
    
    # Show confirmation button if delete was clicked
    if st.session_state.get('confirm_delete_stock') == selected_symbol:
        st.error(f"âš ï¸ **WARNING:** You are about to permanently delete **{selected_symbol}** and **ALL** its transactions. This cannot be undone!")
        
        col_confirm, col_cancel = st.columns([1, 1])
        with col_confirm:
            if st.button("âœ… Confirm Delete", type="primary", key="confirm_delete_btn"):
                try:
                    user_id = st.session_state.get('user_id')
                    conn = get_conn()
                    cur = conn.cursor()
                    
                    # Delete all PORTFOLIO transactions for this stock (not trading)
                    db_execute(cur, "DELETE FROM transactions WHERE stock_symbol = ? AND user_id = ? AND COALESCE(category, 'portfolio') = 'portfolio'", (selected_symbol, user_id))
                    txn_deleted = cur.rowcount
                    
                    # Delete the stock itself
                    db_execute(cur, "DELETE FROM stocks WHERE symbol = ? AND user_id = ?", (selected_symbol, user_id))
                    
                    conn.commit()
                    conn.close()
                    
                    # Clear confirmation state
                    del st.session_state['confirm_delete_stock']
                    build_portfolio_table.clear()  # Clear cache to show updated data
                    
                    st.success(f"âœ… Deleted {selected_symbol} and {txn_deleted:,} transactions")
                    time.sleep(2)
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"Error deleting stock: {e}")
        
        with col_cancel:
            if st.button("âŒ Cancel", key="cancel_delete_btn"):
                del st.session_state['confirm_delete_stock']
                st.rerun()

    # Edit stock name (and other small fields) per user request
    with st.expander("âœï¸ Edit Stock Details", expanded=False):
        try:
            current_name = stock_row.get("name", "")
        except Exception:
            current_name = ""
        # Allow editing the ticker/symbol as well as the name.
        current_symbol = selected_symbol
        new_symbol = st.text_input("Ticker (symbol)", value=current_symbol, key=f"edit_symbol_{selected_symbol}")

        edited_name = st.text_input("Stock name", value=current_name, key=f"edit_name_{selected_symbol}")
        col_apply, col_validate = st.columns([1, 1])
        with col_apply:
            if st.button("Save Name"):
                # Replace the stock name completely with the entered value (allow empty string)
                try:
                    user_id = st.session_state.get('user_id', 1)
                    exec_sql("UPDATE stocks SET name = ? WHERE symbol = ? AND user_id = ?", (edited_name, selected_symbol, user_id))
                    st.success("Stock name updated.")
                    try:
                        st.rerun()
                    except Exception:
                        pass
                except Exception as e:
                    st.error(f"Failed to update stock name: {e}")

            if st.button("Save Ticker"):
                ns = (new_symbol or "").strip().upper()
                if ns == "":
                    st.error("Ticker cannot be empty.")
                elif ns == current_symbol:
                    st.info("Ticker unchanged.")
                else:
                    # Validate new ticker format
                    is_valid, error_msg = validate_stock_symbol(ns, allow_new=True)
                    if not is_valid:
                        st.error(f"Invalid ticker: {error_msg}")
                    else:
                        # ensure no existing stock uses the new symbol
                        user_id = st.session_state.get('user_id', 1)
                        dup = query_df("SELECT COUNT(1) AS c FROM stocks WHERE symbol = ? AND user_id = ?", (ns, user_id))
                        if int(dup.iloc[0]["c"]) > 0:
                            st.error(f"Cannot rename: symbol '{ns}' already exists.")
                        else:
                            try:
                                conn = get_conn()
                                cur = conn.cursor()
                                # perform updates inside a transaction
                                user_id = st.session_state.get('user_id', 1)
                                db_execute(cur, "UPDATE transactions SET stock_symbol = ? WHERE stock_symbol = ? AND user_id = ?", (ns, current_symbol, user_id))
                                db_execute(cur, "UPDATE stocks SET symbol = ? WHERE symbol = ? AND user_id = ?", (ns, current_symbol, user_id))
                                conn.commit()
                                conn.close()
                                # Update cache with new symbol
                                _VALID_SYMBOLS_CACHE.add(ns)
                                st.success(f"Ticker renamed {current_symbol} âž¡ï¸ {ns} and transactions updated.")
                                try:
                                    st.rerun()
                                except Exception:
                                    pass
                            except Exception as e:
                                try:
                                    conn.rollback()
                                    conn.close()
                                except Exception:
                                    pass
                                st.error(f"Failed to rename ticker: {e}")

        with col_validate:
            st.markdown("---")
            if st.button("Map to TradingView"):
                with st.spinner("Searching TradingView..."):
                    tv_cands = map_to_tradingview(selected_symbol, exchange="KSE")
                if not tv_cands:
                    st.warning("No TradingView matches found.")
                else:
                    options = [f"{c['tv_symbol']} â€¢ {c.get('full_name','')} ({c.get('exchange','')})" for c in tv_cands]
                    choice = st.radio("Select TradingView symbol", options, key=f"tv_map_{selected_symbol}")
                    idx = options.index(choice)
                    chosen = tv_cands[idx]
                    if st.button("Apply TradingView Symbol"):
                        try:
                            user_id = st.session_state.get('user_id', 1)
                            exec_sql("UPDATE stocks SET tradingview_symbol = ?, tradingview_exchange = ? WHERE symbol = ? AND user_id = ?", (chosen['tv_symbol'], chosen.get('exchange'), selected_symbol, user_id))
                            st.success(f"Saved TradingView mapping: {chosen.get('exchange','')}:{chosen['tv_symbol']}")
                            try:
                                st.rerun()
                            except Exception:
                                pass
                        except Exception as e:
                            st.error(f"Failed to save TradingView symbol: {e}")

    tx = query_df(
        """
        SELECT
            id,
            stock_symbol,
            txn_date,
            txn_type,
            purchase_cost,
            sell_value,
            shares,
            bonus_shares,
            cash_dividend,
            price_override,
            planned_cum_shares,
            reinvested_dividend,
            fees,
            broker,
            reference,
            notes,
            category,
            created_at
        FROM transactions
        WHERE stock_symbol = ? AND user_id = ?
        ORDER BY txn_date ASC, created_at ASC, id ASC
        """,
        (selected_symbol, user_id),
    )
    
    # Separate subset for metrics calculation (only 'portfolio' category)
    # Handle NULL category as 'portfolio'
    if not tx.empty:
        tx['category'] = tx['category'].fillna('portfolio')
        tx_calc = tx[tx['category'] == 'portfolio']
    else:
        tx_calc = tx

    metrics = compute_stock_metrics(tx_calc)
    current_price = float(current_price_db)
    market_value = metrics["current_shares"] * current_price

    st.markdown(f"### Transactions for: **{selected_symbol}**")
    
    # Excel Upload for this stock
    with st.expander("ðŸ” Upload Transactions for this Stock (Excel)", expanded=False):
        st.caption(f"Upload transactions for **{selected_symbol}** only. The Excel file should have columns: txn_date, txn_type, shares, purchase_cost/sell_value, etc.")
        uploaded_file = st.file_uploader("Choose Excel file", type=['xlsx'], key=f"upload_txn_{selected_symbol}")
        
        if uploaded_file:
            try:
                xl = pd.ExcelFile(uploaded_file)
                sheet = "Transactions" if "Transactions" in xl.sheet_names else xl.sheet_names[0]
                raw = xl.parse(sheet_name=sheet)
                
                if raw.empty:
                    st.warning("Excel sheet is empty.")
                else:
                    # Normalize columns
                    df = raw.copy()
                    df.columns = [_norm_col(c) for c in df.columns]
                    
                    st.write(f"Preview ({len(df):,} rows):")
                    st.dataframe(df.head(20), width="stretch")
                    
                    if st.button("Import These Transactions", type="primary", key=f"import_btn_{selected_symbol}"):
                        # Use the FIXED upload handler with all improvements
                        user_id = st.session_state.get('user_id', 1)
                        
                        # Get portfolio ID from selected stock
                        portfolio_name = stock_row.get('portfolio', 'KFH')
                        portfolio_map = {'KFH': 1, 'BBYN': 2, 'USA': 3}
                        portfolio_id = portfolio_map.get(portfolio_name, 1)
                        
                        # Save file to temp location for upload
                        import tempfile
                        import os
                        temp_dir = tempfile.gettempdir()
                        temp_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(temp_path, 'wb') as f:
                            f.write(uploaded_file.getvalue())
                        
                        # Call the FIXED upload handler
                        debug_log = [f"[TRADING UPLOAD] Started for {selected_symbol}"]
                        result = upload_transactions_fixed(
                            user_id=user_id,
                            excel_file=temp_path,
                            portfolio_id=portfolio_id,
                            stock_symbol=selected_symbol,  # Force all transactions to this symbol
                            debug_log=debug_log
                        )
                        
                        # Clean up temp file
                        try:
                            os.remove(temp_path)
                        except:
                            pass
                        
                        # Store results in session state for display after rerun
                        st.session_state['last_upload_debug_log'] = result.get('debug_log', debug_log)
                        st.session_state['last_upload_errors'] = result.get('errors', [])
                        st.session_state['last_upload_imported'] = result.get('uploaded', 0)
                        st.session_state['last_upload_symbol'] = selected_symbol
                        st.session_state['last_upload_soft_deleted'] = result.get('soft_deleted', 0)
                        
                        if result.get('uploaded', 0) > 0:
                            build_portfolio_table.clear()  # Clear cache to show updated data
                            st.rerun()
                        
            except Exception as e:
                st.error(f"Error reading Excel: {e}")
    
    # Show last upload results (persisted in session state)
    if st.session_state.get('last_upload_debug_log') and st.session_state.get('last_upload_symbol') == selected_symbol:
        debug_log = st.session_state['last_upload_debug_log']
        errors = st.session_state.get('last_upload_errors', [])
        imported = st.session_state.get('last_upload_imported', 0)
        soft_deleted = st.session_state.get('last_upload_soft_deleted', 0)
        
        # Show success message
        if imported > 0:
            msg = f"âœ… Imported {imported:,} transactions for {selected_symbol}"
            if soft_deleted > 0:
                msg += f" (replaced {soft_deleted} previous entries)"
            st.success(msg)
        
        # Show errors if any
        if errors:
            st.error(f"âŒ {len(errors)} errors:")
            st.write(errors[:10])
        
        # Show debug log in expander (always visible after upload)
        with st.expander("ðŸ” Debug Log (Last Upload)", expanded=True):
            st.code("\n".join(debug_log), language="text")
        
        # Clear button
        if st.button("ðŸ§¹ Clear Upload Log", key="clear_upload_log"):
            st.session_state.pop('last_upload_debug_log', None)
            st.session_state.pop('last_upload_errors', None)
            st.session_state.pop('last_upload_imported', None)
            st.session_state.pop('last_upload_symbol', None)
            st.session_state.pop('last_upload_soft_deleted', None)
            st.rerun()

    s1, s2, s3, s4, s5, s6 = st.columns(6)
    s1.metric("Total Purchase", fmt_money_plain(metrics["total_buy_cost"]))
    s2.metric("Total Shares Purchased", fmt_int(metrics["total_buy_shares"]))
    s3.metric("Total Shares (Current)", fmt_int(metrics["current_shares"]))
    s4.metric("Average Cost", fmt_price(metrics['avg_cost'], 6))
    s5.metric("Current Price", f"{current_price:.6f}")
    s6.metric("Market Value", fmt_money_plain(market_value))

    st.divider()

    # Get user_id for all transaction operations
    user_id = st.session_state.get('user_id', 1)

    # Add transaction form
    with st.expander("âž• Add Transaction (more fields)", expanded=True):
        c1, c2, c3, c4 = st.columns([1.1, 1, 1, 1])
        txn_date = c1.date_input("Date", value=date.today(), key="txn_date")
        txn_type = c2.selectbox("Type", ["Buy", "Sell", "Dividend only"], key="txn_type")
        
        # Conditional fields based on transaction type
        if txn_type == "Dividend only":
            # DIVIDEND ONLY MODE - Show only dividend-related fields
            st.info("â„¹ï¸ Recording dividends only (no trade/shares impact). Dividends will increase your cash balance.")
            
            d1, d2, d3 = st.columns([1, 1, 1])
            cash_dividend = d1.number_input("Cash Dividend received (KD)", min_value=0.0, step=1.0, format="%.3f", key="txn_cash_dividend")
            reinv = d2.number_input("Reinvested Dividend (KD)", min_value=0.0, step=1.0, format="%.3f", key="txn_reinv")
            bonus_shares = d3.number_input("Bonus Shares (stock dividend)", min_value=0.0, step=1.0, format="%.0f", key="txn_bonus_shares")
            
            # Dividends always affect portfolio - no record-only option
            category_val = 'portfolio'
            
            notes = st.text_area("Notes (optional)", key="txn_notes")
            
            # Set all trade-related fields to 0
            shares = 0.0
            purchase_cost = 0.0
            sell_value = 0.0
            fees = 0.0
            broker = ""
            reference = ""
            price_override = None
            planned_cum = 0.0
            
            if st.button("Save Dividend Transaction", type="primary"):
                # Validation: at least one dividend field must be > 0
                if cash_dividend <= 0 and reinv <= 0 and bonus_shares <= 0:
                    st.error("âš ï¸ Please enter at least one of: Cash Dividend, Reinvested Dividend, or Bonus Shares.")
                else:
                    current_fx = get_current_fx_rate()  # Store historical FX rate
                    exec_sql(
                        """
                        INSERT INTO transactions
                        (user_id, stock_symbol, txn_date, txn_type, purchase_cost, sell_value, shares,
                         bonus_shares, cash_dividend,
                         price_override, planned_cum_shares, reinvested_dividend, fees,
                         broker, reference, notes, category, fx_rate_at_txn, created_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """,
                        (
                            user_id,
                            normalize_symbol(selected_symbol, user_id),
                            txn_date.isoformat(),
                            "DIVIDEND_ONLY",
                            0.0,
                            0.0,
                            0.0,
                            float(bonus_shares),
                            float(cash_dividend),
                            None,
                            None,
                            float(reinv),
                            0.0,
                            "",
                            "",
                            notes.strip(),
                            category_val,
                            current_fx,
                            int(time.time()),
                        ),
                    )
                    
                    # Audit log: Dividend transaction
                    stock_portfolio = stock_row.get('portfolio', 'KFH')
                    stock_currency = stock_row.get('currency', 'KWD')
                    log_audit_event(
                        user_id=user_id,
                        operation='DIVIDEND',
                        entity_type='transaction',
                        new_value=float(cash_dividend),
                        delta=float(cash_dividend),
                        portfolio=stock_portfolio,
                        currency=stock_currency,
                        reason='USER_ACTION',
                        details=f"{selected_symbol}: Cash={cash_dividend}, Reinv={reinv}, Bonus={bonus_shares}"
                    )
                    
                    # Update portfolio cash: DIVIDEND always increases cash
                    if float(cash_dividend) > 0:
                        update_portfolio_cash(user_id, stock_portfolio, float(cash_dividend), stock_currency)
                        st.success(f"âœ… Dividend saved. Cash +{cash_dividend:,.3f} {stock_currency}")
                    else:
                        st.success("âœ… Dividend transaction saved.")
                    st.rerun()
        
        else:
            # BUY/SELL MODE - Show regular trade fields
            shares = c3.number_input("# of shares", min_value=0.0, step=1.0, format="%.0f", key="txn_shares")
            reinv = c4.number_input("Reinvested dividends (KD)", min_value=0.0, step=1.0, format="%.3f", key="txn_reinv")

            d1, d2 = st.columns([1, 1])
            bonus_shares = d1.number_input("Bonus Shares (stock dividend)", min_value=0.0, step=1.0, format="%.0f", key="txn_bonus_shares")
            cash_dividend = d2.number_input("Cash Dividend (received)", min_value=0.0, step=1.0, format="%.3f", key="txn_cash_dividend")

            c5, c6, c7 = st.columns([1.2, 1.2, 1.6])

            purchase_cost = 0.0
            sell_value = 0.0
            if txn_type == "Buy":
                purchase_cost = c5.number_input("Actual purchase cost", min_value=0.0, step=10.0, format="%.3f", key="txn_buy_cost")
            else:
                sell_value = c5.number_input("Actual sell value", min_value=0.0, step=10.0, format="%.3f", key="txn_sell_value")

            use_override = c6.checkbox("Override price?", value=False, key="use_override_price")
            price_override = None
            if use_override:
                price_override = c6.number_input("Override Price", min_value=0.0, step=0.001, format="%.6f", key="txn_price_override")
            else:
                c6.caption("Price will be calculated automatically from cost/value / shares.")

            planned_cum = c7.number_input("Planned CUM shares (optional)", min_value=0.0, step=1.0, format="%.0f", key="txn_planned_cum")

            # Live price preview
            calc_price = 0.0
            if shares > 0:
                if txn_type == "Buy":
                    calc_price = (float(purchase_cost) / float(shares)) if purchase_cost > 0 else 0.0
                else:
                    calc_price = (float(sell_value) / float(shares)) if sell_value > 0 else 0.0
            st.info(f"Auto Price Preview = {calc_price:.6f}")

            c8, c9, c10 = st.columns([1, 1, 2])
            fees = c8.number_input("Fees (optional)", min_value=0.0, step=0.100, format="%.3f", key="txn_fees")
            broker = c9.text_input("Broker/Platform (optional)", key="txn_broker")
            reference = c10.text_input("Reference / Order ID (optional)", key="txn_reference")

            notes = st.text_area("Notes (optional)", key="txn_notes")

            available_before = float(metrics["current_shares"])
            if txn_type == "Sell" and shares > available_before:
                st.error(f"You are trying to SELL {shares:,.0f} shares but available is {available_before:,.0f}.")

            if st.button("Save Transaction", type="primary"):
                # Only block when trying to sell more than available
                if txn_type == "Sell" and shares > available_before:
                    st.error("Cannot sell more than available quantity.")
                else:
                    # CFA Compliance: Check stock exclusivity (cannot be in both Portfolio and Trading)
                    is_exclusive, excl_err = check_stock_exclusivity(selected_symbol, 'portfolio', st.session_state.get('user_id', 1))
                    if not is_exclusive:
                        st.error(excl_err)
                    else:
                        # Allow empty/zero shares and costs; provide non-blocking warnings
                        if shares <= 0:
                            st.warning("Shares is empty or zero â€¢ transaction will be recorded with 0 shares.")
                        if txn_type == "Buy" and purchase_cost <= 0:
                            st.warning("Purchase cost is empty or zero â€¢ recorded as 0.0.")
                        if txn_type == "Sell" and sell_value <= 0:
                            st.warning("Sell value is empty or zero â€¢ recorded as 0.0.")

                        po = None if (price_override is None) else float(price_override)
                        pc = None if planned_cum == 0 else float(planned_cum)
                        current_fx = get_current_fx_rate()  # Store historical FX rate

                        exec_sql(
                            """
                            INSERT INTO transactions
                            (user_id, stock_symbol, txn_date, txn_type, purchase_cost, sell_value, shares,
                             bonus_shares, cash_dividend,
                             price_override, planned_cum_shares, reinvested_dividend, fees,
                             broker, reference, notes, category, fx_rate_at_txn, created_at)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """,
                            (
                                user_id,
                                normalize_symbol(selected_symbol, user_id),
                                txn_date.isoformat(),
                                txn_type,
                                float(purchase_cost),
                                float(sell_value),
                                float(shares),
                                float(bonus_shares),
                                float(cash_dividend),
                                po,
                                pc,
                                float(reinv),
                                float(fees),
                                broker.strip(),
                                reference.strip(),
                                notes.strip(),
                                'portfolio',
                                current_fx,
                                int(time.time()),
                            ),
                        )

                        # Update portfolio cash balance (ledger effect)
                        stock_portfolio = stock_row.get('portfolio', 'KFH')
                        stock_currency = stock_row.get('currency', 'KWD')
                        
                        # Cash Rules:
                        # - SELL: cash += (sell_value - fees)
                        # - BUY: cash -= (purchase_cost + fees)
                        # - DIVIDEND: cash += cash_dividend (handled separately)
                        
                        cash_delta = 0.0
                        if txn_type == "Sell" and float(sell_value) > 0:
                            # Sell increases cash (minus fees)
                            cash_delta = float(sell_value) - float(fees)
                            update_portfolio_cash(user_id, stock_portfolio, cash_delta, stock_currency)
                            st.success(f"Transaction saved. Cash +{cash_delta:,.3f} {stock_currency}")
                        elif txn_type == "Buy" and float(purchase_cost) > 0:
                            # Buy decreases cash (plus fees)
                            cash_delta = -(float(purchase_cost) + float(fees))
                            update_portfolio_cash(user_id, stock_portfolio, cash_delta, stock_currency)
                            st.success(f"Transaction saved. Cash {cash_delta:,.3f} {stock_currency}")
                        else:
                            # Handle dividend on Buy/Sell transactions
                            if float(cash_dividend) > 0:
                                update_portfolio_cash(user_id, stock_portfolio, float(cash_dividend), stock_currency)
                                st.success(f"Transaction saved. Cash +{cash_dividend:,.3f} {stock_currency} (dividend)")
                            else:
                                st.success("Transaction saved.")
                        
                        # Audit log: Buy/Sell transaction
                        log_audit_event(
                            user_id=user_id,
                            operation=txn_type.upper(),
                            entity_type='transaction',
                            new_value=float(sell_value) if txn_type == 'Sell' else float(purchase_cost),
                            delta=cash_delta,
                            portfolio=stock_portfolio,
                            currency=stock_currency,
                            reason='USER_ACTION',
                            details=f"{selected_symbol}: {shares} shares @ {purchase_cost if txn_type == 'Buy' else sell_value}"
                        )
                        
                        build_portfolio_table.clear()  # Clear cache to show updated cash
                        st.rerun()

    st.markdown("### Transactions Table")
    
    # Initialize session state for editing
    if 'editing_tx_id' not in st.session_state:
        st.session_state.editing_tx_id = None
    if tx.empty:
        st.info("No transactions yet.")
        return


    # Filter controls
    f_col1, f_col2 = st.columns([1, 4])
    show_all_records = f_col1.checkbox("Show 'Record Only' items", value=True, help="Include items not in portfolio analysis")
    
    view = compute_transactions_view(tx)
    if not show_all_records and not tx.empty:
        # Filter out 'record' items from view if unchecked
        # Note: compute_transactions_view preserves all rows, so we filter by index or ID match if needed,
        # but simpler is to use the 'category' column if it was preserved.
        # compute_transactions_view creates a copy, so we need to ensure 'category' is in it.
        # Just map ID back to category
        id_to_cat = dict(zip(tx['id'], tx['category']))
        view['category'] = view['id'].map(id_to_cat)
        view = view[view['category'] == 'portfolio']

    # Column headers
    header_cols = st.columns([0.4, 0.8, 0.6, 0.6, 1, 1, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 1, 0.5])
    header_cols[0].markdown("**#**")
    header_cols[1].markdown("**ID**")
    header_cols[2].markdown("**Date**")
    header_cols[3].markdown("**Type**")
    header_cols[4].markdown("**Purchase**")
    header_cols[5].markdown("**Sell**")
    header_cols[6].markdown("**Shares**")
    header_cols[7].markdown("**Price**")
    header_cols[8].markdown("**CUM**")
    header_cols[9].markdown("**Bonus**")
    header_cols[10].markdown("**Cash Div**")
    header_cols[11].markdown("**Reinvest**")
    header_cols[12].markdown("**Notes**")
    header_cols[13].markdown("**Edit**")
    st.divider()
    
    # Display each transaction with edit button
    for idx, row in view.iterrows():
        tx_id = int(row['id'])
        
        # Check if this transaction is being edited
        if st.session_state.editing_tx_id == tx_id:
            # EDIT MODE - Show editable form
            with st.container():
                st.markdown(f"#### âœï¸ Editing Transaction ID: {tx_id}")
                
                # Determine type index for selectbox
                type_options = ["Buy", "Sell", "Dividend only"]
                current_type = row['txn_type']
                if current_type == 'DIVIDEND_ONLY':
                    type_idx = 2
                elif current_type == 'Sell':
                    type_idx = 1
                else:
                    type_idx = 0
                
                ec1, ec2 = st.columns([1.5, 1.5])
                edit_date = ec1.date_input("Date", value=pd.to_datetime(row['txn_date']).date(), key=f"edit_date_{tx_id}")
                edit_type = ec2.selectbox("Type", type_options, index=type_idx, key=f"edit_type_{tx_id}")
                
                # Conditional fields based on type
                if edit_type == "Dividend only":
                    # DIVIDEND ONLY EDIT MODE
                    st.info("â„¹ï¸ Editing dividend-only transaction")
                    
                    ed1, ed2, ed3 = st.columns([1, 1, 1])
                    edit_cash_div = ed1.number_input("Cash Dividend (KD)", min_value=0.0, step=1.0, format="%.3f", value=float(row.get('cash_dividend', 0)), key=f"edit_cash_div_{tx_id}")
                    edit_reinv = ed2.number_input("Reinvested (KD)", min_value=0.0, step=1.0, format="%.3f", value=float(row.get('reinvested_dividend', 0)), key=f"edit_reinv_{tx_id}")
                    edit_bonus = ed3.number_input("Bonus Shares", min_value=0.0, step=1.0, format="%.0f", value=float(row.get('bonus_shares', 0)), key=f"edit_bonus_{tx_id}")
                    
                    # Option to include in portfolio analysis or keep as record only
                    current_category = row.get('category', 'portfolio')
                    # Handle NULL category as 'portfolio'
                    if pd.isna(current_category) or current_category == '':
                        current_category = 'portfolio'
                        
                    # Dividends always affect portfolio - no record-only option
                    edit_category_val = 'portfolio'
                    
                    edit_notes = st.text_area("Notes", value=str(row.get('notes', '')), key=f"edit_notes_{tx_id}")
                    
                    # Set trade fields to 0 for dividend-only
                    edit_shares = 0.0
                    edit_purchase_cost = 0.0
                    edit_sell_value = 0.0
                    edit_fees = 0.0
                    edit_broker = ""
                    edit_reference = ""
                    edit_price_override = None
                    edit_planned_cum = 0.0
                    
                else:
                    # BUY/SELL EDIT MODE
                    edit_category_val = 'portfolio'  # Buy/Sell always portfolio for now
                    ec3, ec4 = st.columns([1, 1])
                    edit_shares = ec3.number_input("# of shares", min_value=0.0, step=1.0, format="%.0f", value=float(row['shares']), key=f"edit_shares_{tx_id}")
                    edit_reinv = ec4.number_input("Reinvested (KD)", min_value=0.0, step=1.0, format="%.3f", value=float(row.get('reinvested_dividend', 0)), key=f"edit_reinv_{tx_id}")

                    ed1, ed2 = st.columns([1, 1])
                    edit_bonus = ed1.number_input("Bonus Shares", min_value=0.0, step=1.0, format="%.0f", value=float(row.get('bonus_shares', 0)), key=f"edit_bonus_{tx_id}")
                    edit_cash_div = ed2.number_input("Cash Dividend (KD)", min_value=0.0, step=1.0, format="%.3f", value=float(row.get('cash_dividend', 0)), key=f"edit_cash_div_{tx_id}")

                    ec5, ec6, ec7 = st.columns([1.2, 1.2, 1.6])

                    if edit_type == "Buy":
                        edit_purchase_cost = ec5.number_input("Purchase cost", min_value=0.0, step=10.0, format="%.3f", value=float(row['purchase_cost']), key=f"edit_buy_cost_{tx_id}")
                        edit_sell_value = 0.0
                    else:
                        edit_purchase_cost = 0.0
                        edit_sell_value = ec5.number_input("Sell value", min_value=0.0, step=10.0, format="%.3f", value=float(row['sell_value']), key=f"edit_sell_value_{tx_id}")

                    edit_use_override = ec6.checkbox("Override price?", value=row['price_override'] is not None and not pd.isna(row['price_override']), key=f"edit_use_override_{tx_id}")
                    edit_price_override = None
                    if edit_use_override:
                        override_val = float(row['price_override']) if row['price_override'] is not None and not pd.isna(row['price_override']) else 0.0
                        edit_price_override = ec6.number_input("Override Price", min_value=0.0, step=0.001, format="%.6f", value=override_val, key=f"edit_price_override_{tx_id}")

                    edit_planned_cum = ec7.number_input("Planned CUM", min_value=0.0, step=1.0, format="%.0f", value=float(row.get('planned_cum_shares', 0) or 0), key=f"edit_planned_cum_{tx_id}")

                    ec8, ec9, ec10 = st.columns([1, 1, 2])
                    edit_fees = ec8.number_input("Fees", min_value=0.0, step=0.100, format="%.3f", value=float(row.get('fees', 0)), key=f"edit_fees_{tx_id}")
                    edit_broker = ec9.text_input("Broker", value=str(row.get('broker', '')), key=f"edit_broker_{tx_id}")
                    edit_reference = ec10.text_input("Reference", value=str(row.get('reference', '')), key=f"edit_reference_{tx_id}")

                    edit_notes = st.text_area("Notes", value=str(row.get('notes', '')), key=f"edit_notes_{tx_id}")

                col_save, col_cancel, col_delete = st.columns([1, 1, 1])
                
                with col_save:
                    if st.button("ðŸ’¾ Save", type="primary", key=f"save_{tx_id}"):
                        # Validation for dividend-only
                        if edit_type == "Dividend only":
                            if edit_cash_div <= 0 and edit_reinv <= 0 and edit_bonus <= 0:
                                st.error("âš ï¸ At least one dividend field must be > 0")
                            else:
                                exec_sql(
                                    """
                                    UPDATE transactions
                                    SET txn_date = ?, txn_type = ?, purchase_cost = ?, sell_value = ?, shares = ?,
                                        bonus_shares = ?, cash_dividend = ?, price_override = ?, planned_cum_shares = ?,
                                        reinvested_dividend = ?, fees = ?, broker = ?, reference = ?, notes = ?, category = ?
                                    WHERE id = ?
                                    """,
                                    (
                                        edit_date.isoformat(),
                                        "DIVIDEND_ONLY",
                                        0.0,
                                        0.0,
                                        0.0,
                                        float(edit_bonus),
                                        float(edit_cash_div),
                                        None,
                                        None,
                                        float(edit_reinv),
                                        0.0,
                                        "",
                                        "",
                                        edit_notes.strip(),
                                        edit_category_val,
                                        tx_id,
                                    ),
                                )
                                st.session_state.editing_tx_id = None
                                st.success(f"Transaction {tx_id} updated!")
                                st.rerun()
                        else:
                            # Regular buy/sell update
                            edit_po = None if not edit_use_override else float(edit_price_override)
                            edit_pc = None if edit_planned_cum == 0 else float(edit_planned_cum)

                            exec_sql(
                                """
                                UPDATE transactions
                                SET txn_date = ?, txn_type = ?, purchase_cost = ?, sell_value = ?, shares = ?,
                                    bonus_shares = ?, cash_dividend = ?, price_override = ?, planned_cum_shares = ?,
                                    reinvested_dividend = ?, fees = ?, broker = ?, reference = ?, notes = ?, category = ?
                                WHERE id = ?
                                """,
                                (
                                    edit_date.isoformat(),
                                    edit_type,
                                    float(edit_purchase_cost),
                                    float(edit_sell_value),
                                    float(edit_shares),
                                    float(edit_bonus),
                                    float(edit_cash_div),
                                    edit_po,
                                    edit_pc,
                                    float(edit_reinv),
                                    float(edit_fees),
                                    edit_broker.strip(),
                                    edit_reference.strip(),
                                    edit_notes.strip(),
                                    edit_category_val,
                                    tx_id,
                                ),
                            )
                            
                            # Update portfolio cash: reverse old effect, apply new effect
                            old_type = row['txn_type']
                            old_sell = float(row.get('sell_value', 0) or 0)
                            old_buy = float(row.get('purchase_cost', 0) or 0)
                            
                            # Get portfolio and currency from stock_row (it's a Series, not DataFrame)
                            stock_portfolio = stock_row.get('portfolio', 'KFH') if stock_row is not None else 'KFH'
                            stock_currency = stock_row.get('currency', 'KWD') if stock_row is not None else 'KWD'
                            
                            # Calculate old cash effect (what was added/subtracted before)
                            old_cash_effect = 0.0
                            if old_type == 'Sell':
                                old_cash_effect = old_sell  # Sell added cash
                            elif old_type == 'Buy':
                                old_cash_effect = -old_buy  # Buy subtracted cash
                            
                            # Calculate new cash effect
                            new_cash_effect = 0.0
                            if edit_type == 'Sell':
                                new_cash_effect = float(edit_sell_value)
                            elif edit_type == 'Buy':
                                new_cash_effect = -float(edit_purchase_cost)
                            
                            # Net delta = new effect - old effect
                            net_delta = new_cash_effect - old_cash_effect
                            if net_delta != 0:
                                update_portfolio_cash(user_id, stock_portfolio, net_delta, stock_currency)
                            
                            st.session_state.editing_tx_id = None
                            st.success(f"Transaction {tx_id} updated!")
                            build_portfolio_table.clear()
                            st.rerun()
                
                with col_delete:
                    if st.button("ðŸ—‘ï¸ Delete", type="secondary", key=f"delete_{tx_id}"):
                        # Reverse cash effect before deleting
                        old_type = row.get('txn_type', '')
                        old_sell = safe_float(row.get('sell_value'), 0)
                        old_buy = safe_float(row.get('purchase_cost'), 0)
                        old_shares = safe_float(row.get('shares'), 0)
                        stock_portfolio = stock_row.get('portfolio', 'KFH')
                        stock_currency = stock_row.get('currency', 'KWD')
                        stock_symbol = row.get('stock_symbol', '')
                        
                        # Calculate cash delta for audit
                        cash_delta = 0.0
                        if old_type == 'Sell' and old_sell > 0:
                            # Reverse: Sell had added cash, so subtract it
                            cash_delta = -old_sell
                            update_portfolio_cash(user_id, stock_portfolio, cash_delta, stock_currency)
                        elif old_type == 'Buy' and old_buy > 0:
                            # Reverse: Buy had subtracted cash, so add it back
                            cash_delta = old_buy
                            update_portfolio_cash(user_id, stock_portfolio, cash_delta, stock_currency)
                        
                        # Audit log before delete
                        log_audit_event(
                            user_id=user_id,
                            operation='TRANSACTION_DELETE',
                            entity_type='transaction',
                            entity_id=tx_id,
                            old_value=old_sell if old_type == 'Sell' else old_buy,
                            delta=cash_delta,
                            portfolio=stock_portfolio,
                            currency=stock_currency,
                            reason='USER_ACTION',
                            details=f"{old_type} {old_shares} shares of {stock_symbol}"
                        )
                        
                        # Soft-delete transaction (can be restored within 30 days)
                        soft_delete_transaction(user_id, tx_id)
                        st.session_state.editing_tx_id = None
                        st.success(f"Transaction {tx_id} deleted. Use 'Trash' to undo if needed.")
                        build_portfolio_table.clear()
                        st.rerun()
                
                st.divider()
        
        else:
            # VIEW MODE - Show transaction row with edit button
            with st.container():
                cols = st.columns([0.4, 0.8, 0.6, 0.6, 1, 1, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 1, 0.5])
                
                cols[0].write(f"**{row['Serial']}**")
                cols[1].write(f"ID: {tx_id}")
                cols[2].write(row['txn_date'])
                cols[3].write(row['txn_type'])
                cols[4].write(fmt_kwd(row['purchase_cost']))
                cols[5].write(fmt_kwd(row['sell_value']))
                cols[6].write(fmt_int(row['shares']))
                cols[7].write(fmt_price(row['Price'], 6))
                cols[8].write(fmt_int(row['CUM shares']))
                cols[9].write(fmt_int(row.get('bonus_shares', 0)))
                cols[10].write(fmt_kwd(row.get('cash_dividend', 0)))
                cols[11].write(fmt_kwd(row.get('reinvested_dividend', 0)))
                
                # Visual indicator for Record Only
                cat_val = row.get('category')
                # If category is missing in 'view', try to map it from tx
                if pd.isna(cat_val) and not tx.empty:
                     cat_val = tx.loc[tx['id'] == tx_id, 'category'].iloc[0] if not tx[tx['id'] == tx_id].empty else 'portfolio'
                
                if cat_val == 'record':
                    cols[12].markdown("ðŸ“ **(Record Only)** " + (str(row.get('notes', ''))[:15] + "..." if len(str(row.get('notes', ''))) > 15 else str(row.get('notes', ''))))
                else:
                    cols[12].write(str(row.get('notes', ''))[:20] + "..." if len(str(row.get('notes', ''))) > 20 else str(row.get('notes', '')))
                
                if cols[13].button("âœï¸", key=f"edit_btn_{tx_id}"):
                    st.session_state.editing_tx_id = tx_id
                    st.rerun()
                
                st.divider()

    with st.expander("âš ï¸ Remove Stock (deletes all transactions)"):
        st.warning("This soft-deletes the stock AND all related PORTFOLIO transactions. They can be restored from Trash within 30 days.")
        if st.button(f"Remove {selected_symbol}", type="secondary"):
            user_id = st.session_state.get('user_id', 1)
            # Soft-delete all portfolio transactions for this stock
            exec_sql("""
                UPDATE transactions 
                SET is_deleted = 1, deleted_at = ?, deleted_by = ?
                WHERE stock_symbol = ? AND COALESCE(category, 'portfolio') = 'portfolio' 
                AND user_id = ? AND COALESCE(is_deleted, 0) = 0
            """, (int(time.time()), user_id, selected_symbol, user_id))
            exec_sql("DELETE FROM stocks WHERE symbol = ? AND user_id = ?", (selected_symbol, user_id))
            st.success("Stock removed. Transactions moved to Trash.")
            st.rerun()



# =========================
# FINANCIAL PLANNER TAB
# =========================

def ui_financial_planner():
    """Dynamic Financial Planner Calculator with TVM calculations - Gradio-inspired UI."""
    
    # Comprehensive Gradio-inspired CSS
    st.markdown("""
    <style>
        /* ===== GRADIO-INSPIRED THEME FOR PLANNER ===== */
        
        /* Container styling */
        [data-testid="stVerticalBlock"] > [data-testid="stVerticalBlock"] {
            background: transparent;
        }
        
        /* Modern card container */
        .planner-card {
            background: linear-gradient(145deg, #ffffff 0%, #f8fafc 100%);
            border: 1px solid #e2e8f0;
            border-radius: 16px;
            padding: 24px;
            margin-bottom: 20px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
        }
        
        /* Dark mode card */
        @media (prefers-color-scheme: dark) {
            .planner-card {
                background: linear-gradient(145deg, #1e293b 0%, #0f172a 100%);
                border: 1px solid #334155;
            }
        }
        
        /* Modern header styling */
        .planner-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
            border-radius: 20px;
            padding: 32px;
            margin-bottom: 24px;
            box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
            text-align: center;
        }
        
        .planner-header h1 {
            color: white;
            font-size: 2.5rem;
            font-weight: 800;
            margin: 0 0 8px 0;
            text-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .planner-header p {
            color: rgba(255,255,255,0.9);
            font-size: 1.1rem;
            margin: 0;
        }
        
        .planner-badge {
            display: inline-block;
            background: rgba(255,255,255,0.2);
            backdrop-filter: blur(10px);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.85rem;
            color: white;
            font-weight: 600;
            margin-top: 12px;
        }
        
        /* Section headers */
        .section-title {
            display: flex;
            align-items: center;
            gap: 12px;
            margin-bottom: 20px;
        }
        
        .section-icon {
            width: 44px;
            height: 44px;
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.4rem;
        }
        
        .section-icon.green { background: linear-gradient(135deg, #10b981, #059669); }
        .section-icon.purple { background: linear-gradient(135deg, #8b5cf6, #7c3aed); }
        .section-icon.blue { background: linear-gradient(135deg, #3b82f6, #2563eb); }
        .section-icon.pink { background: linear-gradient(135deg, #ec4899, #db2777); }
        
        .section-title h2 {
            font-size: 1.4rem;
            font-weight: 700;
            color: #1e293b;
            margin: 0;
        }
        
        @media (prefers-color-scheme: dark) {
            .section-title h2 { color: #f1f5f9; }
        }
        
        /* Input labels */
        .input-label {
            display: flex;
            align-items: center;
            gap: 8px;
            font-weight: 600;
            font-size: 0.95rem;
            color: #374151;
            margin-bottom: 8px;
        }
        
        .input-label .icon {
            font-size: 1.2rem;
        }
        
        @media (prefers-color-scheme: dark) {
            .input-label { color: #e2e8f0; }
        }
        
        /* Streamlit input overrides - Gradio style */
        .stNumberInput > div > div > input,
        .stTextInput > div > div > input {
            border: 2px solid #e2e8f0 !important;
            border-radius: 12px !important;
            padding: 14px 16px !important;
            font-size: 1rem !important;
            background: #ffffff !important;
            transition: all 0.2s ease !important;
        }
        
        .stNumberInput > div > div > input:focus,
        .stTextInput > div > div > input:focus {
            border-color: #8b5cf6 !important;
            box-shadow: 0 0 0 3px rgba(139, 92, 246, 0.15) !important;
        }
        
        /* Select box styling */
        .stSelectbox > div > div {
            border: 2px solid #e2e8f0 !important;
            border-radius: 12px !important;
            background: #ffffff !important;
        }
        
        .stSelectbox > div > div:hover {
            border-color: #8b5cf6 !important;
        }
        
        /* Primary button - Gradio style */
        .stFormSubmitButton > button,
        .stButton > button[kind="primary"] {
            background: linear-gradient(135deg, #f97316 0%, #ea580c 100%) !important;
            color: white !important;
            border: none !important;
            border-radius: 12px !important;
            padding: 16px 32px !important;
            font-weight: 700 !important;
            font-size: 1.1rem !important;
            box-shadow: 0 4px 15px rgba(249, 115, 22, 0.4) !important;
            transition: all 0.3s ease !important;
            text-transform: none !important;
        }
        
        .stFormSubmitButton > button:hover,
        .stButton > button[kind="primary"]:hover {
            transform: translateY(-2px) !important;
            box-shadow: 0 8px 25px rgba(249, 115, 22, 0.5) !important;
        }
        
        /* Secondary button */
        .stButton > button {
            border: 2px solid #e2e8f0 !important;
            border-radius: 12px !important;
            padding: 12px 24px !important;
            font-weight: 600 !important;
            background: white !important;
            color: #374151 !important;
            transition: all 0.2s ease !important;
        }
        
        .stButton > button:hover {
            border-color: #8b5cf6 !important;
            color: #8b5cf6 !important;
            background: #faf5ff !important;
        }
        
        /* Result card - Big prominent display */
        .result-display {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            border-radius: 20px;
            padding: 40px;
            text-align: center;
            box-shadow: 0 10px 40px rgba(16, 185, 129, 0.35);
            margin: 24px 0;
        }
        
        .result-display .label {
            color: rgba(255,255,255,0.85);
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .result-display .value {
            color: white;
            font-size: 3rem;
            font-weight: 800;
            text-shadow: 0 2px 8px rgba(0,0,0,0.15);
        }
        
        /* Stats grid */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 16px;
            margin: 24px 0;
        }
        
        .stat-box {
            background: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 14px;
            padding: 20px;
            text-align: center;
        }
        
        .stat-box .label {
            color: #64748b;
            font-size: 0.75rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            font-weight: 600;
            margin-bottom: 6px;
        }
        
        .stat-box .value {
            color: #1e293b;
            font-size: 1.3rem;
            font-weight: 700;
        }
        
        @media (prefers-color-scheme: dark) {
            .stat-box {
                background: #1e293b;
                border-color: #334155;
            }
            .stat-box .label { color: #94a3b8; }
            .stat-box .value { color: #f1f5f9; }
        }
        
        /* Progress bar */
        .progress-container {
            background: #e2e8f0;
            border-radius: 10px;
            height: 24px;
            overflow: hidden;
            margin: 16px 0;
        }
        
        .progress-fill {
            height: 100%;
            border-radius: 10px;
            transition: width 0.5s ease;
        }
        
        .progress-principal { background: linear-gradient(90deg, #22c55e, #16a34a); }
        .progress-interest { background: linear-gradient(90deg, #3b82f6, #2563eb); }
        
        /* Data table styling */
        .stDataFrame {
            border-radius: 12px !important;
            overflow: hidden !important;
        }
        
        /* Footer */
        .planner-footer {
            text-align: center;
            padding: 24px;
            background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
            border-radius: 16px;
            margin-top: 32px;
            border: 1px solid #e2e8f0;
        }
        
        .planner-footer .title {
            font-weight: 700;
            color: #475569;
            margin-bottom: 4px;
        }
        
        .planner-footer .subtitle {
            color: #94a3b8;
            font-size: 0.85rem;
        }
        
        @media (prefers-color-scheme: dark) {
            .planner-footer {
                background: linear-gradient(135deg, #1e293b 0%, #0f172a 100%);
                border-color: #334155;
            }
            .planner-footer .title { color: #e2e8f0; }
        }
    </style>
    """, unsafe_allow_html=True)
    
    # ===== HEADER =====
    st.markdown("""
    <div class="planner-header">
        <h1>ðŸ“ˆ Financial Planner Pro</h1>
        <p>Advanced Time Value of Money Calculations</p>
        <span class="planner-badge">âœ¨ TVM Calculator</span>
    </div>
    """, unsafe_allow_html=True)
    
    # ===== GOAL SELECTOR =====
    st.markdown("""
    <div class="section-title">
        <div class="section-icon purple">ðŸŽ¯</div>
        <h2>What do you want to calculate?</h2>
    </div>
    """, unsafe_allow_html=True)
    
    goal_options = {
        "future_value": "ðŸ“Š Future Portfolio Value (Solve for FV)",
        "required_yield": "ðŸ“ˆ Required Yield % to reach a target (Solve for Rate)",
        "required_contribution": "ðŸ’° Required Contribution to reach a target (Solve for PMT)"
    }
    
    selected_goal = st.selectbox(
        "Select goal",
        options=list(goal_options.keys()),
        format_func=lambda x: goal_options[x],
        key="planner_goal",
        label_visibility="collapsed"
    )
    
    # Use a form to prevent refreshes while inputting data
    with st.form("planner_form"):
        # Inputs Section
        st.markdown("""
        <div class="section-title">
            <div class="section-icon green">ðŸ“‹</div>
            <h2>Input Parameters</h2>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown('<div class="input-label"><span class="icon">ðŸ’°</span>Present Value (Current Savings)</div>', unsafe_allow_html=True)
            present_value = st.number_input(
                "Present Value",
                min_value=0.0,
                value=None,
                step=1000.0,
                format="%.2f",
                placeholder="Enter starting amount",
                label_visibility="collapsed"
            )
        
        with col2:
            st.markdown('<div class="input-label"><span class="icon">ðŸ“…</span>Investment Period (Years)</div>', unsafe_allow_html=True)
            years = st.number_input(
                "Years",
                min_value=1,
                max_value=100,
                value=None,
                step=1,
                placeholder="Enter years",
                label_visibility="collapsed"
            )
        
        with col3:
            st.markdown('<div class="input-label"><span class="icon">ðŸ”„</span>Contribution Frequency</div>', unsafe_allow_html=True)
            frequency_options = {"Annually": 1, "Semiannually": 2, "Quarterly": 4, "Monthly": 12}
            frequency_label = st.selectbox(
                "Frequency",
                options=list(frequency_options.keys()),
                index=0,
                label_visibility="collapsed"
            )
            frequency = frequency_options[frequency_label]
        
        # Initialize variables
        annual_yield = None
        contribution = None
        target_fv = None
        
        if selected_goal == "future_value":
            col1, col2 = st.columns(2)
            with col1:
                st.markdown('<div class="input-label"><span class="icon">ðŸ“ˆ</span>Expected Annual Yield (%)</div>', unsafe_allow_html=True)
                annual_yield = st.number_input(
                    "Yield",
                    min_value=0.0,
                    max_value=100.0,
                    value=None,
                    step=0.5,
                    format="%.2f",
                    placeholder="e.g., 8.0",
                    label_visibility="collapsed"
                )
            with col2:
                st.markdown(f'<div class="input-label"><span class="icon">ðŸ’µ</span>{frequency_label} Contribution Amount</div>', unsafe_allow_html=True)
                contribution = st.number_input(
                    "Contribution",
                    min_value=0.0,
                    value=None,
                    step=100.0,
                    format="%.2f",
                    placeholder="Enter amount",
                    label_visibility="collapsed"
                )
        
        elif selected_goal == "required_yield":
            col1, col2 = st.columns(2)
            with col1:
                st.markdown('<div class="input-label"><span class="icon">ðŸŽ¯</span>Target Future Value</div>', unsafe_allow_html=True)
                target_fv = st.number_input(
                    "Target FV",
                    min_value=0.0,
                    value=None,
                    step=10000.0,
                    format="%.2f",
                    placeholder="Enter target amount",
                    label_visibility="collapsed"
                )
            with col2:
                st.markdown(f'<div class="input-label"><span class="icon">ðŸ’µ</span>{frequency_label} Contribution Amount</div>', unsafe_allow_html=True)
                contribution = st.number_input(
                    "Contribution",
                    min_value=0.0,
                    value=None,
                    step=100.0,
                    format="%.2f",
                    placeholder="Enter amount",
                    label_visibility="collapsed"
                )
        
        elif selected_goal == "required_contribution":
            col1, col2 = st.columns(2)
            with col1:
                st.markdown('<div class="input-label"><span class="icon">ðŸŽ¯</span>Target Future Value</div>', unsafe_allow_html=True)
                target_fv = st.number_input(
                    "Target FV",
                    min_value=0.0,
                    value=None,
                    step=10000.0,
                    format="%.2f",
                    placeholder="Enter target amount",
                    label_visibility="collapsed"
                )
            with col2:
                st.markdown('<div class="input-label"><span class="icon">ðŸ“ˆ</span>Expected Annual Yield (%)</div>', unsafe_allow_html=True)
                annual_yield = st.number_input(
                    "Yield",
                    min_value=0.0,
                    max_value=100.0,
                    value=None,
                    step=0.5,
                    format="%.2f",
                    placeholder="e.g., 8.0",
                    label_visibility="collapsed"
                )
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # Calculate Button (form submit)
        calculate_btn = st.form_submit_button("ðŸ§® Calculate Financial Future", width="stretch")
    
    # Validation
    if calculate_btn:
        # Check required fields
        missing_fields = []
        
        if present_value is None:
            missing_fields.append("Present Value")
        if years is None:
            missing_fields.append("Investment Period")
        
        if selected_goal == "future_value":
            if annual_yield is None:
                missing_fields.append("Expected Annual Yield")
            if contribution is None:
                missing_fields.append("Contribution Amount")
        elif selected_goal == "required_yield":
            if target_fv is None:
                missing_fields.append("Target Future Value")
            if contribution is None:
                missing_fields.append("Contribution Amount")
        elif selected_goal == "required_contribution":
            if target_fv is None:
                missing_fields.append("Target Future Value")
            if annual_yield is None:
                missing_fields.append("Expected Annual Yield")
        
        if missing_fields:
            st.error(f"âŒ Please fill in: {', '.join(missing_fields)}")
        else:
            # Store calculation flag in session state
            st.session_state.planner_calculated = True
            st.session_state.planner_data = {
                "goal": selected_goal,
                "present_value": present_value,
                "years": years,
                "frequency": frequency,
                "frequency_label": frequency_label,
                "annual_yield": annual_yield,
                "contribution": contribution,
                "target_fv": target_fv
            }
    
    # --- Display Results (only after calculation) ---
    if st.session_state.get("planner_calculated") and st.session_state.get("planner_data"):
        data = st.session_state.planner_data
        
        # Extract data
        pv = data["present_value"]
        yrs = data["years"]
        freq = data["frequency"]
        freq_label = data["frequency_label"]
        total_periods = yrs * freq
        
        result = None
        result_label = ""
        result_format = ""
        calc_contribution = data["contribution"]
        calc_yield = data["annual_yield"]
        
        if data["goal"] == "future_value":
            # Calculate Future Value
            periodic_rate = (data["annual_yield"] / 100) / freq
            
            if periodic_rate > 0:
                fv_pv = pv * ((1 + periodic_rate) ** total_periods)
                fv_pmt = data["contribution"] * (((1 + periodic_rate) ** total_periods - 1) / periodic_rate)
                result = fv_pv + fv_pmt
            else:
                result = pv + (data["contribution"] * total_periods)
            
            result_label = "Future Portfolio Value"
            result_format = f"${result:,.2f}"
            final_value = result
            
        elif data["goal"] == "required_yield":
            # Solve for Rate using iterative method
            def calculate_fv_for_rate(rate_annual, pv_val, pmt, n, fr):
                periodic_rate = rate_annual / fr
                if periodic_rate > 0:
                    fv_pv = pv_val * ((1 + periodic_rate) ** n)
                    fv_pmt = pmt * (((1 + periodic_rate) ** n - 1) / periodic_rate)
                    return fv_pv + fv_pmt
                else:
                    return pv_val + (pmt * n)
            
            low_rate, high_rate = 0.0001, 1.0
            total_contributions = pv + (data["contribution"] * total_periods)
            
            if data["target_fv"] <= total_contributions:
                calc_yield = 0.0
                result = 0.0
            else:
                for _ in range(100):
                    mid_rate = (low_rate + high_rate) / 2
                    calc_fv = calculate_fv_for_rate(mid_rate, pv, data["contribution"], total_periods, freq)
                    
                    if abs(calc_fv - data["target_fv"]) < 0.01:
                        calc_yield = mid_rate * 100
                        break
                    elif calc_fv < data["target_fv"]:
                        low_rate = mid_rate
                    else:
                        high_rate = mid_rate
                    calc_yield = mid_rate * 100
                
                result = calc_yield
            
            result_label = "Required Annual Yield"
            result_format = f"{result:.2f}%"
            final_value = data["target_fv"]
            
        elif data["goal"] == "required_contribution":
            # Calculate Required PMT
            periodic_rate = (data["annual_yield"] / 100) / freq
            
            if periodic_rate > 0:
                fv_from_pv = pv * ((1 + periodic_rate) ** total_periods)
                remaining_fv = data["target_fv"] - fv_from_pv
                annuity_factor = ((1 + periodic_rate) ** total_periods - 1) / periodic_rate
                calc_contribution = remaining_fv / annuity_factor if annuity_factor > 0 else 0
            else:
                calc_contribution = (data["target_fv"] - pv) / total_periods if total_periods > 0 else 0
            
            result = max(0, calc_contribution)
            calc_contribution = result
            
            result_label = f"Required {freq_label} Contribution"
            result_format = f"${result:,.2f}"
            final_value = data["target_fv"]
        
        # --- Display Result ---
        st.markdown(f"""
        <div class="result-display">
            <div class="label">{result_label.upper()}</div>
            <div class="value">{result_format}</div>
        </div>
        """, unsafe_allow_html=True)
        
        # Summary stats
        if calc_yield is not None and calc_contribution is not None:
            total_contributions_amount = pv + (calc_contribution * total_periods)
            total_interest = final_value - total_contributions_amount
            
            st.markdown(f"""
            <div class="stats-grid">
                <div class="stat-box">
                    <div class="label">Starting Amount</div>
                    <div class="value">${pv:,.2f}</div>
                </div>
                <div class="stat-box">
                    <div class="label">Total Contributions</div>
                    <div class="value">${total_contributions_amount:,.2f}</div>
                </div>
                <div class="stat-box">
                    <div class="label">Interest Earned</div>
                    <div class="value">${total_interest:,.2f}</div>
                </div>
                <div class="stat-box">
                    <div class="label">Time Period</div>
                    <div class="value">{yrs} Years</div>
                </div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("<br>", unsafe_allow_html=True)
        
        # --- Projection Table ---
        st.markdown("""
        <div class="section-title">
            <div class="section-icon blue">ðŸ“Š</div>
            <h2>Projection Schedule</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # Generate projection data
        if calc_yield is not None and calc_contribution is not None:
            periodic_rate = (calc_yield / 100) / freq
            
            projection_data = []
            balance = pv
            total_principal = pv
            cumulative_interest = 0
            
            projection_data.append({
                "Period": 0,
                "Year": 0,
                "Payment Added": 0,
                "Principal (Cash Invested)": pv,
                "Interest Earned": 0,
                "Cumulative Interest": 0,
                "Total Balance": pv
            })
            
            for period in range(1, total_periods + 1):
                balance += calc_contribution
                total_principal += calc_contribution
                
                interest_this_period = balance * periodic_rate
                balance += interest_this_period
                cumulative_interest += interest_this_period
                
                year = period / freq
                
                projection_data.append({
                    "Period": period,
                    "Year": round(year, 2),
                    "Payment Added": calc_contribution,
                    "Principal (Cash Invested)": total_principal,
                    "Interest Earned": interest_this_period,
                    "Cumulative Interest": cumulative_interest,
                    "Total Balance": balance
                })
            
            df_projection = pd.DataFrame(projection_data)
            
            if total_periods > 24:
                yearly_periods = [0] + [i for i in range(freq, total_periods + 1, freq)]
                df_display = df_projection[df_projection['Period'].isin(yearly_periods)].copy()
            else:
                df_display = df_projection.copy()
            
            df_formatted = df_display.copy()
            for col in ["Payment Added", "Principal (Cash Invested)", "Interest Earned", "Cumulative Interest", "Total Balance"]:
                df_formatted[col] = df_formatted[col].apply(lambda x: f"${x:,.2f}")
            
            st.dataframe(df_formatted, width="stretch", hide_index=True)
            
            st.markdown("<br>", unsafe_allow_html=True)
            
            # --- Chart ---
            st.markdown("""
            <div class="section-header">
                <div class="icon-box icon-success">ðŸ“ˆ</div>
                <h3>Growth Visualization</h3>
            </div>
            """, unsafe_allow_html=True)
            
            chart_data = df_projection[["Year", "Principal (Cash Invested)", "Total Balance"]].copy()
            chart_data = chart_data.rename(columns={
                "Principal (Cash Invested)": "Principal",
                "Total Balance": "Portfolio Value"
            })
            
            chart_melted = chart_data.melt(
                id_vars=["Year"], 
                value_vars=["Principal", "Portfolio Value"],
                var_name="Type",
                value_name="Amount"
            )
            
            import altair as alt
            
            chart = alt.Chart(chart_melted).mark_area(opacity=0.6).encode(
                x=alt.X('Year:Q', title='Years'),
                y=alt.Y('Amount:Q', title='Value ($)', stack=None),
                color=alt.Color('Type:N', 
                               scale=alt.Scale(
                                   domain=['Principal', 'Portfolio Value'],
                                   range=['#4CAF50', '#2196F3']
                               ),
                               legend=alt.Legend(title=""))
            ).properties(
                height=400
            ).configure_axis(
                labelFontSize=12,
                titleFontSize=14
            )
            
            st.altair_chart(chart, width="stretch")
            
            # Interest vs Principal breakdown
            st.markdown("""
            <div class="section-title">
                <div class="section-icon pink">ðŸ’Ž</div>
                <h2>Portfolio Breakdown</h2>
            </div>
            """, unsafe_allow_html=True)
            
            if len(projection_data) > 0:
                final_data = projection_data[-1]
                final_principal = final_data["Principal (Cash Invested)"]
                final_interest = final_data["Cumulative Interest"]
                final_bal = final_data["Total Balance"]
                
                if final_bal > 0:
                    principal_pct = (final_principal / final_bal) * 100
                    interest_pct = (final_interest / final_bal) * 100
                    
                    st.markdown(f"""
                    <div class="stats-grid" style="grid-template-columns: repeat(2, 1fr);">
                        <div class="stat-box">
                            <div class="label">ðŸ’¼ Principal (Your Money)</div>
                            <div class="value">${final_principal:,.2f}</div>
                            <div style="color: #22c55e; font-weight: 600; margin-top: 8px; font-size: 0.9rem;">{principal_pct:.1f}% of portfolio</div>
                        </div>
                        <div class="stat-box">
                            <div class="label">ðŸ“ˆ Interest (Growth)</div>
                            <div class="value">${final_interest:,.2f}</div>
                            <div style="color: #3b82f6; font-weight: 600; margin-top: 8px; font-size: 0.9rem;">{interest_pct:.1f}% of portfolio</div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Visual breakdown bar
                    st.markdown(f"""
                    <div class="progress-container">
                        <div class="progress-fill progress-principal" style="width: {principal_pct}%; display: inline-block; float: left;"></div>
                        <div class="progress-fill progress-interest" style="width: {interest_pct}%; display: inline-block;"></div>
                    </div>
                    <div style="display: flex; justify-content: space-between; margin-top: 0.5rem; font-size: 0.85rem; color: #64748b;">
                        <span>ðŸŸ¢ Principal: {principal_pct:.1f}%</span>
                        <span>ðŸ”µ Interest: {interest_pct:.1f}%</span>
                    </div>
                    """, unsafe_allow_html=True)
        
        # ===== EXPORT BUTTONS =====
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("""
        <div class="section-title">
            <div class="section-icon blue">ðŸ“¥</div>
            <h2>Export Results</h2>
        </div>
        """, unsafe_allow_html=True)
        
        export_col1, export_col2 = st.columns(2)
        
        # Prepare export data
        export_summary = {
            "Goal Type": data["goal"].replace("_", " ").title(),
            "Present Value": f"${pv:,.2f}",
            "Investment Period": f"{yrs} years",
            "Frequency": freq_label,
            "Result": result_format,
        }
        if calc_yield is not None:
            export_summary["Annual Yield"] = f"{calc_yield:.2f}%"
        if calc_contribution is not None:
            export_summary["Contribution Amount"] = f"${calc_contribution:,.2f}"
        if data.get("target_fv"):
            export_summary["Target Future Value"] = f"${data['target_fv']:,.2f}"
        
        # Excel Export
        with export_col1:
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                # Summary sheet
                summary_df = pd.DataFrame([export_summary]).T.reset_index()
                summary_df.columns = ["Parameter", "Value"]
                summary_df.to_excel(writer, sheet_name="Summary", index=False)
                
                # Projection sheet
                df_projection.to_excel(writer, sheet_name="Projection Schedule", index=False)
            
            excel_buffer.seek(0)
            st.download_button(
                label="ðŸ“Š Export to Excel",
                data=excel_buffer,
                file_name=f"financial_plan_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                width="stretch"
            )
        
        # PDF Export
        with export_col2:
            def generate_planner_pdf():
                """Generate a styled PDF report with visualization."""
                from reportlab.lib import colors
                from reportlab.lib.pagesizes import letter
                from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
                from reportlab.lib.units import inch
                from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image
                from reportlab.graphics.shapes import Drawing, Rect
                from reportlab.graphics.charts.lineplots import LinePlot
                from reportlab.graphics.charts.legends import Legend
                from reportlab.graphics.widgets.markers import makeMarker
                from reportlab.lib.enums import TA_CENTER
                
                pdf_buffer = io.BytesIO()
                doc = SimpleDocTemplate(pdf_buffer, pagesize=letter, topMargin=0.5*inch, bottomMargin=0.5*inch)
                
                styles = getSampleStyleSheet()
                title_style = ParagraphStyle(
                    'CustomTitle',
                    parent=styles['Heading1'],
                    fontSize=24,
                    textColor=colors.HexColor('#667eea'),
                    spaceAfter=20,
                    alignment=TA_CENTER
                )
                heading_style = ParagraphStyle(
                    'CustomHeading',
                    parent=styles['Heading2'],
                    fontSize=14,
                    textColor=colors.HexColor('#1e293b'),
                    spaceBefore=20,
                    spaceAfter=10
                )
                normal_style = styles['Normal']
                
                elements = []
                
                # Title
                elements.append(Paragraph("ðŸ“ˆ Financial Planner Report", title_style))
                elements.append(Paragraph(f"Generated on {datetime.now().strftime('%B %d, %Y at %I:%M %p')}", 
                                         ParagraphStyle('Subtitle', parent=normal_style, alignment=TA_CENTER, textColor=colors.gray)))
                elements.append(Spacer(1, 20))
                
                # Result highlight
                result_data = [[result_label.upper()], [result_format]]
                result_table = Table(result_data, colWidths=[5*inch])
                result_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#10b981')),
                    ('TEXTCOLOR', (0, 0), (-1, -1), colors.white),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica'),
                    ('FONTSIZE', (0, 0), (-1, 0), 10),
                    ('FONTNAME', (0, 1), (-1, 1), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 1), (-1, 1), 24),
                    ('TOPPADDING', (0, 0), (-1, -1), 15),
                    ('BOTTOMPADDING', (0, 0), (-1, -1), 15),
                    ('ROUNDEDCORNERS', [10, 10, 10, 10]),
                ]))
                elements.append(result_table)
                elements.append(Spacer(1, 20))
                
                # Summary section
                elements.append(Paragraph("ðŸ“‹ Summary", heading_style))
                summary_table_data = [[k, v] for k, v in export_summary.items()]
                summary_table = Table(summary_table_data, colWidths=[2.5*inch, 3*inch])
                summary_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (0, -1), colors.HexColor('#f8fafc')),
                    ('TEXTCOLOR', (0, 0), (-1, -1), colors.HexColor('#1e293b')),
                    ('ALIGN', (0, 0), (0, -1), 'LEFT'),
                    ('ALIGN', (1, 0), (1, -1), 'RIGHT'),
                    ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, -1), 10),
                    ('TOPPADDING', (0, 0), (-1, -1), 8),
                    ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
                    ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                ]))
                elements.append(summary_table)
                elements.append(Spacer(1, 20))
                
                # Statistics
                if calc_yield is not None and calc_contribution is not None:
                    elements.append(Paragraph("ðŸ“Š Statistics", heading_style))
                    stats_data = [
                        ["Starting Value", f"{pv:,.2f} KWD"],
                        ["Total Contributions", f"{total_contributions_amount:,.2f} KWD"],
                        ["Total Interest Earned", f"{total_interest:,.2f} KWD"],
                        ["Final Portfolio Value", f"{final_value:,.2f} KWD"],
                    ]
                    stats_table = Table(stats_data, colWidths=[2.5*inch, 3*inch])
                    stats_table.setStyle(TableStyle([
                        ('BACKGROUND', (0, 0), (0, -1), colors.HexColor('#f8fafc')),
                        ('TEXTCOLOR', (0, 0), (-1, -1), colors.HexColor('#1e293b')),
                        ('ALIGN', (0, 0), (0, -1), 'LEFT'),
                        ('ALIGN', (1, 0), (1, -1), 'RIGHT'),
                        ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),
                        ('FONTSIZE', (0, 0), (-1, -1), 10),
                        ('TOPPADDING', (0, 0), (-1, -1), 8),
                        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
                        ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                    ]))
                    elements.append(stats_table)
                    elements.append(Spacer(1, 20))
                
                # Growth Chart
                elements.append(Paragraph("ðŸ“ˆ Growth Visualization", heading_style))
                
                drawing = Drawing(500, 200)
                
                # Prepare chart data - sample every few periods for clarity
                sample_rate = max(1, len(projection_data) // 20)
                sampled_data = projection_data[::sample_rate]
                if projection_data[-1] not in sampled_data:
                    sampled_data.append(projection_data[-1])
                
                principal_points = [(d["Year"], d["Principal (Cash Invested)"]) for d in sampled_data]
                balance_points = [(d["Year"], d["Total Balance"]) for d in sampled_data]
                
                lp = LinePlot()
                lp.x = 50
                lp.y = 30
                lp.height = 150
                lp.width = 420
                lp.data = [principal_points, balance_points]
                lp.lines[0].strokeColor = colors.HexColor('#4CAF50')
                lp.lines[0].strokeWidth = 2
                lp.lines[1].strokeColor = colors.HexColor('#2196F3')
                lp.lines[1].strokeWidth = 2
                lp.xValueAxis.valueMin = 0
                lp.xValueAxis.valueMax = yrs
                lp.yValueAxis.valueMin = 0
                lp.yValueAxis.valueMax = max(d["Total Balance"] for d in projection_data) * 1.1
                
                drawing.add(lp)
                
                # Legend
                legend = Legend()
                legend.x = 200
                legend.y = 5
                legend.dx = 8
                legend.dy = 8
                legend.fontName = 'Helvetica'
                legend.fontSize = 8
                legend.boxAnchor = 'c'
                legend.columnMaximum = 1
                legend.strokeWidth = 0.5
                legend.alignment = 'right'
                legend.colorNamePairs = [
                    (colors.HexColor('#4CAF50'), 'Principal'),
                    (colors.HexColor('#2196F3'), 'Portfolio Value')
                ]
                drawing.add(legend)
                
                elements.append(drawing)
                elements.append(Spacer(1, 20))
                
                # Portfolio Breakdown
                if len(projection_data) > 0:
                    final_d = projection_data[-1]
                    f_principal = final_d["Principal (Cash Invested)"]
                    f_interest = final_d["Cumulative Interest"]
                    f_bal = final_d["Total Balance"]
                    
                    if f_bal > 0:
                        p_pct = (f_principal / f_bal) * 100
                        i_pct = (f_interest / f_bal) * 100
                        
                        elements.append(Paragraph("ðŸ’Ž Portfolio Breakdown", heading_style))
                        breakdown_data = [
                            ["Component", "Amount", "Percentage"],
                            ["Principal (Your Money)", f"{f_principal:,.2f} KWD", f"{p_pct:.1f}%"],
                            ["Interest (Growth)", f"{f_interest:,.2f} KWD", f"{i_pct:.1f}%"],
                            ["Total", f"{f_bal:,.2f} KWD", "100%"],
                        ]
                        breakdown_table = Table(breakdown_data, colWidths=[2*inch, 2*inch, 1.5*inch])
                        breakdown_table.setStyle(TableStyle([
                            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#667eea')),
                            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                            ('BACKGROUND', (0, -1), (-1, -1), colors.HexColor('#f8fafc')),
                            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                            ('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold'),
                            ('FONTSIZE', (0, 0), (-1, -1), 10),
                            ('TOPPADDING', (0, 0), (-1, -1), 10),
                            ('BOTTOMPADDING', (0, 0), (-1, -1), 10),
                            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e2e8f0')),
                        ]))
                        elements.append(breakdown_table)
                
                # Build PDF
                doc.build(elements)
                pdf_buffer.seek(0)
                return pdf_buffer.getvalue()
            
            try:
                pdf_data = generate_planner_pdf()
                st.download_button(
                    label="ðŸ“„ Export to PDF",
                    data=pdf_data,
                    file_name=f"financial_plan_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                    mime="application/pdf",
                    width="stretch"
                )
            except ImportError:
                st.warning("âš ï¸ PDF export requires reportlab. Install with: pip install reportlab")
            except Exception as e:
                st.error(f"âŒ PDF generation failed: {str(e)}")
        
        # Clear button with modern styling
        st.markdown("<br>", unsafe_allow_html=True)
        col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
        with col_btn2:
            if st.button("ðŸ”„ Clear & Start Over", width="stretch"):
                st.session_state.planner_calculated = False
                st.session_state.planner_data = None
                st.rerun()
    
    # Footer
    st.markdown("""
    <div class="planner-footer">
        <div class="title">ðŸ“ˆ Financial Planner Pro</div>
        <div class="subtitle">Professional Time Value of Money Calculator</div>
    </div>
    """, unsafe_allow_html=True)


def ui_securities_master():
    """
    Securities Master Management - Three-Layer Architecture
    - Layer 1: Canonical securities data (single source of truth)
    - Layer 2: Alias resolution for symbol variations
    - Layer 3: Exchange-aware configuration
    """
    st.header("ðŸ›ï¸ Securities Master")
    st.info("""
    **Professional Securities Data Management**
    
    The Securities Master eliminates ticker mismatches across Kuwait, Bahrain, and US markets.
    Each security has a unique `security_id` that remains constant even after ticker changes.
    """)
    
    user_id = st.session_state.get('user_id', 1)
    
    tab1, tab2, tab3, tab4 = st.tabs([
        "ðŸ“‹ Securities List", 
        "âž• Add Security", 
        "ðŸ”— Aliases", 
        "ðŸ”„ Migration Tools"
    ])
    
    with tab1:
        st.subheader("All Securities")
        
        # Get all securities for this user (table may not exist yet)
        try:
            securities_df = query_df("""
                SELECT security_id, exchange, canonical_ticker, display_name, 
                       currency, country, status, sector
                FROM securities_master
                WHERE user_id = ?
                ORDER BY exchange, canonical_ticker
            """, (user_id,))
        except Exception:
            securities_df = pd.DataFrame()
        
        if securities_df.empty:
            st.warning("No securities in master table. Use **Add Security** tab or **Migration Tools** to populate.")
        else:
            # Filter by exchange
            exchanges = ["All"] + sorted(securities_df['exchange'].unique().tolist())
            selected_exchange = st.selectbox("Filter by Exchange", exchanges)
            
            if selected_exchange != "All":
                securities_df = securities_df[securities_df['exchange'] == selected_exchange]
            
            st.dataframe(
                securities_df,
                column_config={
                    "security_id": st.column_config.TextColumn("Security ID", width="medium"),
                    "exchange": st.column_config.TextColumn("Exchange", width="small"),
                    "canonical_ticker": st.column_config.TextColumn("Ticker", width="small"),
                    "display_name": st.column_config.TextColumn("Name", width="large"),
                    "currency": st.column_config.TextColumn("CCY", width="small"),
                    "country": st.column_config.TextColumn("Country", width="small"),
                    "status": st.column_config.TextColumn("Status", width="small"),
                    "sector": st.column_config.TextColumn("Sector", width="medium"),
                },
                hide_index=True,
                use_container_width=True
            )
            
            st.caption(f"Total: {len(securities_df)} securities")
    
    with tab2:
        st.subheader("Add New Security")
        
        col1, col2 = st.columns(2)
        
        with col1:
            new_ticker = st.text_input("Canonical Ticker *", placeholder="e.g., OOREDOO, AAPL")
            new_exchange = st.selectbox("Exchange *", list(EXCHANGE_CONFIG.keys()))
            new_name = st.text_input("Display Name", placeholder="e.g., Ooredoo Kuwait")
        
        with col2:
            exchange_info = EXCHANGE_CONFIG.get(new_exchange, {})
            new_currency = st.selectbox("Currency", ["KWD", "USD", "BHD", "EUR", "GBP"], 
                                        index=["KWD", "USD", "BHD", "EUR", "GBP"].index(exchange_info.get("currency", "KWD")))
            new_country = st.text_input("Country Code", value=exchange_info.get("country", "KW"))
            new_isin = st.text_input("ISIN (optional)", placeholder="e.g., KW0000000001")
        
        new_sector = st.text_input("Sector (optional)", placeholder="e.g., Financial Services")
        new_aliases = st.text_area("Additional Aliases (one per line)", 
                                   placeholder="e.g.,\nooredoo\nOOREDOO.KW\nOoredoo Kuwait",
                                   help="These will be registered as aliases for symbol resolution")
        
        if st.button("âž• Create Security", type="primary"):
            if not new_ticker:
                st.error("Ticker is required")
            else:
                # Validate ticker format
                is_valid, error_msg = validate_stock_symbol(new_ticker.strip().upper(), allow_new=True)
                if not is_valid:
                    st.error(f"Invalid ticker: {error_msg}")
                else:
                    try:
                        aliases_list = [a.strip() for a in new_aliases.split('\n') if a.strip()]
                        # Validate all aliases too
                        invalid_aliases = []
                        for alias in aliases_list:
                            valid, err = validate_stock_symbol(alias.strip().upper(), allow_new=True)
                            if not valid:
                                invalid_aliases.append(alias)
                        if invalid_aliases:
                            st.error(f"Invalid aliases: {', '.join(invalid_aliases)}")
                        else:
                            security_id = create_security(
                                canonical_ticker=new_ticker,
                                exchange=new_exchange,
                                display_name=new_name or new_ticker,
                                isin=new_isin,
                                currency=new_currency,
                                country=new_country,
                                sector=new_sector,
                                aliases=aliases_list,
                                user_id=user_id
                            )
                            # Refresh the symbols cache
                            refresh_valid_symbols_cache()
                            st.success(f"âœ… Created security: `{security_id}`")
                            st.rerun()
                    except Exception as e:
                        st.error(f"Error: {e}")
    
    with tab3:
        st.subheader("Security Aliases")
        st.caption("Aliases map raw symbol variations to canonical security_id for consistent data resolution.")
        
        # Get all aliases with security info (tables may not exist yet)
        try:
            aliases_df = query_df("""
                SELECT sa.alias_name, sa.alias_type, sa.security_id,
                       sm.canonical_ticker, sm.exchange, sm.display_name
                FROM security_aliases sa
                JOIN securities_master sm ON sa.security_id = sm.security_id
                WHERE sa.user_id = ? AND sm.user_id = ?
                ORDER BY sa.alias_name
            """, (user_id, user_id))
        except Exception:
            aliases_df = pd.DataFrame()
        
        if aliases_df.empty:
            st.info("No aliases registered yet. Use the **Add New Alias** section below or **Migration Tools**.")
        else:
            # Search filter
            search = st.text_input("ðŸ” Search aliases", placeholder="Type to filter...")
            if search:
                mask = aliases_df['alias_name'].str.contains(search, case=False, na=False)
                aliases_df = aliases_df[mask]
            
            st.dataframe(
                aliases_df,
                column_config={
                    "alias_name": st.column_config.TextColumn("Alias", width="medium"),
                    "alias_type": st.column_config.TextColumn("Type", width="small"),
                    "security_id": st.column_config.TextColumn("Security ID", width="medium"),
                    "canonical_ticker": st.column_config.TextColumn("Ticker", width="small"),
                    "exchange": st.column_config.TextColumn("Exchange", width="small"),
                    "display_name": st.column_config.TextColumn("Security Name", width="large"),
                },
                hide_index=True,
                use_container_width=True
            )
            st.caption(f"Total: {len(aliases_df)} aliases")
        
        st.divider()
        st.subheader("Add New Alias")
        
        # Get securities for dropdown (table may not exist yet)
        try:
            securities_list = query_df("SELECT security_id, canonical_ticker, exchange FROM securities_master WHERE user_id = ? ORDER BY canonical_ticker", (user_id,))
        except Exception:
            securities_list = pd.DataFrame()
        
        if not securities_list.empty:
            security_options = {
                f"{row['canonical_ticker']} ({row['exchange']})": row['security_id'] 
                for _, row in securities_list.iterrows()
            }
            
            col1, col2 = st.columns(2)
            with col1:
                selected_security = st.selectbox("Security", list(security_options.keys()))
                alias_text = st.text_input("Alias Name *", placeholder="e.g., ooredoo")
            with col2:
                alias_type = st.selectbox("Alias Type", ["user_input", "broker_format", "official", "legacy"])
            
            if st.button("âž• Register Alias"):
                if alias_text:
                    try:
                        register_alias(
                            security_id=security_options[selected_security],
                            alias_name=alias_text,
                            alias_type=alias_type,
                            user_id=user_id
                        )
                        st.success(f"âœ… Registered alias '{alias_text}' â†’ {selected_security}")
                        st.rerun()
                    except Exception as e:
                        st.error(f"Error: {e}")
                else:
                    st.error("Alias name is required")
        else:
            st.info("Add securities first before registering aliases.")
    
    with tab4:
        st.subheader("Migration & Maintenance Tools")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ðŸŒ± Seed Default Securities")
            st.caption("Populate the securities master with common stocks from Kuwait, Bahrain, and US markets.")
            if st.button("ðŸŒ± Seed Default Securities", type="secondary"):
                with st.spinner("Seeding securities..."):
                    count = seed_default_securities(user_id)
                    st.success(f"âœ… Seeded {count} securities")
                    st.rerun()
        
        with col2:
            st.markdown("#### ðŸ” Scan Transactions for Aliases")
            st.caption("Auto-discover symbol variations from your transaction history.")
            if st.button("ðŸ” Scan & Create Aliases", type="secondary"):
                with st.spinner("Scanning transactions..."):
                    count = populate_aliases_from_transactions(user_id)
                    st.success(f"âœ… Processed {count} symbol variations")
                    st.rerun()
        
        st.divider()
        
        col3, col4 = st.columns(2)
        
        with col3:
            st.markdown("#### ðŸ”— Link Transactions to Securities")
            st.caption("Resolve stock_symbol to security_id for transactions with NULL security_id.")
            
            auto_create = st.checkbox("Auto-create missing securities", value=False,
                                      help="Automatically create securities for symbols not in the master table")
            
            if st.button("ðŸ”— Backfill Security IDs", type="secondary"):
                with st.spinner("Backfilling security IDs (non-destructive)..."):
                    result = backfill_security_ids(user_id, auto_create=auto_create)
                    st.success(f"âœ… Linked {result['resolved_count']} transactions")
                    if result.get('auto_created_count', 0) > 0:
                        st.info(f"ðŸ†• Auto-created {result['auto_created_count']} new securities")
                    if result.get('unresolved_symbols'):
                        st.warning(f"âš ï¸ Unresolved symbols: {', '.join(result['unresolved_symbols'][:10])}")
                        st.caption("Add these to the securities master or register aliases for them.")
                    if result.get('errors'):
                        st.error(f"Errors: {', '.join(result['errors'][:5])}")
        
        with col4:
            st.markdown("#### ðŸ“Š Symbol Resolution Test")
            st.caption("Test how a symbol resolves to a security_id.")
            test_symbol = st.text_input("Test Symbol", placeholder="e.g., ooredoo, AAPL")
            test_portfolio = st.selectbox("Portfolio Context", ["", "KFH", "BBYN", "USA"])
            
            if test_symbol:
                result = resolve_symbol_to_security(test_symbol, test_portfolio or None)
                if result:
                    st.success(f"âœ… Resolved to: `{result['security_id']}`")
                    st.json(result)
                else:
                    st.warning(f"âš ï¸ Symbol '{test_symbol}' not found in securities master")


def ui_backup_restore():
    """
    Professional Backup & Restore System
    - Exports ALL user data to a single Excel file with multiple sheets
    - The same exported file can be directly imported for restore
    - Supports Merge (add to existing) or Full Replace modes
    """
    user_id = st.session_state.get('user_id')
    username = st.session_state.get('username', 'user')
    
    # Professional styling
    st.markdown("""
    <style>
    .backup-card {
        background: linear-gradient(135deg, rgba(59, 130, 246, 0.1) 0%, rgba(139, 92, 246, 0.1) 100%);
        border: 1px solid rgba(59, 130, 246, 0.3);
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    .backup-title {
        font-size: 1.1rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    .backup-info {
        font-size: 0.85rem;
        opacity: 0.8;
    }
    .data-table-header {
        background: rgba(59, 130, 246, 0.2);
        padding: 0.5rem 1rem;
        border-radius: 8px;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.title("ðŸ’¾ Backup & Restore Center")
    st.caption("Securely export and restore all your portfolio data. The exported file can be directly re-imported.")
    
    # =============================
    # HELPER: Ensure all backup tables exist
    # =============================
    def ensure_backup_tables():
        """Create any missing tables required for backup."""
        conn = get_conn()
        cur = conn.cursor()
        try:
            # Create portfolio_snapshots if missing
            db_execute(cur, """
                CREATE TABLE IF NOT EXISTS portfolio_snapshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    snapshot_date TEXT NOT NULL,
                    portfolio_value REAL DEFAULT 0,
                    daily_movement REAL DEFAULT 0,
                    beginning_difference REAL DEFAULT 0,
                    deposit_cash REAL DEFAULT 0,
                    accumulated_cash REAL DEFAULT 0,
                    net_gain REAL DEFAULT 0,
                    change_percent REAL DEFAULT 0,
                    roi_percent REAL DEFAULT 0,
                    created_at INTEGER
                )
            """)
            conn.commit()
        except Exception:
            pass
        finally:
            conn.close()
    
    # Ensure tables exist
    ensure_backup_tables()
    
    # =============================
    # HELPER: Get all exportable data
    # =============================
    def safe_query(sql, params):
        """Query that returns empty DataFrame if table doesn't exist."""
        try:
            return query_df(sql, params)
        except Exception as e:
            return pd.DataFrame()
    
    def get_all_user_data():
        """Fetch all data tables for the current user (excluding id and user_id for clean backup)."""
        # Build soft-delete filters (empty string if column doesn't exist)
        soft_del_txn = _soft_delete_filter()
        soft_del_dep = _soft_delete_filter_deposits()
        
        data = {
            'transactions': safe_query(f"""
                SELECT portfolio, stock_symbol, security_id, txn_date, txn_type, category, shares, 
                       purchase_cost, sell_value, cash_dividend, reinvested_dividend, 
                       bonus_shares, fees, broker, reference, notes 
                FROM transactions WHERE user_id = ?{soft_del_txn} ORDER BY txn_date DESC
            """, (user_id,)),
            'cash_deposits': safe_query(f"""
                SELECT portfolio, amount, currency, deposit_date, include_in_analysis,
                       bank_name, description, comments 
                FROM cash_deposits WHERE user_id = ?{soft_del_dep} ORDER BY deposit_date DESC
            """, (user_id,)),
            'portfolio_snapshots': safe_query("""
                SELECT snapshot_date, portfolio_value, daily_movement, deposit_cash 
                FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date DESC
            """, (user_id,)),
            'securities_master': safe_query("""
                SELECT security_id, exchange, canonical_ticker, display_name, isin,
                       currency, country, status, sector
                FROM securities_master WHERE user_id = ? ORDER BY security_id
            """, (user_id,)),
            'security_aliases': safe_query("""
                SELECT security_id, alias_name, alias_type, valid_from, valid_until
                FROM security_aliases WHERE user_id = ? ORDER BY security_id, alias_name
            """, (user_id,)),
        }
        return data
    
    # =============================
    # HELPER: Parse date safely
    # =============================
    def safe_date(val, default=None):
        """Convert various date formats to YYYY-MM-DD string."""
        if pd.isna(val) or val is None:
            return default or str(date.today())
        if isinstance(val, pd.Timestamp):
            return val.strftime('%Y-%m-%d')
        if isinstance(val, datetime):
            return val.strftime('%Y-%m-%d')
        if isinstance(val, date):
            return val.strftime('%Y-%m-%d')
        return str(val).split(' ')[0].split('T')[0]
    
    # =============================
    # HELPER: Safe float conversion
    # =============================
    def safe_float(val, default=0.0):
        """Safely convert value to float."""
        if pd.isna(val) or val is None:
            return default
        try:
            return float(val)
        except:
            return default
    
    # =============================
    # HELPER: Safe string conversion
    # =============================
    def safe_str(val, default=''):
        """Safely convert value to string."""
        if pd.isna(val) or val is None:
            return default
        return str(val)
    
    tab_exp, tab_imp = st.tabs(["ðŸ“¤ Export Backup", "ðŸ“¥ Restore from Backup"])
    
    # =====================================================
    # TAB 1: EXPORT
    # =====================================================
    with tab_exp:
        st.markdown("### ðŸ“¤ Download Complete Backup")
        
        # Fetch all data
        all_data = get_all_user_data()
        
        # NOTE: Dividends are stored in the transactions table (master storage)
        # No separate dividends sheet needed - they're included in transactions
        # with cash_dividend, bonus_shares, reinvested_dividend columns
        
        # Calculate statistics
        stats = {name: len(df) for name, df in all_data.items()}
        total_records = sum(stats.values())
        
        # Professional summary display
        st.markdown('<div class="data-table-header">ðŸ“Š Your Data Summary</div>', unsafe_allow_html=True)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown("**ðŸ“ˆ Transactions**")
            st.metric("Total Transactions", stats['transactions'], help="Buy, Sell, Dividend, Bonus transactions")
        
        with col2:
            st.markdown("**ðŸ’° Cash Deposits**")
            st.metric("Cash Deposits", stats['cash_deposits'], help="Capital injection records")
        
        with col3:
            st.markdown("**ðŸ“Š Portfolio Tracking**")
            st.metric("ðŸ“ˆ Portfolio Snapshots", stats['portfolio_snapshots'], help="Daily portfolio value snapshots for performance tracking")
        
        with col4:
            st.markdown("**ðŸ›ï¸ Securities**")
            st.metric("Securities Master", stats.get('securities_master', 0), help="Securities master entries + aliases")
        
        st.divider()
        
        # Show what's included
        st.markdown("**ðŸ“‹ What's Included in Backup:**")
        
        included_items = []
        if stats['transactions'] > 0:
            # Count dividends within transactions
            txn_df = all_data['transactions']
            div_count = 0
            if not txn_df.empty:
                if 'cash_dividend' in txn_df.columns:
                    div_count = (txn_df['cash_dividend'].fillna(0) > 0).sum()
            included_items.append(f"âœ… **Transactions** ({stats['transactions']}) - All Buy/Sell/Dividend records (includes {div_count} dividend entries)")
        if stats['cash_deposits'] > 0:
            included_items.append(f"âœ… **Cash Deposits** ({stats['cash_deposits']}) - Capital injections history")
        if stats['portfolio_snapshots'] > 0:
            # Show date range for snapshots
            snap_df = all_data['portfolio_snapshots']
            if not snap_df.empty and 'snapshot_date' in snap_df.columns:
                min_date = snap_df['snapshot_date'].min()
                max_date = snap_df['snapshot_date'].max()
                included_items.append(f"âœ… **Portfolio Tracking History** ({stats['portfolio_snapshots']}) - Daily values from {min_date} to {max_date}")
            else:
                included_items.append(f"âœ… **Portfolio Tracking History** ({stats['portfolio_snapshots']})")
        if stats.get('securities_master', 0) > 0:
            included_items.append(f"âœ… **Securities Master** ({stats['securities_master']}) - Security definitions and metadata")
        if stats.get('security_aliases', 0) > 0:
            included_items.append(f"âœ… **Security Aliases** ({stats['security_aliases']}) - Symbol alias mappings")
        
        for item in included_items:
            st.markdown(item)
        
        if total_records == 0:
            st.warning("âš ï¸ No data to export. Start adding transactions and data to your portfolio!")
        else:
            st.divider()
            
            # Generate backup file
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                workbook = writer.book
                
                # Create formats
                header_format = workbook.add_format({
                    'bold': True, 'bg_color': '#4F81BD', 'font_color': 'white',
                    'border': 1, 'align': 'center'
                })
                
                # Write each non-empty table
                for sheet_name, df in all_data.items():
                    if not df.empty:
                        df.to_excel(writer, index=False, sheet_name=sheet_name)
                        # Format headers
                        worksheet = writer.sheets[sheet_name]
                        for col_num, value in enumerate(df.columns.values):
                            worksheet.write(0, col_num, value, header_format)
                            # Auto-adjust column width
                            max_len = max(df[value].astype(str).map(len).max(), len(str(value))) + 2
                            worksheet.set_column(col_num, col_num, min(max_len, 40))
                
                # Add metadata sheet (for validation on import)
                metadata = pd.DataFrame({
                    'key': [
                        'backup_version', 'backup_date', 'backup_time', 'username',
                        'transactions_count', 'cash_deposits_count', 'portfolio_snapshots_count',
                        'securities_master_count', 'security_aliases_count',
                        'total_records'
                    ],
                    'value': [
                        '3.5', str(date.today()), datetime.now().strftime('%H:%M:%S'), username,
                        stats['transactions'], stats['cash_deposits'], stats['portfolio_snapshots'],
                        stats.get('securities_master', 0), stats.get('security_aliases', 0),
                        total_records
                    ]
                })
                metadata.to_excel(writer, index=False, sheet_name='_backup_info')
            
            # Generate filename with timestamp
            timestamp = datetime.now().strftime('%Y%m%d_%H%M')
            filename = f"portfolio_backup_{username}_{timestamp}.xlsx"
            
            st.markdown(f"""
            <div class="backup-card">
                <div class="backup-title">ðŸ“¦ Backup Ready</div>
                <div class="backup-info">
                    Total: <strong>{total_records:,}</strong> records across <strong>{len([s for s in stats.values() if s > 0])}</strong> tables<br>
                    File: <strong>{filename}</strong>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            st.download_button(
                label="â¬‡ï¸ Download Backup File",
                data=buffer.getvalue(),
                file_name=filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary",
                width="stretch"
            )
            
            st.info("ðŸ’¡ **Tip:** Store this file safely. You can restore from it anytime using the 'Restore from Backup' tab.")
            
            # === Database File Backup ===
            st.divider()
            st.markdown("### ðŸ—„ï¸ Full Database Backup")
            st.caption("Download the raw SQLite database file. Useful for migration, full system recovery, or advanced debugging.")
            
            try:
                db_path = "portfolio.db"
                with open(db_path, "rb") as fp:
                    db_timestamp = datetime.now().strftime('%Y%m%d_%H%M')
                    st.download_button(
                        label="â¬‡ï¸ Download portfolio.db",
                        data=fp.read(),
                        file_name=f"portfolio_backup_{db_timestamp}.db",
                        mime="application/x-sqlite3",
                        width="stretch"
                    )
                st.caption("âš ï¸ **Note:** This is your complete database. Handle with care - it contains all user data.")
            except FileNotFoundError:
                st.warning("Database file not found. You may be using an external database configuration.")
            except Exception as e:
                st.warning(f"Unable to read database file: {e}")
    
    # =====================================================
    # TAB 2: RESTORE
    # =====================================================
    with tab_imp:
        st.markdown("### ðŸ“¥ Restore from Backup File")
        st.markdown("Upload a backup file previously exported from this app. The same Excel file you downloaded can be directly restored.")
        
        # Restore mode selection
        st.markdown("**ðŸ”§ Restore Mode:**")
        restore_mode = st.radio(
            "Select how to handle existing data:",
            options=["merge", "replace"],
            format_func=lambda x: "ðŸ”„ **Merge** - Add backup data to existing records (safe, no data loss)" if x == "merge" else "ðŸ—‘ï¸ **Full Replace** - Delete ALL current data and restore from backup",
            label_visibility="collapsed"
        )
        
        if restore_mode == "replace":
            st.error("âš ï¸ **DANGER:** Full Replace will permanently DELETE all your current data before restoring!")
        
        st.divider()
        
        # File upload
        uploaded_file = st.file_uploader(
            "ðŸ“ Upload your backup file (.xlsx)",
            type=['xlsx'],
            help="Upload the Excel backup file you want to restore from"
        )
        
        if uploaded_file:
            try:
                # Read and validate the file
                xl = pd.ExcelFile(uploaded_file)
                sheets = xl.sheet_names
                
                # Check for metadata
                backup_info = {}
                if '_backup_info' in sheets:
                    info_df = pd.read_excel(uploaded_file, sheet_name='_backup_info')
                    backup_info = dict(zip(info_df['key'], info_df['value']))
                elif '_metadata' in sheets:  # Legacy format
                    info_df = pd.read_excel(uploaded_file, sheet_name='_metadata')
                    backup_info = dict(zip(info_df['info'], info_df['value']))
                
                # Show backup info
                if backup_info:
                    st.success(f"âœ… Valid backup file detected")
                    backup_date = backup_info.get('backup_date', backup_info.get('backup_date', 'Unknown'))
                    backup_version = backup_info.get('backup_version', backup_info.get('app_version', '1.0'))
                    st.info(f"ðŸ“… **Backup Date:** {backup_date} | **Version:** {backup_version}")
                
                # Preview contents
                st.markdown("**ðŸ“‹ Backup Contents:**")
                
                # Exclude dividends sheet from restore (it's derived from transactions)
                data_sheets = [s for s in sheets if not s.startswith('_') and s != 'dividends']
                preview_data = {}
                
                for sheet in data_sheets:
                    df = pd.read_excel(uploaded_file, sheet_name=sheet)
                    preview_data[sheet] = {'count': len(df), 'columns': list(df.columns)}
                
                # Also show dividends if present (read-only info)
                if 'dividends' in sheets:
                    div_df = pd.read_excel(uploaded_file, sheet_name='dividends')
                    st.info(f"ðŸ’° **Dividends sheet detected:** {len(div_df)} dividend records (included in transactions, no separate restore needed)")
                
                # Display in grid
                cols = st.columns(3)
                for idx, (sheet, info) in enumerate(preview_data.items()):
                    with cols[idx % 3]:
                        icon = {
                            'stocks': 'ðŸ“ˆ',
                            'transactions': 'ðŸ’³',
                            'cash_deposits': 'ðŸ’µ',
                            'portfolio_cash': 'ðŸ’°',
                            'portfolio_snapshots': 'ðŸ“‰'
                        }.get(sheet, 'ðŸ“„')
                        st.metric(f"{icon} {sheet}", f"{info['count']:,} rows")
                
                total_to_restore = sum(info['count'] for info in preview_data.values())
                
                st.divider()
                
                # Confirmation section - simple button confirmation
                if restore_mode == "replace":
                    st.warning("âš ï¸ **Full Replace Mode:** This will DELETE all your existing data and replace it with the backup.")
                else:
                    st.info("â„¹ï¸ **Merge Mode:** This will add backup data to your existing data (duplicates may occur).")
                
                # Restore button with confirmation
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ðŸ”„ Confirm & Restore", type="primary", width="stretch"):
                        
                        # IMPORTANT: Reset file pointer for reading sheets again
                        uploaded_file.seek(0)
                        
                        # Use a FRESH connection for restore (not the cached persistent one)
                        # This avoids "connection already closed" from stale pooled connections
                        from db_layer import get_conn as _db_fresh_conn
                        conn = _db_fresh_conn()
                        cur = conn.cursor()
                        
                        # PostgreSQL savepoint helpers:
                        # When a single INSERT fails on PostgreSQL, it aborts the ENTIRE transaction.
                        # All subsequent SQL calls fail with "current transaction is aborted".
                        # Savepoints allow us to rollback just the failed row and continue.
                        _pg = is_postgres()
                        def _sp_begin():
                            if _pg: cur.execute("SAVEPOINT row_sp")
                        def _sp_ok():
                            if _pg: cur.execute("RELEASE SAVEPOINT row_sp")
                        def _sp_fail():
                            if _pg:
                                try: cur.execute("ROLLBACK TO SAVEPOINT row_sp")
                                except Exception: pass
                        
                        try:
                            progress = st.progress(0, text="Initializing...")
                            imported = 0
                            errors = 0
                            error_details = []
                            
                            # STEP 1: Clear data if Full Replace
                            if restore_mode == "replace":
                                progress.progress(5, text="ðŸ—‘ï¸ Clearing existing data...")
                                tables_to_clear = ['portfolio_snapshots', 'portfolio_cash', 
                                                 'cash_deposits', 'transactions', 'stocks']
                                for tbl in tables_to_clear:
                                    try:
                                        db_execute(cur, f"DELETE FROM {tbl} WHERE user_id = ?", (user_id,))
                                    except Exception as e:
                                        error_details.append(f"Clear {tbl}: {e}")
                                conn.commit()
                            
                            # STEP 2: Restore Stocks (must be first - other tables reference stocks)
                            if 'stocks' in preview_data:
                                progress.progress(15, text="ðŸ“ˆ Restoring stocks...")
                                uploaded_file.seek(0)  # Reset file pointer
                                df = pd.read_excel(uploaded_file, sheet_name='stocks')
                                stocks_imported = 0
                                stocks_updated = 0
                                stocks_invalid = 0
                                for _, row in df.iterrows():
                                    try:
                                        symbol = safe_str(row.get('symbol'))
                                        if not symbol:
                                            continue
                                        
                                        # Validate symbol format before import
                                        is_valid, _ = validate_stock_symbol(symbol.strip().upper(), allow_new=True)
                                        if not is_valid:
                                            stocks_invalid += 1
                                            continue
                                        
                                        # Handle both 'name' (SQLite) and 'company_name' (PostgreSQL) columns
                                        stock_name = safe_str(row.get('name')) or safe_str(row.get('company_name')) or symbol
                                        
                                        _sp_begin()
                                        # Check if exists (use same cursor to stay on same connection)
                                        check_cur = conn.cursor()
                                        db_execute(check_cur, "SELECT id FROM stocks WHERE symbol = ? AND user_id = ?", (symbol, user_id))
                                        existing = check_cur.fetchone()
                                        check_cur.close()
                                        if not existing:
                                            # INSERT new stock - use simpler column set that works for both schemas
                                            db_execute(cur, """
                                                INSERT INTO stocks (user_id, symbol, name, portfolio, currency, current_price)
                                                VALUES (?, ?, ?, ?, ?, ?)
                                            """, (
                                                user_id, symbol, stock_name,
                                                safe_str(row.get('portfolio'), 'KFH'),
                                                safe_str(row.get('currency'), 'KWD'),
                                                safe_float(row.get('current_price'))
                                            ))
                                            # Add to symbols cache
                                            _VALID_SYMBOLS_CACHE.add(symbol.upper())
                                            stocks_imported += 1
                                        else:
                                            # UPDATE existing stock with backup data
                                            db_execute(cur, """
                                                UPDATE stocks SET 
                                                    name = ?, portfolio = ?, currency = ?, current_price = ?
                                                WHERE symbol = ? AND user_id = ?
                                            """, (
                                                stock_name,
                                                safe_str(row.get('portfolio'), 'KFH'),
                                                safe_str(row.get('currency'), 'KWD'),
                                                safe_float(row.get('current_price')),
                                                symbol, user_id
                                            ))
                                            stocks_updated += 1
                                        imported += 1
                                        _sp_ok()
                                    except Exception as e:
                                        _sp_fail()
                                        errors += 1
                                        error_details.append(f"Stock {row.get('symbol')}: {e}")
                                conn.commit()
                                summary_msg = f"Stocks: {stocks_imported} new, {stocks_updated} updated"
                                if stocks_invalid > 0:
                                    summary_msg += f", {stocks_invalid} skipped (invalid format)"
                                error_details.append(summary_msg)
                        
                            # STEP 3: Restore Transactions (includes dividends, bonus shares)
                            if 'transactions' in preview_data:
                                progress.progress(35, text="ðŸ’³ Restoring transactions...")
                                uploaded_file.seek(0)  # Reset file pointer
                                df = pd.read_excel(uploaded_file, sheet_name='transactions')
                                txn_count = 0
                                txn_errors = 0
                                for idx, row in df.iterrows():
                                    try:
                                        _sp_begin()
                                        raw_stock_sym = safe_str(row.get('stock_symbol'))
                                        txn_date = safe_date(row.get('txn_date'))
                                        txn_type = safe_str(row.get('txn_type'), 'Buy')
                                        security_id = safe_str(row.get('security_id')) if pd.notna(row.get('security_id')) else None
                                        portfolio = safe_str(row.get('portfolio'), 'KFH')
                                        
                                        if not raw_stock_sym:
                                            txn_errors += 1
                                            error_details.append(f"Transaction row {idx}: Missing stock_symbol")
                                            continue
                                        
                                        # SYMBOL NORMALIZATION: Resolve user input to canonical ticker
                                        stock_sym = normalize_stock_symbol(raw_stock_sym, portfolio)
                                        
                                        # Auto-register new mapping if normalized differently
                                        if raw_stock_sym.upper() != stock_sym:
                                            add_symbol_mapping(raw_stock_sym, stock_sym)
                                        
                                        db_execute(cur, """
                                            INSERT INTO transactions 
                                            (user_id, portfolio, stock_symbol, security_id, txn_date, txn_type, 
                                             shares, purchase_cost, sell_value, cash_dividend, 
                                             bonus_shares, reinvested_dividend, fees, broker,
                                             reference, notes, category, created_at)
                                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                        """, (
                                            user_id,
                                            safe_str(row.get('portfolio'), 'KFH'),
                                            stock_sym,
                                            security_id,
                                            txn_date,
                                            txn_type,
                                            safe_float(row.get('shares')),
                                            safe_float(row.get('purchase_cost')),
                                            safe_float(row.get('sell_value')),
                                            safe_float(row.get('cash_dividend')),
                                            safe_float(row.get('bonus_shares')),
                                            safe_float(row.get('reinvested_dividend')),
                                            safe_float(row.get('fees')),
                                            safe_str(row.get('broker')),
                                            safe_str(row.get('reference')),
                                            safe_str(row.get('notes')),
                                            safe_str(row.get('category'), 'portfolio'),
                                            int(time.time())
                                        ))
                                        imported += 1
                                        txn_count += 1
                                        _sp_ok()
                                    except Exception as e:
                                        _sp_fail()
                                        errors += 1
                                        txn_errors += 1
                                        error_details.append(f"Transaction row {idx} ({row.get('stock_symbol')}): {str(e)[:100]}")
                                conn.commit()
                                error_details.append(f"Transactions: {txn_count} imported, {txn_errors} errors")
                        
                            # STEP 4: Restore Cash Deposits
                            if 'cash_deposits' in preview_data:
                                progress.progress(50, text="ðŸ’µ Restoring cash deposits...")
                                uploaded_file.seek(0)  # Reset file pointer
                                df = pd.read_excel(uploaded_file, sheet_name='cash_deposits')
                                cash_count = 0
                                
                                for _, row in df.iterrows():
                                    try:
                                        _sp_begin()
                                        db_execute(cur, """
                                            INSERT INTO cash_deposits 
                                            (user_id, portfolio, amount, currency, deposit_date, 
                                             include_in_analysis, bank_name, description, comments, created_at)
                                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                        """, (
                                            user_id,
                                            safe_str(row.get('portfolio'), 'KFH'),
                                            safe_float(row.get('amount')),
                                            safe_str(row.get('currency'), 'KWD'),
                                            safe_date(row.get('deposit_date')),
                                            int(safe_float(row.get('include_in_analysis'), 1)),
                                            safe_str(row.get('bank_name'), 'Cash Deposit'),
                                            safe_str(row.get('description')),
                                            safe_str(row.get('comments')),
                                            int(time.time())
                                        ))
                                        imported += 1
                                        cash_count += 1
                                        _sp_ok()
                                    except Exception as e:
                                        _sp_fail()
                                        errors += 1
                                        error_details.append(f"Cash deposit: {e}")
                                conn.commit()
                                error_details.append(f"Cash Deposits: {cash_count} imported")
                            
                            # STEP 5: Restore Portfolio Cash Balances
                            if 'portfolio_cash' in preview_data:
                                progress.progress(65, text="ðŸ’° Restoring cash balances...")
                                uploaded_file.seek(0)  # Reset file pointer
                                df = pd.read_excel(uploaded_file, sheet_name='portfolio_cash')
                                for _, row in df.iterrows():
                                    try:
                                        _sp_begin()
                                        portfolio = safe_str(row.get('portfolio'))
                                        check_cur = conn.cursor()
                                        db_execute(check_cur, "SELECT 1 FROM portfolio_cash WHERE portfolio = ? AND user_id = ?", (portfolio, user_id))
                                        existing = check_cur.fetchone()
                                        check_cur.close()
                                        if not existing:
                                            db_execute(cur, """
                                                INSERT INTO portfolio_cash (user_id, portfolio, balance, currency, last_updated)
                                                VALUES (?, ?, ?, ?, ?)
                                            """, (
                                                user_id, portfolio,
                                                safe_float(row.get('balance')),
                                                safe_str(row.get('currency'), 'KWD'),
                                                int(time.time())
                                            ))
                                        else:
                                            db_execute(cur, """
                                                UPDATE portfolio_cash SET balance = ?, currency = ?, last_updated = ?
                                                WHERE portfolio = ? AND user_id = ?
                                            """, (
                                                safe_float(row.get('balance')),
                                                safe_str(row.get('currency'), 'KWD'),
                                                int(time.time()),
                                                portfolio, user_id
                                            ))
                                        imported += 1
                                        _sp_ok()
                                    except Exception as e:
                                        _sp_fail()
                                        errors += 1
                                conn.commit()
                            
                            # STEP 6: Restore Portfolio Snapshots
                            if 'portfolio_snapshots' in preview_data:
                                progress.progress(75, text="ðŸ“‰ Restoring portfolio snapshots...")
                                uploaded_file.seek(0)  # Reset file pointer
                                df = pd.read_excel(uploaded_file, sheet_name='portfolio_snapshots')
                                # Sort by date ascending to calculate cumulative values correctly
                                df = df.sort_values('snapshot_date', ascending=True)
                                snap_count = 0
                                accumulated_cash = 0.0
                                first_value = None
                                
                                for _, row in df.iterrows():
                                    try:
                                        _sp_begin()
                                        snap_date = safe_date(row.get('snapshot_date'))
                                        portfolio_value = safe_float(row.get('portfolio_value'))
                                        daily_movement = safe_float(row.get('daily_movement'))
                                        deposit_cash = safe_float(row.get('deposit_cash'))
                                        
                                        # Calculate derived values
                                        accumulated_cash += deposit_cash
                                        if first_value is None:
                                            first_value = portfolio_value
                                        beginning_difference = portfolio_value - first_value
                                        net_gain = portfolio_value - accumulated_cash
                                        change_percent = ((portfolio_value - first_value) / first_value * 100) if first_value > 0 else 0
                                        roi_percent = (net_gain / accumulated_cash * 100) if accumulated_cash > 0 else 0
                                        
                                        # Check for existing (unique per user+date) - use same connection
                                        check_cur = conn.cursor()
                                        db_execute(check_cur, "SELECT id FROM portfolio_snapshots WHERE snapshot_date = ? AND user_id = ?", (snap_date, user_id))
                                        existing = check_cur.fetchone()
                                        check_cur.close()
                                        if not existing:
                                            db_execute(cur, """
                                                INSERT INTO portfolio_snapshots 
                                                (user_id, snapshot_date, portfolio_value, daily_movement,
                                                 beginning_difference, deposit_cash, accumulated_cash,
                                                 net_gain, change_percent, roi_percent, created_at)
                                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                            """, (
                                                user_id, snap_date,
                                                portfolio_value,
                                                daily_movement,
                                                beginning_difference,
                                                deposit_cash,
                                                accumulated_cash,
                                                net_gain,
                                                change_percent,
                                                roi_percent,
                                                int(time.time())
                                            ))
                                            imported += 1
                                            snap_count += 1
                                        _sp_ok()
                                    except Exception as e:
                                        _sp_fail()
                                        errors += 1
                                        error_details.append(f"Snapshot: {e}")
                                conn.commit()
                                error_details.append(f"Portfolio Snapshots: {snap_count} imported")
                            
                            # STEP 7: Restore Securities Master (global, not user-specific)
                            if 'securities_master' in preview_data:
                                progress.progress(85, text="ðŸ›ï¸ Restoring securities master...")
                                uploaded_file.seek(0)
                                df = pd.read_excel(uploaded_file, sheet_name='securities_master')
                                sec_count = 0
                                for _, row in df.iterrows():
                                    try:
                                        security_id = safe_str(row.get('security_id'))
                                        if not security_id:
                                            continue
                                        _sp_begin()
                                        db_execute(cur, """
                                            INSERT OR IGNORE INTO securities_master 
                                            (security_id, exchange, canonical_ticker, display_name, isin,
                                             currency, country, status, sector, created_at, updated_at)
                                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                                        """, (
                                            security_id,
                                            safe_str(row.get('exchange'), 'KSE'),
                                            safe_str(row.get('canonical_ticker')),
                                            safe_str(row.get('display_name')),
                                            safe_str(row.get('isin')),
                                            safe_str(row.get('currency'), 'KWD'),
                                            safe_str(row.get('country'), 'KW'),
                                            safe_str(row.get('status'), 'active'),
                                            safe_str(row.get('sector')),
                                            int(time.time()),
                                            int(time.time())
                                        ))
                                        imported += 1
                                        sec_count += 1
                                        _sp_ok()
                                    except Exception as e:
                                        _sp_fail()
                                        errors += 1
                                conn.commit()
                                error_details.append(f"Securities Master: {sec_count} imported")
                            
                            # STEP 8: Restore Security Aliases (global)
                            if 'security_aliases' in preview_data:
                                progress.progress(95, text="ðŸ”— Restoring security aliases...")
                                uploaded_file.seek(0)
                                df = pd.read_excel(uploaded_file, sheet_name='security_aliases')
                                alias_count = 0
                                for _, row in df.iterrows():
                                    try:
                                        security_id = safe_str(row.get('security_id'))
                                        alias_name = safe_str(row.get('alias_name'))
                                        if not security_id or not alias_name:
                                            continue
                                        _sp_begin()
                                        db_execute(cur, """
                                            INSERT OR IGNORE INTO security_aliases 
                                            (security_id, alias_name, alias_type, valid_from, valid_until, created_at)
                                            VALUES (?, ?, ?, ?, ?, ?)
                                        """, (
                                            security_id,
                                            alias_name,
                                            safe_str(row.get('alias_type'), 'legacy'),
                                            safe_str(row.get('valid_from')),
                                            safe_str(row.get('valid_until')) if pd.notna(row.get('valid_until')) else None,
                                            int(time.time())
                                        ))
                                        imported += 1
                                        alias_count += 1
                                        _sp_ok()
                                    except Exception as e:
                                        _sp_fail()
                                        errors += 1
                                conn.commit()
                                error_details.append(f"Security Aliases: {alias_count} imported")
                            
                            # STEP 9: Auto-populate securities from restored data
                            progress.progress(98, text="ðŸ”— Populating securities from restored data...")
                            try:
                                conn.close()
                            except Exception:
                                pass
                            try:
                                seed_default_securities(user_id)
                                populate_aliases_from_transactions(user_id)
                                error_details.append("Securities: auto-populated from restored data")
                            except Exception as e:
                                logger.warning(f"Securities auto-populate warning: {e}")
                                error_details.append(f"Securities auto-populate: skipped ({e})")
                            
                            progress.progress(100, text="âœ… Complete!")
                            
                            # Show results with details
                            st.success(f"âœ… **Restore completed! {imported:,} total records processed.**")
                            
                            # Show details breakdown
                            with st.expander("ðŸ“‹ View restore details", expanded=True):
                                for detail in error_details:
                                    if "imported" in detail or "new" in detail or "updated" in detail:
                                        st.info(detail)
                                    elif errors > 0:
                                        st.warning(detail)
                            
                            if errors > 0:
                                st.warning(f"âš ï¸ {errors:,} records skipped (likely duplicates or invalid data)")
                            
                            st.balloons()
                            time.sleep(2)
                            st.rerun()
                            
                        except Exception as e:
                            try:
                                conn.rollback()
                            except Exception:
                                pass
                            try:
                                conn.close()
                            except Exception:
                                pass
                            st.error(f"âŒ Restore failed: {e}")
                            import traceback
                            logger.error(f"Restore error: {traceback.format_exc()}")
                with col2:
                    st.caption("Click the button to start restoring your backup data.")
                    
            except Exception as e:
                st.error(f"âŒ Error reading file: {e}")
                st.info("Make sure you uploaded a valid Excel backup file exported from this app.")
    
    # =============================
    # MASTER DELETE - Reset All User Data
    # =============================
    st.divider()
    st.markdown("## ðŸ—‘ï¸ Master Delete - Reset Account")
    
    st.error("""
    **âš ï¸ DANGER ZONE**
    
    This will **PERMANENTLY DELETE ALL YOUR DATA** including:
    - All transactions (buys, sells, dividends, bonus shares)
    - All cash deposits
    - All portfolio snapshots
    - All stock holdings
    - All portfolio cash balances
    - All PFM (Personal Finance) data
    
    **This action CANNOT be undone!** Make sure to export a backup first.
    """)
    
    # Simple checkbox + button confirmation
    confirm_checkbox = st.checkbox(
        "âœ… I understand this will permanently delete ALL my data and cannot be undone",
        key="master_delete_confirm_checkbox",
        value=False
    )
    
    delete_btn = st.button(
        "ðŸ—‘ï¸ DELETE ALL MY DATA", 
        type="primary", 
        disabled=not confirm_checkbox,
        key="master_delete_btn"
    )
    
    if delete_btn and confirm_checkbox:
        # Additional confirmation dialog
        st.session_state.confirm_master_delete = True
    
    if st.session_state.get('confirm_master_delete', False):
        st.warning("âš ï¸ **FINAL CONFIRMATION** - Are you absolutely sure? This is irreversible!")
        
        col_yes, col_no = st.columns(2)
        with col_yes:
            if st.button("âœ… YES, DELETE EVERYTHING", type="primary"):
                with st.spinner("Deleting all user data..."):
                    try:
                        deleted_counts = master_delete_user_data(user_id)
                        
                        st.session_state.confirm_master_delete = False
                        
                        # Show deletion summary
                        st.success("âœ… **All data has been permanently deleted.**")
                        
                        with st.expander("ðŸ“‹ Deletion Summary", expanded=True):
                            for table, count in deleted_counts.items():
                                if count > 0:
                                    st.info(f"ðŸ—‘ï¸ {table}: {count:,} records deleted")
                                else:
                                    st.caption(f"â€¢ {table}: No records")
                        
                        st.info("Your account is now clean. You can start fresh or restore from a backup.")
                        time.sleep(2)
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"âŒ Error during deletion: {e}")
                        logger.error(f"Master delete error for user {user_id}: {e}")
        
        with col_no:
            if st.button("âŒ CANCEL", type="secondary"):
                st.session_state.confirm_master_delete = False
                st.rerun()


def master_delete_user_data(user_id: int) -> dict:
    """
    Permanently delete ALL data for a specific user.
    
    This is a complete account reset - removes all:
    - Transactions
    - Cash deposits
    - Portfolio snapshots
    - Stocks
    - Portfolio cash
    - PFM data (snapshots, assets, income/expense items)
    
    Returns dict with count of deleted records per table.
    """
    if not user_id:
        raise ValueError("Invalid user_id")
    
    deleted_counts = {}
    
    conn = get_conn()
    cur = conn.cursor()
    
    try:
        # List of tables to delete from (order matters for foreign keys)
        tables_to_delete = [
            # Core portfolio data
            ("transactions", "user_id"),
            ("cash_deposits", "user_id"),
            ("portfolio_snapshots", "user_id"),
            ("stocks", "user_id"),
            ("portfolio_cash", "user_id"),
            
            # PFM data - delete items first (child tables)
            ("pfm_asset_items", "user_id"),
            ("pfm_liability_items", "user_id"),
            ("pfm_income_expense_items", "user_id"),
            ("pfm_snapshots", "user_id"),
            
            # Other user data
            ("stock_alerts", "user_id"),
            ("user_watchlist", "user_id"),
        ]
        
        # Pre-fetch existing tables to avoid querying non-existent ones
        existing_tables = set()
        if is_postgres():
            db_execute(cur, """
                SELECT table_name FROM information_schema.tables
                WHERE table_schema = 'public'
            """, ())
            existing_tables = {row[0] for row in cur.fetchall()}
        else:
            cur.execute("SELECT name FROM sqlite_master WHERE type='table'")
            existing_tables = {row[0] for row in cur.fetchall()}
        
        for table_name, user_column in tables_to_delete:
            try:
                if table_name not in existing_tables:
                    deleted_counts[table_name] = 0
                    continue
                
                # Use SAVEPOINT for PostgreSQL to isolate errors per table
                if is_postgres():
                    cur.execute(f"SAVEPOINT sp_delete_{table_name}")
                
                db_execute(cur, f"DELETE FROM {table_name} WHERE {user_column} = ?", (user_id,))
                deleted_counts[table_name] = cur.rowcount
                
                if is_postgres():
                    cur.execute(f"RELEASE SAVEPOINT sp_delete_{table_name}")
                    
            except Exception as e:
                logger.warning(f"Could not delete from {table_name}: {e}")
                deleted_counts[table_name] = 0
                # Roll back to savepoint so subsequent deletes can continue
                if is_postgres():
                    try:
                        cur.execute(f"ROLLBACK TO SAVEPOINT sp_delete_{table_name}")
                    except Exception:
                        pass
        
        conn.commit()
        
        # VACUUM to reclaim space (SQLite only)
        if not is_postgres():
            try:
                cur.execute("VACUUM")
            except Exception:
                pass
        
        logger.info(f"âœ… Master delete completed for user {user_id}: {deleted_counts}")
        
    except Exception as e:
        conn.rollback()
        logger.error(f"âŒ Master delete failed for user {user_id}: {e}")
        raise
    finally:
        conn.close()
    
    return deleted_counts


# =========================
# DATA INTEGRITY VERIFICATION
# =========================
def verify_data_integrity(user_id: int) -> dict:
    """
    Run data integrity verification checks.
    
    Checks:
    1. Cash balance drift (portfolio_cash vs calculated from transactions)
    2. Snapshot accumulated_cash accuracy (vs direct calculation from deposits)
    3. Dividend handling consistency (cash vs reinvested vs bonus)
    
    Returns dict with results for each check.
    """
    results = {
        "cash_balance": {"status": "unknown", "data": [], "issues": []},
        "snapshot_drift": {"status": "unknown", "data": [], "issues": []},
        "dividend_handling": {"status": "unknown", "data": [], "issues": []},
    }
    
    try:
        conn = get_conn()
        
        # ============================================
        # 1. Cash Balance Drift Check
        # ============================================
        try:
            # Check if manual_override column exists before querying it
            _pc_cols = table_columns("portfolio_cash")
            _mo_col = ", pc.manual_override" if "manual_override" in _pc_cols else ", 0 as manual_override"
            cash_balance_df = pd.read_sql_query(convert_sql_placeholders(f"""
                SELECT 
                    pc.portfolio,
                    pc.balance as current_balance
                    {_mo_col}
                FROM portfolio_cash pc
                WHERE pc.user_id = ?
            """), conn, params=(user_id,))
            
            if not cash_balance_df.empty:
                results["cash_balance"]["data"] = cash_balance_df.to_dict('records')
                results["cash_balance"]["status"] = "ok"
            else:
                results["cash_balance"]["status"] = "no_data"
                results["cash_balance"]["issues"].append("No portfolio_cash records found")
        except Exception as e:
            results["cash_balance"]["status"] = "error"
            results["cash_balance"]["issues"].append(str(e))
        
        # ============================================
        # 2. Snapshot Accumulated Cash Accuracy
        # ============================================
        try:
            # Get recent snapshots with their accumulated_cash
            snapshots_df = pd.read_sql_query(convert_sql_placeholders("""
                SELECT 
                    ps.snapshot_date,
                    ps.accumulated_cash as stored_value,
                    ps.deposit_cash,
                    ps.net_gain
                FROM portfolio_snapshots ps
                WHERE ps.user_id = ?
                ORDER BY ps.snapshot_date DESC
                LIMIT 10
            """), conn, params=(user_id,))
            
            if not snapshots_df.empty:
                # Calculate correct values for each snapshot
                drift_data = []
                has_drift = False
                
                for _, snap in snapshots_df.iterrows():
                    snap_date = snap['snapshot_date']
                    stored_val = float(snap['stored_value']) if pd.notna(snap['stored_value']) else 0
                    
                    # Calculate correct value from deposits
                    correct_val = calculate_accumulated_cash(user_id, snap_date)
                    drift = stored_val - correct_val
                    
                    drift_data.append({
                        "date": snap_date,
                        "stored": round(stored_val, 3),
                        "calculated": round(correct_val, 3),
                        "drift": round(drift, 3),
                        "drift_pct": round((drift / correct_val * 100) if correct_val > 0 else 0, 2)
                    })
                    
                    if abs(drift) > 0.01:  # Allow tiny rounding differences
                        has_drift = True
                
                results["snapshot_drift"]["data"] = drift_data
                results["snapshot_drift"]["status"] = "warning" if has_drift else "ok"
                if has_drift:
                    results["snapshot_drift"]["issues"].append(
                        "Some snapshots have accumulated_cash drift. Consider re-saving affected snapshots."
                    )
            else:
                results["snapshot_drift"]["status"] = "no_data"
                results["snapshot_drift"]["issues"].append("No portfolio snapshots found")
        except Exception as e:
            results["snapshot_drift"]["status"] = "error"
            results["snapshot_drift"]["issues"].append(str(e))
        
        # ============================================
        # 3. Dividend Handling Check
        # ============================================
        try:
            dividend_df = pd.read_sql_query(convert_sql_placeholders("""
                SELECT 
                    stock_symbol,
                    SUM(COALESCE(cash_dividend, 0)) as total_cash_div,
                    SUM(COALESCE(reinvested_dividend, 0)) as total_reinvested,
                    SUM(COALESCE(bonus_shares, 0)) as total_bonus_shares,
                    COUNT(CASE WHEN cash_dividend > 0 OR reinvested_dividend > 0 OR bonus_shares > 0 THEN 1 END) as dividend_count
                FROM transactions
                WHERE user_id = ?
                GROUP BY stock_symbol
                HAVING SUM(COALESCE(cash_dividend, 0)) > 0 OR SUM(COALESCE(reinvested_dividend, 0)) > 0 OR SUM(COALESCE(bonus_shares, 0)) > 0
                ORDER BY SUM(COALESCE(cash_dividend, 0)) DESC
            """), conn, params=(user_id,))
            
            if not dividend_df.empty:
                results["dividend_handling"]["data"] = dividend_df.to_dict('records')
                results["dividend_handling"]["status"] = "ok"
                
                # Check for potential issues
                for _, row in dividend_df.iterrows():
                    reinvested = float(row['total_reinvested']) if pd.notna(row['total_reinvested']) else 0
                    bonus = float(row['total_bonus_shares']) if pd.notna(row['total_bonus_shares']) else 0
                    
                    # Warning if both reinvested and bonus exist (potential double-count)
                    if reinvested > 0 and bonus > 0:
                        results["dividend_handling"]["issues"].append(
                            f"âš ï¸ {row['stock_symbol']}: Has both reinvested ({reinvested:.2f}) AND bonus shares ({bonus:.0f}). Verify no double-counting."
                        )
                        results["dividend_handling"]["status"] = "warning"
            else:
                results["dividend_handling"]["status"] = "no_data"
                results["dividend_handling"]["issues"].append("No dividend records found")
        except Exception as e:
            results["dividend_handling"]["status"] = "error"
            results["dividend_handling"]["issues"].append(str(e))
        
        conn.close()
        
    except Exception as e:
        for key in results:
            results[key]["status"] = "error"
            results[key]["issues"].append(f"Database error: {str(e)}")
    
    return results


def ui_data_integrity():
    """UI for data integrity verification."""
    st.subheader("ðŸ” Data Integrity Verification")
    st.caption("Run diagnostic checks to verify data consistency across your portfolio.")
    
    user_id = st.session_state.get('user_id', 1)
    
    if st.button("ðŸ” Run Integrity Checks", type="primary"):
        with st.spinner("Running data integrity checks..."):
            results = verify_data_integrity(user_id)
        
        # Display results
        st.divider()
        
        # Summary
        status_icons = {"ok": "âœ…", "warning": "âš ï¸", "error": "âŒ", "no_data": "â„¹ï¸", "unknown": "â“"}
        
        col1, col2, col3 = st.columns(3)
        with col1:
            status = results["cash_balance"]["status"]
            st.metric("Cash Balance", status_icons.get(status, "â“"), status.upper())
        with col2:
            status = results["snapshot_drift"]["status"]
            st.metric("Snapshot Accuracy", status_icons.get(status, "â“"), status.upper())
        with col3:
            status = results["dividend_handling"]["status"]
            st.metric("Dividend Handling", status_icons.get(status, "â“"), status.upper())
        
        st.divider()
        
        # Detailed results
        tab1, tab2, tab3 = st.tabs(["ðŸ’° Cash Balance", "ðŸ“Š Snapshot Drift", "ðŸ’µ Dividends"])
        
        with tab1:
            st.markdown("### Cash Balance Check")
            st.caption("Compares portfolio_cash table with calculated values from transactions.")
            
            if results["cash_balance"]["data"]:
                df = pd.DataFrame(results["cash_balance"]["data"])
                st.dataframe(df, use_container_width=True, hide_index=True)
            
            if results["cash_balance"]["issues"]:
                for issue in results["cash_balance"]["issues"]:
                    st.warning(issue)
            elif results["cash_balance"]["status"] == "ok":
                st.success("âœ… Cash balances are consistent.")
        
        with tab2:
            st.markdown("### Snapshot Accumulated Cash Drift")
            st.caption("Compares stored accumulated_cash with direct calculation from deposits.")
            
            if results["snapshot_drift"]["data"]:
                df = pd.DataFrame(results["snapshot_drift"]["data"])
                
                # Highlight drift
                def highlight_drift(row):
                    if abs(row['drift']) > 0.01:
                        return ['background-color: rgba(255, 193, 7, 0.3)'] * len(row)
                    return [''] * len(row)
                
                st.dataframe(
                    df.style.apply(highlight_drift, axis=1),
                    use_container_width=True,
                    hide_index=True
                )
            
            if results["snapshot_drift"]["issues"]:
                for issue in results["snapshot_drift"]["issues"]:
                    st.warning(issue)
            elif results["snapshot_drift"]["status"] == "ok":
                st.success("âœ… All snapshot accumulated_cash values are accurate.")
        
        with tab3:
            st.markdown("### Dividend Handling Check")
            st.caption("Shows cash dividends, reinvested amounts, and bonus shares by stock.")
            
            if results["dividend_handling"]["data"]:
                df = pd.DataFrame(results["dividend_handling"]["data"])
                st.dataframe(df, use_container_width=True, hide_index=True)
            
            if results["dividend_handling"]["issues"]:
                for issue in results["dividend_handling"]["issues"]:
                    st.warning(issue)
            elif results["dividend_handling"]["status"] == "ok":
                st.success("âœ… Dividend handling looks consistent.")
            
            st.info("""
            **Dividend Double-Counting Prevention:**
            - **Cash Dividends**: Actual cash received â†’ counted as income
            - **Reinvested Dividends**: Value reinvested into shares â†’ reflected in share count only
            - **Bonus Shares**: Free shares received â†’ reflected in share count only
            
            Total P&L excludes dividends to prevent double-counting when they're reinvested.
            """)


# =========================
# UI - PORTFOLIO ANALYSIS
# =========================
def ui_portfolio_analysis():
    # Inject KPI Card CSS (once)
    def inject_kpi_css():
        st.markdown("""
        <style>
        .kpi-card {
            height: 120px;
            padding: 14px 16px;
            border-radius: 12px;
            background: rgba(255, 255, 255, 0.03);
            border: 1px solid rgba(255, 255, 255, 0.08);
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            transition: all 0.3s ease;
        }
        .kpi-card:hover {
            transform: translateY(-3px);
            box-shadow: 0 8px 20px rgba(56, 189, 248, 0.15);
            border-color: rgba(59, 130, 246, 0.3);
        }
        .kpi-title {
            font-size: 0.75rem;
            opacity: 0.7;
            text-transform: uppercase;
            letter-spacing: 0.04em;
        }
        .kpi-value {
            font-size: 1.45rem;
            font-weight: 700;
            line-height: 1.2;
        }
        .kpi-sub {
            font-size: 0.7rem;
            opacity: 0.65;
        }
        </style>
        """, unsafe_allow_html=True)
    
    inject_kpi_css()
    
    def kpi_card(title, value, subtext=None):
        """Render a professional KPI card with equal height."""
        st.markdown(f"""
        <div class="kpi-card">
            <div class="kpi-title">{title}</div>
            <div class="kpi-value">{value}</div>
            <div class="kpi-sub">{subtext if subtext else ""}</div>
        </div>
        """, unsafe_allow_html=True)
    
    # Determine colors based on user-selected theme
    if st.session_state.theme == "dark":
        bg_color = "#0f172a"
        text_color = "#f1f5f9"
        muted_color = "#94a3b8"
        card_bg = "rgba(30, 41, 59, 0.5)"
        card_border = "rgba(71, 85, 105, 0.5)"
        table_header_bg = "rgba(15, 23, 42, 0.8)"
        accent_color = "#3b82f6"
        success_color = "#10b981"
        warning_color = "#f59e0b"
        error_color = "#ef4444"
    else:  # Light mode
        bg_color = "#f8fafc"
        text_color = "#1e293b"
        muted_color = "#64748b"
        card_bg = "white"
        card_border = "rgba(203, 213, 225, 0.8)"
        table_header_bg = "rgba(241, 245, 249, 0.8)"
        accent_color = "#3b82f6"
        success_color = "#10b981"
        warning_color = "#f59e0b"
        error_color = "#ef4444"

    st.markdown(f"""
    <style>
    /* Base Theme */
    .stApp {{
        background: {bg_color};
        color: {text_color};
    }}
    /* Header - Theme Adaptive */
    .app-header {{
        padding: 1rem 0.5rem 0.75rem 0.5rem;
        border-bottom: 1px solid {card_border};
        margin-bottom: 1rem;
    }}
    .app-title {{
        font-size: 1.6rem;
        font-weight: 700;
        line-height: 1.2;
        color: {text_color};
    }}
    .app-subtitle {{
        font-size: 0.85rem;
        opacity: 0.7;
        margin-top: 0.2rem;
        color: {text_color};
    }}
    .app-status {{
        text-align: right;
        padding-top: 0.8rem;
        opacity: 0.6;
        font-size: 0.8rem;
        color: {text_color};
    }}
    /* Metric Cards - Consistent sizing */
    .stMetric {{
        background: {card_bg};
        border: 1px solid {card_border};
        border-radius: 12px;
        padding: 1.25rem !important;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        transition: all 0.3s ease;
        min-height: 120px;
        display: flex;
        flex-direction: column;
        justify-content: center;
    }}
    .stMetric:hover {{
        transform: translateY(-5px);
        box-shadow: 0 8px 20px rgba(56, 189, 248, 0.2);
        border-color: {accent_color};
    }}
    .stMetric label {{
        color: {muted_color} !important;
        font-weight: 600;
        font-size: 0.75rem;
        text-transform: uppercase;
        letter-spacing: 0.05em;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }}
    .stMetric [data-testid="stMetricValue"] {{
        color: {text_color} !important;
        font-size: 1.5rem !important;
        font-weight: 700;
        line-height: 1.2;
        margin: 0.5rem 0;
    }}
    .stMetric [data-testid="stMetricDelta"] {{
        font-weight: 600;
        font-size: 0.85rem;
        font-size: 0.8rem;
    }}
    /* Headers */
    h1, h2, h3 {{
        color: {text_color};
        font-weight: 700;
    }}
    /* Portfolio Section Cards */
    .portfolio-section {{
        background: {card_bg};
        border: 1px solid {card_border};
        border-radius: 16px;
        padding: 1.5rem;
        margin: 1.5rem 0;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
    }}
    .portfolio-section-header {{
        display: flex;
        align-items: center;
        gap: 0.75rem;
        padding: 1rem;
        border-bottom: 1px solid {card_border};
        margin: -1.5rem -1.5rem 1rem -1.5rem;
        background: {table_header_bg};
        border-radius: 16px 16px 0 0;
    }}
    .portfolio-section-header h3 {{
        margin: 0;
        font-size: 1.25rem;
        color: {text_color};
    }}
    /* DataFrames */
    .stDataFrame {{
        background: {card_bg} !important;
        border: 1px solid {card_border} !important;
        border-radius: 12px;
        overflow: hidden;
    }}
    .stDataFrame table {{
        background: transparent !important;
    }}
    .stDataFrame thead tr {{
        background: {table_header_bg} !important;
        color: {muted_color} !important;
    }}
    .stDataFrame thead th {{
        color: {muted_color} !important;
        font-weight: 600 !important;
        font-size: 0.875rem !important;
        text-transform: uppercase;
        letter-spacing: 0.05em;
        padding: 1rem !important;
    }}
    .stDataFrame tbody tr {{
        border-top: 1px solid {card_border} !important;
        transition: background 0.2s ease;
    }}
    .stDataFrame tbody tr:hover {{
        background: rgba(71, 85, 105, 0.1) !important;
    }}
    .stDataFrame tbody td {{
        color: {text_color} !important;
        padding: 1rem !important;
    }}
    /* Buttons */
    .stButton button {{
        background: linear-gradient(135deg, {accent_color} 0%, #2563eb 100%);
        color: white;
        border: none;
        border-radius: 10px;
        font-weight: 600;
        padding: 0.65rem 1.5rem;
        transition: all 0.3s ease;
        box-shadow: 0 4px 10px rgba(59, 130, 246, 0.3);
    }}
    .stButton button:hover {{
        background: linear-gradient(135deg, #2563eb 0%, #1d4ed8 100%);
        box-shadow: 0 6px 15px rgba(59, 130, 246, 0.4);
        transform: translateY(-2px);
    }}
    .stButton button:active {{
        transform: translateY(0);
    }}
    /* Dividers */
    hr {{
        border: none;
        border-top: 1px solid {card_border};
        margin: 2rem 0;
    }}
    /* Caption text */
    .stCaption {{
        color: {muted_color} !important;
        font-size: 0.85rem;
    }}
    /* Success/Error/Info messages */
    .stSuccess {{
        background: rgba(16, 185, 129, 0.1) !important;
        border-left: 4px solid {success_color} !important;
        border-radius: 8px;
        color: {success_color} !important;
    }}
    .stError {{
        background: rgba(239, 68, 68, 0.1) !important;
        border-left: 4px solid {error_color} !important;
        border-radius: 8px;
        color: {error_color} !important;
    }}
    .stInfo {{
        background: rgba(59, 130, 246, 0.1) !important;
        border-left: 4px solid {accent_color} !important;
        border-radius: 8px;
        color: {accent_color} !important;
    }}
    .stWarning {{
        background: rgba(245, 158, 11, 0.1) !important;
        border-left: 4px solid {warning_color} !important;
        border-radius: 8px;
        color: {warning_color} !important;
    }}
    /* Progress bars */
    .stProgress > div > div {{
        background: linear-gradient(90deg, {accent_color}, #8b5cf6) !important;
    }}
    /* Tabs styling */
    .stTabs [data-baseweb="tab-list"] {{
        gap: 0.5rem;
        background: {card_bg};
        padding: 0.5rem;
        border-radius: 12px;
    }}
    .stTabs [data-baseweb="tab"] {{
        background: transparent;
        border-radius: 8px;
        color: {muted_color};
        font-weight: 500;
        padding: 0.75rem 1.5rem;
        transition: all 0.2s ease;
    }}
    .stTabs [data-baseweb="tab"]:hover {{
        background: rgba(71, 85, 105, 0.3);
        color: {text_color};
    }}
    .stTabs [aria-selected="true"] {{
        background: linear-gradient(135deg, rgba(59, 130, 246, 0.2) 0%, rgba(139, 92, 246, 0.2) 100%);
        border: 1px solid rgba(59, 130, 246, 0.3);
        color: {text_color} !important;
    }}
    /* Expander styling */
    .streamlit-expanderHeader {{
        background: {card_bg};
        border: 1px solid {card_border};
        border-radius: 8px;
        color: {text_color} !important;
        font-weight: 600;
    }}
    .streamlit-expanderHeader:hover {{
        background: rgba(71, 85, 105, 0.3);
    }}
    /* Footer */
    .portfolio-footer {{
        text-align: center;
        padding: 2rem 0;
        border-top: 1px solid {card_border};
        color: {muted_color};
        font-size: 0.875rem;
        margin-top: 3rem;
    }}
    </style>
    """, unsafe_allow_html=True)
    
    # Professional Header with Status
    col1, col2, col3 = st.columns([3, 1, 1])
    
    with col1:
        st.markdown("""
        <div class="app-header">
            <div class="app-title">KuwaitPortfolio.ai</div>
            <div class="app-subtitle">Advanced Portfolio Management System</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        # datetime is already imported globally
        st.markdown(f"""
        <div class="app-status">
            â± Last update<br>
            <strong>{datetime.now().strftime("%b %d, %H:%M")}</strong>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.write("")  # Spacing for alignment
        if st.button("ðŸ”„ Fetch All Prices", key="fetch_all_portfolio", width="stretch"):
            user_id = st.session_state.get('user_id')
            if not user_id:
                st.error("Please log in.")
            else:
                try:
                    # 1. Fetch only stocks with positive holdings (shares > 0)
                    # Calculate net shares from transactions: Buy + Bonus - Sell
                    symbols_df = query_df("""
                        SELECT s.symbol, s.currency, COALESCE(h.net_shares, 0) as net_shares
                        FROM stocks s
                        LEFT JOIN (
                            SELECT stock_symbol,
                                   SUM(CASE WHEN txn_type = 'Buy' THEN COALESCE(shares, 0) ELSE 0 END) +
                                   SUM(COALESCE(bonus_shares, 0)) -
                                   SUM(CASE WHEN txn_type = 'Sell' THEN COALESCE(shares, 0) ELSE 0 END) as net_shares
                            FROM transactions
                            WHERE user_id = ?
                            GROUP BY stock_symbol
                        ) h ON UPPER(s.symbol) = UPPER(h.stock_symbol)
                        WHERE s.user_id = ? AND COALESCE(h.net_shares, 0) > 0
                    """, (user_id, user_id))
                except Exception as e:
                    st.error(f"DB query failed: {e}")
                    symbols_df = pd.DataFrame()
                
                if symbols_df.empty:
                    st.info("No stocks found.")
                else:
                    # Map Yahoo Ticker -> {DB Symbol (original case), DB Currency}
                    ticker_map = {}
                    
                    for _, row in symbols_df.iterrows():
                        # Keep ORIGINAL symbol from DB for UPDATE (preserves case)
                        db_sym_original = str(row['symbol']).strip()
                        db_sym_upper = db_sym_original.upper()
                        # Default to KWD if currency is missing/null
                        ccy = str(row.get('currency', 'KWD') or 'KWD').strip().upper()
                        
                        # Convert to yfinance ticker format (use uppercase for Yahoo)
                        if db_sym_upper.endswith('.KW'):
                            yf_sym = db_sym_upper
                        elif ccy == 'KWD' and '.' not in db_sym_upper:
                            # FORCE .KW suffix for KWD stocks
                            yf_sym = f"{db_sym_upper}.KW"
                        else:
                            yf_sym = db_sym_upper
                        
                        # Store ORIGINAL symbol for DB update (case-sensitive match)
                        ticker_map[yf_sym] = {'symbol': db_sym_original, 'currency': ccy}

                    unique_yf_tickers = list(ticker_map.keys())
                    
                    # Lazy-load yfinance
                    if not _ensure_yfinance():
                        st.error("yfinance not installed.")
                    else:
                        st.info(f"ðŸš€ Fetching {len(unique_yf_tickers)} stocks in batch...")
                        progress = st.progress(0, text="Downloading price data...")
                        
                        try:
                            success_count = 0
                            success_details = []
                            failed_symbols = []
                            
                            # === BATCH FETCH OPTIMIZATION (N+1 Fix) ===
                            # Use yfinance batch download - fetches all tickers in ONE API call
                            # This is ~10x faster than individual downloads
                            tickers_str = " ".join(unique_yf_tickers)
                            
                            progress.progress(0.1, text="Downloading from Yahoo Finance...")
                            batch_data = yf.download(
                                tickers_str, 
                                period="5d", 
                                progress=False, 
                                threads=True,  # Parallel fetching within batch
                                group_by='ticker'  # Organize by ticker symbol
                            )
                            progress.progress(0.5, text="Processing price data...")
                            
                            # Process each ticker from the batch result
                            for i, yf_tick in enumerate(unique_yf_tickers):
                                stock_info = ticker_map[yf_tick]
                                db_symbol = stock_info['symbol']
                                db_ccy = stock_info['currency']
                                
                                try:
                                    # Extract data for this ticker from batch result
                                    if len(unique_yf_tickers) == 1:
                                        # Single ticker: batch_data has simple structure
                                        ticker_data = batch_data
                                    else:
                                        # Multiple tickers: access by ticker name
                                        if yf_tick in batch_data.columns.get_level_values(0):
                                            ticker_data = batch_data[yf_tick]
                                        else:
                                            failed_symbols.append(db_symbol)
                                            continue
                                    
                                    if ticker_data is not None and not ticker_data.empty and 'Close' in ticker_data.columns:
                                        close_series = ticker_data['Close'].dropna()
                                        if not close_series.empty:
                                            raw_price = float(close_series.iloc[-1])
                                            
                                            # Normalize Kuwait prices (Fils to KWD)
                                            if db_ccy == 'KWD':
                                                price = normalize_kwd_price(raw_price, db_ccy)
                                            else:
                                                price = raw_price
                                            
                                            # Update database
                                            exec_sql(
                                                "UPDATE stocks SET current_price = ? WHERE symbol = ? AND user_id = ?",
                                                (price, db_symbol, user_id)
                                            )
                                            success_count += 1
                                            success_details.append(f"{db_symbol} = {price:,.3f} {db_ccy}")
                                        else:
                                            failed_symbols.append(db_symbol)
                                    else:
                                        failed_symbols.append(db_symbol)
                                        
                                except Exception as ticker_err:
                                    failed_symbols.append(db_symbol)
                                    
                                progress.progress(0.5 + (0.5 * (i + 1) / len(unique_yf_tickers)), 
                                                  text=f"Processing {i+1}/{len(unique_yf_tickers)}...")

                            progress.empty()
                            
                            # Show results
                            if success_count > 0:
                                st.success(f"âœ… Updated {success_count} stock prices")
                                with st.expander("View updated prices", expanded=False):
                                    for detail in success_details:
                                        st.text(detail)
                            
                            if failed_symbols:
                                st.warning(f"âš ï¸ Could not fetch: {', '.join(failed_symbols)}")
                            
                            # Clear cache and refresh to show new prices
                            build_portfolio_table.clear()
                            st.rerun()
                            
                        except Exception as e:
                            progress.empty()
                            st.error(f"Batch fetch failed: {e}")

    st.divider()

    # ----------------------------------------------------
    # CASH MANAGEMENT (Inline Editor)
    # ----------------------------------------------------
    st.subheader("ðŸ’µ Cash Management")
    st.caption("Edit cash balances manually below. Future transactions (Buy/Sell/Dividend/Deposit) will automatically update these balances.")

    _user_id = st.session_state.get('user_id')

    # 1. Fetch Summary Data (exclude soft-deleted deposits)
    cash_data = []
    _cash_portfolios = ["KFH", "BBYN", "USA"]
    
    # Get USD to KWD conversion rate to show in CCY column for USD row
    _usd_kwd_rate = st.session_state.get("usd_to_kwd", 0.307)
    
    for p in _cash_portfolios:
        # A. Total Deposited (Read-only Reference) - only include deposits marked for analysis
        _soft_del_dep = _soft_delete_filter_deposits()
        # CORRECT QUERY: Filter by include_in_analysis = 1 and sum only positive amounts
        _total_dep = query_val(f"""
            SELECT COALESCE(SUM(CASE WHEN amount > 0 THEN amount ELSE 0 END), 0)
            FROM cash_deposits 
            WHERE portfolio = ? 
            AND user_id = ?
            AND include_in_analysis = 1
            {_soft_del_dep}
        """, (p, _user_id)) 
        if _total_dep is None: _total_dep = 0.0
        
        # B. Manual Cash Balance (Source of Truth for Buying Power)
        _manual_bal_df = query_df("SELECT balance FROM portfolio_cash WHERE portfolio=? AND user_id=?", (p, _user_id))
        _manual_balance = float(_manual_bal_df.iloc[0]['balance']) if not _manual_bal_df.empty else 0.0
        
        _currency = PORTFOLIO_CCY.get(p, "KWD")
        # Show conversion rate in brackets for USD row
        _currency_display = f"USD ({_usd_kwd_rate:.3f})" if _currency == "USD" else _currency
        
        cash_data.append({
            "Portfolio": p,
            "Currency": _currency_display,
            "Total Capital": float(_total_dep),
            "Available Cash": float(_manual_balance)
        })
        
    cash_df_display = pd.DataFrame(cash_data)
    
    # Render Editor
    _c1, _c2 = st.columns([3, 1])
    with _c1:
        edited_cash = st.data_editor(
            cash_df_display,
            column_config={
                "Portfolio": st.column_config.TextColumn("Portfolio", disabled=True),
                "Currency": st.column_config.TextColumn("CCY", disabled=True, width="small"),
                "Total Capital": st.column_config.NumberColumn(
                    "Total Capital (Deposited)",
                    disabled=True, 
                    format="%,.0f",
                    help="Sum of all deposits in 'Cash/Deposits' table."
                ),
                "Available Cash": st.column_config.NumberColumn(
                    "Available Cash (Manual)",
                    min_value=0.0, step=100.0, format="%.2f",
                    help="Double-click to edit. Enter your actual current cash balance.",
                    disabled=False
                )
            },
            hide_index=True,
            use_container_width=True,
            num_rows="fixed",
            disabled=False,
            key="cash_editor_widget"
        )
        
    with _c2:
        # Mini Total - use edited_cash to show current values (including any edits)
        _total_cash_kwd = 0.0
        _rate = st.session_state.get("usd_to_kwd", 0.307)
        # Use edited_cash (current editor values) instead of cash_df_display (pre-edit values)
        for _, r in edited_cash.iterrows():
            if str(r["Currency"]).startswith("USD"):
                _total_cash_kwd += r["Available Cash"] * _rate
            else:
                _total_cash_kwd += r["Available Cash"]
        st.metric("Total Free Cash", fmt_money(_total_cash_kwd, "KWD"))
    
    # Handle Edits
    if not cash_df_display.equals(edited_cash):
        _changes = False
        for _i, _row in edited_cash.iterrows():
            _old_val = cash_df_display.loc[_i, "Available Cash"]
            _new_val = _row["Available Cash"]
            
            # If value changed
            if abs(_new_val - _old_val) > 0.001:
                _p_name = _row["Portfolio"]
                # Get actual currency from portfolio (not display value which may have rate in brackets)
                _p_ccy = PORTFOLIO_CCY.get(_p_name, "KWD")
                _ts = int(time.time())
                _user_id = st.session_state.get('user_id', 1)
                
                # Audit log: Manual cash adjustment
                log_audit_event(
                    user_id=_user_id,
                    operation='MANUAL_CASH_ADJUST',
                    entity_type='cash_balance',
                    old_value=_old_val,
                    new_value=_new_val,
                    delta=_new_val - _old_val,
                    portfolio=_p_name,
                    currency=_p_ccy,
                    reason='USER_ACTION',
                    details=f"Manual override: {_old_val:,.2f} -> {_new_val:,.2f}"
                )
                
                # Upsert into portfolio_cash with manual_override=1 (user explicitly set this balance)
                # Ensure manual_override column exists (self-healing for PostgreSQL)
                try:
                    add_column_if_missing("portfolio_cash", "manual_override", "INTEGER DEFAULT 0")
                except Exception:
                    pass
                exec_sql("""
                    INSERT INTO portfolio_cash (portfolio, user_id, balance, currency, last_updated, manual_override)
                    VALUES (?, ?, ?, ?, ?, 1)
                    ON CONFLICT(portfolio, user_id) DO UPDATE SET
                        balance=excluded.balance,
                        currency=excluded.currency,
                        last_updated=excluded.last_updated,
                        manual_override=1
                """, (_p_name, _user_id, _new_val, _p_ccy, _ts))
                _changes = True

        if _changes:
            st.toast("âœ… Cash Balances Updated (Manual Override)")
            time.sleep(1)
            st.rerun()

    st.divider()

    # Fetch USD/KWD rate and update session state for consistency
    fx_usdkwd = fetch_usd_kwd_rate()
    if fx_usdkwd and fx_usdkwd > 0:
        st.session_state.usd_to_kwd = fx_usdkwd

    kfh_df = build_portfolio_table("KFH")
    bbyn_df = build_portfolio_table("BBYN")
    usa_df = build_portfolio_table("USA")
    
    # Calculate Overall Portfolio Summary (All Portfolios Combined)
    st.markdown("## ðŸ“Š Overall Portfolio Summary (All Portfolios)")
    
    # Calculate totals in KWD (convert USD portfolios)
    overall_total_cost = 0.0
    overall_total_mv = 0.0
    overall_total_unreal = 0.0
    overall_total_cash_div = 0.0
    overall_total_pnl = 0.0
    overall_total_realized = 0.0
    
    for portfolio_name, df in [("KFH", kfh_df), ("BBYN", bbyn_df), ("USA", usa_df)]:
        if not df.empty:
            ccy = PORTFOLIO_CCY.get(portfolio_name, "KWD")
            
            # Sum portfolio values
            port_cost = float(df["Total Cost"].sum())
            port_mv = float(df["Market Value"].sum())
            port_unreal = float(df["Unrealized P/L"].sum())
            port_realized = float(df["Realized P/L"].sum()) if "Realized P/L" in df.columns else 0.0
            port_cash_div = float(df["Cash Dividends"].sum())
            port_pnl = float(df["Total PNL"].sum())
            
            # Convert to KWD for overall totals
            overall_total_cost += convert_to_kwd(port_cost, ccy)
            overall_total_mv += convert_to_kwd(port_mv, ccy)
            overall_total_unreal += convert_to_kwd(port_unreal, ccy)
            overall_total_realized += convert_to_kwd(port_realized, ccy)
            overall_total_cash_div += convert_to_kwd(port_cash_div, ccy)
            overall_total_pnl += convert_to_kwd(port_pnl, ccy)
    
    # --- Integration of Manual Cash for Totals ---
    _overall_cash_kwd = 0.0
    _user_id = st.session_state.get('user_id')
    _cash_recs = query_df("SELECT balance, currency FROM portfolio_cash WHERE user_id=?", (_user_id,))
    if not _cash_recs.empty:
        for _, _cr in _cash_recs.iterrows():
            _overall_cash_kwd += convert_to_kwd(_cr["balance"], _cr["currency"])
            
    overall_total_value = overall_total_mv + _overall_cash_kwd
    # ---------------------------------------------

    if overall_total_cost > 0:
        overall_total_pnl_pct = overall_total_pnl / overall_total_cost
        
        # Calculate performance metrics (Equity Only)
        mv_change_pct = ((overall_total_mv - overall_total_cost) / overall_total_cost * 100)
        unreal_change_pct = (overall_total_unreal / overall_total_cost * 100)
        
        col1, col2, col3, col4, col5, col6 = st.columns(6)
        with col1:
            kpi_card("Total Cost", fmt_money(overall_total_cost, "KWD"))
        with col2:
            # Stock Holdings Value (Equity Only - excluding cash)
            kpi_card("Stock Holdings", fmt_money(overall_total_mv, "KWD"), f"â–² {mv_change_pct:.2f}%")
        with col3:
            # Total Value (Equity + Cash)
            kpi_card("Total Portfolio", fmt_money(overall_total_value, "KWD"), f"Cash: {fmt_money(_overall_cash_kwd, 'KWD')}")
        with col4:
            kpi_card("Unrealized P/L", fmt_money(overall_total_unreal, "KWD"), f"â–² {unreal_change_pct:.2f}%")
        with col5:
            kpi_card("Total PNL", fmt_money(overall_total_pnl, "KWD"), f"â–² {overall_total_pnl_pct:.2%}")
        with col6:
            kpi_card("PNL %", pct(overall_total_pnl_pct))
        
        st.caption(f"All values in KWD. USA portfolio converted at USDâ†’KWD rate: {st.session_state.usd_to_kwd:.6f}")
    else:
        st.info("No portfolio data available yet.")
    
    st.divider()

    def get_theme_colors():
        """Return colors optimized for dark theme."""
        return {
            "bg": "rgba(0, 0, 0, 0)",  # Transparent
            "paper_bg": "rgba(30, 41, 59, 0.5)",
            "text": "#f1f5f9",
            "grid": "rgba(71, 85, 105, 0.3)",
            "accent": "#60a5fa",
        }

    def render_portfolio_section(title: str, df: pd.DataFrame, fx_usdkwd: Optional[float] = None, show_title: bool = True, portfolio_ccy: str = "KWD"):
        # Portfolio Section Container
        st.markdown('<div class="portfolio-section">', unsafe_allow_html=True)
        
        if show_title:
            # Determine emoji based on portfolio name
            emoji = "ðŸ¦"
            if "KFH" in title:
                emoji = "ðŸ‡°ðŸ‡¼"
            elif "BBYN" in title:
                emoji = "ðŸ’¼"
            elif "USA" in title:
                emoji = "ðŸ‡ºðŸ‡¸"
            
            st.markdown(f'''
            <div class="portfolio-section-header">
                <span style="font-size: 1.5rem;">{emoji}</span>
                <h3 style="margin: 0; font-size: 1.25rem; font-weight: 700;">{title}</h3>
            </div>
            ''', unsafe_allow_html=True)

        if df.empty:
            st.markdown('<div style="text-align: center; padding: 2rem; color: #94a3b8;">No stocks in this portfolio yet.</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
            return
        
        # Display Portfolio KPI Cards (in native currency)
        port_cost = float(df["Total Cost"].sum())
        port_mv = float(df["Market Value"].sum())
        port_unreal = float(df["Unrealized P/L"].sum())
        port_pnl = float(df["Total PNL"].sum())
        port_pnl_pct = (port_pnl / port_cost) if port_cost > 0 else 0.0
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            kpi_card("Total Cost", fmt_money(port_cost, portfolio_ccy))
        with col2:
            kpi_card("Market Value", fmt_money(port_mv, portfolio_ccy))
        with col3:
            kpi_card("Unrealized P/L", fmt_money(port_unreal, portfolio_ccy))
        with col4:
            kpi_card("Total PNL", fmt_money(port_pnl, portfolio_ccy), f"{port_pnl_pct:.2%}")
        
        st.markdown("")  # Spacing

        # Ensure numeric columns exist and always show percentages (even if zero)
        view_df = df.copy()
        if "Weight by Cost" not in view_df.columns:
            view_df["Weight by Cost"] = 0.0
        if "PNL %" not in view_df.columns:
            view_df["PNL %"] = 0.0

        # Prepare clean chart dataframe
        chart_df = view_df[["Company", "Weight by Cost", "PNL %"]].copy()
        chart_df = chart_df.rename(columns={"Weight by Cost": "weight", "PNL %": "pnl"})
        chart_df["weight"] = chart_df["weight"].astype(float).fillna(0.0)
        chart_df["pnl"] = chart_df["pnl"].astype(float).fillna(0.0)
        
        # Filter out zero-weight entries
        chart_df = chart_df[chart_df["weight"] > 0]

        # Professional Donut Pie Chart with Callouts
        st.markdown("**Weight by Cost**")
        total_weight = float(chart_df["weight"].sum())
        if total_weight <= 0:
            st.info("No weight data to display (all weights are zero).")
        else:
            if go is not None:
                # Get theme colors from session state
                bg_color = "#ffffff" if st.session_state.theme == "light" else "#0e1117"
                text_color = "#1e293b" if st.session_state.theme == "light" else "#f1f5f9"
                grid_color = "#ddd" if st.session_state.theme == "light" else "#333"

                # Generate custom colors
                colors = px.colors.qualitative.Pastel if px else None
                if colors and len(colors) < len(chart_df):
                    colors = colors * (len(chart_df) // len(colors) + 1)

                # Create donut pie chart
                fig = go.Figure(data=[go.Pie(
                    labels=chart_df["Company"],
                    values=chart_df["weight"],
                    hole=0.4,
                    textinfo='percent',
                    textposition='outside',
                    insidetextorientation='radial',
                    textfont=dict(size=11, color=text_color),
                    marker=dict(
                        colors=colors,
                        line=dict(color=bg_color, width=2)
                    ),
                    pull=[0.05 if w == chart_df["weight"].max() else 0 for w in chart_df["weight"]],
                    rotation=0,
                    direction="clockwise",
                    sort=False,
                    hovertemplate=(
                        "<b>%{label}</b><br>" +
                        "Allocation: %{percent}<br>" +
                        "Weight: %{value:.3f}<extra></extra>"
                    ),
                )])

                fig.update_layout(
                    title=dict(text="Portfolio Allocation by Weight", x=0.5, font=dict(size=18, color=text_color)),
                    font=dict(color=text_color, size=12),
                    paper_bgcolor=bg_color,
                    plot_bgcolor=bg_color,
                    margin=dict(t=50, b=50, l=20, r=20),
                    showlegend=False,
                    height=400,
                    hoverlabel=dict(
                        bgcolor="white" if bg_color == "white" else "#1e293b",
                        font_size=13,
                        font_color=text_color,
                        bordercolor=grid_color,
                    ),
                    transition=dict(duration=300, easing='cubic-in-out'),
                )

                # Display chart and legend
                c_left, c_right = st.columns([2, 1])
                with c_left:
                    st.plotly_chart(fig, width="stretch", config={"displayModeBar": False})
                with c_right:
                    legend_df = chart_df.copy()
                    legend_df["Weight (%)"] = (legend_df["weight"] * 100).round(1).astype(str) + "%"
                    st.markdown("**Allocation Breakdown**")
                    st.dataframe(
                        legend_df[["Company", "Weight (%)"]],
                        width="stretch",
                        hide_index=True,
                        column_config={
                            "Company": st.column_config.TextColumn("Company", width="medium"),
                            "Weight (%)": st.column_config.TextColumn("Weight", width="small"),
                        }
                    )
            else:
                st.warning("Plotly not available. Install with: pip install plotly")
                st.write(chart_df[["Company", "weight"]])

        st.divider()
        # PNL chart removed per user request â€” render the portfolio table below the pie
        render_portfolio_table(title, df, fx_usdkwd=fx_usdkwd)
        
        # Close portfolio section div
        st.markdown('</div>', unsafe_allow_html=True)

    render_portfolio_section("KFH Portfolio", kfh_df, portfolio_ccy="KWD")
    st.divider()
    render_portfolio_section("BBYN Portfolio", bbyn_df, portfolio_ccy="KWD")
    st.divider()
    
    # USA Portfolio with FX rate display
    st.markdown("### USA Portfolio")
    st.info(f"ðŸ’± USD â†’ KWD conversion rate: **{st.session_state.usd_to_kwd:.6f}**")
    render_portfolio_section("USA Portfolio", usa_df, fx_usdkwd=fx_usdkwd, show_title=False, portfolio_ccy="USD")
    
    # USA Portfolio - KWD Equivalent Card
    if not usa_df.empty:
        usa_cost_usd = float(usa_df["Total Cost"].sum())
        usa_mv_usd = float(usa_df["Market Value"].sum())
        usa_unreal_usd = float(usa_df["Unrealized P/L"].sum())
        usa_cash_div_usd = float(usa_df["Cash Dividends"].sum())
        usa_pnl_usd = float(usa_df["Total PNL"].sum())
        
        # Convert to KWD
        fx_rate = st.session_state.usd_to_kwd
        usa_cost_kwd = usa_cost_usd * fx_rate
        usa_mv_kwd = usa_mv_usd * fx_rate
        usa_unreal_kwd = usa_unreal_usd * fx_rate
        usa_cash_div_kwd = usa_cash_div_usd * fx_rate
        usa_pnl_kwd = usa_pnl_usd * fx_rate
        
        st.markdown("#### ðŸ‡°ðŸ‡¼ USD Portfolio in KWD Equivalent")
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            kpi_card("Total Cost (KWD)", fmt_money(usa_cost_kwd, "KWD"))
        with col2:
            kpi_card("Market Value (KWD)", fmt_money(usa_mv_kwd, "KWD"))
        with col3:
            kpi_card("Unrealized P/L (KWD)", fmt_money(usa_unreal_kwd, "KWD"))
        with col4:
            kpi_card("Cash Dividends (KWD)", fmt_money(usa_cash_div_kwd, "KWD"))
        with col5:
            usa_pnl_pct = (usa_pnl_usd / usa_cost_usd) if usa_cost_usd > 0 else 0.0
            kpi_card("Total PNL (KWD)", fmt_money(usa_pnl_kwd, "KWD"), f"{usa_pnl_pct:.2%}")
    
    st.divider()
    
    # =========================================================================
    # UI FIX #2: TRANSACTION ANALYSIS FROM UNIFIED portfolio_transactions
    # =========================================================================
    st.markdown("## ðŸ“ˆ Transaction Analysis")
    st.caption("Analysis from unified portfolio_transactions table - always accurate")
    
    user_id = st.session_state.get('user_id', 1)
    
    # Get analysis data from new helper functions
    analysis_data = get_portfolio_analysis_data(user_id)
    
    # Monthly Breakdown Section
    monthly_df = analysis_data.get('monthly_breakdown', pd.DataFrame())
    cumulative_deposits_df = analysis_data.get('cumulative_deposits', pd.DataFrame())
    cumulative_cash_df = analysis_data.get('cumulative_cash_flow', pd.DataFrame())
    
    if not monthly_df.empty:
        with st.expander("ðŸ“Š Monthly Transaction Breakdown", expanded=True):
            st.caption("Transactions grouped by month and type from portfolio_transactions")
            
            # Pivot for better display
            pivot_df = monthly_df.pivot_table(
                index='month',
                columns='txn_type',
                values='total_amount',
                aggfunc='sum',
                fill_value=0
            ).reset_index()
            
            # Add transaction counts
            count_pivot = monthly_df.pivot_table(
                index='month',
                columns='txn_type',
                values='transaction_count',
                aggfunc='sum',
                fill_value=0
            ).reset_index()
            
            # Sort by month descending
            pivot_df = pivot_df.sort_values('month', ascending=False)
            
            # Format amounts
            for col in pivot_df.columns:
                if col != 'month':
                    pivot_df[col] = pivot_df[col].apply(lambda x: f"{x:,.2f}")
            
            st.dataframe(pivot_df, use_container_width=True, hide_index=True)
            
            # Summary metrics
            total_deposits = monthly_df[monthly_df['txn_type'] == 'DEPOSIT']['total_amount'].sum()
            total_buys = abs(monthly_df[monthly_df['txn_type'] == 'BUY']['total_amount'].sum())
            total_sells = monthly_df[monthly_df['txn_type'] == 'SELL']['total_amount'].sum()
            total_dividends = monthly_df[monthly_df['txn_type'] == 'DIVIDEND']['total_amount'].sum()
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ðŸ’° Total Deposits", fmt_money_plain(total_deposits), delta_color="off")
            with col2:
                st.metric("ðŸ›’ Total Invested", fmt_money_plain(total_buys), delta_color="off")
            with col3:
                st.metric("ðŸ’µ Total Sold", fmt_money_plain(total_sells), delta_color="off")
            with col4:
                st.metric("ðŸ“Š Total Dividends", fmt_money_plain(total_dividends), delta_color="off")
    else:
        st.info("No transaction data in portfolio_transactions table yet.")
    
    # Cumulative Deposits Chart
    if not cumulative_deposits_df.empty and go is not None:
        with st.expander("ðŸ“ˆ Cumulative Deposits Over Time", expanded=False):
            st.caption("Running total of deposits from portfolio_transactions")
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=cumulative_deposits_df['txn_date'],
                y=cumulative_deposits_df['cumulative_deposits'],
                mode='lines+markers',
                name='Cumulative Deposits',
                line=dict(color='#10b981', width=2),
                marker=dict(size=6)
            ))
            
            fig.update_layout(
                title='Cumulative Deposits Over Time',
                xaxis_title='Date',
                yaxis_title='Cumulative Deposits',
                template='plotly_dark' if st.session_state.theme == 'dark' else 'plotly_white',
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # Cumulative Cash Flow Chart
    if not cumulative_cash_df.empty and go is not None:
        with st.expander("ðŸ’¹ Cumulative Cash Flow Over Time", expanded=False):
            st.caption("Running balance: deposits + dividends + sells - buys - withdrawals")
            
            fig = go.Figure()
            
            # Color by transaction type
            colors = {
                'DEPOSIT': '#10b981',
                'WITHDRAWAL': '#ef4444',
                'BUY': '#f59e0b',
                'SELL': '#3b82f6',
                'DIVIDEND': '#8b5cf6'
            }
            
            for txn_type in cumulative_cash_df['txn_type'].unique():
                type_df = cumulative_cash_df[cumulative_cash_df['txn_type'] == txn_type]
                fig.add_trace(go.Scatter(
                    x=type_df['txn_date'],
                    y=type_df['cumulative_cash_flow'],
                    mode='markers',
                    name=txn_type,
                    marker=dict(color=colors.get(txn_type, '#64748b'), size=8)
                ))
            
            # Add running line
            fig.add_trace(go.Scatter(
                x=cumulative_cash_df['txn_date'],
                y=cumulative_cash_df['cumulative_cash_flow'],
                mode='lines',
                name='Cash Flow',
                line=dict(color='#60a5fa', width=2),
                showlegend=True
            ))
            
            fig.update_layout(
                title='Cumulative Cash Flow Over Time',
                xaxis_title='Date',
                yaxis_title='Cash Flow Balance',
                template='plotly_dark' if st.session_state.theme == 'dark' else 'plotly_white',
                height=400,
                legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    # Footer
    st.markdown("""
    <div class="portfolio-footer">
        KuwaitPortfolio.ai â€¢ Advanced Portfolio Management System â€¢ DB: portfolio.db â€¢ Last updated: Jan 2, 2026
    </div>
    """, unsafe_allow_html=True)


# =========================
# PLACEHOLDERS
# =========================
def ui_portfolio_tracker():
    st.subheader("Portfolio Tracker")
    
    # Get user_id for all queries
    user_id = st.session_state.get('user_id')
    
    # Debug: Check if Plotly is available
    if go is None:
        st.error("ðŸš¨ Critical: Plotly is not loaded! Charts will not display.")
        st.info("Try: `pip install plotly` in your terminal")
    
    # === RECONCILIATION REPORT SECTION ===
    with st.expander("ðŸ“‹ Generate Reconciliation Report", expanded=False):
        st.caption("Generate a monthly reconciliation report to verify cash and portfolio balances.")
        
        recon_col1, recon_col2, recon_col3 = st.columns([1, 1, 2])
        
        with recon_col1:
            current_year = date.today().year
            recon_year = st.selectbox("Year", options=list(range(current_year, current_year - 5, -1)), key="recon_year")
        
        with recon_col2:
            month_names = ["January", "February", "March", "April", "May", "June", 
                          "July", "August", "September", "October", "November", "December"]
            current_month = date.today().month
            recon_month = st.selectbox("Month", options=list(range(1, 13)), 
                                       format_func=lambda x: month_names[x-1],
                                       index=current_month - 1, key="recon_month")
        
        with recon_col3:
            if st.button("ðŸ“Š Generate Report", type="primary", key="gen_recon_btn"):
                with st.spinner("Calculating reconciliation..."):
                    try:
                        recon_data = calculate_monthly_reconciliation(user_id, recon_year, recon_month)
                        st.session_state['last_recon_data'] = recon_data
                    except Exception as e:
                        st.error(f"Error calculating reconciliation: {e}")
                        logger.error(f"Reconciliation error: {e}")
        
        # Display reconciliation results if available
        if 'last_recon_data' in st.session_state:
            recon = st.session_state['last_recon_data']
            
            st.markdown(f"### {recon['month_name']} Reconciliation")
            
            # Cash Reconciliation Card
            cash_status = "âœ… RECONCILED" if recon['cash_reconciled'] else f"âš ï¸ Variance: {recon['cash_difference']:.3f} KWD"
            cash_color = "green" if recon['cash_reconciled'] else "red"
            
            st.markdown("#### ðŸ’° Cash Reconciliation")
            cash_col1, cash_col2 = st.columns(2)
            
            with cash_col1:
                st.markdown(f"""
                | Item | Amount |
                |------|-------:|
                | Starting Cash | {recon['cash_starting']:,.3f} KWD |
                | + Deposits | {recon['cash_deposits']:,.3f} KWD |
                | + Dividends | {recon['cash_dividends']:,.3f} KWD |
                | - Buys | ({recon['cash_buys']:,.3f} KWD) |
                | + Sells | {recon['cash_sells']:,.3f} KWD |
                | **Calculated** | **{recon['cash_ending_calc']:,.3f} KWD** |
                """)
            
            with cash_col2:
                st.metric("Actual Cash Balance", f"{recon['cash_ending_manual']:,.3f} KWD")
                if recon['cash_reconciled']:
                    st.success(cash_status)
                else:
                    st.error(cash_status)
            
            # Portfolio Reconciliation Card
            portfolio_status = "âœ… RECONCILED" if recon['portfolio_reconciled'] else f"âš ï¸ Variance: {recon['portfolio_difference']:.3f} KWD"
            
            st.markdown("#### ðŸ“ˆ Portfolio Value Reconciliation")
            port_col1, port_col2 = st.columns(2)
            
            with port_col1:
                appreciation_sign = "+" if recon['portfolio_appreciation'] >= 0 else ""
                st.markdown(f"""
                | Item | Amount |
                |------|-------:|
                | Starting Value | {recon['portfolio_starting']:,.3f} KWD |
                | {appreciation_sign} Market Movement | {recon['portfolio_appreciation']:,.3f} KWD |
                | + New Buys | {recon['portfolio_new_buys']:,.3f} KWD |
                | - Sells | ({recon['portfolio_sells']:,.3f} KWD) |
                | **Ending Value** | **{recon['portfolio_ending']:,.3f} KWD** |
                """)
            
            with port_col2:
                st.metric("Current Portfolio Value", f"{recon['portfolio_ending']:,.3f} KWD", 
                         delta=f"{recon['portfolio_ending'] - recon['portfolio_starting']:,.3f} KWD")
                if recon['portfolio_reconciled']:
                    st.success(portfolio_status)
                else:
                    st.error(portfolio_status)
            
            # Download PDF button
            st.markdown("---")
            try:
                pdf_data = generate_reconciliation_pdf(recon)
                if pdf_data:
                    st.download_button(
                        label="ðŸ“¥ Download PDF Report",
                        data=pdf_data,
                        file_name=f"reconciliation_{recon['year']}_{recon['month']:02d}.pdf",
                        mime="application/pdf",
                        type="primary"
                    )
                else:
                    st.warning("PDF generation requires reportlab. Install with: pip install reportlab")
            except Exception as e:
                st.error(f"PDF generation failed: {e}")
    
    # === ACTION BUTTONS ROW ===
    # Weekend warning for market data accuracy
    if date.today().weekday() >= 5:  # Saturday=5, Sunday=6
        st.warning("âš ï¸ **Weekend Snapshot:** Stock prices may not reflect current market values (markets are closed).")
    
    col_save, col_delete = st.columns([3, 1])
    
    with col_save:
        save_snapshot_btn = st.button("ðŸ’¾ Save Today's Snapshot (Live Data)", type="primary", width="stretch")
    
    with col_delete:
        if st.button("ðŸ—‘ï¸ Delete All", width="stretch"):
            st.session_state.confirm_delete_snapshots = True
    
    # Confirmation dialog
    if st.session_state.get('confirm_delete_snapshots', False):
        st.error("âš ï¸ **WARNING: This will PERMANENTLY delete ALL your portfolio tracker data!**")
        col_yes, col_no = st.columns(2)
        with col_yes:
            if st.button("âœ… Yes, Delete All", type="primary", width="stretch"):
                try:
                    conn = get_conn()
                    cur = conn.cursor()
                    
                    # Delete ALL snapshots for this user (including user_id=1 default and NULL)
                    db_execute(cur, "DELETE FROM portfolio_snapshots WHERE user_id = ?", (user_id,))
                    deleted_count = cur.rowcount
                    
                    conn.commit()
                    
                    # VACUUM to reclaim space (SQLite only - hard removal from disk)
                    if not is_postgres():
                        cur.execute("VACUUM")
                    conn.close()
                    
                    st.session_state.confirm_delete_snapshots = False
                    st.success(f"âœ… Deleted {deleted_count:,} snapshots.")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"Error: {e}")
        with col_no:
            if st.button("âŒ Cancel", width="stretch"):
                st.session_state.confirm_delete_snapshots = False
                st.rerun()
    
    # === SAVE TODAY'S SNAPSHOT ===
    if save_snapshot_btn:
        with st.spinner("Calculating live portfolio value..."):
            # 1. Calculate LIVE portfolio value (Stock Market Values)
            live_stock_value = 0.0
            for port_name in PORTFOLIO_CCY.keys():
                df_port = build_portfolio_table(port_name)
                if not df_port.empty:
                    for _, row in df_port.iterrows():
                        live_stock_value += convert_to_kwd(row['Market Value'], row['Currency'])
            
            # 1b. Add Manual Cash from portfolio_cash table (matching Overview tab)
            manual_cash_kwd = 0.0
            cash_recs = query_df("SELECT balance, currency FROM portfolio_cash WHERE user_id=?", (user_id,))
            if not cash_recs.empty:
                for _, cr in cash_recs.iterrows():
                    manual_cash_kwd += convert_to_kwd(cr["balance"], cr["currency"])
            
            # Total Portfolio Value = Stocks + Cash
            live_portfolio_value = live_stock_value + manual_cash_kwd
            
            # 2. Calculate Accumulated Cash (Total Deposits) - USE UNIFIED VIEW
            # This view ALWAYS shows correct totals regardless of upload status
            deposit_summary = query_df("""
                SELECT portfolio_name, total_deposits, total_withdrawals, net_deposits, deposit_count
                FROM portfolio_deposit_summary 
                WHERE user_id = ?
            """, (user_id,))
            
            today_str = date.today().strftime("%Y-%m-%d")
            total_deposits_kwd = 0.0
            today_deposits_kwd = 0.0
            all_deposits = pd.DataFrame()  # Initialize empty to prevent UnboundLocalError
            analysis_deposits = pd.DataFrame()  # Initialize empty
            
            if not deposit_summary.empty:
                # Convert to KWD based on portfolio currency
                for _, row in deposit_summary.iterrows():
                    port_name = row['portfolio_name']
                    ccy = PORTFOLIO_CCY.get(port_name, 'KWD')
                    total_deposits_kwd += convert_to_kwd(float(row['net_deposits'] or 0), ccy)
            else:
                # FALLBACK 1: Try legacy cash_deposits table
                _soft_del_dep = _soft_delete_filter_deposits()
                all_deposits = query_df(f"SELECT amount, currency, include_in_analysis, deposit_date FROM cash_deposits WHERE user_id = ?{_soft_del_dep}", (user_id,))
                
                if not all_deposits.empty:
                    # Convert all to KWD first
                    all_deposits["amount_in_kwd"] = all_deposits.apply(
                        lambda row: convert_to_kwd(row["amount"], row.get("currency", "KWD")),
                        axis=1
                    )
                    # Filter for analysis
                    analysis_deposits = all_deposits[all_deposits["include_in_analysis"] == 1]
                    
                    # Total accumulated up to today (inclusive)
                    total_deposits_kwd = analysis_deposits["amount_in_kwd"].sum()
                    
                    # Deposits specifically for today
                    today_deposits_kwd = analysis_deposits[analysis_deposits["deposit_date"] == today_str]["amount_in_kwd"].sum()
                else:
                    # FALLBACK 2: Calculate Net Invested Capital from transactions
                    _soft_del_txn = _soft_delete_filter()
                    
                    # Get total purchase cost (Buy transactions)
                    buys_df = query_df(f"""
                        SELECT portfolio, purchase_cost 
                        FROM transactions 
                        WHERE user_id = ? AND txn_type = 'Buy' AND purchase_cost IS NOT NULL{_soft_del_txn}
                    """, (user_id,))
                    
                    # Get total sell value (Sell transactions)
                    sells_df = query_df(f"""
                        SELECT portfolio, sell_value 
                        FROM transactions 
                        WHERE user_id = ? AND txn_type = 'Sell' AND sell_value IS NOT NULL{_soft_del_txn}
                    """, (user_id,))
                    
                    # Calculate totals in KWD
                    total_buys_kwd = 0.0
                    if not buys_df.empty:
                        for _, row in buys_df.iterrows():
                            port = row.get('portfolio', 'KFH')
                            ccy = PORTFOLIO_CCY.get(port, 'KWD')
                            total_buys_kwd += convert_to_kwd(float(row['purchase_cost'] or 0), ccy)
                    
                    total_sells_kwd = 0.0
                    if not sells_df.empty:
                        for _, row in sells_df.iterrows():
                            port = row.get('portfolio', 'KFH')
                            ccy = PORTFOLIO_CCY.get(port, 'KWD')
                            total_sells_kwd += convert_to_kwd(float(row['sell_value'] or 0), ccy)
                    
                    # Net Invested Capital = Money put in - Money taken out
                    total_deposits_kwd = total_buys_kwd - total_sells_kwd
            
            # 3. Get Previous Snapshot for Deltas
            prev_snap = query_df(
                "SELECT * FROM portfolio_snapshots WHERE snapshot_date < ? AND user_id = ? ORDER BY snapshot_date DESC LIMIT 1",
                (today_str, user_id)
            )
            
            prev_value = 0.0
            prev_accumulated = 0.0
            
            if not prev_snap.empty:
                prev_value = float(prev_snap["portfolio_value"].iloc[0])
                prev_accumulated = float(prev_snap["accumulated_cash"].iloc[0]) if pd.notna(prev_snap["accumulated_cash"].iloc[0]) else 0.0
                prev_date = prev_snap["snapshot_date"].iloc[0]
            else:
                prev_date = "1970-01-01" # Start of time
            
            # Calculate accumulated cash incrementally:
            # accumulated_cash = previous accumulated_cash + today's deposit_cash
            # This ensures the value builds up over time from each snapshot
            
            # Calculate today's deposit amount (will be used as deposit_cash)
            today_deposits_kwd = 0.0
            if not all_deposits.empty:
                # Filter deposits for today only
                today_deposits_df = analysis_deposits[analysis_deposits["deposit_date"] == today_str]
                today_deposits_kwd = today_deposits_df["amount_in_kwd"].sum()
            
            # accumulated_cash = previous accumulated + today's deposit
            accumulated_cash = prev_accumulated + today_deposits_kwd
            
            # 4. Calculate Metrics
            daily_movement = live_portfolio_value - prev_value if prev_value > 0 else 0.0
            # If we want daily movement to exclude today's deposit:
            # daily_movement = (live_portfolio_value - today_deposits_kwd) - prev_value
            
            # Calculate Beginning Diff: Current Value - First Value (Baseline)
            # Get the baseline value (value of the earliest snapshot)
            first_snap = query_df("SELECT portfolio_value, snapshot_date FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date ASC LIMIT 1", (user_id,))
            
            if first_snap.empty:
                # This is the first snapshot ever
                beginning_diff = 0.0
            else:
                first_date = first_snap["snapshot_date"].iloc[0]
                # If today is strictly after the first date, use first snapshot as baseline
                if today_str > first_date:
                    baseline_value = float(first_snap["portfolio_value"].iloc[0])
                    beginning_diff = live_portfolio_value - baseline_value
                # If today is the first date (or before), diff is 0
                else:
                    beginning_diff = 0.0
            
            # Net Gain = Beginning Diff - Accumulated Cash (Corrected Formula)
            net_gain = beginning_diff - accumulated_cash
            
            # Calculate NET INVESTED CAPITAL (Deposits - Withdrawals, all converted to KWD)
            total_deposits_kwd = 0.0
            total_withdrawals_kwd = 0.0
            
            # Sum all deposits (exclude soft-deleted if column exists)
            _soft_del_dep = _soft_delete_filter_deposits()
            all_deps = query_df(
                f"SELECT amount, currency FROM cash_deposits WHERE user_id = ? AND include_in_analysis = 1{_soft_del_dep}",
                (user_id,)
            )
            if not all_deps.empty:
                for _, dep_row in all_deps.iterrows():
                    dep_amt = float(dep_row["amount"]) if pd.notna(dep_row["amount"]) else 0.0
                    dep_ccy = dep_row.get("currency", "KWD") or "KWD"
                    total_deposits_kwd += convert_to_kwd(dep_amt, dep_ccy)
            
            # Sum all withdrawals (from transactions table where txn_type = 'Withdrawal' or category = 'FLOW_OUT')
            all_withdrawals = query_df(
                "SELECT sell_value, COALESCE(s.currency, 'KWD') as currency FROM transactions t LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND s.user_id = t.user_id WHERE t.user_id = ? AND (t.txn_type = 'Withdrawal' OR t.category = 'FLOW_OUT')",
                (user_id,)
            )
            if not all_withdrawals.empty:
                for _, wd_row in all_withdrawals.iterrows():
                    wd_amt = float(wd_row["sell_value"]) if pd.notna(wd_row["sell_value"]) else 0.0
                    wd_ccy = wd_row.get("currency", "KWD") or "KWD"
                    total_withdrawals_kwd += convert_to_kwd(wd_amt, wd_ccy)
            
            # Net Invested Capital = Deposits - Withdrawals
            net_invested_capital = total_deposits_kwd - total_withdrawals_kwd
            
            # ROI % = Net Gain / Net Invested Capital * 100
            roi_percent = (net_gain / net_invested_capital * 100) if net_invested_capital > 0 else 0.0
            change_percent = ((live_portfolio_value - prev_value) / prev_value * 100) if prev_value > 0 else 0.0
            
            # 5. Insert or Update
            # Check if exists
            existing = query_df("SELECT * FROM portfolio_snapshots WHERE snapshot_date = ? AND user_id = ?", (today_str, user_id))
            
            if not existing.empty:
                # --- FIX: Strict Type Casting for PostgreSQL ---
                # Ensure no Numpy types are passed to the DB adapter
                exec_sql(
                    """
                    UPDATE portfolio_snapshots
                    SET portfolio_value = ?, daily_movement = ?, beginning_difference = ?,
                        deposit_cash = ?, accumulated_cash = ?, net_gain = ?, 
                        change_percent = ?, roi_percent = ?, created_at = ?
                    WHERE snapshot_date = ? AND user_id = ?
                    """,
                    (float(live_portfolio_value), float(daily_movement), float(beginning_diff),
                     float(today_deposits_kwd), float(accumulated_cash), float(net_gain),
                     float(change_percent), float(roi_percent), int(time.time()),
                     str(today_str), int(user_id))
                )
                st.success(f"âœ… Updated snapshot for {today_str}")
            else:
                # --- FIX: Strict Type Casting for PostgreSQL ---
                # Ensure no Numpy types are passed to the DB adapter
                sql_params = (
                    int(user_id),
                    str(today_str),
                    float(live_portfolio_value),
                    float(daily_movement),
                    float(beginning_diff),
                    float(today_deposits_kwd),
                    float(accumulated_cash),
                    float(net_gain),
                    float(change_percent),
                    float(roi_percent),
                    int(time.time())
                )
                
                exec_sql(
                    """
                    INSERT INTO portfolio_snapshots 
                    (user_id, snapshot_date, portfolio_value, daily_movement, beginning_difference, 
                     deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    sql_params
                )
                st.success(f"âœ… Saved new snapshot for {today_str}")
            
            build_portfolio_table.clear()  # Clear cache to show updated data
            time.sleep(1)
            st.rerun()

    # Excel upload and download
    col1, col2 = st.columns(2)
    with col1:
        # Download sample template
        if st.button("ðŸ“¥ Download Sample Excel Template"):
            sample_data = {
                "Date": ["2025-01-15", "2025-01-16", "2025-01-17"],
                "Value": [128022.00, 127410.00, 127693.00],
                "Daily Movement": [0, -613, 283],
                "Beginning Difference": [0, -613, -329],
                "Deposit Cash": [0, 0, 0],
            }
            sample_df = pd.DataFrame(sample_data)
            
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                sample_df.to_excel(writer, sheet_name='Portfolio Snapshots', index=False)
            
            st.download_button(
                label="Download Template",
                data=output.getvalue(),
                file_name="portfolio_tracker_template.xlsx",
                mime="application/vnd.openxmlsheet"
            )
    
    with col2:
        # Upload Excel file
        with st.expander("ðŸ“¤ Upload Portfolio Snapshots Excel", expanded=False):
            uploaded_file = st.file_uploader("Select Excel file", type=["xlsx", "xls"], key="upload_snapshots")
            if uploaded_file:
                try:
                    df = pd.read_excel(uploaded_file, sheet_name=0)
                    
                    # Normalize column names
                    df.columns = [str(c).strip().lower().replace(' ', '_') for c in df.columns]
                    
                    # Map columns
                    col_map = {
                        'date': 'snapshot_date',
                        'value': 'portfolio_value',
                        'daily_movement': 'daily_movement',
                        'beginning_difference': 'beginning_difference',
                        'deposit_cash': 'deposit_cash'
                    }
                    
                    df = df.rename(columns=col_map)
                    
                    # Validate required columns
                    required = ['snapshot_date', 'portfolio_value']
                    missing = [c for c in required if c not in df.columns]
                    if missing:
                        st.error(f"Missing required columns: {', '.join(missing)}")
                    else:
                        # Fill optional columns with defaults
                        if 'daily_movement' not in df.columns:
                            df['daily_movement'] = 0
                        if 'beginning_difference' not in df.columns:
                            df['beginning_difference'] = 0
                        if 'deposit_cash' not in df.columns:
                            df['deposit_cash'] = 0
                        
                        # Convert date column
                        df['snapshot_date'] = pd.to_datetime(df['snapshot_date']).dt.strftime('%Y-%m-%d')
                        
                        # Sort by date
                        df = df.sort_values('snapshot_date')
                        
                        # Get accumulated cash from the date BEFORE our import data
                        earliest_import_date = df['snapshot_date'].iloc[0]
                        before_import = query_df(
                            "SELECT accumulated_cash FROM portfolio_snapshots WHERE snapshot_date < ? AND user_id = ? ORDER BY snapshot_date DESC LIMIT 1",
                            (earliest_import_date, user_id)
                        )
                        if not before_import.empty:
                            val = before_import["accumulated_cash"].iloc[0]
                            accumulated_cash = float(val) if pd.notna(val) else None
                        else:
                            accumulated_cash = None
                        
                        prev_value = 0
                        
                        records_to_insert = []
                        duplicates = []
                        
                        for idx, row in df.iterrows():
                            snap_date = row['snapshot_date']
                            portfolio_value = float(row['portfolio_value'])
                            daily_movement = float(row.get('daily_movement', 0))
                            beginning_diff = float(row.get('beginning_difference', 0))
                            deposit_cash = float(row.get('deposit_cash', 0))
                            
                            # Check for duplicates
                            existing = query_df("SELECT * FROM portfolio_snapshots WHERE snapshot_date = ? AND user_id = ?", (snap_date, user_id))
                            if not existing.empty:
                                duplicates.append(snap_date)
                                continue
                            
                            # Calculate values
                            # Accumulated cash: add new deposit to previous (or start fresh if None)
                            if accumulated_cash is None:
                                # No previous accumulated value
                                if deposit_cash > 0:
                                    accumulated_cash = deposit_cash
                                # else: stays None
                            else:
                                # Has previous accumulated value
                                if deposit_cash > 0:
                                    # Add new deposit to previous accumulated
                                    accumulated_cash += deposit_cash
                                # else: carry forward previous value (no change to accumulated_cash)
                            
                            # Calculate NET INVESTED CAPITAL (Deposits - Withdrawals)
                            total_deposits_kwd = 0.0
                            total_withdrawals_kwd = 0.0
                            
                            all_deps = query_df("""
                                SELECT amount, currency 
                                FROM cash_deposits 
                                WHERE user_id = ? AND include_in_analysis = 1
                            """, (user_id,))
                            if not all_deps.empty:
                                for _, dep_row in all_deps.iterrows():
                                    dep_amt = float(dep_row["amount"]) if pd.notna(dep_row["amount"]) else 0.0
                                    dep_ccy = dep_row.get("currency", "KWD") or "KWD"
                                    total_deposits_kwd += convert_to_kwd(dep_amt, dep_ccy)
                            
                            all_withdrawals = query_df(
                                "SELECT sell_value, COALESCE(s.currency, 'KWD') as currency FROM transactions t LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND s.user_id = t.user_id WHERE t.user_id = ? AND (t.txn_type = 'Withdrawal' OR t.category = 'FLOW_OUT')",
                                (user_id,)
                            )
                            if not all_withdrawals.empty:
                                for _, wd_row in all_withdrawals.iterrows():
                                    wd_amt = float(wd_row["sell_value"]) if pd.notna(wd_row["sell_value"]) else 0.0
                                    wd_ccy = wd_row.get("currency", "KWD") or "KWD"
                                    total_withdrawals_kwd += convert_to_kwd(wd_amt, wd_ccy)
                            
                            net_invested_capital = total_deposits_kwd - total_withdrawals_kwd
                            
                            # Net gain from stocks = Beginning Difference - Accumulated Cash (Corrected Formula)
                            net_gain = beginning_diff - accumulated_cash if accumulated_cash else beginning_diff
                            # ROI % = Net Gain / Net Invested Capital * 100
                            roi_percent = (net_gain / net_invested_capital * 100) if net_invested_capital > 0 else 0
                            # Change % = change from previous day
                            change_percent = ((portfolio_value - prev_value) / prev_value * 100) if prev_value > 0 else 0
                            
                            records_to_insert.append((
                                user_id, snap_date, portfolio_value, daily_movement, beginning_diff,
                                deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, int(time.time())
                            ))
                            
                            prev_value = portfolio_value
                        
                        # Insert records
                        if records_to_insert:
                            conn = get_conn()
                            cur = conn.cursor()
                            sql = convert_sql_placeholders("""
                                INSERT INTO portfolio_snapshots 
                                (user_id, snapshot_date, portfolio_value, daily_movement, beginning_difference, 
                                 deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """)
                            cur.executemany(sql, records_to_insert)
                            conn.commit()
                            conn.close()
                            
                            st.success(f"âœ… Imported {len(records_to_insert):,} snapshots successfully!")
                            if duplicates:
                                st.warning(f"âš ï¸ Skipped {len(duplicates)} duplicate dates: {', '.join(duplicates[:5])}{'...' if len(duplicates) > 5 else ''}")
                            st.rerun()
                        else:
                            st.info("No new records to import (all duplicates).")
                            
                except Exception as e:
                    st.error(f"Error reading Excel file: {e}")
    
    st.divider()
    
    # Add manual snapshot
    with st.expander("âž• Add Manual Snapshot (Transaction)", expanded=False):
        st.caption("Manually add a historical portfolio snapshot. Metrics will be auto-calculated if left as 0.")
        col1, col2 = st.columns(2)
        with col1:
            snap_date = st.date_input("Date", value=date.today(), key="manual_snap_date")
            portfolio_value = st.number_input("Portfolio Value", min_value=0.0, step=0.001, format="%.3f", key="manual_snap_value")
            deposit_cash = st.number_input("Deposit Cash (if any)", min_value=0.0, step=0.001, format="%.3f", key="manual_snap_deposit")
        with col2:
            daily_movement = st.number_input("Daily Movement (Optional)", step=0.001, format="%.3f", key="manual_snap_movement")
            beginning_diff = st.number_input("Beginning Difference (Optional)", step=0.001, format="%.3f", key="manual_snap_diff")
        
        if st.button("Save Manual Snapshot"):
            snap_date_str = snap_date.strftime("%Y-%m-%d")
            
            # Check if snapshot already exists
            existing = query_df("SELECT * FROM portfolio_snapshots WHERE snapshot_date = ? AND user_id = ?", (snap_date_str, user_id))
            if not existing.empty:
                st.error(f"Snapshot for {snap_date_str} already exists. Please edit it in the table below instead.")
            else:
                # Get previous snapshot relative to this date
                prev_snap = query_df(
                    "SELECT * FROM portfolio_snapshots WHERE snapshot_date < ? AND user_id = ? ORDER BY snapshot_date DESC LIMIT 1",
                    (snap_date_str, user_id)
                )
                
                prev_value = 0.0
                prev_accumulated = 0.0
                
                if not prev_snap.empty:
                    prev_value = float(prev_snap["portfolio_value"].iloc[0])
                    prev_accumulated = float(prev_snap["accumulated_cash"].iloc[0]) if pd.notna(prev_snap["accumulated_cash"].iloc[0]) else 0.0
                
                # accumulated_cash = previous accumulated + this deposit
                accumulated_cash = prev_accumulated + deposit_cash
                
                # Auto-calculate metrics if 0
                if daily_movement == 0:
                    daily_movement = portfolio_value - prev_value if prev_value > 0 else 0.0
                
                if beginning_diff == 0:
                    # Calculate Beginning Diff: Current Value - First Value (Baseline)
                    first_snap = query_df("SELECT portfolio_value, snapshot_date FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date ASC LIMIT 1", (user_id,))
                    if first_snap.empty:
                        beginning_diff = 0.0
                    else:
                        first_date = first_snap["snapshot_date"].iloc[0]
                        if snap_date_str > first_date:
                            baseline_value = float(first_snap["portfolio_value"].iloc[0])
                            beginning_diff = portfolio_value - baseline_value
                        else:
                            beginning_diff = 0.0
                
                net_gain = beginning_diff - accumulated_cash
                
                # Calculate NET INVESTED CAPITAL (Deposits - Withdrawals)
                total_deposits_kwd = 0.0
                total_withdrawals_kwd = 0.0
                
                _soft_del_dep = _soft_delete_filter_deposits()
                all_deps = query_df(
                    f"SELECT amount, currency FROM cash_deposits WHERE user_id = ? AND include_in_analysis = 1{_soft_del_dep}",
                    (user_id,)
                )
                if not all_deps.empty:
                    for _, dep_row in all_deps.iterrows():
                        dep_amt = float(dep_row["amount"]) if pd.notna(dep_row["amount"]) else 0.0
                        dep_ccy = dep_row.get("currency", "KWD") or "KWD"
                        total_deposits_kwd += convert_to_kwd(dep_amt, dep_ccy)
                
                all_withdrawals = query_df(
                    "SELECT sell_value, COALESCE(s.currency, 'KWD') as currency FROM transactions t LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND s.user_id = t.user_id WHERE t.user_id = ? AND (t.txn_type = 'Withdrawal' OR t.category = 'FLOW_OUT')",
                    (user_id,)
                )
                if not all_withdrawals.empty:
                    for _, wd_row in all_withdrawals.iterrows():
                        wd_amt = float(wd_row["sell_value"]) if pd.notna(wd_row["sell_value"]) else 0.0
                        wd_ccy = wd_row.get("currency", "KWD") or "KWD"
                        total_withdrawals_kwd += convert_to_kwd(wd_amt, wd_ccy)
                
                net_invested_capital = total_deposits_kwd - total_withdrawals_kwd
                
                # ROI % = Net Gain / Net Invested Capital * 100
                roi_percent = (net_gain / net_invested_capital * 100) if net_invested_capital > 0 else 0.0
                change_percent = ((portfolio_value - prev_value) / prev_value * 100) if prev_value > 0 else 0.0
                
                exec_sql(
                    """
                    INSERT INTO portfolio_snapshots 
                    (user_id, snapshot_date, portfolio_value, daily_movement, beginning_difference, 
                     deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                    (user_id, snap_date_str, portfolio_value, daily_movement, beginning_diff,
                     deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, int(time.time()))
                )
                st.success(f"âœ… Saved snapshot for {snap_date_str}")
                time.sleep(1)
                st.rerun()
    
    st.divider()
    
    # Display snapshots
    snapshots = query_df(
        "SELECT * FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date DESC",
        (user_id,)
    )
    
    if snapshots.empty:
        st.info("No portfolio snapshots yet. Add your first snapshot above.")
        return
    
    # === MODERN DASHBOARD ===
    
    # 1. Prepare Data
    df = snapshots.sort_values("snapshot_date").copy()
    df["snapshot_date"] = pd.to_datetime(df["snapshot_date"])
    
    # Calculate metrics for the cards
    if not df.empty:
        latest = df.iloc[-1]
        total_revenue = latest["portfolio_value"]
        
        # User request: Get Net Gain strictly from the "Net Gain" column of the latest snapshot
        # This ensures it matches exactly what is shown in the table below
        # DO NOT RECALCULATE. Source of truth is the database row.
        total_profit = latest["net_gain"] 
        
        profit_margin = latest["roi_percent"] if "roi_percent" in latest else 0.0
    else:
        total_revenue = 0
        total_profit = 0
        profit_margin = 0

    # 2. Define Theme Colors (Synced with Global Theme)
    is_dark = st.session_state.get("theme", "light") == "dark"
    
    theme = {
        "app_bg": "linear-gradient(to bottom right, #111827, #1f2937, #000000)" if is_dark else "linear-gradient(to bottom right, #f9fafb, #ffffff, #f3f4f6)",
        "text_main": "#ffffff" if is_dark else "#111827",
        "text_sub": "#9ca3af" if is_dark else "#4b5563",
        "card_bg": "rgba(31, 41, 55, 0.5)" if is_dark else "rgba(255, 255, 255, 0.8)",
        "card_border": "rgba(55, 65, 81, 0.5)" if is_dark else "rgba(229, 231, 235, 0.5)",
        "shadow": "0 25px 50px -12px rgba(0, 0, 0, 0.25)" if is_dark else "0 10px 15px -3px rgba(0, 0, 0, 0.1)",
        
        # Chart Colors
        "rev_line": "#06b6d4" if is_dark else "#1D4ED8",
        "rev_glow": "rgba(6, 182, 212, 0.3)" if is_dark else "rgba(29, 78, 216, 0.25)",
        "prof_line": "#10b981" if is_dark else "#047857",
        "prof_glow": "rgba(16, 185, 129, 0.3)" if is_dark else "rgba(4, 120, 87, 0.25)",
        
        # Grid/Axes
        "grid": "rgba(125, 211, 252, 0.1)" if is_dark else "rgba(229, 231, 235, 0.5)",
        "tick_text": "rgba(209, 213, 219, 0.6)" if is_dark else "rgba(55, 65, 81, 0.7)",
        
        # Tooltip
        "tooltip_bg": "rgba(17, 24, 39, 0.9)" if is_dark else "rgba(255, 255, 255, 0.9)",
        "tooltip_text": "#22d3ee" if is_dark else "#2563eb",
        "tooltip_border": "rgba(6, 182, 212, 0.3)" if is_dark else "rgba(147, 197, 253, 0.3)",
        
        # Stats Cards Gradients
        "stat_rev_bg": "linear-gradient(to right, rgba(6, 182, 212, 0.1), rgba(8, 145, 178, 0.1))" if is_dark else "linear-gradient(to right, rgba(239, 246, 255, 0.5), rgba(219, 234, 254, 0.5))",
        "stat_rev_border": "rgba(6, 182, 212, 0.2)" if is_dark else "rgba(191, 219, 254, 0.5)",
        "stat_rev_text": "#67e8f9" if is_dark else "#1d4ed8",
        
        "stat_prof_bg": "linear-gradient(to right, rgba(16, 185, 129, 0.1), rgba(5, 150, 105, 0.1))" if is_dark else "linear-gradient(to right, rgba(240, 253, 244, 0.5), rgba(220, 252, 231, 0.5))",
        "stat_prof_border": "rgba(16, 185, 129, 0.2)" if is_dark else "rgba(187, 247, 208, 0.5)",
        "stat_prof_text": "#6ee7b7" if is_dark else "#15803d",
        
        "stat_marg_bg": "linear-gradient(to right, rgba(168, 85, 247, 0.1), rgba(147, 51, 234, 0.1))" if is_dark else "linear-gradient(to right, rgba(250, 245, 255, 0.5), rgba(243, 232, 255, 0.5))",
        "stat_marg_border": "rgba(168, 85, 247, 0.2)" if is_dark else "rgba(233, 213, 255, 0.5)",
        "stat_marg_text": "#d8b4fe" if is_dark else "#7e22ce",
    }

    # 3. CSS Styling (Dynamic)
    st.markdown(f"""
    <style>
        /* Main Container Background */
        .stApp {{
            background: {theme['app_bg']};
            color: {theme['text_main']};
        }}
        
        /* Header Text Gradient */
        .header-gradient {{
            background: linear-gradient(to right, #22d3ee, #60a5fa, #34d399);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 800;
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }}
        
        /* Card Styles */
        .dashboard-card {{
            background-color: {theme['card_bg']};
            backdrop-filter: blur(8px);
            border: 1px solid {theme['card_border']};
            border-radius: 1rem;
            padding: 2rem;
            box-shadow: {theme['shadow']};
            margin-bottom: 2rem;
        }}
        
        /* Stat Cards */
        .stat-card {{
            border-radius: 0.75rem;
            padding: 1.5rem;
            height: 100%;
            transition: all 0.3s ease;
        }}
        
        .stat-card-cyan {{
            background: {theme['stat_rev_bg']};
            border: 1px solid {theme['stat_rev_border']};
        }}
        .stat-card-cyan h3 {{ color: {theme['stat_rev_text']}; }}
        
        .stat-card-emerald {{
            background: {theme['stat_prof_bg']};
            border: 1px solid {theme['stat_prof_border']};
        }}
        .stat-card-emerald h3 {{ color: {theme['stat_prof_text']}; }}
        
        .stat-card-purple {{
            background: {theme['stat_marg_bg']};
            border: 1px solid {theme['stat_marg_border']};
        }}
        .stat-card-purple h3 {{ color: {theme['stat_marg_text']}; }}
        
        /* Legend Dots */
        .legend-dot {{
            width: 0.75rem;
            height: 0.75rem;
            border-radius: 9999px;
            margin-right: 0.5rem;
            display: inline-block;
        }}
        
        .glow-cyan {{ box-shadow: 0 0 15px {theme['rev_glow']}; background-color: {theme['rev_line']}; }}
        .glow-emerald {{ box-shadow: 0 0 15px {theme['prof_glow']}; background-color: {theme['prof_line']}; }}
        
    </style>
    """, unsafe_allow_html=True)

    # 4. Header Section
    st.markdown('<div style="text-align: center; margin-bottom: 3rem;">', unsafe_allow_html=True)
    st.markdown('<h1 class="header-gradient">Financial Performance Dashboard</h1>', unsafe_allow_html=True)
    st.markdown(f'<p style="color: {theme["text_sub"]}; font-size: 1.125rem;">Real-time insights into your financial metrics</p>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

    # 5. Main Chart Cards (Separated)
    
    if go:
        # === CHART 1: REVENUE (Portfolio Value) ===
        st.markdown('<div class="dashboard-card">', unsafe_allow_html=True)
        
        # Header
        col_rev_title, col_rev_legend = st.columns([3, 1])
        with col_rev_title:
            st.markdown(f'<h2 style="color: {theme["text_main"]}; font-weight: 700; font-size: 1.5rem; margin-bottom: 0.5rem;">Total Portfolio Value Over Time</h2>', unsafe_allow_html=True)
            st.markdown(f'<p style="color: {theme["text_sub"]}; font-size: 0.875rem;">Historical Performance</p>', unsafe_allow_html=True)
        with col_rev_legend:
            st.markdown(f"""
            <div style="display: flex; justify-content: flex-end; margin-top: 1rem;">
                <div style="display: flex; align-items: center;">
                    <div class="legend-dot glow-cyan"></div>
                    <span style="color: {theme["text_sub"]}; font-size: 0.875rem;">Revenue</span>
                </div>
            </div>
            """, unsafe_allow_html=True)

        # Chart
        fig_rev = go.Figure()
        fig_rev.add_trace(go.Scatter(
            x=df["snapshot_date"],
            y=df["portfolio_value"],
            mode='lines+markers',
            name='Revenue',
            line=dict(color=theme['rev_line'], width=3, shape='spline'),
            marker=dict(size=6, color='#022c22' if is_dark else '#ffffff', line=dict(color=theme['rev_line'], width=2)),
            hovertemplate='<b>Revenue</b>: %{y:,.0f} KWD<extra></extra>'
        ))
        
        fig_rev.update_layout(
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            margin=dict(l=0, r=0, t=20, b=0),
            height=350,
            showlegend=False,
            hovermode="x unified",
            xaxis=dict(showgrid=True, gridcolor=theme['grid'], gridwidth=1, showline=False, tickfont=dict(color=theme['tick_text'], size=12)),
            yaxis=dict(showgrid=True, gridcolor=theme['grid'], gridwidth=1, showline=False, tickfont=dict(color=theme['tick_text'], size=12), tickformat=",.0f"),
            hoverlabel=dict(bgcolor=theme['tooltip_bg'], bordercolor=theme['tooltip_border'], font=dict(color=theme['tooltip_text'], family="Inter, sans-serif"))
        )
        st.plotly_chart(fig_rev, width="stretch", config={'displayModeBar': False})
        st.markdown('</div>', unsafe_allow_html=True)


        # === CHART 2: PROFIT (Net Gain) ===
        st.markdown('<div class="dashboard-card">', unsafe_allow_html=True)
        
        # Header
        col_prof_title, col_prof_legend = st.columns([3, 1])
        with col_prof_title:
            st.markdown(f'<h2 style="color: {theme["text_main"]}; font-weight: 700; font-size: 1.5rem; margin-bottom: 0.5rem;">Net Gain from Stocks Over Time</h2>', unsafe_allow_html=True)
            st.markdown(f'<p style="color: {theme["text_sub"]}; font-size: 0.875rem;">Historical Performance</p>', unsafe_allow_html=True)
        with col_prof_legend:
            st.markdown(f"""
            <div style="display: flex; justify-content: flex-end; margin-top: 1rem;">
                <div style="display: flex; align-items: center;">
                    <div class="legend-dot glow-emerald"></div>
                    <span style="color: {theme["text_sub"]}; font-size: 0.875rem;">Profit</span>
                </div>
            </div>
            """, unsafe_allow_html=True)

        # Chart
        fig_prof = go.Figure()
        fig_prof.add_trace(go.Scatter(
            x=df["snapshot_date"],
            y=df["net_gain"],
            mode='lines+markers',
            name='Profit',
            line=dict(color=theme['prof_line'], width=3, shape='spline'),
            marker=dict(size=6, color='#022c22' if is_dark else '#ffffff', line=dict(color=theme['prof_line'], width=2)),
            hovertemplate='<b>Profit</b>: %{y:,.0f} KWD<extra></extra>'
        ))
        
        fig_prof.update_layout(
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            margin=dict(l=0, r=0, t=20, b=0),
            height=350,
            showlegend=False,
            hovermode="x unified",
            xaxis=dict(showgrid=True, gridcolor=theme['grid'], gridwidth=1, showline=False, tickfont=dict(color=theme['tick_text'], size=12)),
            yaxis=dict(showgrid=True, gridcolor=theme['grid'], gridwidth=1, showline=False, tickfont=dict(color=theme['tick_text'], size=12), tickformat=",.0f"),
            hoverlabel=dict(bgcolor=theme['tooltip_bg'], bordercolor=theme['prof_line'], font=dict(color=theme['prof_line'], family="Inter, sans-serif"))
        )
        st.plotly_chart(fig_prof, width="stretch", config={'displayModeBar': False})
        st.markdown('</div>', unsafe_allow_html=True)

        # 6. Stats Summary Cards (New)
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        
        with col_stat1:
            st.markdown(f"""
            <div class="stat-card stat-card-cyan">
                <h3 style="font-weight: 600; margin-bottom: 0.5rem;">Total Portfolio Value</h3>
                <p style="font-size: 1.5rem; font-weight: 700; color: {theme['text_main']};">{total_revenue:,.0f} KWD</p>
                <p style="font-size: 0.875rem; color: {theme['stat_rev_text']}; display: flex; align-items: center;">
                    <span style="margin-right: 0.25rem;">â†‘</span> Current Value
                </p>
            </div>
            """, unsafe_allow_html=True)
            
        with col_stat2:
            st.markdown(f"""
            <div class="stat-card stat-card-emerald">
                <h3 style="font-weight: 600; margin-bottom: 0.5rem;">Net Gain From Stocks</h3>
                <p style="font-size: 1.5rem; font-weight: 700; color: {theme['text_main']};">{total_profit:,.0f} KWD</p>
                <p style="font-size: 0.875rem; color: {theme['stat_prof_text']}; display: flex; align-items: center;">
                    <span style="margin-right: 0.25rem;">â†‘</span> Net Gain
                </p>
            </div>
            """, unsafe_allow_html=True)
            
        with col_stat3:
            st.markdown(f"""
            <div class="stat-card stat-card-purple">
                <h3 style="font-weight: 600; margin-bottom: 0.5rem;">Profit Margin</h3>
                <p style="font-size: 1.5rem; font-weight: 700; color: {theme['text_main']};">{profit_margin:.1f}%</p>
                <p style="font-size: 0.875rem; color: {theme['stat_marg_text']}; display: flex; align-items: center;">
                    <span style="margin-right: 0.25rem;">â†‘</span> ROI
                </p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown('<div style="text-align: center; margin-top: 3rem; margin-bottom: 2rem;">', unsafe_allow_html=True)
        st.markdown(f'<p style="color: {theme["text_sub"]}; font-size: 0.875rem;">Data refreshed â€¢ Last updated: {pd.Timestamp.now().strftime("%B %d, %Y")}</p>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Footer
    st.divider()
    
    # Format and display table
    st.markdown("### ðŸ“Š Portfolio Snapshots")
    
    # === DELETE INDIVIDUAL SNAPSHOT ===
    with st.expander("ðŸ—‘ï¸ Delete Individual Snapshot", expanded=False):
        if not snapshots.empty:
            # Create dropdown options from existing snapshots
            snap_options = snapshots.sort_values('snapshot_date', ascending=False)['snapshot_date'].tolist()
            selected_snap_date = st.selectbox(
                "Select snapshot date to delete:",
                snap_options,
                key="delete_snap_selector"
            )
            
            col_del_btn, col_del_warn = st.columns([1, 3])
            with col_del_btn:
                if st.button("ðŸ—‘ï¸ Delete Selected", type="secondary", key="delete_single_snap"):
                    try:
                        exec_sql("DELETE FROM portfolio_snapshots WHERE snapshot_date = ? AND user_id = ?", 
                                (str(selected_snap_date), user_id))
                        st.success(f"âœ… Deleted snapshot for {selected_snap_date}")
                        time.sleep(1)
                        st.rerun()
                    except Exception as e:
                        st.error(f"Error: {e}")
            with col_del_warn:
                st.caption("âš ï¸ This action cannot be undone.")
        else:
            st.info("No snapshots to delete.")
    
    # === RECALCULATE ACCUMULATED CASH ===
    with st.expander("ðŸ”„ Recalculate Accumulated Cash", expanded=False):
        st.caption("""
        **Accumulated Cash** = Running total of deposit_cash column.
        
        Logic: For each snapshot (in date order):
        - accumulated_cash = deposit_cash + previous_accumulated_cash
        
        This also updates Net Gain and ROI % accordingly.
        """)
        
        if st.button("ðŸ”„ Recalculate All Snapshots", type="primary", key="recalc_accumulated_cash"):
            with st.spinner("Recalculating accumulated cash for all snapshots..."):
                try:
                    # Get all snapshots for this user, ordered by date ASC
                    all_snaps = query_df(
                        "SELECT id, snapshot_date, portfolio_value, beginning_difference, deposit_cash FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date ASC",
                        (user_id,)
                    )
                    
                    if all_snaps.empty:
                        st.warning("No snapshots found to recalculate.")
                    else:
                        updated_count = 0
                        running_accumulated = 0.0  # Start from 0
                        
                        for _, snap_row in all_snaps.iterrows():
                            snap_id = int(snap_row['id'])
                            beginning_diff = float(snap_row['beginning_difference']) if pd.notna(snap_row['beginning_difference']) else 0.0
                            deposit_cash = float(snap_row['deposit_cash']) if pd.notna(snap_row['deposit_cash']) else 0.0
                            
                            # accumulated_cash = deposit_cash + previous_accumulated_cash
                            running_accumulated += deposit_cash
                            correct_accumulated = running_accumulated
                            
                            # Calculate Net Gain = Beginning Diff - Accumulated Cash
                            new_net_gain = beginning_diff - correct_accumulated
                            
                            # Calculate ROI % = Net Gain / Accumulated Cash * 100
                            new_roi = (new_net_gain / correct_accumulated * 100) if correct_accumulated > 0 else 0.0
                            
                            # Update the snapshot
                            exec_sql("""
                                UPDATE portfolio_snapshots 
                                SET accumulated_cash = ?, net_gain = ?, roi_percent = ?
                                WHERE id = ?
                            """, (float(correct_accumulated), float(new_net_gain), float(new_roi), snap_id))
                            
                            updated_count += 1
                        
                        st.success(f"âœ… Recalculated {updated_count} snapshots!")
                        time.sleep(1)
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"Error: {e}")
                    logger.error(f"Error recalculating accumulated cash: {e}")
    
    # View Mode Toggle (like Trading Section)
    col_mode, col_spacer = st.columns([2, 3])
    with col_mode:
        view_mode = st.radio(" ", ["ðŸ“Š Read View", "âœï¸ Edit Mode"], horizontal=True, label_visibility="collapsed", key="snapshot_view_mode")
    
    if view_mode == "ðŸ“Š Read View":
        # Professional styled HTML table with coloring
        st.caption("Switch to **Edit Mode** to modify data.")
        
        display_df = snapshots.copy()
        display_df = display_df.sort_values('snapshot_date', ascending=False)
        
        # Render styled table with financial formatting
        render_snapshot_table(display_df)
        
    else:
        # Edit Mode
        st.caption("Double-click any cell to edit. Click 'Save Changes' to update the database and graphs.")
        
        # Prepare dataframe for editor (raw values)
        edit_df = snapshots.copy()
        # Ensure date is string for consistency or date object
        # st.data_editor handles date columns well if they are datetime objects
        edit_df["snapshot_date"] = pd.to_datetime(edit_df["snapshot_date"]).dt.date
        
        # Columns to edit - formatted for editing with 2 decimals for money
        cols_config = {
            "snapshot_date": st.column_config.DateColumn("Date", format="YYYY-MM-DD", required=True),
            "portfolio_value": st.column_config.NumberColumn("Value", format="%,.2f", required=True),
            "daily_movement": st.column_config.NumberColumn("Daily Movement", format="%,.2f"),
            "beginning_difference": st.column_config.NumberColumn("Beginning Diff", format="%,.2f"),
            "deposit_cash": st.column_config.NumberColumn("Deposit Cash", format="%,.0f"),
            "accumulated_cash": st.column_config.NumberColumn("Accumulated Cash", format="%,.0f"),
            "net_gain": st.column_config.NumberColumn("Net Gain", format="%,.2f"),
            "change_percent": st.column_config.NumberColumn("Change %", format="%.2f%%"),
            "roi_percent": st.column_config.NumberColumn("ROI %", format="%.2f%%"),
            "created_at": st.column_config.NumberColumn("Created At", disabled=True)
        }
        
        # Show editor
        edited_data = st.data_editor(
            edit_df,
            column_config=cols_config,
            width="stretch",
            num_rows="dynamic", # Allow adding/deleting rows
            key="snapshot_editor",
            hide_index=True,
            column_order=[
                "snapshot_date", "portfolio_value", "daily_movement", "beginning_difference",
                "deposit_cash", "accumulated_cash", "net_gain", "change_percent", "roi_percent"
            ]
        )
        
        if st.button("ðŸ’¾ Save Changes", type="primary"):
            try:
                # 1. Delete all existing snapshots for this user
                conn = get_conn()
                cur = conn.cursor()
                db_execute(cur, "DELETE FROM portfolio_snapshots WHERE user_id = ?", (user_id,))
                
                # 2. Insert all rows from edited_data
                records = []
                for _, row in edited_data.iterrows():
                    # Convert date back to string YYYY-MM-DD
                    s_date = row["snapshot_date"].strftime("%Y-%m-%d") if isinstance(row["snapshot_date"], date) else str(row["snapshot_date"])
                    
                    records.append((
                        user_id,
                        s_date,
                        float(row["portfolio_value"]),
                        float(row["daily_movement"]),
                        float(row["beginning_difference"]),
                        float(row["deposit_cash"]),
                        float(row["accumulated_cash"]),
                        float(row["net_gain"]),
                        float(row["change_percent"]),
                        float(row["roi_percent"]),
                        int(time.time()) # Update created_at or keep original? Let's update to show it was modified
                    ))
                
                sql = convert_sql_placeholders("""
                    INSERT INTO portfolio_snapshots 
                    (user_id, snapshot_date, portfolio_value, daily_movement, beginning_difference, 
                     deposit_cash, accumulated_cash, net_gain, change_percent, roi_percent, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """)
                cur.executemany(sql, records)
                conn.commit()
                conn.close()
                
                st.success("âœ… Changes saved successfully!")
                time.sleep(1)
                st.rerun()
                
            except Exception as e:
                st.error(f"Error saving changes: {e}")


def ui_dividends_tracker():
    st.subheader("ðŸ’° Dividends Tracker")
    
    user_id = st.session_state.get('user_id', 1)
    soft_del = _soft_delete_filter("t")
    
    # Query dividend data from transactions table (master storage - single source of truth)
    # This matches the logic in calculate_total_cash_dividends()
    dividends_df = query_df(f"""
        SELECT 
            t.id,
            t.stock_symbol,
            t.txn_date,
            COALESCE(t.cash_dividend, 0) as cash_dividend,
            COALESCE(t.bonus_shares, 0) as bonus_shares,
            COALESCE(t.reinvested_dividend, 0) as reinvested_dividend,
            COALESCE(s.currency, 'KWD') as currency,
            t.notes,
            'portfolio' as source
        FROM transactions t
        LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND s.user_id = t.user_id
        WHERE t.user_id = ?{soft_del} AND (
            COALESCE(t.cash_dividend, 0) > 0 
           OR COALESCE(t.bonus_shares, 0) > 0
           OR COALESCE(t.reinvested_dividend, 0) > 0
        )
        ORDER BY t.txn_date DESC, t.stock_symbol
    """, (user_id,))
    
    if dividends_df.empty:
        st.info("ðŸ“Š No dividend data found. Dividends are stored with your transactions - add cash dividends, bonus shares, or reinvested dividends when recording transactions.")
        return
    
    # Convert cash_dividend to KWD for consistent totals
    dividends_df["cash_dividend_kwd"] = dividends_df.apply(
        lambda row: convert_to_kwd(safe_float(row["cash_dividend"], 0), row.get("currency", "KWD")),
        axis=1
    )
    dividends_df["reinvested_kwd"] = dividends_df.apply(
        lambda row: convert_to_kwd(safe_float(row["reinvested_dividend"], 0), row.get("currency", "KWD")),
        axis=1
    )
    
    # Get cost basis for yield calculation
    soft_del_cost = _soft_delete_filter()
    cost_df = query_df(f"""
        SELECT 
            stock_symbol,
            SUM(CASE WHEN txn_type = 'Buy' THEN purchase_cost ELSE 0 END) as total_cost
        FROM transactions
        WHERE user_id = ?{soft_del_cost}
        GROUP BY stock_symbol
    """, (user_id,))
    
    # Summary Cards - USE CONVERTED KWD VALUES (matches Overview tab)
    total_cash_div_kwd = dividends_df['cash_dividend_kwd'].sum()
    total_bonus_shares = dividends_df['bonus_shares'].sum()
    total_reinvested_kwd = dividends_df['reinvested_kwd'].sum()
    unique_stocks = dividends_df['stock_symbol'].nunique()
    dividend_count = len(dividends_df)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ðŸ’µ Total Cash Dividends Received", fmt_money(total_cash_div_kwd, "KWD"), 
                  help=f"{dividend_count} dividend records. Cash dividends only - does NOT include reinvested amounts.")
    with col2:
        st.metric("ðŸŽ Total Bonus Shares", f"{total_bonus_shares:,.0f}",
                  help="Total bonus shares received (share-based, not cash)")
    with col3:
        st.metric("ðŸ”„ Total Reinvested", fmt_money(total_reinvested_kwd, "KWD"),
                  help="Dividends reinvested into shares (already converted to shares)")
    with col4:
        st.metric("ðŸ“Š Dividend-Paying Stocks", f"{unique_stocks:,}")
    
    st.divider()
    
    # Tabs for different views
    tab1, tab2, tab3 = st.tabs(["ðŸ“‹ All Dividends", "ðŸ“Š Summary by Stock", "ðŸŽ Bonus Shares"])
    
    with tab1:
        st.subheader("All Dividend Transactions")
        
        # Delete functionality
        with st.expander("ðŸ—‘ï¸ Delete Dividend Record", expanded=False):
            st.warning("âš ï¸ Deleting a dividend record will permanently remove it from the database.")
            
            # Create options for deletion dropdown
            if not dividends_df.empty:
                delete_options = []
                for _, row in dividends_df.iterrows():
                    div_type = []
                    if row['cash_dividend'] > 0:
                        div_type.append(f"Cash: {row['cash_dividend']:.3f}")
                    if row['bonus_shares'] > 0:
                        div_type.append(f"Bonus: {row['bonus_shares']:.0f}")
                    if row['reinvested_dividend'] > 0:
                        div_type.append(f"Reinvested: {row['reinvested_dividend']:.3f}")
                    div_info = " | ".join(div_type) if div_type else "No dividend data"
                    source_label = "[Portfolio]" if row.get('source') == 'portfolio' else "[Trading]"
                    label = f"{source_label} {row['stock_symbol']} - {row['txn_date']} - {div_info}"
                    delete_options.append((row['id'], row.get('source', 'portfolio'), label))
                
                selected_delete = st.selectbox(
                    "Select dividend record to delete:",
                    options=delete_options,
                    format_func=lambda x: x[2],
                    key="div_delete_select"
                )
                
                col_del1, col_del2 = st.columns([1, 3])
                with col_del1:
                    if st.button("ðŸ—‘ï¸ Delete", type="primary", width="stretch"):
                        if selected_delete:
                            try:
                                record_id = selected_delete[0]
                                conn = get_conn()
                                cur = conn.cursor()
                                
                                # Check if it has shares (exclude soft-deleted if column exists)
                                _soft_del = _soft_delete_filter()
                                db_execute(cur, f"SELECT shares, purchase_cost, sell_value FROM transactions WHERE id = ? AND user_id = ?{_soft_del}", (record_id, user_id))
                                row = cur.fetchone()
                                    
                                if row and (row[0] > 0 or row[1] > 0 or row[2] > 0):
                                    # Has share data - only clear dividend fields
                                    db_execute(cur, """
                                        UPDATE transactions 
                                        SET cash_dividend = 0, bonus_shares = 0, reinvested_dividend = 0 
                                        WHERE id = ? AND user_id = ?
                                    """, (record_id, user_id))
                                    conn.commit()
                                    st.success("âœ… Dividend data cleared from transaction (shares preserved).")
                                else:
                                    # No share data - soft-delete entire record
                                    soft_delete_transaction(user_id, record_id)
                                    st.success("âœ… Dividend record deleted. Use 'Trash' to undo.")
                                
                                conn.close()
                                time.sleep(0.5)
                                st.rerun()
                            except Exception as e:
                                st.error(f"Error deleting: {e}")
                with col_del2:
                    st.caption("This will permanently remove the selected dividend record.")
            else:
                st.info("No dividend records to delete.")
        
        st.divider()
        
        # Display all dividends with date and source
        display_df = dividends_df.copy()
        display_df['Date'] = pd.to_datetime(display_df['txn_date']).dt.strftime('%Y-%m-%d')
        display_df['Source'] = display_df['source'].apply(lambda x: 'ðŸ“Š Portfolio' if x == 'portfolio' else 'ðŸ“ˆ Trading')
        display_df = display_df.rename(columns={
            'stock_symbol': 'Stock',
            'cash_dividend_kwd': 'Cash Dividend (KWD)',
            'bonus_shares': 'Bonus Shares',
            'reinvested_kwd': 'Reinvested (KWD)',
            'currency': 'CCY'
        })
        
        display_df = display_df[['Stock', 'Date', 'Cash Dividend (KWD)', 'Bonus Shares', 'Reinvested (KWD)', 'CCY', 'Source']]
        
        # Format numbers - no decimals for money values
        display_df['Cash Dividend (KWD)'] = display_df['Cash Dividend (KWD)'].apply(lambda x: fmt_money_plain(x, 0))
        display_df['Bonus Shares'] = display_df['Bonus Shares'].apply(lambda x: f"{x:,.0f}" if x > 0 else "-")
        display_df['Reinvested (KWD)'] = display_df['Reinvested (KWD)'].apply(lambda x: fmt_money_plain(x, 0) if x > 0 else "-")
        
        st.dataframe(display_df, width="stretch", hide_index=True)
        
        # Download button
        csv = display_df.to_csv(index=False)
        st.download_button(
            label="ðŸ“¥ Download as CSV",
            data=csv,
            file_name=f"all_dividends_{date.today()}.csv",
            mime="text/csv"
        )
    
    with tab2:
        st.subheader("Summary by Stock")
        
        # Group by stock - use KWD converted values for consistency
        summary = dividends_df.groupby('stock_symbol').agg({
            'cash_dividend_kwd': 'sum',
            'bonus_shares': 'sum',
            'reinvested_kwd': 'sum',
            'txn_date': 'count'
        }).reset_index()
        
        summary.columns = ['Stock', 'Total Cash Dividend', 'Total Bonus Shares', 'Total Reinvested', 'Dividend Count']
        
        # Merge with cost for yield calculation
        summary = summary.merge(cost_df, left_on='Stock', right_on='stock_symbol', how='left')
        summary['total_cost'] = summary['total_cost'].fillna(0)
        
        # Calculate yield on cost
        summary['Yield on Cost %'] = summary.apply(
            lambda row: (row['Total Cash Dividend'] / row['total_cost'] * 100) if row['total_cost'] > 0 else 0,
            axis=1
        )
        
        # Total Dividends Received = Cash Dividends only (NOT reinvested - that's already converted to shares)
        summary['Total Dividends Received'] = summary['Total Cash Dividend']
        
        # Format for display
        summary_display = summary[['Stock', 'Total Cash Dividend', 'Total Bonus Shares', 
                                   'Total Reinvested', 'Total Dividends Received', 'Dividend Count', 
                                   'Yield on Cost %']].copy()
        
        # Format the display columns - no decimals for money
        summary_display['Total Cash Dividend'] = summary_display['Total Cash Dividend'].apply(lambda x: f"{x:,.0f} KWD")
        summary_display['Total Bonus Shares'] = summary_display['Total Bonus Shares'].apply(lambda x: f"{x:,.0f}")
        summary_display['Total Reinvested'] = summary_display['Total Reinvested'].apply(lambda x: f"{x:,.0f} KWD")
        summary_display['Total Dividends Received'] = summary_display['Total Dividends Received'].apply(lambda x: f"{x:,.0f} KWD")
        summary_display['Dividend Count'] = summary_display['Dividend Count'].apply(lambda x: f"{x:,.0f}")
        summary_display['Yield on Cost %'] = summary_display['Yield on Cost %'].apply(lambda x: f"{x:.2f}%")
        
        st.caption("â„¹ï¸ **Total Dividends Received** = Cash dividends only. Does not include reinvested amounts (already converted to shares).")
        
        st.dataframe(
            summary_display,
            width="stretch",
            hide_index=True
        )
        
        # Download button
        csv = summary_display.to_csv(index=False)
        st.download_button(
            label="ðŸ“¥ Download Summary as CSV",
            data=csv,
            file_name=f"dividend_summary_{date.today()}.csv",
            mime="text/csv"
        )
    
    with tab3:
        st.subheader("Bonus Shares History")
        
        # Filter only bonus shares
        bonus_df = dividends_df[dividends_df['bonus_shares'] > 0].copy()
        
        if bonus_df.empty:
            st.info("ðŸ“Š No bonus shares received yet.")
        else:
            bonus_df['Date'] = pd.to_datetime(bonus_df['txn_date']).dt.strftime('%Y-%m-%d')
            bonus_display = bonus_df[['stock_symbol', 'Date', 'bonus_shares']].rename(columns={
                'stock_symbol': 'Stock',
                'bonus_shares': 'Bonus Shares Received'
            })
            
            bonus_display['Bonus Shares Received'] = bonus_display['Bonus Shares Received'].apply(lambda x: f"{x:,.0f}")
            
            st.dataframe(bonus_display, width="stretch", hide_index=True)
            
            # Summary by stock
            st.subheader("Total Bonus Shares by Stock")
            bonus_summary = bonus_df.groupby('stock_symbol')['bonus_shares'].sum().reset_index()
            bonus_summary.columns = ['Stock', 'Total Bonus Shares']
            bonus_summary['Total Bonus Shares'] = bonus_summary['Total Bonus Shares'].apply(lambda x: f"{x:,.0f}")
            
            st.dataframe(bonus_summary, width="stretch", hide_index=True)
            
            # Download button
            csv = bonus_display.to_csv(index=False)
            st.download_button(
                label="ðŸ“¥ Download Bonus Shares as CSV",
                data=csv,
                file_name=f"bonus_shares_{date.today()}.csv",
                mime="text/csv"
            )


def ui_trading_section():
    """Trading Section - Full view of ALL transactions from main transactions table.
    
    Key features:
    - NO data entry - all new transactions must use "Add Transactions" or other tabs
    - Queries from 'transactions' table (single source of truth)
    - Edits UPDATE the 'transactions' table directly
    - Shows ALL transaction types: Buy, Sell, Deposit, Withdrawal, Dividend, Bonus Shares, etc.
    """
    st.subheader("ðŸ“ˆ Trading Section - All Transactions")
    
    user_id = st.session_state.get('user_id', 1)
    
    # Add refresh button - recalculates avg costs, P&L, and refreshes all data
    col_refresh, col_spacer = st.columns([1, 5])
    with col_refresh:
        if st.button("ðŸ”„ Refresh & Recalculate", type="primary", help="Recalculate avg costs, P&L and refresh all transaction data"):
            with st.spinner("Recalculating avg costs and P&L for all transactions..."):
                stats = recalculate_and_store_avg_costs(user_id)
                # Clear all relevant caches
                build_portfolio_table.clear()
                st.cache_data.clear()  # Clear all cached data to ensure fresh reads
                
                if stats['errors']:
                    st.error(f"Errors during recalculation: {stats['errors'][:3]}")
                else:
                    st.success(f"âœ… Recalculated {stats['updated']} transactions across {stats['positions_processed']} positions")
                time.sleep(0.5)
            st.rerun()
    
    st.info("""
    **ðŸ“‹ This shows ALL your saved transactions.**
    
    â€¢ **Buy/Sell** trades, **Cash Deposits/Withdrawals**, **Dividends**, **Bonus Shares** - all in one view.
    â€¢ To add new transactions, use the **"Add Transactions"** or **"Cash Management"** tabs.
    â€¢ You can **edit** existing transactions here, which updates the main transaction record.
    â€¢ Portfolio positions and cash are calculated from the same data.
    """)
    
    # Query ALL transactions from the main transactions table (no date filter in query)
    conn = get_conn()
    
    # Query all transactions with current prices for P&L calculation
    # Include source column for filtering and display
    # Include stored avg_cost columns for accurate historical P&L
    query = """
        SELECT 
            t.id,
            t.stock_symbol AS symbol,
            t.txn_date AS date,
            COALESCE(t.portfolio, s.portfolio, 'KFH') AS portfolio,
            t.txn_type AS type,
            t.category,
            t.shares AS quantity,
            t.purchase_cost,
            t.sell_value,
            t.fees,
            t.cash_dividend AS dividend,
            t.bonus_shares,
            t.reinvested_dividend,
            t.notes,
            COALESCE(t.source, 'MANUAL') AS source,
            t.source_reference,
            COALESCE(s.current_price, 0) AS current_price,
            t.avg_cost_at_txn,
            t.realized_pnl_at_txn,
            t.cost_basis_at_txn,
            t.shares_held_at_txn
        FROM transactions t
        LEFT JOIN stocks s ON UPPER(t.stock_symbol) = UPPER(s.symbol) AND t.user_id = s.user_id
        WHERE t.user_id = ? 
        AND (t.is_deleted = 0 OR t.is_deleted IS NULL)
        ORDER BY t.txn_date DESC, t.id DESC
    """
    df = pd.read_sql_query(convert_sql_placeholders(query), conn, params=(user_id,))
    
    # Build a comprehensive price lookup from ALL stocks with prices > 0
    # This handles cases where transaction symbol doesn't exactly match stock symbol
    price_lookup_query = """
        SELECT UPPER(symbol) as symbol_upper, symbol, current_price
        FROM stocks
        WHERE user_id = ? AND current_price > 0
    """
    price_df = pd.read_sql_query(convert_sql_placeholders(price_lookup_query), conn, params=(user_id,))
    price_map = {row['symbol_upper']: row['current_price'] for _, row in price_df.iterrows()}
    
    # For rows with current_price = 0, try to find a matching price
    def lookup_price(row):
        if row['current_price'] > 0:
            return row['current_price']
        sym = str(row['symbol']).upper() if row['symbol'] else ''
        if not sym:
            return 0
        # Direct match
        if sym in price_map:
            return price_map[sym]
        # Try without .KW suffix
        if sym.endswith('.KW') and sym[:-3] in price_map:
            return price_map[sym[:-3]]
        # Try with .KW suffix
        if f"{sym}.KW" in price_map:
            return price_map[f"{sym}.KW"]
        # Try partial match (contains)
        for stock_sym, price in price_map.items():
            if sym in stock_sym or stock_sym in sym:
                return price
        return 0
    
    df['current_price'] = df.apply(lookup_price, axis=1)
    
    # ============================================================
    # CFA/IFRS-Compliant Cost Basis Calculation (Weighted Average Cost Method)
    # ============================================================
    # Process transactions chronologically to compute proper state per (symbol, portfolio):
    # - total_shares: Shares currently held
    # - total_cost: Remaining cost basis of held shares
    # - avg_cost: Weighted average cost per share
    # - realized_pnl: Cumulative realized P&L from sells
    # IMPORTANT: Avg cost is calculated PER PORTFOLIO - same stock in different
    #            portfolios will have independent avg cost calculations.
    # ============================================================
    
    # Get ALL transactions sorted chronologically (oldest first) for state calculation
    # Exclude soft-deleted records from cost basis calculation
    # Include portfolio column for per-portfolio avg cost calculation
    all_txn_query = """
        SELECT id, stock_symbol, COALESCE(portfolio, 'KFH') as portfolio, txn_type, txn_date, 
               COALESCE(shares, 0) as shares,
               COALESCE(purchase_cost, 0) as purchase_cost,
               COALESCE(sell_value, 0) as sell_value,
               COALESCE(fees, 0) as fees,
               COALESCE(bonus_shares, 0) as bonus_shares,
               COALESCE(cash_dividend, 0) as cash_dividend,
               COALESCE(reinvested_dividend, 0) as reinvested_dividend
        FROM transactions
        WHERE user_id = ?
        AND (is_deleted = 0 OR is_deleted IS NULL)
        ORDER BY txn_date ASC, id ASC
    """
    all_txn_df = pd.read_sql_query(convert_sql_placeholders(all_txn_query), conn, params=(user_id,))
    
    # Build state per (symbol, portfolio) by processing chronologically
    # Key is tuple (symbol, portfolio) for independent avg cost per portfolio
    position_state = {}  # (symbol, portfolio) -> {total_shares, total_cost, avg_cost, ...}
    txn_state = {}       # txn_id -> {avg_cost_at_time, realized_pnl_increment}
    
    for _, txn in all_txn_df.iterrows():
        sym = txn['stock_symbol']
        port = txn['portfolio']
        position_key = (sym, port)  # Key by both symbol AND portfolio
        txn_id = txn['id']
        txn_type = txn['txn_type']
        
        # Initialize state if new (symbol, portfolio) combination
        if position_key not in position_state:
            position_state[position_key] = {
                'total_shares': 0.0,
                'total_cost': 0.0,
                'avg_cost': 0.0,
                'realized_pnl': 0.0,
                'dividends_received': 0.0,
                'position_open': False  # Will be set True on first Buy
            }
        
        state = position_state[position_key]
        
        if txn_type == 'Buy':
            # BUY: Add cost + shares (fees increase cost basis)
            buy_shares = float(txn['shares'])
            buy_cost = float(txn['purchase_cost'])  # Already includes price Ã— shares
            fees = float(txn['fees'])
            
            new_cost = buy_cost + fees  # Total cost of this purchase
            state['total_cost'] += new_cost
            state['total_shares'] += buy_shares
            state['avg_cost'] = state['total_cost'] / state['total_shares'] if state['total_shares'] > 0 else 0
            state['position_open'] = True  # Position is open
            
            txn_state[txn_id] = {'avg_cost_at_time': state['avg_cost'], 'realized_pnl': 0}
        
        elif txn_type == 'Sell':
            # SELL: Weighted Average Cost Method
            sell_shares = float(txn['shares'])
            sell_value = float(txn['sell_value'])
            fees = float(txn['fees'])
            
            # Compute proceeds and cost of goods sold
            proceeds = sell_value - fees
            cost_of_shares_sold = sell_shares * state['avg_cost']
            
            # Realized P&L increment
            realized_pnl_increment = proceeds - cost_of_shares_sold
            state['realized_pnl'] += realized_pnl_increment
            
            # Reduce state proportionally
            state['total_cost'] -= cost_of_shares_sold
            state['total_shares'] -= sell_shares
            
            # Recalculate avg_cost (should stay same under WAC, but recalc for safety)
            # CRITICAL: Position closure state management
            if state['total_shares'] > 0:
                state['avg_cost'] = state['total_cost'] / state['total_shares']
                state['position_open'] = True
            else:
                # Position fully closed - reset all state except realized_pnl
                state['avg_cost'] = 0
                state['total_cost'] = 0
                state['total_shares'] = 0
                state['position_open'] = False  # Mark as closed
            
            txn_state[txn_id] = {'avg_cost_at_time': state['avg_cost'], 'realized_pnl': realized_pnl_increment}
        
        elif txn_type in ('Bonus Shares', 'Bonus'):
            # BONUS: 0-cost stock dividends - shares increase, cost unchanged
            bonus = float(txn['bonus_shares']) if txn['bonus_shares'] else float(txn['shares'])
            state['total_shares'] += bonus
            state['avg_cost'] = state['total_cost'] / state['total_shares'] if state['total_shares'] > 0 else 0
            state['position_open'] = state['total_shares'] > 0  # Position open if shares > 0
            
            txn_state[txn_id] = {'avg_cost_at_time': state['avg_cost'], 'realized_pnl': 0}
        
        elif txn_type in ('DIVIDEND_ONLY', 'Dividend'):
            # CASH DIVIDEND: Income, does NOT affect cost basis
            dividend_amount = float(txn['cash_dividend']) if txn['cash_dividend'] else 0
            state['dividends_received'] += dividend_amount
            
            # CHECK FOR BONUS SHARES attached to dividend transaction
            # Some dividends include stock dividends (bonus shares) - these dilute avg cost
            bonus_in_dividend = float(txn['bonus_shares']) if txn['bonus_shares'] and float(txn['bonus_shares']) > 0 else 0
            if bonus_in_dividend > 0:
                state['total_shares'] += bonus_in_dividend
                # Recalculate avg_cost after adding bonus shares (cost unchanged, shares increased)
                state['avg_cost'] = state['total_cost'] / state['total_shares'] if state['total_shares'] > 0 else 0
                state['position_open'] = state['total_shares'] > 0
            
            txn_state[txn_id] = {'avg_cost_at_time': state['avg_cost'], 'realized_pnl': 0, 'dividend': dividend_amount}
        
        else:
            # Other types (Deposit, Withdrawal, etc.) - no effect on stock state
            txn_state[txn_id] = {'avg_cost_at_time': state['avg_cost'], 'realized_pnl': 0}
    
    # ============================================================
    # AVG COST ASSIGNMENT - Use stored values when available
    # ============================================================
    # Priority: 1) Stored avg_cost_at_txn (accurate historical record)
    #           2) Runtime calculated (fallback for old data)
    # CRITICAL: For closed positions, we STILL show the avg_cost from stored value
    #           This allows accurate P&L display even after position is closed
    # IMPORTANT: Uses (symbol, portfolio) key for per-portfolio avg cost
    # ============================================================
    
    def get_avg_cost_for_row(row):
        """Get avg_cost: prefer stored value, fallback to runtime calculation."""
        # First check if we have a stored avg_cost_at_txn
        stored_avg = row.get('avg_cost_at_txn')
        if stored_avg is not None and pd.notna(stored_avg) and stored_avg > 0:
            return float(stored_avg)
        
        # Fallback to runtime calculation using (symbol, portfolio) key
        sym = row.get('symbol', '')
        port = row.get('portfolio', 'KFH')
        position_key = (sym, port)
        
        if position_key in position_state:
            # For open positions, use current state
            if position_state[position_key].get('position_open', False):
                return position_state[position_key]['avg_cost']
            # For closed positions without stored value, return 0
            return 0
        return 0
    
    df['avg_cost'] = df.apply(get_avg_cost_for_row, axis=1)
    
    # Also get stored realized_pnl for sell transactions
    def get_realized_pnl_for_row(row):
        """Get realized P&L: prefer stored value, fallback to txn_state."""
        if row.get('type') != 'Sell':
            return 0
        # Check stored value first
        stored_pnl = row.get('realized_pnl_at_txn')
        if stored_pnl is not None and pd.notna(stored_pnl):
            return float(stored_pnl)
        # Fallback to runtime calculation
        txn_id = row.get('id')
        if txn_id in txn_state:
            return txn_state[txn_id].get('realized_pnl', 0)
        return 0
    
    df['stored_realized_pnl'] = df.apply(get_realized_pnl_for_row, axis=1)
    
    conn.close()
    
    if df.empty:
        st.warning("No transactions found. Use **Add Transactions** or **Cash Management** tabs to record transactions.")
        return
    
    # Ensure date column is properly parsed and sorted newest to oldest
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df = df.sort_values(by=['date', 'id'], ascending=[False, False]).reset_index(drop=True)
    
    # Calculate derived columns
    df['price'] = df.apply(lambda r: 
        r['purchase_cost'] / r['quantity'] if r['type'] == 'Buy' and r['quantity'] and r['quantity'] > 0 else
        r['sell_value'] / r['quantity'] if r['type'] == 'Sell' and r['quantity'] and r['quantity'] > 0 else 0, 
        axis=1
    )
    # Sell price per share (for Sell transactions only)
    df['sell_price'] = df.apply(lambda r: 
        r['sell_value'] / r['quantity'] if r['type'] == 'Sell' and r['quantity'] and r['quantity'] > 0 else 0, 
        axis=1
    )
    df['value'] = df.apply(lambda r: 
        r['purchase_cost'] if r['type'] == 'Buy' else 
        r['sell_value'] if r['type'] in ('Sell', 'Withdrawal') else
        r['dividend'] if r['type'] in ('DIVIDEND_ONLY', 'Dividend') else
        (r['purchase_cost'] + r['sell_value']) if r['type'] == 'Deposit' or r.get('category') == 'FLOW_IN' else 0, 
        axis=1
    )
    # Status column: Realized for Sell, Unrealized for Buy, Income for Dividend, blank for others
    def get_status(row):
        t = row['type']
        sym = row.get('symbol', '')
        port = row.get('portfolio', 'KFH')
        position_key = (sym, port)
        if t == 'Sell':
            return 'Realized'
        elif t == 'Buy':
            # Check if position is closed (per portfolio)
            if position_key in position_state and not position_state[position_key].get('position_open', False):
                return 'Closed'  # Position fully exited
            return 'Unrealized'
        elif t in ('DIVIDEND_ONLY', 'Dividend'):
            return 'Income'
        elif t in ('Bonus Shares', 'Bonus'):
            return 'Bonus'
        else:
            return ''
    df['status'] = df.apply(get_status, axis=1)
    
    # ============================================================
    # CFA/IFRS-Compliant P&L Calculation
    # ============================================================
    # - Buy (Unrealized): (Current Price - Avg Cost) Ã— Shares
    # - Sell (Realized): Use stored realized_pnl_at_txn OR calculate
    # - Dividend (Income): Cash received (no cost basis impact)
    # - Bonus: No P&L (just dilutes avg cost)
    # CRITICAL: For sells, we use stored avg_cost_at_txn to ensure accuracy
    #           even after the position is fully closed
    # ============================================================
    
    def calc_pnl(row):
        txn_type = row.get('type', '')
        txn_id = row.get('id')
        qty = float(row.get('quantity', 0) or 0)
        sym = row.get('symbol', '')
        port = row.get('portfolio', 'KFH')
        position_key = (sym, port)
        
        if txn_type == 'Buy':
            # CFA/IFRS Rule: Unrealized P&L only calculated for OPEN positions
            # If position is closed (total_shares = 0), unrealized P&L = 0
            if position_key in position_state and not position_state[position_key].get('position_open', False):
                return 0  # Position closed - no unrealized P&L
            
            # Unrealized P&L: (Current Price - Avg Cost) Ã— Shares held from this lot
            current_price = float(row.get('current_price', 0) or 0)
            avg_cost = float(row.get('avg_cost', 0) or 0)
            if current_price > 0 and qty > 0 and avg_cost > 0:
                return (current_price - avg_cost) * qty
            elif current_price > 0 and qty > 0:
                # Fallback: use purchase cost
                purchase_cost = float(row.get('purchase_cost', 0) or 0)
                if purchase_cost > 0:
                    cost_per_share = purchase_cost / qty
                    return (current_price - cost_per_share) * qty
            return 0
        
        elif txn_type == 'Sell':
            # PRIORITY 1: Use stored realized_pnl_at_txn (most accurate)
            stored_pnl = row.get('stored_realized_pnl', 0)
            if stored_pnl != 0:
                return stored_pnl
            
            # PRIORITY 2: Use runtime calculated txn_state
            if txn_id in txn_state:
                return txn_state[txn_id].get('realized_pnl', 0)
            
            # PRIORITY 3: Fallback calculation using stored avg_cost
            sell_value = float(row.get('sell_value', 0) or 0)
            avg_cost = float(row.get('avg_cost', 0) or 0)
            fees = float(row.get('fees', 0) or 0)
            if qty > 0 and avg_cost > 0:
                proceeds = sell_value - fees
                cost_basis = avg_cost * qty
                return proceeds - cost_basis
            return 0
        
        elif txn_type in ('DIVIDEND_ONLY', 'Dividend'):
            # Dividend income - pure income, not P&L on investment
            return float(row.get('dividend', 0) or 0)
        
        elif txn_type in ('Bonus Shares', 'Bonus'):
            # Bonus shares have no direct P&L (they dilute avg cost)
            return 0
        
        else:
            return 0
    
    def calc_pnl_pct(row):
        txn_type = row.get('type', '')
        pnl = row.get('pnl', 0)
        qty = float(row.get('quantity', 0) or 0)
        avg_cost = float(row.get('avg_cost', 0) or 0)
        sym = row.get('symbol', '')
        port = row.get('portfolio', 'KFH')
        position_key = (sym, port)
        
        if txn_type == 'Buy':
            # CFA/IFRS Rule: No unrealized return % for closed positions
            if position_key in position_state and not position_state[position_key].get('position_open', False):
                return 0  # Position closed - no unrealized P&L %
            
            # Unrealized return %: P&L / Cost Basis
            if avg_cost > 0 and qty > 0:
                cost_basis = avg_cost * qty
                return (pnl / cost_basis) * 100
            # Fallback
            purchase_cost = float(row.get('purchase_cost', 0) or 0)
            if purchase_cost > 0:
                return (pnl / purchase_cost) * 100
            return 0
        
        elif txn_type == 'Sell':
            avg_cost = float(row.get('avg_cost', 0) or 0)
            qty = float(row.get('quantity', 0) or 0)
            if avg_cost > 0 and qty > 0:
                cost_basis = avg_cost * qty
                return (pnl / cost_basis) * 100
            return 0
        
        elif txn_type in ('DIVIDEND_ONLY', 'Dividend'):
            # Dividend yield can be calculated if we have cost basis
            return 0  # Would need investment base
        
        else:
            return 0
    
    df['pnl'] = df.apply(calc_pnl, axis=1)
    df['pnl_pct'] = df.apply(calc_pnl_pct, axis=1)
    
    # ============================================================
    # Summary Metrics (CFA/IFRS Compliant)
    # ============================================================
    st.divider()
    buy_df = df[df['type'] == 'Buy']
    sell_df = df[df['type'] == 'Sell']
    
    # ============================================================
    # DEPOSIT SOURCE-OF-TRUTH: Use cash_deposits table (not transactions)
    # ============================================================
    # cash_deposits is the authoritative source for all cash deposits.
    # This ensures consistency with Portfolio Analysis and avoids
    # duplicate counting between transactions and cash_deposits tables.
    # ============================================================
    cash_deposits_df = query_df("""
        SELECT id, deposit_date as date, amount, currency, portfolio, 'DEPOSIT' as type
        FROM cash_deposits 
        WHERE user_id = ? AND include_in_analysis = 1
    """, (user_id,))
    
    # Convert to KWD for consistent totals
    if not cash_deposits_df.empty:
        cash_deposits_df['amount_kwd'] = cash_deposits_df.apply(
            lambda r: convert_to_kwd(float(r['amount']), r.get('currency', 'KWD') or 'KWD'), axis=1
        )
        total_deposits = cash_deposits_df['amount_kwd'].sum()
        deposit_count = len(cash_deposits_df)
    else:
        total_deposits = 0
        deposit_count = 0
    
    # Withdrawals still come from transactions (category=FLOW_OUT or txn_type=Withdrawal)
    withdrawal_df = df[(df['type'] == 'Withdrawal') | (df['category'] == 'FLOW_OUT')]
    dividend_df = df[df['type'].isin(['DIVIDEND_ONLY', 'Dividend'])]
    bonus_df = df[df['type'].isin(['Bonus Shares', 'Bonus'])]
    
    total_buys = buy_df['purchase_cost'].fillna(0).sum() if not buy_df.empty else 0
    total_sells = sell_df['sell_value'].fillna(0).sum() if not sell_df.empty else 0
    total_withdrawals = withdrawal_df['sell_value'].fillna(0).sum() if not withdrawal_df.empty else 0
    total_fees = df['fees'].fillna(0).sum() if 'fees' in df.columns else 0
    
    # ============================================================
    # CFA-COMPLIANT SUMMARY METRICS - USE STORED DB VALUES
    # Priority: Stored values > Runtime calculation (fallback)
    # ============================================================
    
    # 1. REALIZED P&L - sum of all stored realized_pnl_at_txn (sell transactions)
    if 'stored_realized_pnl' in df.columns and df['stored_realized_pnl'].notna().any():
        total_realized_pnl = df['stored_realized_pnl'].fillna(0).sum()
    else:
        total_realized_pnl = sum(s['realized_pnl'] for s in position_state.values())
    
    # 2. DIVIDENDS - sum directly from cash_dividend column in transactions
    if 'dividend' in df.columns:
        total_dividends_received = df['dividend'].fillna(0).sum()
    else:
        total_dividends_received = sum(s['dividends_received'] for s in position_state.values())
    
    # 3. CURRENT SHARES - use stored shares_held_at_txn from LATEST transaction per position
    # df is sorted by date DESC, so .first() gives latest transaction per (symbol, portfolio)
    if 'shares_held_at_txn' in df.columns and df['shares_held_at_txn'].notna().any():
        latest_per_position = df.groupby(['symbol', 'portfolio']).first()
        total_current_shares = latest_per_position['shares_held_at_txn'].fillna(0).sum()
    else:
        total_current_shares = sum(s['total_shares'] for s in position_state.values())
    
    # 4. CURRENT COST BASIS - use stored cost_basis_at_txn from LATEST transaction per position
    if 'cost_basis_at_txn' in df.columns and df['cost_basis_at_txn'].notna().any():
        latest_per_position = df.groupby(['symbol', 'portfolio']).first()
        total_current_cost = latest_per_position['cost_basis_at_txn'].fillna(0).sum()
    else:
        total_current_cost = sum(s['total_cost'] for s in position_state.values())
    
    # 5. UNREALIZED P&L - calculated from OPEN positions (current market value - cost basis)
    # Uses stored cost_basis_at_txn where available, falls back to position_state
    total_unrealized_pnl = 0
    if 'shares_held_at_txn' in df.columns and df['shares_held_at_txn'].notna().any():
        # Use stored values - get latest state per position
        latest_per_position = df.groupby(['symbol', 'portfolio']).first().reset_index()
        for _, row in latest_per_position.iterrows():
            shares = row.get('shares_held_at_txn', 0) or 0
            cost_basis = row.get('cost_basis_at_txn', 0) or 0
            current_price = row.get('current_price', 0) or 0
            if shares > 0 and current_price > 0:
                market_value = current_price * shares
                total_unrealized_pnl += (market_value - cost_basis)
    else:
        # Fallback to runtime position_state
        for (sym, port), state in position_state.items():
            if state.get('position_open', False) and state['total_shares'] > 0:
                sym_prices = df[(df['symbol'] == sym) & (df['portfolio'] == port)]['current_price'].dropna()
                if len(sym_prices) == 0:
                    sym_prices = df[df['symbol'] == sym]['current_price'].dropna()
                current_price = sym_prices.iloc[0] if len(sym_prices) > 0 else 0
                if current_price > 0:
                    market_value = current_price * state['total_shares']
                    cost_basis = state['total_cost']
                    total_unrealized_pnl += (market_value - cost_basis)
    
    # ============================================================
    # DIVIDEND DOUBLE-COUNTING PREVENTION (CFA/IFRS Compliant)
    # ============================================================
    # Total P&L = Capital Gains ONLY (Unrealized + Realized)
    # Dividends are tracked SEPARATELY to avoid double-counting:
    #   - Cash dividends: Reported as income (NOT in P&L)
    #   - Reinvested dividends: Already reflected in share count
    #   - Bonus shares: Already reflected in share count (cost basis adjusted)
    # 
    # Total Return = P&L + Cash Dividends (for investors who want full picture)
    # ============================================================
    total_pnl = total_unrealized_pnl + total_realized_pnl  # Capital gains ONLY
    total_return = total_pnl + total_dividends_received  # Total return including cash dividend income
    
    # Summary row 1: Trade activity
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("ðŸ›’ Total Buys", f"{total_buys:,.0f}", f"{len(buy_df)} txns")
    k2.metric("ðŸ’° Total Sells", f"{total_sells:,.0f}", f"{len(sell_df)} txns")
    k3.metric("ðŸ“¥ Deposits", f"{total_deposits:,.0f}", f"{deposit_count} deposits",
              help="Source: Cash Deposits table (single source of truth)")
    k4.metric("ðŸ“¤ Withdrawals", f"{total_withdrawals:,.0f}", f"{len(withdrawal_df)} txns")
    
    # Summary row 2: P&L metrics (CFA compliant)
    k5, k6, k7, k8 = st.columns(4)
    k5.metric("ðŸ“ˆ Unrealized P&L", f"{total_unrealized_pnl:+,.2f}", "Open positions",
              help="Market value minus cost basis for positions still held")
    k6.metric("ðŸ“Š Realized P&L", f"{total_realized_pnl:+,.2f}", "Closed positions",
              help="Profit/loss from shares sold (FIFO method)")
    k7.metric("ðŸ’µ Total P&L", f"{total_pnl:+,.2f}", "Capital gains",
              delta_color="normal" if total_pnl >= 0 else "inverse",
              help="Capital gains only. Does NOT include dividends to avoid double-counting with reinvested amounts.")
    k8.metric("ðŸ“ Total Txns", f"{len(df):,}")
    
    # Summary row 3: Other metrics
    k9, k10, k11, k12 = st.columns(4)
    k9.metric("ðŸ’µ Cash Dividends", f"{total_dividends_received:,.2f}", f"{len(dividend_df)} txns",
              help="Cash dividends ONLY. Reinvested dividends are reflected in share count, not cash income.")
    k10.metric("ðŸ“Š Fees", f"{total_fees:,.2f}")
    net_cash_flow = total_sells + total_deposits + total_dividends_received - total_buys - total_withdrawals - total_fees
    k11.metric("ðŸ’µ Net Cash Flow", f"{net_cash_flow:+,.0f}", 
              delta_color="normal" if net_cash_flow >= 0 else "inverse")
    if total_buys > 0:
        total_return_pct = (total_return / total_buys) * 100
        k12.metric("ðŸ“ˆ Total Return %", f"{total_return_pct:+.2f}%", "Incl. dividends",
                   help="P&L + Cash Dividends / Total Invested. Includes cash dividend income but NOT reinvested (already in shares).")
    else:
        k12.metric("ðŸ“ˆ Total Return %", "N/A")
    
    st.divider()
    
    # === FILTERS SECTION ===
    st.markdown("**Filters:**")
    
    # Date range filter
    col1, col2, col3, col4, col5 = st.columns([2, 2, 1, 1, 1])
    with col1:
        start_date = st.date_input("From Date", value=date(2024, 1, 1), key="trading_start")
    with col2:
        end_date = st.date_input("To Date", value=date.today(), key="trading_end")
    with col3:
        st.write("")
        st.write("")
        apply_date_filter = st.button("ðŸ” Apply Date", key="trading_filter_btn")
    with col4:
        st.write("")
        st.write("")
        clear_filters = st.button("ðŸ—‘ï¸ Clear", key="trading_clear_btn")
    with col5:
        st.write("")
        st.write("")
        refresh_btn = st.button("ðŸ”„ Refresh", key="trading_refresh")
    
    # Handle Refresh button
    if refresh_btn:
        build_portfolio_table.clear()
        st.rerun()
    
    # Track date filter state and clear all filters
    if clear_filters:
        st.session_state['trading_date_filter'] = False
        st.session_state['trading_search'] = ''  # Clear search box
        # Clear type filter checkboxes by forcing a rerun with cleared state
        for txn_type in ["Buy", "Sell", "Deposit", "Withdrawal", "DIVIDEND_ONLY", "Dividend", "Bonus Shares"]:
            st.session_state[f"trading_filter_{txn_type}"] = False
        # Clear source filter checkboxes
        for src_type in ["MANUAL", "UPLOAD", "RESTORE", "API", "LEGACY"]:
            st.session_state[f"trading_filter_source_{src_type}"] = False
        st.rerun()
    
    if apply_date_filter:
        st.session_state['trading_date_filter'] = True
        st.session_state['trading_start_date'] = start_date
        st.session_state['trading_end_date'] = end_date
    
    # Transaction Type Filter - Checkboxes for each type
    st.markdown("**Filter by Type:**")
    all_types = ["Buy", "Sell", "Deposit", "Withdrawal", "DIVIDEND_ONLY", "Dividend", "Bonus Shares"]
    
    # Create checkboxes in columns - use session state for values
    cols = st.columns(len(all_types))
    selected_types = []
    for i, txn_type in enumerate(all_types):
        default_val = st.session_state.get(f"trading_filter_{txn_type}", False)
        if cols[i].checkbox(txn_type, value=default_val, key=f"trading_filter_{txn_type}"):
            selected_types.append(txn_type)
    
    # Source Filter - Filter by how the transaction was entered
    st.markdown("**Filter by Source:**")
    source_types = ["MANUAL", "UPLOAD", "RESTORE", "API", "LEGACY"]
    source_cols = st.columns(len(source_types))
    selected_sources = []
    for i, src_type in enumerate(source_types):
        default_val = st.session_state.get(f"trading_filter_source_{src_type}", False)
        if source_cols[i].checkbox(src_type, value=default_val, key=f"trading_filter_source_{src_type}"):
            selected_sources.append(src_type)
    
    # Smart Search Filter
    st.markdown("**ðŸ” Search:**")
    search_query = st.text_input(
        "Search transactions", 
        placeholder="Type to search... (symbol, notes, portfolio, amount, etc.)",
        key="trading_search",
        label_visibility="collapsed"
    )
    
    # Apply filters to display data
    display_data = df.copy()
    
    # Apply smart search filter
    if search_query and search_query.strip():
        query = search_query.strip().lower()
        
        # Create a searchable text column combining multiple fields
        def create_searchable_text(row):
            searchable_parts = []
            # Add symbol
            if pd.notna(row.get('symbol')):
                searchable_parts.append(str(row['symbol']).lower())
            # Add portfolio
            if pd.notna(row.get('portfolio')):
                searchable_parts.append(str(row['portfolio']).lower())
            # Add type
            if pd.notna(row.get('type')):
                searchable_parts.append(str(row['type']).lower())
            # Add category
            if pd.notna(row.get('category')):
                searchable_parts.append(str(row['category']).lower())
            # Add notes
            if pd.notna(row.get('notes')):
                searchable_parts.append(str(row['notes']).lower())
            # Add source for filtering by upload/manual
            if pd.notna(row.get('source')):
                searchable_parts.append(str(row['source']).lower())
            # Add amounts as strings for searching
            if pd.notna(row.get('quantity')) and row['quantity'] != 0:
                searchable_parts.append(str(int(row['quantity'])))
            if pd.notna(row.get('purchase_cost')) and row['purchase_cost'] != 0:
                searchable_parts.append(str(row['purchase_cost']))
            if pd.notna(row.get('sell_value')) and row['sell_value'] != 0:
                searchable_parts.append(str(row['sell_value']))
            if pd.notna(row.get('dividend')) and row['dividend'] != 0:
                searchable_parts.append(str(row['dividend']))
            # Add date as string
            if pd.notna(row.get('date')):
                searchable_parts.append(str(row['date']).lower())
            return ' '.join(searchable_parts)
        
        display_data['_searchable'] = display_data.apply(create_searchable_text, axis=1)
        
        # Smart search: split query into words and match all of them (AND logic)
        query_words = query.split()
        for word in query_words:
            display_data = display_data[display_data['_searchable'].str.contains(word, case=False, na=False)]
        
        # Drop the temporary searchable column
        display_data = display_data.drop(columns=['_searchable'])
        
        st.caption(f"ðŸ” Found {len(display_data)} transactions matching '{search_query}'")
    
    # Apply date filter if active
    if st.session_state.get('trading_date_filter', False):
        filter_start = st.session_state.get('trading_start_date', start_date)
        filter_end = st.session_state.get('trading_end_date', end_date)
        display_data = display_data[(display_data['date'].dt.date >= filter_start) & (display_data['date'].dt.date <= filter_end)]
        st.caption(f"ðŸ“… Showing transactions from {filter_start} to {filter_end}")
    
    # Apply type filter if any checkboxes selected
    if selected_types:
        display_data = display_data[display_data['type'].isin(selected_types)]
    
    # Apply source filter if any checkboxes selected
    if selected_sources:
        display_data = display_data[display_data['source'].isin(selected_sources)]
    
    # View/Edit mode toggle
    view_mode = st.radio("", ["ðŸ“Š View", "âœï¸ Edit"], horizontal=True, label_visibility="collapsed", key="trading_view_mode")
    
    if view_mode == "ðŸ“Š View":
        # Display table (read-only) with all relevant columns including P&L and Source
        display_df = display_data[['id', 'date', 'symbol', 'portfolio', 'type', 'status', 'source', 'quantity', 'avg_cost', 'price', 'current_price', 'sell_price', 'value', 'pnl', 'pnl_pct', 'fees', 'dividend', 'bonus_shares', 'notes']].copy()
        
        # Current price only for Unrealized (Buy) transactions
        display_df['current_price'] = display_df.apply(
            lambda r: r['current_price'] if r['status'] == 'Unrealized' else 0, axis=1
        )
        
        # Add source badge with emoji for visual distinction
        def format_source_badge(src):
            badges = {
                'MANUAL': 'âœï¸ Manual',
                'UPLOAD': 'ðŸ“¤ Upload',
                'RESTORE': 'ðŸ”„ Restore',
                'API': 'ðŸ”Œ API',
                'LEGACY': 'ðŸ“œ Legacy',
                None: 'âœï¸ Manual'
            }
            return badges.get(src, f'ðŸ“‹ {src}')
        
        display_df['source'] = display_df['source'].apply(format_source_badge)
        
        # Rename columns for clarity
        display_df = display_df.rename(columns={
            'dividend': 'Cash Dividend',
            'bonus_shares': 'Bonus Shares',
            'pnl': 'P&L',
            'pnl_pct': 'P&L %',
            'avg_cost': 'Avg Cost',
            'sell_price': 'Sell Price',
            'current_price': 'Current Price',
            'source': 'Source'
        })
        
        # Format date to show only date (no time)
        display_df['date'] = display_df['date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notna(x) else "")
        
        # Format for display
        display_df['quantity'] = display_df['quantity'].apply(lambda x: f"{x:,.0f}" if pd.notna(x) and x != 0 else "")
        display_df['price'] = display_df['price'].apply(lambda x: f"{x:.3f}" if pd.notna(x) and x > 0 else "")
        display_df['value'] = display_df['value'].apply(lambda x: f"{x:,.2f}" if pd.notna(x) and x != 0 else "")
        display_df['P&L'] = display_df['P&L'].apply(lambda x: f"{x:+,.2f}" if pd.notna(x) and x != 0 else "")
        display_df['P&L %'] = display_df['P&L %'].apply(lambda x: f"{x:+.2f}%" if pd.notna(x) and x != 0 else "")
        display_df['Avg Cost'] = display_df['Avg Cost'].apply(lambda x: f"{x:.3f}" if pd.notna(x) and x > 0 else "")
        display_df['Current Price'] = display_df['Current Price'].apply(lambda x: f"{x:.3f}" if pd.notna(x) and x > 0 else "")
        display_df['Sell Price'] = display_df['Sell Price'].apply(lambda x: f"{x:.3f}" if pd.notna(x) and x > 0 else "")
        display_df['fees'] = display_df['fees'].apply(lambda x: f"{x:.2f}" if pd.notna(x) and x > 0 else "")
        display_df['Cash Dividend'] = display_df['Cash Dividend'].apply(lambda x: f"{x:.2f}" if pd.notna(x) and x > 0 else "")
        display_df['Bonus Shares'] = display_df['Bonus Shares'].apply(lambda x: f"{x:.0f}" if pd.notna(x) and x > 0 else "")
        
        st.dataframe(display_df, hide_index=True, use_container_width=True)
        st.caption("Switch to **Edit** mode to modify transactions.")
        
    else:
        # Editable table with delete functionality
        st.warning("âš ï¸ Editing here updates the main transactions table. Changes affect portfolio positions and cash.")
        
        # Initialize session state for delete confirmation
        if 'trading_delete_pending' not in st.session_state:
            st.session_state['trading_delete_pending'] = False
            st.session_state['trading_delete_ids'] = []
        
        # Add a 'select' column for deletion
        edit_df = display_data[['id', 'date', 'symbol', 'portfolio', 'type', 'quantity', 'price', 'fees', 'notes']].copy()
        edit_df.insert(0, 'select', False)  # Add checkbox column at the beginning
        
        # All possible transaction types
        all_txn_types = ["Buy", "Sell", "Deposit", "Withdrawal", "DIVIDEND_ONLY", "Dividend"]
        
        column_config = {
            "select": st.column_config.CheckboxColumn("ðŸ—‘ï¸", default=False, help="Select to delete"),
            "id": st.column_config.NumberColumn("ID", disabled=True, width="small"),
            "date": st.column_config.DateColumn("Date", format="YYYY-MM-DD"),
            "symbol": st.column_config.TextColumn("Symbol"),
            "portfolio": st.column_config.SelectboxColumn("Portfolio", options=["KFH", "BBYN", "USA"]),
            "type": st.column_config.SelectboxColumn("Type", options=all_txn_types, disabled=True),
            "quantity": st.column_config.NumberColumn("Qty", min_value=0, format="%.0f"),
            "price": st.column_config.NumberColumn("Price", min_value=0, format="%.3f"),
            "fees": st.column_config.NumberColumn("Fees", min_value=0, format="%.3f"),
            "notes": st.column_config.TextColumn("Notes"),
        }
        
        edited_df = st.data_editor(
            edit_df,
            column_config=column_config,
            hide_index=True,
            use_container_width=True,
            num_rows="fixed",
            key="trading_editor"
        )
        
        # Buttons row
        btn_col1, btn_col2, btn_col3 = st.columns([1, 1, 6])
        
        with btn_col1:
            save_btn = st.button("ðŸ’¾ Save Changes", type="primary", key="trading_save_btn")
        
        with btn_col2:
            # Count selected rows (convert to native Python int to avoid numpy type issues)
            selected_count = int(edited_df['select'].sum()) if 'select' in edited_df.columns else 0
            delete_btn = st.button(
                f"ðŸ—‘ï¸ Delete ({selected_count})", 
                type="secondary", 
                disabled=(selected_count == 0),
                key="trading_delete_btn"
            )
        
        # Handle Delete - Stage 1: Set pending state
        if delete_btn and selected_count > 0:
            selected_ids = edited_df[edited_df['select'] == True]['id'].tolist()
            st.session_state['trading_delete_pending'] = True
            st.session_state['trading_delete_ids'] = [int(i) for i in selected_ids]
            st.rerun()
        
        # Handle Delete - Stage 2: Confirmation dialog (persisted via session state)
        if st.session_state.get('trading_delete_pending', False):
            pending_ids = st.session_state.get('trading_delete_ids', [])
            if pending_ids:
                st.error(f"âš ï¸ **CONFIRM DELETE:** You are about to permanently delete {len(pending_ids)} transaction(s). This cannot be undone!")
                
                confirm_col1, confirm_col2, _ = st.columns([1, 1, 6])
                with confirm_col1:
                    if st.button("âœ… Yes, Delete", type="primary", key="confirm_delete_btn"):
                        try:
                            deleted_count = 0
                            for txn_id in pending_ids:
                                # Soft-delete instead of hard delete
                                soft_delete_transaction(user_id, int(txn_id))
                                deleted_count += 1
                            
                            # Clear pending state
                            st.session_state['trading_delete_pending'] = False
                            st.session_state['trading_delete_ids'] = []
                            
                            st.success(f"âœ… Deleted {deleted_count} transaction(s). Use 'Trash' to undo.")
                            # Recalculate avg costs and realized P&L after deletion
                            recalculate_and_store_avg_costs(user_id)
                            # Recalculate cash after deletion
                            recalc_portfolio_cash(user_id)
                            build_portfolio_table.clear()
                            time.sleep(0.5)
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"Error deleting: {e}")
                            st.session_state['trading_delete_pending'] = False
                            st.session_state['trading_delete_ids'] = []
                
                with confirm_col2:
                    if st.button("âŒ Cancel", key="cancel_delete_btn"):
                        st.session_state['trading_delete_pending'] = False
                        st.session_state['trading_delete_ids'] = []
                        st.rerun()
        
        # Handle Save
        if save_btn:
            try:
                conn = get_conn()
                cur = conn.cursor()
                changes = 0
                
                for idx in range(len(edited_df)):
                    row = edited_df.iloc[idx]
                    orig_row = edit_df.iloc[idx]
                    
                    # Check if anything changed (including transaction type)
                    changed = False
                    for col in ['date', 'symbol', 'portfolio', 'type', 'quantity', 'price', 'fees', 'notes']:
                        if str(row.get(col, '')) != str(orig_row.get(col, '')):
                            changed = True
                            break
                    
                    if changed:
                        txn_id = int(row['id'])
                        txn_type = row['type']
                        qty = float(row['quantity']) if pd.notna(row['quantity']) else 0
                        price = float(row['price']) if pd.notna(row['price']) else 0
                        fees = float(row['fees']) if pd.notna(row['fees']) else 0
                        
                        # Calculate purchase_cost or sell_value based on txn_type
                        if txn_type in ('Buy', 'Deposit'):
                            purchase_cost = qty * price if qty > 0 and price > 0 else 0
                            sell_value = 0
                        elif txn_type in ('Sell', 'Withdrawal'):
                            purchase_cost = 0
                            sell_value = qty * price if qty > 0 and price > 0 else 0
                        else:
                            # For DIVIDEND_ONLY and other types, don't modify cost/value
                            purchase_cost = 0
                            sell_value = 0
                        
                        # Update the transaction in master transactions table
                        db_execute(cur, """
                            UPDATE transactions 
                            SET txn_date = ?, 
                                stock_symbol = ?,
                                portfolio = ?,
                                txn_type = ?,
                                shares = ?,
                                purchase_cost = ?,
                                sell_value = ?,
                                fees = ?,
                                notes = ?
                            WHERE id = ? AND user_id = ?
                        """, (
                            pd.to_datetime(row['date']).strftime('%Y-%m-%d') if pd.notna(row['date']) else None,
                            row['symbol'],
                            row['portfolio'],
                            txn_type,
                            qty,
                            purchase_cost,
                            sell_value,
                            fees,
                            row['notes'] if pd.notna(row['notes']) else '',
                            txn_id,
                            user_id
                        ))
                        changes += 1
                
                conn.commit()
                conn.close()
                
                if changes > 0:
                    st.success(f"âœ… Updated {changes} transaction(s)")
                    # Recalculate avg costs and realized P&L after edits
                    recalculate_and_store_avg_costs(user_id)
                    # Recalculate cash after edits
                    recalc_portfolio_cash(user_id)
                    build_portfolio_table.clear()
                    time.sleep(1)
                    st.rerun()
                else:
                    st.info("No changes detected")
                    
            except Exception as e:
                st.error(f"Error saving: {e}")
    
    # Download section
    st.divider()
    from io import BytesIO
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='Trading History', index=False)
    
    st.download_button(
        label="ðŸ“¥ Download Trading History (Excel)",
        data=output.getvalue(),
        file_name=f"transactions_{date.today()}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="trading_download"
    )


# =========================
# OVERVIEW TAB
# =========================

# CBK Rate Cache - Global variable for in-memory caching
_cbk_rate_cache = {
    'rate': None,
    'fetched_date': None,
    'source': None  # 'cbk_api', 'config', 'db_cache', 'default'
}

def _init_cbk_rate_table():
    """Initialize the CBK rate cache table in the database."""
    from db_layer import is_postgres
    conn = get_conn()
    cur = conn.cursor()
    try:
        if is_postgres():
            db_execute(cur, """
                CREATE TABLE IF NOT EXISTS cbk_rate_cache (
                    id SERIAL PRIMARY KEY,
                    rate DOUBLE PRECISION NOT NULL,
                    fetched_date TEXT NOT NULL,
                    source TEXT NOT NULL,
                    created_at INTEGER DEFAULT EXTRACT(EPOCH FROM NOW())::INTEGER
                )
            """)
        else:
            db_execute(cur, """
                CREATE TABLE IF NOT EXISTS cbk_rate_cache (
                    id INTEGER PRIMARY KEY,
                    rate REAL NOT NULL,
                    fetched_date TEXT NOT NULL,
                    source TEXT NOT NULL,
                    created_at INTEGER DEFAULT (strftime('%s', 'now'))
                )
            """)
        conn.commit()
    except Exception as e:
        logger.error(f"Error creating cbk_rate_cache table: {e}")
    finally:
        conn.close()

def _fetch_cbk_rate_from_api():
    """
    Attempt to fetch the CBK discount rate from official sources.
    Returns: (rate: float, success: bool)
    """
    import requests
    from bs4 import BeautifulSoup
    
    # Primary source: Central Bank of Kuwait official website
    # The CBK publishes the discount rate on their statistics page
    cbk_urls = [
        "https://www.cbk.gov.kw/en/statistics-and-publications/statistics/interest-rates",
        "https://www.cbk.gov.kw/en/statistics-and-publications/statistics",
    ]
    
    for url in cbk_urls:
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Look for discount rate in various formats
                text = soup.get_text().lower()
                
                # Pattern matching for discount rate
                import re
                patterns = [
                    r'discount\s*rate[:\s]*(\d+\.?\d*)\s*%',
                    r'cbk\s*discount[:\s]*(\d+\.?\d*)\s*%',
                    r'policy\s*rate[:\s]*(\d+\.?\d*)\s*%',
                    r'base\s*rate[:\s]*(\d+\.?\d*)\s*%',
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, text)
                    if match:
                        rate = float(match.group(1)) / 100  # Convert percentage to decimal
                        if 0.01 <= rate <= 0.20:  # Sanity check: 1% to 20%
                            return rate, True
                            
        except requests.RequestException as e:
            logger.debug(f"CBK API request failed for {url}: {e}")
        except Exception as e:
            logger.debug(f"Error parsing CBK response: {e}")
    
    # Secondary source: Try to get from financial data APIs
    try:
        # Try World Bank API for Kuwait interest rates
        wb_url = "https://api.worldbank.org/v2/country/kwt/indicator/FR.INR.DPST?format=json&per_page=1&mrv=1"
        response = requests.get(wb_url, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if len(data) > 1 and data[1]:
                rate_value = data[1][0].get('value')
                if rate_value and 0.5 <= rate_value <= 20:  # Sanity check
                    return rate_value / 100, True
    except Exception as e:
        logger.debug(f"World Bank API failed: {e}")
    
    return None, False

def _get_cbk_rate_from_config():
    """
    Get CBK rate from configuration sources.
    Checks: environment variable, Streamlit secrets, or .env file.
    Returns: (rate: float or None, found: bool)
    """
    import os
    
    # 1. Check environment variable
    env_rate = os.environ.get('CBK_RISK_FREE_RATE')
    if env_rate:
        try:
            rate = float(env_rate)
            # Handle both decimal (0.0425) and percentage (4.25) formats
            if rate > 1:
                rate = rate / 100
            return rate, True
        except ValueError:
            pass
    
    # 2. Check Streamlit secrets
    try:
        if hasattr(st, 'secrets') and 'CBK_RISK_FREE_RATE' in st.secrets:
            rate = float(st.secrets['CBK_RISK_FREE_RATE'])
            if rate > 1:
                rate = rate / 100
            return rate, True
    except Exception:
        pass
    
    # 3. Check database for config setting
    try:
        conn = get_conn()
        cur = conn.cursor()
        db_execute(cur, "SELECT rate FROM cbk_rate_cache ORDER BY created_at DESC LIMIT 1")
        row = cur.fetchone()
        conn.close()
        if row and row[0]:
            return float(row[0]), True
    except Exception:
        pass
    
    return None, False

def _get_cbk_rate_from_db_cache():
    """
    Get the last successfully fetched CBK rate from database cache.
    Returns: (rate: float, fetched_date: str, source: str) or (None, None, None)
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        db_execute(cur, """
            SELECT rate, fetched_date, source 
            FROM cbk_rate_cache 
            ORDER BY created_at DESC LIMIT 1
        """)
        row = cur.fetchone()
        conn.close()
        if row:
            return float(row[0]), row[1], row[2]
    except Exception as e:
        logger.debug(f"Error reading CBK rate from cache: {e}")
    
    return None, None, None

def _save_cbk_rate_to_cache(rate, source):
    """Save the CBK rate to database cache."""
    from datetime import datetime
    
    try:
        _init_cbk_rate_table()
        conn = get_conn()
        cur = conn.cursor()
        
        fetched_date = datetime.now().strftime('%Y-%m-%d')
        
        db_execute(cur, """
            INSERT INTO cbk_rate_cache (rate, fetched_date, source)
            VALUES (?, ?, ?)
        """, (rate, fetched_date, source))
        conn.commit()
        conn.close()
        
        # Update global cache
        _cbk_rate_cache['rate'] = rate
        _cbk_rate_cache['fetched_date'] = fetched_date
        _cbk_rate_cache['source'] = source
        
    except Exception as e:
        logger.error(f"Error saving CBK rate to cache: {e}")

def get_cbk_risk_free_rate(force_refresh=False):
    """
    Get the Central Bank of Kuwait risk-free rate dynamically.
    
    Priority order:
    1. In-memory cache (if < 24 hours old and not force_refresh)
    2. Fetch from CBK official website/API
    3. Fall back to config value (env var, secrets, or db setting)
    4. Fall back to database cache (last known good value)
    5. Return None if all sources fail
    
    Returns: dict with keys:
        - 'rate': float (e.g., 0.0425) or None
        - 'rate_percent': float (e.g., 4.25) or None
        - 'source': str ('cbk_api', 'config', 'db_cache', 'default', 'unavailable')
        - 'fetched_date': str (YYYY-MM-DD) or None
        - 'is_stale': bool (True if using cached/fallback value)
        - 'warning': str or None
    """
    from datetime import datetime, timedelta
    
    global _cbk_rate_cache
    
    result = {
        'rate': None,
        'rate_percent': None,
        'source': 'unavailable',
        'fetched_date': None,
        'is_stale': False,
        'warning': None
    }
    
    # Initialize the cache table
    _init_cbk_rate_table()
    
    # Check in-memory cache first (unless force refresh)
    if not force_refresh and _cbk_rate_cache['rate'] is not None:
        if _cbk_rate_cache['fetched_date']:
            try:
                cached_date = datetime.strptime(_cbk_rate_cache['fetched_date'], '%Y-%m-%d')
                if datetime.now() - cached_date < timedelta(hours=24):
                    result['rate'] = _cbk_rate_cache['rate']
                    result['rate_percent'] = _cbk_rate_cache['rate'] * 100
                    result['source'] = _cbk_rate_cache['source']
                    result['fetched_date'] = _cbk_rate_cache['fetched_date']
                    result['is_stale'] = _cbk_rate_cache['source'] != 'cbk_api'
                    return result
            except ValueError:
                pass
    
    # Try primary source: CBK API
    try:
        rate, success = _fetch_cbk_rate_from_api()
        if success and rate is not None:
            _save_cbk_rate_to_cache(rate, 'cbk_api')
            result['rate'] = rate
            result['rate_percent'] = rate * 100
            result['source'] = 'cbk_api'
            result['fetched_date'] = datetime.now().strftime('%Y-%m-%d')
            result['is_stale'] = False
            return result
    except Exception as e:
        logger.debug(f"CBK API fetch error: {e}")
    
    # Try config fallback
    config_rate, config_found = _get_cbk_rate_from_config()
    if config_found and config_rate is not None:
        _save_cbk_rate_to_cache(config_rate, 'config')
        result['rate'] = config_rate
        result['rate_percent'] = config_rate * 100
        result['source'] = 'config'
        result['fetched_date'] = datetime.now().strftime('%Y-%m-%d')
        result['is_stale'] = True
        result['warning'] = "Using configured rate (CBK fetch unavailable)"
        return result
    
    # Try database cache fallback
    cached_rate, cached_date, cached_source = _get_cbk_rate_from_db_cache()
    if cached_rate is not None:
        _cbk_rate_cache['rate'] = cached_rate
        _cbk_rate_cache['fetched_date'] = cached_date
        _cbk_rate_cache['source'] = 'db_cache'
        
        result['rate'] = cached_rate
        result['rate_percent'] = cached_rate * 100
        result['source'] = 'db_cache'
        result['fetched_date'] = cached_date
        result['is_stale'] = True
        result['warning'] = f"Using last known CBK rate (updated on {cached_date})"
        return result
    
    # Final fallback: default value with warning
    default_rate = 0.0425  # Last known CBK rate as of 2024
    result['rate'] = default_rate
    result['rate_percent'] = default_rate * 100
    result['source'] = 'default'
    result['fetched_date'] = None
    result['is_stale'] = True
    result['warning'] = "Using default CBK rate (4.25%) - please configure CBK_RISK_FREE_RATE"
    
    # Save default to cache so it persists
    _save_cbk_rate_to_cache(default_rate, 'default')
    
    return result

def get_risk_free_rate():
    """
    Legacy wrapper for backward compatibility.
    Returns just the rate value as a float.
    """
    cbk_data = get_cbk_risk_free_rate()
    if cbk_data['rate'] is not None:
        return cbk_data['rate']
    return 0.0425  # Fallback

def calculate_sharpe_ratio(rf_rate):
    """Calculate Sharpe Ratio based on portfolio snapshots."""
    # Load portfolio snapshots
    user_id = st.session_state.get('user_id', 1)
    df = query_df("SELECT snapshot_date, portfolio_value FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date ASC", (user_id,))
    
    if df.empty or len(df) < 2:
        return None
    
    # Convert snapshot_date to datetime for time delta calculation
    df['snapshot_date'] = pd.to_datetime(df['snapshot_date'])
    
    # Calculate average days between snapshots to determine annualization factor
    avg_days = df['snapshot_date'].diff().dt.days.mean()
    if pd.isna(avg_days) or avg_days <= 0:
        avg_days = 1  # Default to daily
    
    # Determine annualization factor based on snapshot frequency
    if avg_days > 25:      # Monthly snapshots
        annual_factor = 12
    elif avg_days > 5:     # Weekly snapshots  
        annual_factor = 52
    else:                  # Daily snapshots
        annual_factor = 252
        
    # Calculate period returns
    df['period_return'] = df['portfolio_value'].pct_change()
    
    # Drop NaN (first row)
    df = df.dropna()
    
    if df.empty:
        return None
        
    # Convert annual Rf to period Rf
    # period_rf = (1 + annual_rf) ^ (1/annual_factor) - 1
    period_rf = (1 + rf_rate) ** (1/annual_factor) - 1
    
    # Calculate Excess Returns
    df['excess_return'] = df['period_return'] - period_rf
    
    # Calculate Sharpe
    mean_excess = df['excess_return'].mean()
    std_excess = df['excess_return'].std()
    
    if std_excess == 0:
        return 0.0
        
    # Annualize using appropriate factor
    sharpe = (mean_excess / std_excess) * np.sqrt(annual_factor)
    
    return sharpe

@st.cache_data(ttl=3600)
def get_us_risk_free_rate():
    """Fetch 10-Year Treasury Yield (^TNX) for Sortino Ratio."""
    default_rate = 0.045
    # Lazy-load yfinance
    if not _ensure_yfinance():
        return default_rate
    
    try:
        # Use cached Ticker object
        ticker = _get_yf_ticker("^TNX")
        if ticker is None:
            return default_rate
        hist = ticker.history(period="1d")
        if not hist.empty:
            # TNX is in percentage points (e.g. 4.50), so divide by 100
            return float(hist["Close"].iloc[-1]) / 100.0
    except Exception:
        pass
    return default_rate

def calculate_sortino_ratio(rf_rate=None):
    """
    Calculate Sortino Ratio based on portfolio snapshots.
    Uses MAR (Minimum Acceptable Return) = 0%, which is the industry standard
    for absolute return strategies (penalize only losses, not returns below CBK rate).
    """
    # Load portfolio snapshots
    user_id = st.session_state.get('user_id', 1)
    df = query_df("SELECT snapshot_date, portfolio_value FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date ASC", (user_id,))
    
    if df.empty or len(df) < 2:
        return None
    
    # Convert snapshot_date to datetime for time delta calculation
    df['snapshot_date'] = pd.to_datetime(df['snapshot_date'])
    
    # Calculate average days between snapshots to determine annualization factor
    avg_days = df['snapshot_date'].diff().dt.days.mean()
    if pd.isna(avg_days) or avg_days <= 0:
        avg_days = 1  # Default to daily
    
    # Determine annualization factor based on snapshot frequency
    if avg_days > 25:      # Monthly snapshots
        annual_factor = 12
    elif avg_days > 5:     # Weekly snapshots  
        annual_factor = 52
    else:                  # Daily snapshots
        annual_factor = 252
        
    # Calculate period returns
    df['period_return'] = df['portfolio_value'].pct_change()
    
    # Drop NaN (first row)
    df = df.dropna()
    
    if df.empty:
        return None
        
    # MAR (Minimum Acceptable Return) = 0% (Break-even)
    # We penalize only negative returns, not returns below CBK rate
    mar = 0.0
    
    # Calculate Excess Returns vs 0% MAR
    df['excess_return'] = df['period_return'] - mar
    
    # Calculate Downside Deviation
    # Keep only negative excess returns, replace positives with 0
    negative_returns = np.minimum(df['excess_return'], 0)
    
    # Calculate standard deviation of these negative movements
    downside_std = np.std(negative_returns)
    
    if downside_std == 0:
        return 10.0 # Cap if no downside volatility
        
    # Calculate Sortino using appropriate annualization factor
    mean_excess = df['excess_return'].mean()
    sortino = (mean_excess / downside_std) * np.sqrt(annual_factor)
    
    return sortino

def calculate_trading_realized_profit(user_id):
    """
    Calculate realized profit from transactions table using FIFO matching.
    Uses FIFO matching of Buy/Sell pairs for closed positions.
    Returns profit in KWD (converted from original currency).
    """
    result = calculate_realized_profit_details(user_id)
    return result['total_realized_kwd']


def calculate_realized_profit_details(user_id):
    """
    Calculate realized profit from ALL transactions using stored CFA-compliant values.
    Returns a dict with:
      - 'total_realized_kwd': Total realized profit in KWD
      - 'total_profit_kwd': Total profits only (positive trades)
      - 'total_loss_kwd': Total losses only (negative trades)
      - 'details': DataFrame with trade-by-trade breakdown
    
    USES STORED realized_pnl_at_txn values from database (same as Trading Section).
    Falls back to runtime calculation if stored values not available.
    """
    conn = get_conn()
    try:
        # Query all sell transactions with their stored realized_pnl_at_txn
        query = """
            SELECT 
                t.id,
                t.stock_symbol,
                t.txn_date,
                t.txn_type,
                t.shares,
                t.purchase_cost,
                t.sell_value,
                t.realized_pnl_at_txn,
                t.avg_cost_at_txn,
                COALESCE(t.portfolio, s.portfolio, 'KFH') as portfolio,
                COALESCE(s.currency, 'KWD') as currency,
                COALESCE(t.category, 'portfolio') as category
            FROM transactions t
            LEFT JOIN stocks s ON UPPER(t.stock_symbol) = UPPER(s.symbol) AND s.user_id = t.user_id
            WHERE t.user_id = ? 
            AND (t.is_deleted = 0 OR t.is_deleted IS NULL)
            ORDER BY t.stock_symbol, t.portfolio, t.txn_date ASC, t.id ASC
        """
        df = pd.read_sql_query(convert_sql_placeholders(query), conn, params=(user_id,))
    except Exception:
        df = pd.DataFrame()
    finally:
        conn.close()
    
    if df.empty:
        return {
            'total_realized_kwd': 0.0,
            'total_profit_kwd': 0.0,
            'total_loss_kwd': 0.0,
            'details': pd.DataFrame()
        }
    
    # Check if stored values are available
    has_stored_values = 'realized_pnl_at_txn' in df.columns and df['realized_pnl_at_txn'].notna().any()
    
    # List to store trade details
    trade_details = []
    total_realized_kwd = 0.0
    total_profit_kwd = 0.0
    total_loss_kwd = 0.0
    
    if has_stored_values:
        # USE STORED VALUES (CFA-compliant, matches Trading Section)
        sell_df = df[df['txn_type'] == 'Sell'].copy()
        
        for _, row in sell_df.iterrows():
            stored_pnl = row.get('realized_pnl_at_txn')
            if pd.notna(stored_pnl):
                profit = float(stored_pnl)
                ccy = row.get('currency', 'KWD') or 'KWD'
                profit_kwd = convert_to_kwd(profit, ccy)
                
                total_realized_kwd += profit_kwd
                if profit_kwd >= 0:
                    total_profit_kwd += profit_kwd
                else:
                    total_loss_kwd += profit_kwd
                
                # Record trade detail
                avg_cost = row.get('avg_cost_at_txn', 0) or 0
                qty = safe_float(row['shares'], 0)
                proceeds = safe_float(row['sell_value'], 0)
                cost_of_sold = avg_cost * qty
                
                trade_details.append({
                    'Stock': row['stock_symbol'],
                    'Portfolio': row.get('portfolio', 'KFH'),
                    'Sell Date': row['txn_date'],
                    'Shares': qty,
                    'Avg Cost': round(avg_cost, 4),
                    'Buy Cost': round(cost_of_sold, 3),
                    'Sell Value': round(proceeds, 3),
                    'Profit/Loss': round(profit, 4),
                    'Profit/Loss (KWD)': round(profit_kwd, 4),
                    'Currency': ccy,
                    'Category': row.get('category', 'portfolio')
                })
    else:
        # FALLBACK: Runtime calculation using Average Cost Method per (symbol, portfolio)
        # Track cost basis per (stock, portfolio) using Average Cost Method
        position_basis = {}  # Key: (symbol, portfolio)
        
        for _, row in df.iterrows():
            typ = row['txn_type']
            qty = safe_float(row['shares'], 0)
            ccy = row.get('currency', 'KWD') or 'KWD'
            stock = row['stock_symbol']
            portfolio = row.get('portfolio', 'KFH')
            pos_key = (stock, portfolio)
            
            if pos_key not in position_basis:
                position_basis[pos_key] = {'qty': 0.0, 'total_cost': 0.0, 'currency': ccy}
            
            position_basis[pos_key]['currency'] = ccy
            
            if typ == 'Buy':
                cost = safe_float(row['purchase_cost'], 0)
                position_basis[pos_key]['qty'] += qty
                position_basis[pos_key]['total_cost'] += cost
                
            elif typ == 'Sell' and qty > 0:
                current_qty = position_basis[pos_key]['qty']
                current_cost = position_basis[pos_key]['total_cost']
                
                if current_qty > 0:
                    avg_cost_per_share = current_cost / current_qty
                    cost_of_sold_shares = avg_cost_per_share * qty
                    
                    proceeds = safe_float(row['sell_value'], 0)
                    profit = proceeds - cost_of_sold_shares
                    profit_kwd = convert_to_kwd(profit, ccy)
                    
                    total_realized_kwd += profit_kwd
                    if profit_kwd >= 0:
                        total_profit_kwd += profit_kwd
                    else:
                        total_loss_kwd += profit_kwd
                    
                    trade_details.append({
                        'Stock': stock,
                        'Portfolio': portfolio,
                        'Sell Date': row['txn_date'],
                        'Shares': qty,
                        'Avg Cost': round(avg_cost_per_share, 4),
                        'Buy Cost': round(cost_of_sold_shares, 3),
                        'Sell Value': round(proceeds, 3),
                        'Profit/Loss': round(profit, 4),
                        'Profit/Loss (KWD)': round(profit_kwd, 4),
                        'Currency': ccy,
                        'Category': row.get('category', 'portfolio')
                    })
                    
                    position_basis[pos_key]['qty'] -= qty
                    position_basis[pos_key]['total_cost'] -= cost_of_sold_shares
    
    # Create DataFrame from trade details
    details_df = pd.DataFrame(trade_details) if trade_details else pd.DataFrame()
    
    return {
        'total_realized_kwd': total_realized_kwd,
        'total_profit_kwd': total_profit_kwd,
        'total_loss_kwd': total_loss_kwd,
        'details': details_df
    }


def calculate_total_cash_dividends(user_id, debug=False):
    """
    Calculate total CASH dividends received.
    Matches the 'Dividends Tracker' tab logic (Portfolio Dividends only).
    
    NOTE: Trading history dividends are tracked separately in Trading Section.
    """
    # Query strictly from transactions table (Portfolio) to match Dividend Tracker tab
    dividends_df = query_df("""
        SELECT 
            t.cash_dividend,
            COALESCE(s.currency, 'KWD') as currency
        FROM transactions t
        LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND s.user_id = t.user_id
        WHERE t.user_id = ? 
          AND t.cash_dividend > 0
    """, (user_id,))
    
    total_dividends_kwd = 0.0
    dividend_count = 0
    
    if not dividends_df.empty:
        # Calculate KWD value row by row
        dividends_df["val_kwd"] = dividends_df.apply(
            lambda row: convert_to_kwd(safe_float(row["cash_dividend"], 0), row.get("currency", "KWD")),
            axis=1
        )
        total_dividends_kwd = dividends_df["val_kwd"].sum()
        dividend_count = len(dividends_df)
    
    return total_dividends_kwd, dividend_count, None


def ui_overview():
    """FINANCIAL DASHBOARD - Overview Tab (Theme-Aware: Neon Dark / Clean Light)"""

    is_dark = st.session_state.get("theme", "light") == "dark"

    # ======================
    # THEME-AWARE CSS
    # ======================
    if is_dark:
        _css_vars = """
        :root {
            --bg-primary: #0a0a15;
            --bg-secondary: #121220;
            --bg-card: #1a1a2e;
            --bg-card-hover: #22223e;
            --text-primary: #e6e6f0;
            --text-secondary: #a0a0b0;
            --accent-primary: #8a2be2;
            --accent-secondary: #4cc9f0;
            --accent-tertiary: #ff00cc;
            --success: #00d4ff;
            --warning: #ff9e00;
            --danger: #ff4757;
            --card-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            --card-border: 1px solid rgba(138, 43, 226, 0.2);
            --neon-glow: 0 0 15px rgba(138, 43, 226, 0.6);
            --icon-bg-base: rgba(138, 43, 226, 0.1);
            --icon-shadow-base: 0 4px 12px rgba(138, 43, 226, 0.2);
            --sub-border: 1px dashed rgba(255, 255, 255, 0.06);
            --section-border-color: rgba(138, 43, 226, 0.3);
            --hm-border-default: rgba(255, 255, 255, 0.05);
        }
        [data-testid="stAppViewContainer"] {
            background: linear-gradient(135deg, #0a0a15 0%, #0d0d25 100%) !important;
            background-attachment: fixed;
        }
        [data-testid="stAppViewContainer"] > section { background: transparent !important; }
        [data-testid="stVerticalBlock"] > div { background: transparent !important; }
        [data-testid="stMarkdown"] p,
        [data-testid="stMarkdown"] h1,
        [data-testid="stMarkdown"] h2,
        [data-testid="stMarkdown"] h3,
        [data-testid="stMarkdown"] h4,
        [data-testid="stMarkdown"] h5,
        [data-testid="stMarkdown"] h6 { color: var(--text-primary) !important; }
        """
        _css_btn = """
        [data-testid="stButton"] button {
            background: linear-gradient(135deg, var(--accent-primary), var(--accent-secondary)) !important;
            color: white !important; border: none !important;
            border-radius: 10px !important; padding: 0.8rem 1.5rem !important;
            font-weight: 600 !important; font-size: 1rem !important;
            transition: all 0.3s ease !important;
            box-shadow: 0 4px 15px rgba(138, 43, 226, 0.4) !important;
            position: relative !important; overflow: hidden !important;
        }
        [data-testid="stButton"] button:hover {
            transform: translateY(-3px) !important;
            box-shadow: 0 6px 20px rgba(138, 43, 226, 0.7) !important;
            background: linear-gradient(135deg, var(--accent-secondary), var(--accent-tertiary)) !important;
        }
        """
        _css_expander = """
        [data-testid="stExpander"] {
            background: var(--bg-card) !important; border-radius: 12px !important;
            border: var(--card-border) !important; box-shadow: var(--card-shadow) !important;
            margin-bottom: 1rem !important;
        }
        [data-testid="stExpander"] > div { background: transparent !important; }
        [data-testid="stExpander"] summary {
            background: transparent !important; color: var(--text-primary) !important;
            font-weight: 600 !important; font-size: 1.1rem !important;
        }
        [data-testid="stExpanderContent"] { background: transparent !important; color: var(--text-primary) !important; }
        """
        _css_card_extras = """
        .dashboard-card:hover::before { opacity: 0.3; }
        .metric-value { text-shadow: 0 0 10px rgba(138, 43, 226, 0.3); }
        .metric-value.positive { text-shadow: 0 0 10px rgba(0, 212, 255, 0.5); }
        .metric-value.negative { text-shadow: 0 0 10px rgba(255, 71, 87, 0.5); }
        .heatmap-value {
            background: linear-gradient(45deg, var(--success), var(--accent-secondary));
            -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text;
        }
        .heatmap-card.positive .heatmap-value {
            background: linear-gradient(45deg, var(--success), #059669);
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }
        .heatmap-card.negative .heatmap-value {
            background: linear-gradient(45deg, var(--danger), #dc2626);
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }
        """
    else:
        # ===== LIGHT / PROFESSIONAL THEME =====
        _css_vars = """
        :root {
            --bg-primary: #f8fafc;
            --bg-secondary: #ffffff;
            --bg-card: #ffffff;
            --bg-card-hover: #f1f5f9;
            --text-primary: #1e293b;
            --text-secondary: #64748b;
            --text-muted: #64748b;
            --accent-primary: #6366f1;
            --accent-secondary: #3b82f6;
            --accent-tertiary: #ec4899;
            --success: #10b981;
            --warning: #f59e0b;
            --danger: #ef4444;
            --card-shadow: 0 4px 16px rgba(0, 0, 0, 0.06);
            --card-shadow-hover: 0 8px 24px rgba(0, 0, 0, 0.1);
            --card-border: 1px solid rgba(203, 213, 225, 0.6);
            --neon-glow: 0 4px 20px rgba(99, 102, 241, 0.15);
            --icon-bg-base: rgba(99, 102, 241, 0.08);
            --icon-shadow-base: 0 2px 8px rgba(99, 102, 241, 0.1);
            --sub-border: 1px dashed rgba(0, 0, 0, 0.08);
            --section-border-color: rgba(99, 102, 241, 0.25);
            --hm-border-default: rgba(0, 0, 0, 0.06);
        }
        """
        _css_btn = """
        [data-testid="stButton"] button {
            background: linear-gradient(135deg, #6366f1, #3b82f6) !important;
            color: white !important; border: none !important;
            border-radius: 10px !important; padding: 0.8rem 1.5rem !important;
            font-weight: 600 !important; font-size: 1rem !important;
            transition: all 0.3s ease !important;
            box-shadow: 0 4px 12px rgba(99, 102, 241, 0.25) !important;
        }
        [data-testid="stButton"] button:hover {
            transform: translateY(-2px) !important;
            box-shadow: 0 6px 18px rgba(99, 102, 241, 0.35) !important;
        }
        """
        _css_expander = """
        [data-testid="stExpander"] {
            background: var(--bg-card) !important; border-radius: 12px !important;
            border: var(--card-border) !important; box-shadow: var(--card-shadow) !important;
            margin-bottom: 1rem !important;
        }
        [data-testid="stExpander"] summary {
            font-weight: 600 !important; font-size: 1.05rem !important;
            color: var(--text-primary) !important;
        }
        """
        _css_card_extras = """
        .dashboard-card:hover::before { opacity: 0; }
        .metric-card { border-radius: 20px; }
        .metric-card:hover { box-shadow: var(--card-shadow-hover); }
        .metric-value { text-shadow: none; }
        .metric-value.positive { text-shadow: none; }
        .metric-value.negative { text-shadow: none; }
        .heatmap-value { color: var(--text-primary); }
        .heatmap-card.positive .heatmap-value { color: var(--success); }
        .heatmap-card.negative .heatmap-value { color: var(--danger); }
        .light-footer {
            margin-top: 3rem; padding: 1.5rem;
            background: linear-gradient(135deg, rgba(99, 102, 241, 0.04) 0%, rgba(59, 130, 246, 0.04) 100%);
            border-radius: 16px; border: 1px solid rgba(203, 213, 225, 0.4);
        }
        """

    # ===== SHARED CSS (uses CSS vars for theming â€” uses CSS vars) =====
    _css_shared = """
    /* ===== DASHBOARD CARD ===== */
    .dashboard-card {
        background: var(--bg-card); border-radius: 16px;
        border: var(--card-border); box-shadow: var(--card-shadow);
        padding: 1.5rem; margin-bottom: 1.5rem;
        transition: all 0.3s ease; position: relative;
        overflow: hidden; backdrop-filter: blur(10px);
    }
    .dashboard-card:hover {
        transform: translateY(-5px);
        box-shadow: var(--neon-glow), var(--card-shadow);
        border-color: var(--accent-primary);
    }
    .dashboard-card::before {
        content: ''; position: absolute;
        top: -2px; left: -2px; right: -2px; bottom: -2px;
        background: linear-gradient(45deg, var(--accent-primary), var(--accent-secondary), var(--accent-tertiary));
        z-index: -1; border-radius: 18px;
        filter: blur(10px); opacity: 0; transition: 0.3s ease;
    }

    /* ===== METRIC CARDS ===== */
    .metric-card {
        background: var(--bg-secondary); border-radius: 12px;
        padding: 1.25rem; display: flex; flex-direction: column;
        height: 100%; position: relative; overflow: hidden;
        border: 1px solid var(--hm-border-default);
        transition: all 0.3s ease;
    }
    .metric-card:hover {
        transform: translateY(-3px);
        border-color: var(--accent-primary);
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.12);
    }
    .metric-card::before {
        content: ''; position: absolute;
        top: 0; left: 0; right: 0; height: 4px;
        background: linear-gradient(90deg, var(--accent-primary), var(--accent-secondary));
    }
    .metric-icon {
        font-size: 2.5rem; margin-bottom: 0.75rem;
        width: 60px; height: 60px; border-radius: 16px;
        display: flex; align-items: center; justify-content: center;
        margin-right: auto;
        background: var(--icon-bg-base);
        box-shadow: var(--icon-shadow-base);
    }
    .metric-icon.positive { background: rgba(16, 185, 129, 0.12); color: var(--success); }
    .metric-icon.negative { background: rgba(239, 68, 68, 0.12); color: var(--danger); }
    .metric-icon.primary { background: rgba(99, 102, 241, 0.12); color: var(--accent-primary); }
    .metric-icon.warning { background: rgba(245, 158, 11, 0.12); color: var(--warning); }
    .metric-icon.purple { background: rgba(139, 92, 246, 0.12); color: var(--accent-primary); }
    .metric-icon.pink { background: rgba(236, 72, 153, 0.12); color: var(--accent-tertiary); }
    .metric-icon.green { background: rgba(16, 185, 129, 0.12); color: var(--success); }
    .metric-value {
        font-size: 2.25rem; font-weight: 800; line-height: 1.2;
        margin: 0.75rem 0; color: var(--text-primary);
    }
    .metric-value.positive { color: var(--success); }
    .metric-value.negative { color: var(--danger); }
    .metric-label {
        font-size: 0.95rem; color: var(--text-secondary);
        font-weight: 600; margin-bottom: 0.25rem;
        text-transform: uppercase; letter-spacing: 0.5px;
    }
    .metric-sub {
        font-size: 0.9rem; color: var(--text-secondary);
        margin-top: auto; padding-top: 0.75rem;
        border-top: var(--sub-border);
    }
    .metric-sub.positive { color: var(--success); font-weight: 600; }
    .metric-sub.negative { color: var(--danger); font-weight: 600; }

    /* ===== SECTION HEADERS ===== */
    .section-header {
        display: flex; align-items: center; gap: 0.75rem;
        padding-bottom: 0.75rem; margin: 2rem 0 1.25rem;
        border-bottom: 2px solid var(--section-border-color);
    }
    .section-title {
        font-size: 1.8rem; font-weight: 700; color: var(--text-primary);
        display: flex; align-items: center; gap: 0.75rem;
        letter-spacing: -0.5px;
    }
    .section-icon {
        width: 40px; height: 40px; border-radius: 12px;
        display: flex; align-items: center; justify-content: center;
        font-size: 1.6rem;
        background: var(--icon-bg-base);
        box-shadow: var(--icon-shadow-base);
    }
    .section-icon.blue { background: rgba(59, 130, 246, 0.12); color: var(--accent-secondary); }
    .section-icon.green { background: rgba(16, 185, 129, 0.12); color: var(--success); }
    .section-icon.purple { background: rgba(99, 102, 241, 0.12); color: var(--accent-primary); }
    .section-icon.pink { background: rgba(236, 72, 153, 0.12); color: var(--accent-tertiary); }

    /* ===== CHART CONTAINER ===== */
    .chart-container {
        background: var(--bg-card); border-radius: 16px;
        padding: 1.5rem; box-shadow: var(--card-shadow);
        margin: 1.5rem 0; border: var(--card-border);
        backdrop-filter: blur(10px);
    }
    .chart-title {
        font-size: 1.5rem; font-weight: 700; color: var(--text-primary);
        margin-bottom: 1.25rem; display: flex; align-items: center;
        gap: 0.75rem; letter-spacing: -0.5px;
    }

    /* ===== PERFORMANCE HEATMAP ===== */
    .heatmap-container {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(220px, 1fr));
        gap: 1.25rem; margin-top: 1rem;
    }
    .heatmap-card {
        background: var(--bg-secondary); border-radius: 14px;
        padding: 1.25rem; box-shadow: 0 3px 10px rgba(0, 0, 0, 0.08);
        border-left: 4px solid var(--accent-primary);
        transition: all 0.25s ease;
        border: 1px solid var(--hm-border-default);
    }
    .heatmap-card:hover {
        transform: translateX(4px);
        box-shadow: 0 4px 14px rgba(0, 0, 0, 0.12);
        border-left-color: var(--accent-secondary);
    }
    .heatmap-card.positive { border-left-color: var(--success); }
    .heatmap-card.negative { border-left-color: var(--danger); }
    .heatmap-value {
        font-size: 1.8rem; font-weight: 800; margin: 0.25rem 0;
        color: var(--text-primary);
    }
    .heatmap-label { font-size: 0.95rem; font-weight: 600; color: var(--text-secondary); margin-bottom: 0.25rem; }
    .heatmap-sub { font-size: 0.85rem; color: var(--text-secondary); }

    /* ===== FOOTER ===== */
    .neon-footer {
        margin-top: 3rem; padding: 1.5rem;
        background: linear-gradient(135deg, rgba(99, 102, 241, 0.08) 0%, rgba(59, 130, 246, 0.08) 100%);
        border-radius: 16px; border: 1px solid var(--section-border-color);
        backdrop-filter: blur(10px);
    }

    /* ===== RESPONSIVE ===== */
    @media (max-width: 768px) {
        .section-title { font-size: 1.5rem; }
        .metric-value { font-size: 1.8rem; }
        .heatmap-container { grid-template-columns: 1fr; }
    }
    """

    st.markdown(f"<style>{_css_vars}\n{_css_shared}\n{_css_card_extras}\n{_css_btn}\n{_css_expander}</style>", unsafe_allow_html=True)

    # ======================
    # HEADER SECTION (Theme-Specific)
    # ======================
    if is_dark:
        st.markdown("""
        <div class="dashboard-card">
            <div style="text-align: center; padding: 1rem 0;">
                <h1 style="font-size: 2.5rem; font-weight: 800; margin: 0; color: var(--text-primary); letter-spacing: -1px; text-shadow: 0 0 15px rgba(138, 43, 226, 0.5);">
                    ðŸ’¼ PORTFOLIO INTELLIGENCE
                </h1>
                <p style="font-size: 1.1rem; color: var(--text-secondary); margin: 0.5rem 0 0; font-weight: 500;">
                    Real-time performance analytics â€¢ Risk-adjusted returns â€¢ AI-powered insights
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div class="dashboard-card">
            <div style="text-align: center; padding: 1rem 0;">
                <h1 style="font-size: 2.5rem; font-weight: 800; margin: 0; color: var(--text-primary); letter-spacing: -1px;">
                    ðŸ’¼ Portfolio Intelligence Dashboard
                </h1>
                <p style="font-size: 1.1rem; color: var(--text-secondary); margin: 0.5rem 0 0; font-weight: 500;">
                    Real-time performance analytics â€¢ Risk-adjusted returns â€¢ AI-powered insights
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)

    # Refresh Button
    col_refresh, col_spacer = st.columns([1, 5])
    with col_refresh:
        if st.button("ðŸ”„ Refresh Data", key="overview_refresh_modern", use_container_width=True):
            build_portfolio_table.clear()
            st.cache_data.clear()
            st.toast("âœ… Data refreshed successfully!", icon="âœ¨")
            st.rerun()

    # ======================
    # CALCULATION LOGIC (UNCHANGED)
    # ======================
    # Get total portfolio value from latest snapshot (for reference)
    user_id = st.session_state.get('user_id', 1)
    latest_snapshot = query_df(
        "SELECT portfolio_value, accumulated_cash, net_gain, roi_percent, snapshot_date FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date DESC LIMIT 1",
        (user_id,)
    )
    
    # Get previous day's snapshot for daily movement calculation
    previous_snapshot = query_df(
        "SELECT portfolio_value, snapshot_date FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date DESC LIMIT 1 OFFSET 1",
        (user_id,)
    )
    
    # Calculate LIVE portfolio value from current prices and holdings
    live_stock_value = 0.0
    num_stocks = 0
    
    for port_name in PORTFOLIO_CCY.keys():
        df_port = build_portfolio_table(port_name)
        if not df_port.empty:
            # Count actual holdings (Shares > 0)
            active_holdings = df_port[df_port['Shares Qty'] > 0.001]
            num_stocks += len(active_holdings)
            
            for _, row in df_port.iterrows():
                live_stock_value += convert_to_kwd(row['Market Value'], row['Currency'])

    # --- Integration of Manual Cash for Totals (matching Portfolio Analysis) ---
    user_id = st.session_state.get('user_id')
    manual_cash_kwd = 0.0
    cash_recs = query_df("SELECT balance, currency FROM portfolio_cash WHERE user_id=?", (user_id,))
    if not cash_recs.empty:
        for _, cr in cash_recs.iterrows():
            manual_cash_kwd += convert_to_kwd(cr["balance"], cr["currency"])
    
    # LIVE Portfolio Value = Stock Market Values + Manual Cash
    live_portfolio_value = live_stock_value + manual_cash_kwd
    # ---------------------------------------------------------------------------

    # Get total cash deposits - USE NEW UNIFIED HELPER FUNCTIONS
    # These query cash_deposits table and ALWAYS show correct totals
    user_id = st.session_state.get('user_id', 1)
    
    # PRIMARY SOURCE: cash_deposits table (single source of truth for deposits)
    # This is the same table that Cash Management uses
    _soft_del_dep = _soft_delete_filter_deposits()
    all_deposits = query_df(f"""
        SELECT amount, currency, include_in_analysis, portfolio 
        FROM cash_deposits 
        WHERE user_id = ?{_soft_del_dep}
    """, (user_id,))
    
    deposits_from_unified = False
    total_deposits_kwd = 0.0
    deposits_in_analysis = 0.0
    
    if not all_deposits.empty:
        # Convert all to KWD
        all_deposits["amount_in_kwd"] = all_deposits.apply(
            lambda row: convert_to_kwd(row["amount"], row.get("currency", "KWD")),
            axis=1
        )
        # NET deposits (deposits minus withdrawals) - this is what the user actually put in
        total_deposits_kwd = all_deposits["amount_in_kwd"].sum()
        
        # For analysis: only include those marked for analysis
        analysis_deposits = all_deposits[all_deposits["include_in_analysis"] == 1]
        deposits_in_analysis = analysis_deposits["amount_in_kwd"].sum()
        deposits_from_unified = True
    else:
        # FALLBACK: Calculate Net Invested Capital from transactions if no deposits recorded
        _soft_del_txn = _soft_delete_filter()
        
        buys_df = query_df(f"""
            SELECT portfolio, purchase_cost 
            FROM transactions 
            WHERE user_id = ? AND txn_type = 'Buy' AND purchase_cost IS NOT NULL{_soft_del_txn}
        """, (user_id,))
        
        sells_df = query_df(f"""
            SELECT portfolio, sell_value 
            FROM transactions 
            WHERE user_id = ? AND txn_type = 'Sell' AND sell_value IS NOT NULL{_soft_del_txn}
        """, (user_id,))
        
        total_buys_kwd = 0.0
        if not buys_df.empty:
            for _, row in buys_df.iterrows():
                port = row.get('portfolio', 'KFH')
                ccy = PORTFOLIO_CCY.get(port, 'KWD')
                total_buys_kwd += convert_to_kwd(float(row['purchase_cost'] or 0), ccy)
        
        total_sells_kwd = 0.0
        if not sells_df.empty:
            for _, row in sells_df.iterrows():
                port = row.get('portfolio', 'KFH')
                ccy = PORTFOLIO_CCY.get(port, 'KWD')
                total_sells_kwd += convert_to_kwd(float(row['sell_value'] or 0), ccy)
        
        total_deposits_kwd = total_buys_kwd - total_sells_kwd
        deposits_in_analysis = total_deposits_kwd
    
    # Get total cash dividends (properly calculated - excludes bonus shares, reinvested, etc.)
    total_dividends_kwd, dividend_count, _ = calculate_total_cash_dividends(user_id, debug=False)
    
    # Calculate Realized Profit using the consolidated function
    # This uses Average Cost method and returns detailed breakdown
    realized_details = calculate_realized_profit_details(user_id)
    realized_profit_kwd = realized_details['total_realized_kwd']
    total_profits_kwd = realized_details['total_profit_kwd']
    total_losses_kwd = realized_details['total_loss_kwd']
    realized_trades_df = realized_details['details']
    
    # For backward compatibility with breakdown display
    portfolio_realized_kwd = realized_profit_kwd
    trading_realized_kwd = 0.0  # Now merged into single calculation
    
    # Calculate Unrealized Profit (current holdings)
    unrealized_profit_kwd = 0.0
    for port_name in PORTFOLIO_CCY.keys():
        df_port = build_portfolio_table(port_name)
        if not df_port.empty and 'Unrealized P/L' in df_port.columns:
            for _, row in df_port.iterrows():
                unrealized_profit_kwd += convert_to_kwd(row['Unrealized P/L'], row['Currency'])
    
    # Get total transactions (exclude soft-deleted if column exists)
    user_id = st.session_state.get('user_id', 1)
    _soft_del_txn = _soft_delete_filter()
    total_txns = query_df(f"SELECT COUNT(*) as count FROM transactions WHERE user_id = ?{_soft_del_txn}", (user_id,))
    num_txns = total_txns["count"].iloc[0] if not total_txns.empty else 0
    
    # Get CBK Risk-Free Rate dynamically
    cbk_rate_data = get_cbk_risk_free_rate()
    rf_rate = cbk_rate_data['rate'] if cbk_rate_data['rate'] is not None else 0.0425
    rf_rate_percent = cbk_rate_data['rate_percent'] if cbk_rate_data['rate_percent'] is not None else 4.25
    cbk_rate_source = cbk_rate_data['source']
    cbk_rate_warning = cbk_rate_data.get('warning')
    cbk_rate_date = cbk_rate_data.get('fetched_date')
    cbk_rate_is_stale = cbk_rate_data.get('is_stale', False)
    
    # Calculate Sharpe Ratio (only if rate available)
    sharpe_ratio = None
    sortino_ratio = None
    sharpe_sortino_error = None
    
    if cbk_rate_data['rate'] is not None:
        sharpe_ratio = calculate_sharpe_ratio(rf_rate)
        # Calculate Sortino Ratio (Using Kuwait Rate as requested)
        sortino_ratio = calculate_sortino_ratio(rf_rate)
    else:
        sharpe_sortino_error = "CBK rate unavailable - cannot calculate risk-adjusted metrics"
    
    # ======================
    # PRECOMPUTE DISPLAY VARIABLES
    # ======================
    daily_change_value = 0.0
    daily_change_pct = 0.0
    daily_change_available = False
    if not previous_snapshot.empty:
        prev_value = previous_snapshot['portfolio_value'].iloc[0]
        if prev_value and prev_value > 0:
            daily_change_value = live_portfolio_value - prev_value
            daily_change_pct = (daily_change_value / prev_value) * 100
            daily_change_available = True

    net_gain = live_portfolio_value - total_deposits_kwd
    roi = (net_gain / total_deposits_kwd * 100) if total_deposits_kwd > 0 else 0
    total_profit = realized_profit_kwd + unrealized_profit_kwd + total_dividends_kwd
    profitable_trades = len(realized_trades_df[realized_trades_df['Profit/Loss (KWD)'] > 0]) if not realized_trades_df.empty else 0
    deposit_source_text = "âœ… All deposits since inception" if deposits_from_unified else "ðŸ“Š Calculated from Buy-Sell"

    # ======================
    # METRIC CARDS - ROW 1
    # ======================
    st.markdown('<div class="section-header"><div class="section-icon purple">ðŸ“Š</div><div class="section-title">Portfolio Snapshot</div></div>', unsafe_allow_html=True)

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon primary">ðŸ’¼</div>
            <div class="metric-label">TOTAL VALUE</div>
            <div class="metric-value">{fmt_money_plain(live_portfolio_value)} KWD</div>
            <div class="metric-sub">Stocks: {fmt_money_plain(live_stock_value)} â€¢ Cash: {fmt_money_plain(manual_cash_kwd)}</div>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon purple">ðŸ’°</div>
            <div class="metric-label">TOTAL DEPOSITS</div>
            <div class="metric-value">{fmt_money_plain(total_deposits_kwd)} KWD</div>
            <div class="metric-sub" style="font-size:0.85rem">{deposit_source_text[:30]}...</div>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        _delta_class = "positive" if roi >= 0 else "negative"
        _delta_sign = "+" if roi >= 0 else ""
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon {'positive' if roi >= 0 else 'negative'}">ðŸ“ˆ</div>
            <div class="metric-label">NET GAIN</div>
            <div class="metric-value {_delta_class}">{_delta_sign}{fmt_money_plain(net_gain)} KWD</div>
            <div class="metric-sub {_delta_class}">{_delta_sign}{roi:.2f}% ROI</div>
        </div>
        """, unsafe_allow_html=True)

    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon warning">ðŸ“Š</div>
            <div class="metric-label">ACTIVE HOLDINGS</div>
            <div class="metric-value">{num_stocks}</div>
            <div class="metric-sub">{num_txns} transactions</div>
        </div>
        """, unsafe_allow_html=True)

    with col5:
        if daily_change_available:
            _dc_class = "positive" if daily_change_value >= 0 else "negative"
            _dc_sign = "+" if daily_change_value >= 0 else ""
            _dc_arrow = "â–²" if daily_change_value >= 0 else "â–¼"
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-icon {'positive' if daily_change_value >= 0 else 'negative'}">ðŸ“…</div>
                <div class="metric-label">DAILY MOVEMENT</div>
                <div class="metric-value {_dc_class}">{_dc_sign}{fmt_money_plain(abs(daily_change_value))} KWD</div>
                <div class="metric-sub {_dc_class}">{_dc_arrow} {_dc_sign}{daily_change_pct:.2f}%</div>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="metric-card">
                <div class="metric-icon">ðŸ“…</div>
                <div class="metric-label">DAILY MOVEMENT</div>
                <div class="metric-value">N/A</div>
                <div class="metric-sub">Need 2+ snapshots</div>
            </div>
            """, unsafe_allow_html=True)

    # ======================
    # METRIC CARDS - ROW 2
    # ======================
    st.markdown('<div style="height:1.5rem"></div>', unsafe_allow_html=True)
    col_r1, col_r2, col_r3 = st.columns(3)

    with col_r1:
        _r_class = "positive" if realized_profit_kwd >= 0 else "negative"
        _r_sign = "+" if realized_profit_kwd >= 0 else ""
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon {'positive' if realized_profit_kwd >= 0 else 'negative'}">ðŸ’µ</div>
            <div class="metric-label">REALIZED PROFIT</div>
            <div class="metric-value {_r_class}">{_r_sign}{fmt_money_plain(realized_profit_kwd)} KWD</div>
            <div class="metric-sub">{profitable_trades}/{len(realized_trades_df)} profitable trades</div>
        </div>
        """, unsafe_allow_html=True)

    with col_r2:
        _u_class = "positive" if unrealized_profit_kwd >= 0 else "negative"
        _u_sign = "+" if unrealized_profit_kwd >= 0 else ""
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon green">ðŸ“Š</div>
            <div class="metric-label">UNREALIZED P&L</div>
            <div class="metric-value {_u_class}">{_u_sign}{fmt_money_plain(unrealized_profit_kwd)} KWD</div>
            <div class="metric-sub">Current market positions</div>
        </div>
        """, unsafe_allow_html=True)

    with col_r3:
        _t_class = "positive" if total_profit >= 0 else "negative"
        _t_sign = "+" if total_profit >= 0 else ""
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon pink">ðŸ†</div>
            <div class="metric-label">TOTAL PROFIT</div>
            <div class="metric-value {_t_class}">{_t_sign}{fmt_money_plain(total_profit)} KWD</div>
            <div class="metric-sub">Includes {dividend_count} dividend records</div>
        </div>
        """, unsafe_allow_html=True)

    # ==========================================
    # ðŸ“‹ REALIZED TRADES BREAKDOWN (Detailed View)
    # ==========================================
    if not realized_trades_df.empty:
        with st.expander("ðŸ“‹ Realized Trades Breakdown (Buy â†’ Sell)", expanded=False):
            st.caption("All completed trades where you bought and then sold shares. Profit/Loss is calculated using the Average Cost method.")
            
            # Summary row
            summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)
            with summary_col1:
                st.metric("Total Trades", len(realized_trades_df))
            with summary_col2:
                profitable_trades = len(realized_trades_df[realized_trades_df['Profit/Loss (KWD)'] > 0])
                st.metric("Profitable Trades", profitable_trades, delta=f"{profitable_trades/len(realized_trades_df)*100:.0f}%" if len(realized_trades_df) > 0 else "0%")
            with summary_col3:
                st.metric("Total Gains", f"+{fmt_money_plain(total_profits_kwd)} KWD", delta_color="normal")
            with summary_col4:
                st.metric("Total Losses", f"{fmt_money_plain(total_losses_kwd)} KWD", delta_color="inverse")
            
            st.divider()
            
            # Display detailed table
            display_df = realized_trades_df.copy()
            
            # Format for display
            display_df['Sell Date'] = pd.to_datetime(display_df['Sell Date']).dt.strftime('%Y-%m-%d')
            
            # Color-code profit/loss column
            def color_pnl(val):
                if val > 0:
                    return 'color: #10b981; font-weight: bold'  # Green
                elif val < 0:
                    return 'color: #ef4444; font-weight: bold'  # Red
                return ''
            
            # Sort by date descending (most recent first)
            display_df = display_df.sort_values('Sell Date', ascending=False)
            
            # Style the dataframe
            styled_df = display_df.style.applymap(color_pnl, subset=['Profit/Loss', 'Profit/Loss (KWD)'])
            styled_df = styled_df.format({
                'Shares': '{:,.2f}',
                'Buy Cost': '{:,.3f}',
                'Sell Value': '{:,.3f}',
                'Profit/Loss': '{:+,.3f}',
                'Profit/Loss (KWD)': '{:+,.3f}'
            })
            
            st.dataframe(
                styled_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    'Stock': st.column_config.TextColumn('Stock', width='medium'),
                    'Sell Date': st.column_config.TextColumn('Sell Date', width='small'),
                    'Shares': st.column_config.NumberColumn('Shares', format='%.2f'),
                    'Buy Cost': st.column_config.NumberColumn('Buy Cost', format='%.3f'),
                    'Sell Value': st.column_config.NumberColumn('Sell Value', format='%.3f'),
                    'Profit/Loss': st.column_config.NumberColumn('P/L (Original)', format='%.3f'),
                    'Profit/Loss (KWD)': st.column_config.NumberColumn('P/L (KWD)', format='%.3f'),
                    'Currency': st.column_config.TextColumn('Currency', width='small'),
                    'Category': st.column_config.TextColumn('Category', width='small')
                }
            )
            
            # Group by stock summary
            st.write("")
            st.caption("**Summary by Stock:**")
            stock_summary = realized_trades_df.groupby('Stock').agg({
                'Shares': 'sum',
                'Buy Cost': 'sum',
                'Sell Value': 'sum',
                'Profit/Loss (KWD)': 'sum'
            }).reset_index()
            stock_summary.columns = ['Stock', 'Total Shares Sold', 'Total Cost', 'Total Proceeds', 'Net P/L (KWD)']
            stock_summary = stock_summary.sort_values('Net P/L (KWD)', ascending=False)
            
            st.dataframe(
                stock_summary.style.applymap(color_pnl, subset=['Net P/L (KWD)']).format({
                    'Total Shares Sold': '{:,.2f}',
                    'Total Cost': '{:,.3f}',
                    'Total Proceeds': '{:,.3f}',
                    'Net P/L (KWD)': '{:+,.3f}'
                }),
                use_container_width=True,
                hide_index=True
            )

    # CBK Rate Refresh (collapsed expander)
    with st.expander("âš™ï¸ Risk-Free Rate (CBK)", expanded=False):
        source_icons = {'cbk_api': 'ðŸŒ', 'config': 'âš™ï¸', 'db_cache': 'ðŸ’¾', 'default': 'âš ï¸', 'unavailable': 'âŒ'}
        source_labels = {'cbk_api': 'Live from CBK', 'config': 'Configured Value', 'db_cache': 'Cached Value', 'default': 'Default Value', 'unavailable': 'Unavailable'}
        source_icon = source_icons.get(cbk_rate_source, 'â“')
        source_label = source_labels.get(cbk_rate_source, 'Unknown')
        if cbk_rate_is_stale and cbk_rate_warning:
            st.caption(f"{source_icon} Risk-Free Rate (CBK): **{rf_rate_percent:.2f}%** â€” *{cbk_rate_warning}*")
        elif cbk_rate_date:
            st.caption(f"{source_icon} Risk-Free Rate (CBK): **{rf_rate_percent:.2f}%** â€” {source_label} (as of {cbk_rate_date})")
        else:
            st.caption(f"{source_icon} Risk-Free Rate (CBK): **{rf_rate_percent:.2f}%** â€” {source_label}")
        if st.button("ðŸ”„ Refresh CBK Rate", key="refresh_cbk_rate", help="Fetch latest rate from Central Bank of Kuwait"):
            with st.spinner("Fetching CBK rate..."):
                refreshed_data = get_cbk_risk_free_rate(force_refresh=True)
                if refreshed_data['rate'] is not None:
                    st.success(f"Rate updated: {refreshed_data['rate_percent']:.2f}% ({refreshed_data['source']})")
                    st.rerun()
                else:
                    st.error("Could not fetch CBK rate. Using fallback value.")
        if sharpe_sortino_error:
            st.warning(sharpe_sortino_error)

    # ======================
    # PORTFOLIO VALUE CHART
    # ======================
    user_id = st.session_state.get('user_id', 1)
    try:
        portfolio_history = query_df(
            "SELECT snapshot_date as date, portfolio_value as balance, accumulated_cash FROM portfolio_snapshots WHERE user_id = ? ORDER BY snapshot_date",
            (user_id,)
        )
    except Exception:
        portfolio_history = pd.DataFrame(columns=['date', 'balance', 'accumulated_cash'])

    st.markdown('<div class="chart-container">', unsafe_allow_html=True)
    st.markdown('<div class="chart-title"><div class="section-icon blue">ðŸ“ˆ</div> Portfolio Value History</div>', unsafe_allow_html=True)

    if not portfolio_history.empty and go is not None:
        _chart_hist = portfolio_history.copy()
        _chart_hist['date'] = pd.to_datetime(_chart_hist['date'])
        # Theme-aware chart colors
        if is_dark:
            _line_color, _marker_color = '#4cc9f0', '#8a2be2'
            _dep_line, _dep_fill = '#00d4ff', 'rgba(0, 212, 255, 0.1)'
            _plot_bg, _paper_bg = 'rgba(26, 26, 46, 0.5)', 'rgba(0,0,0,0)'
            _grid_c, _axis_c, _label_c = 'rgba(255,255,255,0.05)', '#e6e6f0', '#a0a0b0'
            _legend_bg, _legend_border = 'rgba(26, 26, 46, 0.8)', 'rgba(138, 43, 226, 0.3)'
            _hover_bg = 'rgba(26, 26, 46, 0.95)'
        else:
            _line_color, _marker_color = '#6366f1', '#3b82f6'
            _dep_line, _dep_fill = '#10b981', 'rgba(16, 185, 129, 0.08)'
            _plot_bg, _paper_bg = '#ffffff', 'rgba(0,0,0,0)'
            _grid_c, _axis_c, _label_c = 'rgba(0,0,0,0.06)', '#1e293b', '#64748b'
            _legend_bg, _legend_border = 'rgba(255,255,255,0.9)', 'rgba(203, 213, 225, 0.6)'
            _hover_bg = 'rgba(255,255,255,0.95)'
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=_chart_hist['date'], y=_chart_hist['balance'],
            mode='lines+markers', name='Portfolio Value',
            line=dict(color=_line_color, width=3, shape='spline'),
            marker=dict(size=7, color=_marker_color, symbol='circle'),
            hovertemplate='<b>Date</b>: %{x|%Y-%m-%d}<br><b>Value</b>: %{y:,.0f} KWD<extra></extra>'
        ))
        if 'accumulated_cash' in _chart_hist.columns:
            fig.add_trace(go.Scatter(
                x=_chart_hist['date'], y=_chart_hist['accumulated_cash'],
                mode='lines', name='Deposits',
                line=dict(color=_dep_line, width=1.5, dash='dot'),
                fill='tozeroy', fillcolor=_dep_fill,
                hovertemplate='<b>Deposits</b>: %{y:,.0f} KWD<extra></extra>'
            ))
        fig.update_layout(
            height=420,
            margin=dict(l=20, r=20, t=40, b=40),
            plot_bgcolor=_plot_bg,
            paper_bgcolor=_paper_bg,
            hovermode='x unified',
            xaxis=dict(showgrid=True, gridcolor=_grid_c, zeroline=False,
                       title=dict(text='Date', font=dict(size=12, color=_label_c)), color=_axis_c),
            yaxis=dict(showgrid=True, gridcolor=_grid_c, zeroline=False,
                       title=dict(text='Value (KWD)', font=dict(size=12, color=_label_c)),
                       tickformat=',.0f', color=_axis_c),
            legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1,
                        bgcolor=_legend_bg, bordercolor=_legend_border,
                        borderwidth=1, font=dict(color=_axis_c)),
            hoverlabel=dict(bgcolor=_hover_bg, font_size=13,
                            font_family='Inter, sans-serif', namelength=-1,
                            font=dict(color=_axis_c))
        )
        st.plotly_chart(fig, use_container_width=True, config={'displayModeBar': False})
    else:
        st.info("ðŸ’¡ Add portfolio snapshots to visualize your growth history.")

    st.markdown('</div>', unsafe_allow_html=True)
    
    # Collect ALL cash flows (deposits + dividends) with their timing
    # FOR MWRR: Use CORRECT data sources per user specification
    
    # 1. CASH DEPOSITS & WITHDRAWALS from cash_deposits table
    # Positive amounts â†’ DEPOSIT  (money OUT of investor = negative in XIRR)
    # Negative amounts â†’ WITHDRAWAL (money BACK to investor = positive in XIRR)
    # USD deposits are converted to KWD using the session FX rate (default 0.307)
    try:
        cash_deposits_for_mwrr = query_df(
            """
            SELECT deposit_date as date, 
                   amount, 
                   COALESCE(currency, 'KWD') as currency,
                   CASE WHEN amount >= 0 THEN 'DEPOSIT' ELSE 'WITHDRAWAL' END as type,
                   'cash_deposits' as source
            FROM cash_deposits 
            WHERE deposit_date IS NOT NULL
            AND amount != 0
            AND deposit_date > '1971-01-01'
            AND (include_in_analysis = 1 OR include_in_analysis IS NULL)
            AND (is_deleted IS NULL OR is_deleted = 0)
            AND user_id = ?
            """,
            (user_id,)
        )
        # For withdrawals (negative amounts), flip to positive so XIRR sign logic works:
        #   calculate_mwrr forces WITHDRAWAL â†’ +abs(amount)
        if not cash_deposits_for_mwrr.empty:
            _wd_mask = cash_deposits_for_mwrr['type'] == 'WITHDRAWAL'
            if _wd_mask.any():
                cash_deposits_for_mwrr.loc[_wd_mask, 'amount'] = \
                    cash_deposits_for_mwrr.loc[_wd_mask, 'amount'].abs()
        # Convert USD deposits to KWD so all MWRR cash flows are in a single currency
        if not cash_deposits_for_mwrr.empty and 'currency' in cash_deposits_for_mwrr.columns:
            _usd_kwd_rate = st.session_state.get("usd_to_kwd", 0.307)
            _usd_mask = cash_deposits_for_mwrr['currency'].str.upper() == 'USD'
            if _usd_mask.any():
                cash_deposits_for_mwrr.loc[_usd_mask, 'amount'] = (
                    cash_deposits_for_mwrr.loc[_usd_mask, 'amount'] * _usd_kwd_rate
                )
            cash_deposits_for_mwrr = cash_deposits_for_mwrr.drop(columns=['currency'])
    except Exception:
        cash_deposits_for_mwrr = pd.DataFrame(columns=['date', 'amount', 'type', 'source'])
    
    # 2. NON-REINVESTED DIVIDENDS ONLY (CASH PAID OUT = POSITIVE)
    # Exclude reinvested dividends from IRR calculation
    try:
        cash_dividends_only = query_df(
            """
            SELECT txn_date as date, 
                   COALESCE(cash_dividend, 0) as amount, 
                   'DIVIDEND' as type,
                   'transactions' as source
            FROM transactions 
            WHERE COALESCE(cash_dividend, 0) > 0
            AND txn_date IS NOT NULL
            AND txn_date > '1971-01-01'
            AND (is_deleted IS NULL OR is_deleted = 0)
            AND user_id = ?
            """,
            (user_id,)
        )
    except Exception:
        cash_dividends_only = pd.DataFrame(columns=['date', 'amount', 'type', 'source'])
    
    # FOR TWR: Still use cash_deposits with include_in_analysis flag (exclude soft-deleted if column exists)
    user_id = st.session_state.get('user_id', 1)
    _soft_del_dep = _soft_delete_filter_deposits()
    try:
        deposits_for_twr = query_df(
            f"SELECT deposit_date as date, amount, 'DEPOSIT' as type FROM cash_deposits WHERE include_in_analysis = 1{_soft_del_dep} AND user_id = ?",
            (user_id,)
        )
    except Exception:
        deposits_for_twr = pd.DataFrame(columns=['date', 'amount', 'type'])
    
    # Withdrawals (Explicit Withdrawals Only - NOT Sells)
    # Using the new General Ledger 'Withdrawal' type
    try:
        withdrawals = query_df(
            """
            SELECT txn_date, sell_value, 'WITHDRAWAL' as type
            FROM transactions
            WHERE (txn_type = 'Withdrawal' OR category = 'FLOW_OUT')
            AND user_id = ?
            """,
            (user_id,)
        )
        withdrawals = withdrawals.rename(columns={'txn_date': 'date', 'sell_value': 'amount'})
    except Exception:
        withdrawals = pd.DataFrame(columns=['date', 'amount', 'type'])
    
    # NEW: Additional Deposits from General Ledger (Type = Deposit)
    # Merging with legacy cash_deposits
    try:
        ledger_deposits = query_df(
            """
            SELECT txn_date, purchase_cost, 'DEPOSIT' as type
            FROM transactions
            WHERE (txn_type = 'Deposit' OR category = 'FLOW_IN')
            AND user_id = ?
            """,
            (user_id,)
        )
        ledger_deposits = ledger_deposits.rename(columns={'txn_date': 'date', 'purchase_cost': 'amount'})
    except Exception:
        ledger_deposits = pd.DataFrame(columns=['date', 'amount', 'type'])

    # Transfer In of Assets (e.g., in-kind contributions, shares transferred in)
    # These are external flows that increase portfolio value without cash movement
    try:
        transfers_in = query_df(
            """
            SELECT txn_date, COALESCE(purchase_cost, 0) as amount, 'DEPOSIT' as type
            FROM transactions
            WHERE txn_type = 'Transfer In'
            AND user_id = ?
            """,
            (user_id,)
        )
        transfers_in = transfers_in.rename(columns={'txn_date': 'date'})
    except Exception:
        transfers_in = pd.DataFrame(columns=['date', 'amount', 'type'])
    
    # Transfer Out of Assets (e.g., in-kind withdrawals, shares transferred out)
    # These are external flows that decrease portfolio value without cash movement
    try:
        transfers_out = query_df(
            """
            SELECT txn_date, COALESCE(sell_value, 0) as amount, 'WITHDRAWAL' as type
            FROM transactions
            WHERE txn_type = 'Transfer Out'
            AND user_id = ?
            """,
            (user_id,)
        )
        transfers_out = transfers_out.rename(columns={'txn_date': 'date'})
    except Exception:
        transfers_out = pd.DataFrame(columns=['date', 'amount', 'type'])

    # Cash flows for MWRR (Legacy Cash Deposits + New Ledger Deposits + Dividends + Withdrawals + Transfers)
    # NOTE: Reinvested dividends are EXCLUDED (they stay in portfolio value)
    mwrr_components = []
    if not cash_deposits_for_mwrr.empty:
        mwrr_components.append(cash_deposits_for_mwrr)
    if not ledger_deposits.empty:
        mwrr_components.append(ledger_deposits)
    if not cash_dividends_only.empty:
        mwrr_components.append(cash_dividends_only)
    if not withdrawals.empty:
        mwrr_components.append(withdrawals)
    if not transfers_in.empty:
        mwrr_components.append(transfers_in)
    if not transfers_out.empty:
        mwrr_components.append(transfers_out)
    
    if mwrr_components:
        cash_flows_mwrr = pd.concat(mwrr_components, ignore_index=True).sort_values('date')
    else:
        cash_flows_mwrr = pd.DataFrame(columns=['date', 'amount', 'type'])
    
    # Cash flows for TWR (CFA/GIPS compliant - STRICT DEFINITION)
    # Per CFA Vol 2 Ch 4: ONLY deposits/withdrawals split subperiods
    # EXCLUDES: buy/sell/dividend - these are internal reallocations, not external flows
    # 
    # TWR External Flows that break performance periods:
    #   1. Cash deposits/contributions âœ”
    #   2. Withdrawals âœ”
    #   3. Transfer in/out of assets âœ” (in-kind contributions/withdrawals)
    # 
    # EXCLUDED from TWR flows (internal reallocations):
    #   - Dividends (they are investment returns, NOT external flows)
    #   - Buy/Sell transactions (net to zero in MV change)
    twr_components = []
    if not deposits_for_twr.empty:
        twr_components.append(deposits_for_twr)
    if not ledger_deposits.empty:
        twr_components.append(ledger_deposits)
    # DIVIDENDS EXCLUDED: They are investment returns, not external flows
    # if not cash_dividends_only.empty:
    #     twr_components.append(cash_dividends_only)
    if not withdrawals.empty:
        twr_components.append(withdrawals)
    if not transfers_in.empty:
        twr_components.append(transfers_in)
    if not transfers_out.empty:
        twr_components.append(transfers_out)
    
    if twr_components:
        cash_flows_twr = pd.concat(twr_components, ignore_index=True).sort_values('date')
    else:
        cash_flows_twr = pd.DataFrame(columns=['date', 'amount', 'type'])
    
    # Calculate metrics
    calc = PortfolioCalculator()
    
    # Get inception date from ALL cash flow sources (CFA-compliant)
    # CRITICAL: Must consider BOTH cash_deposits AND transactions tables
    # The earliest date across all sources is the true inception date.
    # Bug fix: Previously only checked transactions (2022-11-01), ignoring
    # earlier cash deposits (2022-06-30), which excluded 152 days of idle cash.
    try:
        _inception_dates = []
        
        # Source 1: Earliest cash deposit
        _earliest_deposit = query_df(
            """
            SELECT MIN(deposit_date) as earliest_date
            FROM cash_deposits
            WHERE deposit_date IS NOT NULL
            AND deposit_date > '1971-01-01'
            AND amount > 0
            AND (include_in_analysis = 1 OR include_in_analysis IS NULL)
            AND (is_deleted IS NULL OR is_deleted = 0)
            AND user_id = ?
            """,
            (user_id,)
        )
        if not _earliest_deposit.empty and _earliest_deposit.iloc[0]['earliest_date']:
            _inception_dates.append(pd.to_datetime(_earliest_deposit.iloc[0]['earliest_date']).date())
        
        # Source 2: Earliest transaction
        _earliest_txn = query_df(
            """
            SELECT MIN(txn_date) as earliest_date
            FROM transactions
            WHERE txn_date IS NOT NULL
            AND txn_date > '1971-01-01'
            AND user_id = ?
            """,
            (user_id,)
        )
        if not _earliest_txn.empty and _earliest_txn.iloc[0]['earliest_date']:
            _inception_dates.append(pd.to_datetime(_earliest_txn.iloc[0]['earliest_date']).date())
        
        # CFA-compliant: inception = earliest date across ALL sources
        inception_date = min(_inception_dates) if _inception_dates else None
    except Exception:
        inception_date = None
    
    # Get current value and other metrics from portfolio history
    if not portfolio_history.empty:
        # End date: Last snapshot date (current valuation date)
        current_date = pd.to_datetime(portfolio_history.iloc[-1]['date']).date()
        
        # Fallback inception date to first snapshot if no transactions found
        if inception_date is None:
            inception_date = pd.to_datetime(portfolio_history.iloc[0]['date']).date()
        
        # Starting value: ONLY the initial investment (first accumulated_cash)
        # This excludes subsequent deposits from the growth calculation
        initial_investment = portfolio_history.iloc[0]['accumulated_cash']
        if pd.isna(initial_investment) or initial_investment <= 0:
            initial_investment = portfolio_history.iloc[0]['balance']
        
        # Ending value: Current portfolio value
        current_portfolio_value = portfolio_history.iloc[-1]['balance']
        
        # Total invested (for reference)
        total_invested = portfolio_history.iloc[-1]['accumulated_cash']
        if pd.isna(total_invested):
            total_invested = initial_investment
            
        # Calculate precise time period using transaction-based inception date
        days_elapsed = (current_date - inception_date).days
        years_elapsed = days_elapsed / 365.25
        
    else:
        if inception_date is None:
            inception_date = date.today()
        current_date = date.today()
        current_portfolio_value = 0
        total_invested = 0
        initial_investment = 0
        years_elapsed = 0
    
    # Calculate TWR using Modified TWR Calculator (full history with MV reconstruction)
    # This uses dynamic deposit handling and KSE index proxy for pre-snapshot periods
    twr = None
    twr_details = None
    if _MODIFIED_TWR_AVAILABLE:
        try:
            twr_result = calculate_modified_twr()
            if twr_result and 'twr_decimal' in twr_result:
                twr = twr_result['twr_decimal']
                twr_details = twr_result
        except Exception as e:
            logger.warning(f"Modified TWR calculation failed: {e}, falling back to original")
            twr = calc.calculate_twr(portfolio_history, cash_flows_twr)
    else:
        # Fallback to original TWR calculation if module not available
        twr = calc.calculate_twr(portfolio_history, cash_flows_twr)
    
    # Calculate MWRR (uses only cash dividends - reinvested are not cash flows)
    # Debug: log key values
    _mwrr_debug = {
        'cash_flows_mwrr_count': len(cash_flows_mwrr),
        'current_portfolio_value': current_portfolio_value,
        'inception_date': str(inception_date),
        'user_id': user_id
    }
    mwrr = calc.calculate_mwrr(cash_flows_mwrr, current_portfolio_value, inception_date)
    
    # â”€â”€ CAGR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # WARNING: CAGR is NOT a performance metric per CFA/GIPS standards.
    # WARNING: It ignores ALL intermediate cash flows (deposits/withdrawals).
    # WARNING: Later deposits artificially inflate V_end without affecting V_start.
    # WARNING: Example: 10k initial + 90k later deposits â†’ 105k final = 65% CAGR
    #          even though initial 10k only grew 5% â†’ MISLEADING.
    # RECOMMENDATION: Use TWR for investment skill, IRR for wealth growth.
    # CAGR USE CASE: Simple descriptive statistic ONLY (not for performance reporting).
    #
    # V_start = FIRST deposit amount from cash_deposits (NOT snapshot accumulated_cash)
    # V_end   = current portfolio value from latest snapshot
    # t       = years from first deposit date to latest snapshot date
    try:
        _cagr_first_dep = query_df(
            """
            SELECT deposit_date, amount
            FROM cash_deposits
            WHERE deposit_date IS NOT NULL
            AND deposit_date > '1971-01-01'
            AND amount > 0
            AND (include_in_analysis = 1 OR include_in_analysis IS NULL)
            AND (is_deleted IS NULL OR is_deleted = 0)
            AND user_id = ?
            ORDER BY deposit_date ASC
            LIMIT 1
            """,
            (user_id,)
        )
        if not _cagr_first_dep.empty:
            _cagr_v_start = float(_cagr_first_dep.iloc[0]['amount'])
            _cagr_inception = pd.to_datetime(_cagr_first_dep.iloc[0]['deposit_date']).date()
        else:
            _cagr_v_start = initial_investment
            _cagr_inception = inception_date
    except Exception:
        _cagr_v_start = initial_investment
        _cagr_inception = inception_date

    _cagr_days = (current_date - _cagr_inception).days if _cagr_inception else 0
    _cagr_years = _cagr_days / 365.25 if _cagr_days > 0 else 0

    if _cagr_v_start > 0 and _cagr_years > 0 and current_portfolio_value > 0:
        cagr = (current_portfolio_value / _cagr_v_start) ** (1 / _cagr_years) - 1
    else:
        cagr = None
    
    # â”€â”€ Win Rate calculation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    win_rate_data = PortfolioCalculator.calculate_win_rate(get_conn(), user_id)

    # ======================
    # PERFORMANCE HEATMAP
    # ======================
    st.markdown('<div class="section-header"><div class="section-icon green">âš¡</div><div class="section-title">Performance Metrics</div></div>', unsafe_allow_html=True)

    heatmap_cols = st.columns(2)

    with heatmap_cols[0]:
        st.markdown('<div class="heatmap-container">', unsafe_allow_html=True)

        # TWR Card
        _twr_pct = twr * 100 if twr is not None else None
        _twr_class = "positive" if twr is not None and twr >= 0 else "negative" if twr is not None and twr < 0 else ""
        _twr_sub = "Eliminates impact of cash flows â€¢ Since inception"
        if twr_details:
            _sp_count = twr_details.get('subperiod_count', 0)
            _twr_sub = f"{twr_details.get('period_start', '')} â†’ {twr_details.get('period_end', '')} â€¢ {_sp_count} subperiods"
        st.markdown(f"""
        <div class="heatmap-card {_twr_class}">
            <div class="heatmap-label">â±ï¸ Time-Weighted Return (TWR)</div>
            <div class="heatmap-value">{f'{_twr_pct:.2f}%' if _twr_pct is not None else 'N/A'}</div>
            <div class="heatmap-sub">{_twr_sub}</div>
        </div>
        """, unsafe_allow_html=True)

        # MWRR Card
        _mwrr_pct = mwrr * 100 if mwrr is not None else None
        _mwrr_class = "positive" if mwrr is not None and mwrr >= 0 else "negative" if mwrr is not None and mwrr < 0 else ""
        st.markdown(f"""
        <div class="heatmap-card {_mwrr_class}">
            <div class="heatmap-label">ðŸ’µ Money-Weighted Return (IRR)</div>
            <div class="heatmap-value">{f'{_mwrr_pct:.2f}%' if _mwrr_pct is not None else 'N/A'}</div>
            <div class="heatmap-sub">Personal wealth growth â€¢ Includes deposit timing</div>
        </div>
        """, unsafe_allow_html=True)

        # CAGR Card
        _cagr_pct = cagr * 100 if cagr is not None else None
        _cagr_class = "positive" if cagr is not None and cagr >= 0 else "negative" if cagr is not None and cagr < 0 else ""
        _cagr_sub_text = f"{_cagr_inception} â†’ {current_date} ({_cagr_years:.1f}y) Â· Vâ‚€ = {_cagr_v_start:,.0f} KWD" if cagr is not None else "Insufficient data"
        st.markdown(f"""
        <div class="heatmap-card {_cagr_class}">
            <div class="heatmap-label">ðŸ“Š Compound Annual Growth (CAGR)</div>
            <div class="heatmap-value">{f'{_cagr_pct:.2f}%' if _cagr_pct is not None else 'N/A'}</div>
            <div class="heatmap-sub">{_cagr_sub_text}</div>
        </div>
        """, unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)

    with heatmap_cols[1]:
        st.markdown('<div class="heatmap-container">', unsafe_allow_html=True)

        # Win Rate Card
        _wr = win_rate_data.get('win_rate')
        _wr_class = "positive" if _wr is not None and _wr > 55 else "negative" if _wr is not None and _wr < 50 else ""
        _wr_wins = win_rate_data.get('winning_trades', 0)
        _wr_losses = win_rate_data.get('losing_trades', 0)
        _wr_pf = win_rate_data.get('profit_factor', 'N/A')
        st.markdown(f"""
        <div class="heatmap-card {_wr_class}">
            <div class="heatmap-label">ðŸŽ¯ Win Rate</div>
            <div class="heatmap-value">{f'{_wr:.1f}%' if _wr is not None else 'N/A'}</div>
            <div class="heatmap-sub">{_wr_wins}W / {_wr_losses}L â€¢ PF {_wr_pf}x</div>
        </div>
        """, unsafe_allow_html=True)

        # Sharpe Ratio Card
        _sr_val = sharpe_ratio
        _sr_class = "positive" if _sr_val is not None and _sr_val > 1.0 else "negative" if _sr_val is not None and _sr_val < 0 else ""
        st.markdown(f"""
        <div class="heatmap-card {_sr_class}">
            <div class="heatmap-label">ðŸ”· Sharpe Ratio</div>
            <div class="heatmap-value">{f'{_sr_val:.2f}' if _sr_val is not None else 'N/A'}</div>
            <div class="heatmap-sub">Risk-adjusted return â€¢ CBK Rate: {rf_rate_percent:.2f}%</div>
        </div>
        """, unsafe_allow_html=True)

        # Sortino Ratio Card
        _so_val = sortino_ratio
        _so_class = "positive" if _so_val is not None and _so_val > 2.0 else "negative" if _so_val is not None and _so_val < 1.0 else ""
        st.markdown(f"""
        <div class="heatmap-card {_so_class}">
            <div class="heatmap-label">ðŸ”¶ Sortino Ratio</div>
            <div class="heatmap-value">{f'{_so_val:.2f}' if _so_val is not None else 'N/A'}</div>
            <div class="heatmap-sub">Downside risk focus â€¢ MAR: 0%</div>
        </div>
        """, unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)

    # ======================
    # RISK-ADJUSTED PERFORMANCE (4-Column)
    # ======================
    st.markdown('<div class="section-header"><div class="section-icon blue">ðŸ›¡ï¸</div><div class="section-title">Risk-Adjusted Performance</div></div>', unsafe_allow_html=True)

    risk_col1, risk_col2, risk_col3, risk_col4 = st.columns(4)

    with risk_col1:
        _sr_class = "positive" if sharpe_ratio is not None and sharpe_ratio > 1.0 else "negative" if sharpe_ratio is not None and sharpe_ratio < 0 else ""
        _sr_icon = "positive" if sharpe_ratio is not None and sharpe_ratio > 1.0 else "negative" if sharpe_ratio is not None and sharpe_ratio < 0 else "primary"
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon {_sr_icon}">ðŸ”·</div>
            <div class="metric-label">SHARPE RATIO</div>
            <div class="metric-value {_sr_class}">{f'{sharpe_ratio:.2f}' if sharpe_ratio is not None else 'N/A'}</div>
            <div class="metric-sub">Risk-adjusted return â€¢ CBK: {rf_rate_percent:.2f}%</div>
        </div>
        """, unsafe_allow_html=True)

    with risk_col2:
        _so_class = "positive" if sortino_ratio is not None and sortino_ratio > 2.0 else "negative" if sortino_ratio is not None and sortino_ratio < 1.0 else ""
        _so_icon = "positive" if sortino_ratio is not None and sortino_ratio > 2.0 else "negative" if sortino_ratio is not None and sortino_ratio < 1.0 else "warning"
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon {_so_icon}">ðŸ”¶</div>
            <div class="metric-label">SORTINO RATIO</div>
            <div class="metric-value {_so_class}">{f'{sortino_ratio:.2f}' if sortino_ratio is not None else 'N/A'}</div>
            <div class="metric-sub">Downside risk focus â€¢ MAR: 0%</div>
        </div>
        """, unsafe_allow_html=True)

    with risk_col3:
        _wr2 = win_rate_data.get('win_rate')
        _wr2_class = "positive" if _wr2 is not None and _wr2 > 55 else "negative" if _wr2 is not None and _wr2 < 50 else ""
        _wr2_icon = "positive" if _wr2 is not None and _wr2 > 55 else "negative" if _wr2 is not None and _wr2 < 50 else "primary"
        _wr2_wins = win_rate_data.get('winning_trades', 0)
        _wr2_losses = win_rate_data.get('losing_trades', 0)
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon {_wr2_icon}">ðŸŽ¯</div>
            <div class="metric-label">WIN RATE</div>
            <div class="metric-value {_wr2_class}">{f'{_wr2:.1f}%' if _wr2 is not None else 'N/A'}</div>
            <div class="metric-sub">{_wr2_wins}W / {_wr2_losses}L trades</div>
        </div>
        """, unsafe_allow_html=True)

    with risk_col4:
        _pf_raw = win_rate_data.get('profit_factor')
        try:
            _pf_val = float(_pf_raw) if _pf_raw is not None else None
        except (ValueError, TypeError):
            _pf_val = None
        _pf_class = "positive" if _pf_val is not None and _pf_val > 1.5 else "negative" if _pf_val is not None and _pf_val < 1.0 else ""
        _pf_icon = "positive" if _pf_val is not None and _pf_val > 1.5 else "negative" if _pf_val is not None and _pf_val < 1.0 else "purple"
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon {_pf_icon}">âš–ï¸</div>
            <div class="metric-label">PROFIT FACTOR</div>
            <div class="metric-value {_pf_class}">{f'{_pf_val:.2f}x' if _pf_val is not None else 'N/A'}</div>
            <div class="metric-sub">Gross profits / Gross losses</div>
        </div>
        """, unsafe_allow_html=True)

    # MWRR Debug (collapsed)
    with st.expander("ðŸ”§ MWRR Debug Info", expanded=False):
        st.write(f"**User ID:** {user_id}")
        st.write(f"**Portfolio History Rows:** {len(portfolio_history)}")
        st.write(f"**Cash Flows for MWRR:** {len(cash_flows_mwrr)}")
        st.write(f"**Current Portfolio Value:** {current_portfolio_value:,.2f}")
        st.write(f"**Inception Date (from deposits + transactions):** {inception_date}")
        st.write(f"**MWRR Result:** {mwrr}")
        if not cash_flows_mwrr.empty:
            st.write("**Cash Flow Sample (first 5):**")
            st.dataframe(cash_flows_mwrr.head(5))

    # --- Calculate Portfolio P/E ---
    # 1. Gather all holdings
    all_holdings = []
    for port_name in PORTFOLIO_CCY.keys():
        df_port = build_portfolio_table(port_name)
        if not df_port.empty and "Symbol" in df_port.columns:
            # We need Symbol, Currency, Market Value (for weighting)
            # Convert Market Value to KWD for consistent weighting
            for _, row in df_port.iterrows():
                mv_kwd = convert_to_kwd(row['Market Value'], row['Currency'])
                all_holdings.append({
                    "Symbol": row['Symbol'],
                    "Currency": row['Currency'],
                    "Market Value KWD": mv_kwd
                })
    
    portfolio_pe_display = "N/A"
    portfolio_earnings_yield_display = "N/A"
    
    if all_holdings:
        holdings_df = pd.DataFrame(all_holdings)
        
        # Fetch P/E Ratios
        # We need unique symbols
        unique_items = tuple(set(zip(holdings_df["Symbol"], holdings_df["Currency"])))  # tuple for cache
        pe_map = get_pe_ratios(unique_items)
        
        holdings_df["PE"] = holdings_df["Symbol"].map(pe_map)
        
        # Filter Valid Holdings: Keep only stocks with pe > 0
        # Convert PE to numeric first
        holdings_df["PE"] = pd.to_numeric(holdings_df["PE"], errors='coerce')
        valid_holdings = holdings_df[holdings_df["PE"] > 0].copy()
        
        if not valid_holdings.empty:
            # Re-normalize Weights
            total_valid_weight = valid_holdings["Market Value KWD"].sum()
            
            if total_valid_weight > 0:
                valid_holdings["adjusted_weight"] = valid_holdings["Market Value KWD"] / total_valid_weight
                
                # Compute Earnings Yield for Each Valid Holding
                valid_holdings["earnings_yield"] = 1 / valid_holdings["PE"]
                
                # Calculate Portfolio Earnings Yield
                portfolio_earnings_yield = (valid_holdings["adjusted_weight"] * valid_holdings["earnings_yield"]).sum()
                
                # Derive Portfolio P/E
                if portfolio_earnings_yield > 0:
                    portfolio_pe = 1 / portfolio_earnings_yield
                    portfolio_pe_display = f"{portfolio_pe:.2f}"
                    portfolio_earnings_yield_display = f"{portfolio_earnings_yield:.2%}"

    # Calculate Cash Yield Dividend
    cash_yield_dividend_display = "N/A"
    if total_deposits_kwd > 0:
        cash_yield_val = total_dividends_kwd / total_deposits_kwd
        cash_yield_dividend_display = f"{cash_yield_val:.2%}"

    # ======================
    # VALUATION METRICS
    # ======================
    st.markdown('<div class="section-header"><div class="section-icon purple">ðŸ“‰</div><div class="section-title">Valuation Metrics</div></div>', unsafe_allow_html=True)

    val_col1, val_col2 = st.columns(2)

    with val_col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon purple">ðŸ·ï¸</div>
            <div class="metric-label">PORTFOLIO P/E RATIO</div>
            <div class="metric-value">{portfolio_pe_display}</div>
            <div class="metric-sub">Earnings Yield: {portfolio_earnings_yield_display}</div>
        </div>
        """, unsafe_allow_html=True)

    with val_col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon pink">ðŸ’¸</div>
            <div class="metric-label">CASH YIELD DIVIDEND</div>
            <div class="metric-value">{cash_yield_dividend_display}</div>
            <div class="metric-sub">Dividends / Total Deposits</div>
        </div>
        """, unsafe_allow_html=True)

    # ======================
    # AI SECTION
    # ======================
    st.markdown('<div class="section-header"><div class="section-icon pink">ðŸ¤–</div><div class="section-title">AI Financial Intelligence</div></div>', unsafe_allow_html=True)

    with st.expander("âœ¨ Generate Professional Investment Report", expanded=False):
        st.caption("Get AI-powered insights, recommendations, and PDF reports based on your portfolio data")

        # 1. API Key Check
        # Check for key in Session or DB
        if "gemini_api_key" not in st.session_state or not st.session_state.gemini_api_key:
            conn = get_conn()
            cur = conn.cursor()
            db_execute(cur, "SELECT gemini_api_key FROM users WHERE id = ?", (user_id,))
            res = cur.fetchone()
            conn.close()
            if res and res[0]:
                st.session_state.gemini_api_key = res[0]

        api_key = st.text_input(
            "Google Gemini API Key", 
            type="password", 
            value=st.session_state.get("gemini_api_key", ""),
            help="Get free key: https://aistudio.google.com/app/apikey",
            key="overview_ai_key"
        )

        if api_key:
            st.session_state.gemini_api_key = api_key
            # Save to DB if changed
            try:
                conn = get_conn()
                cur = conn.cursor()
                db_execute(cur, "UPDATE users SET gemini_api_key = ? WHERE id = ?", (api_key, user_id))
                conn.commit()
                conn.close()
            except Exception as e:
                pass  # Silent save
            
            try:
                import google.generativeai as genai
                genai.configure(api_key=api_key)
            except ImportError:
                st.error("Library missing: pip install google-generativeai")
                st.stop()

            # 2. Prompt Library
            prompts = {
                "ðŸ§  Portfolio Recommendations": [
                    "Analyze my portfolio and recommend what to Buy, Hold, or Sell.",
                    "What are the top risks in my portfolio right now?",
                    "Suggest rebalancing actions for better returns & lower risk.",
                    "Tell me which stock is dragging down my performance.",
                    "If I want a safer portfolio, what should I adjust?"
                ],
                "ðŸ“Š Benchmark & Comparison": [
                    "Compare my portfolio performance vs Kuwait market (Boursa).",
                    "Compare my portfolio vs S&P 500 / NASDAQ.",
                    "Compare my portfolio to an ideal diversified portfolio.",
                    "How does my return compare to a professional fund manager?"
                ],
                "ðŸ’° Income & Dividends": [
                    "Predict my dividends for the next 12 months.",
                    "Show me how to maximize my annual dividend income.",
                    "How close am I to financial independence using dividends?"
                ],
                "ðŸ“ˆ Growth Forecast": [
                    "Project my portfolio value in 1, 3, 5 years.",
                    "If I invest 500 KWD monthly, what will my net worth become?"
                ],
                "ðŸ§© Investor Strategy": [
                    "Analyze my portfolio using Warren Buffett principles.",
                    "Analyze my portfolio using Charlie Munger's mental models.",
                    "Evaluate my portfolio the way Peter Lynch would.",
                    "Explain my portfolio as if I am a value investor.",
                    "Explain my portfolio as if I am a growth investor."
                ],
                "ðŸ§  AI Financial Coaching": [
                    "Am I on track to reach 1,000,000 KWD in net worth?",
                    "Identify my bad trading habits and how to fix them.",
                    "Tell me the weaknesses in my portfolio."
                ],
                "ðŸ“„ Professional Reports": [
                    "Create a monthly portfolio report.",
                    "Create a risk report for my portfolio.",
                    "Create a Warren Buffett-style commentary on my portfolio."
                ],
                "âš¡ Stock Specific": [
                    "Analyze my largest holding and give a recommendation.",
                    "Tell me if my entry prices were good."
                ]
            }

            c_nav, c_main = st.columns([1, 2])

            with c_nav:
                st.markdown("### ðŸ“š Analysis Type")
                selected_category = st.selectbox("Select Category", list(prompts.keys()), key="ov_ai_cat")
                selected_prompt = st.radio("Choose Analysis:", prompts[selected_category], label_visibility="collapsed", key="ov_ai_radio")

            with c_main:
                st.markdown("### ðŸ’¬ Your Inquiry")
                custom_query = st.text_area(
                    "Selected Prompt (or type your own):", 
                    value=selected_prompt,
                    height=100,
                    key="ov_ai_input"
                )
                
                generate = st.button("ðŸš€ Run Analysis & Generate Report", type="primary", width="stretch", key="ov_ai_btn")

            # 3. Generation Logic
            if generate:
                # STRICT USER CHECK
                if not user_id:
                    st.error("You must be logged in to analyze data.")
                    st.stop()
                
                # Fetch comprehensive user data
                context_data = get_full_financial_context(user_id)
                
                # Check if context has errors
                if context_data.startswith("ERROR") or context_data.startswith("CRITICAL"):
                    st.error(context_data)
                    st.stop()
                
                # DEBUG: Show the user exactly what data is being sent to AI
                with st.expander("ðŸ‘ï¸ View Your Data Sent to AI (Debug)", expanded=False):
                    st.info("This is the exact financial data the AI will analyze:")
                    st.text_area("Context Payload", context_data, height=400, disabled=True)
                    st.caption(f"Data size: {len(context_data):,} characters")

                with st.spinner("ðŸ¤– Analyzing your financial data..."):
                    try:
                        # Construct intelligent prompt based on query type
                        query_lower = custom_query.lower()
                        
                        # Determine focus area based on query
                        focus_instructions = ""
                        if any(word in query_lower for word in ['dividend', 'income', 'yield']):
                            focus_instructions = "Focus especially on Section 3 (DIVIDENDS RECEIVED) for this analysis."
                        elif any(word in query_lower for word in ['trade', 'trading', 'realized', 'profit']):
                            focus_instructions = "Focus especially on Sections 4-5 (TRADING HISTORY) for this analysis."
                        elif any(word in query_lower for word in ['net worth', 'assets', 'liabilities', 'debt']):
                            focus_instructions = "Focus especially on Section 6 (PERSONAL FINANCE) for this analysis."
                        elif any(word in query_lower for word in ['performance', 'roi', 'return', 'growth']):
                            focus_instructions = "Focus especially on Section 7 (PERFORMANCE SUMMARY) for this analysis."
                        elif any(word in query_lower for word in ['hold', 'portfolio', 'stock', 'position']):
                            focus_instructions = "Focus especially on Section 1 (STOCK PORTFOLIOS) for this analysis."
                        
                        full_prompt = f"""
You are a Senior CFO and Financial Analyst providing personalized advice.

**USER'S QUESTION:** "{custom_query}"

**IMPORTANT:** The following is the USER'S ACTUAL SAVED FINANCIAL DATA. Use ONLY this data for your analysis.
Do NOT make up numbers, stocks, or transactions that are not in this data.

---
{context_data}
---

**ANALYSIS INSTRUCTIONS:**
1. {focus_instructions if focus_instructions else "Analyze all relevant sections based on the user's question."}
2. Reference SPECIFIC numbers, stocks, and dates from the data above.
3. If asked about something not in the data, clearly state "This data is not available in your records."
4. All monetary values should be in KWD (Kuwaiti Dinar) unless the data specifies USD.
5. Provide actionable recommendations based on the actual data.
6. Format your response with:
   - **Bold** for key numbers and metrics
   - Bullet points for recommendations
   - Clear section headers

If the data shows "No active stock holdings" or empty sections, acknowledge this and provide guidance on next steps.
"""

                        # Safe Cascading Call to AI
                        analysis_text, used_model = generate_content_safe(full_prompt)
                        
                        st.session_state['overview_ai_analysis'] = analysis_text
                        st.success(f"âœ… Analysis generated using: {used_model}")
                        
                    except Exception as e:
                        import google.generativeai as genai
                        error_msg = str(e)
                        
                        st.error(f"âŒ All AI models failed.")
                        
                        with st.expander("ðŸ”§ Troubleshooting Info", expanded=True):
                            st.write(f"**Library Version:** {genai.__version__}")
                            st.code(error_msg, language="text")
                            
                            if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
                                st.warning("ðŸ’¡ **All models hit rate limits.** Wait 1-2 minutes and try again.")
                            elif "404" in error_msg:
                                st.warning("ðŸ’¡ **Models not found.** Your API key may not have access to these models.")
                            else:
                                st.info("ðŸ’¡ **Fix:** Check your API key is valid. Try: `pip install -U google-generativeai`")

            # 4. Result & Export
            if 'overview_ai_analysis' in st.session_state:
                st.divider()
                st.markdown("### ðŸ“„ Analyst Report")
                st.markdown(st.session_state['overview_ai_analysis'])
                
                # PDF Generation
                pdf_data = create_pdf_report(st.session_state['overview_ai_analysis'])
                
                if pdf_data:
                    st.download_button(
                        label="â¬‡ï¸ Download Report as PDF",
                        data=pdf_data,
                        file_name=f"Portfolio_Report_{datetime.now().strftime('%Y%m%d')}.pdf",
                        mime="application/pdf",
                        key="ov_ai_pdf"
                    )
                else:
                    st.info("PDF export requires: pip install reportlab")
        else:
            st.info("ðŸ”‘ Please enter API Key to enable AI features.")
            st.markdown("[ðŸ‘‰ Get Free API Key](https://aistudio.google.com/app/apikey)")

    # ======================
    # FOOTER (Theme-Aware)
    # ======================
    _footer_class = 'neon-footer' if is_dark else 'light-footer'
    _badge_bg = 'rgba(255, 255, 255, 0.05)' if is_dark else 'rgba(99, 102, 241, 0.06)'
    _badge_glow1 = 'text-shadow: 0 0 10px rgba(138, 43, 226, 0.3);' if is_dark else ''
    _badge_glow2 = 'text-shadow: 0 0 10px rgba(76, 201, 240, 0.3);' if is_dark else ''
    st.markdown(f"""
    <div class="{_footer_class}">
        <div style="display: flex; justify-content: space-between; flex-wrap: wrap; gap: 1.5rem;">
            <div>
                <div style="font-size: 1.1rem; font-weight: 700; color: var(--text-primary); margin-bottom: 0.5rem; letter-spacing: -0.5px;">
                    ðŸ“ˆ Portfolio Intelligence Dashboard
                </div>
                <div style="color: var(--text-secondary); line-height: 1.6; font-size: 0.95rem;">
                    Real-time analytics â€¢ Risk-adjusted returns â€¢ AI-powered insights<br>
                    Data updated: <strong>{datetime.now().strftime("%b %d, %Y at %I:%M %p")}</strong> â€¢ All values in KWD
                </div>
            </div>
            <div style="display: flex; align-items: center; gap: 1rem;">
                <div style="background: {_badge_bg}; border-radius: 12px; padding: 0.75rem 1.25rem; text-align: center; border: 1px solid var(--section-border-color);">
                    <div style="font-weight: 700; font-size: 1.4rem; color: var(--accent-primary); margin-bottom: 0.25rem; {_badge_glow1}">
                        {num_stocks}
                    </div>
                    <div style="color: var(--text-secondary); font-size: 0.9rem;">Active Stocks</div>
                </div>
                <div style="background: {_badge_bg}; border-radius: 12px; padding: 0.75rem 1.25rem; text-align: center; border: 1px solid var(--section-border-color);">
                    <div style="font-weight: 700; font-size: 1.4rem; color: var(--accent-secondary); margin-bottom: 0.25rem; {_badge_glow2}">
                        {num_txns}
                    </div>
                    <div style="color: var(--text-secondary); font-size: 0.9rem;">Total Transactions</div>
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)


# =========================
# PEER ANALYSIS HELPERS
# =========================

@st.cache_data(ttl=3600*12)  # Cache for 12 hours
def fetch_single_peer_data(ticker):
    """Fetch extensive data for a single ticker to optimize performance."""
    # Lazy-load yfinance
    if not _ensure_yfinance():
        return {"error": "yfinance not loaded"}
        
    try:
        # Use cached Ticker object for efficiency
        t = _get_yf_ticker(ticker)
        if t is None:
            return {"error": "Failed to create Ticker"}
        info = t.info
        
        # Fetch history for total return calcs (10y to be safe)
        # Use 'max' or '10y'
        hist = t.history(period="10y")
        
        data = {
            "info": info,
            "history": hist,
            "financials": t.financials,
            "balance_sheet": t.balance_sheet
        }
        return data
    except Exception as e:
        return {"error": str(e)}

def calculate_peer_metrics(hist, info, financials):
    """
    Calculate advanced metrics:
    - calc_ret_*: Time-period returns (1Mo, 3Mo, 1Y...)
    - calc_cagr_*: Revenue/NetIncome/EPS CAGRs (3Y)
    - calc_net_debt, calc_capex
    """
    metrics = {}
    
    # --- 1. Historical Returns ---
    if not hist.empty:
        current_price = info.get("regularMarketPrice") or info.get("currentPrice")
        if not current_price:
            current_price = hist["Close"].iloc[-1]
            
        def get_ret(days_ago):
            target_date = pd.Timestamp.now(tz=hist.index.tz) - pd.Timedelta(days=days_ago)
            # Find closest date before target
            try:
                idx = hist.index.get_indexer([target_date], method='nearest')[0]
                if idx < 0 or idx >= len(hist):
                    # If target is too far back (beyond start of data), and we asked for < 5 years, invalid.
                    # If > 5 years, maybe use start price. 
                    if days_ago > 365*5 and len(hist) > 0:
                         past_price = hist["Close"].iloc[0] 
                    else:
                        return None
                else:
                    past_price = hist["Close"].iloc[idx]
                
                if past_price and past_price > 0:
                    return (current_price - past_price) / past_price
            except Exception:
                return None
            return None

        # YTD
        try:
            current_year = pd.Timestamp.now().year
            ytd_start = pd.Timestamp(f"{current_year-1}-12-31").tz_localize(hist.index.tz)
            if ytd_start >= hist.index[0]:
                ytd_idx = hist.index.get_indexer([ytd_start], method='bfill')[0]
                if ytd_idx >= 0 and ytd_idx < len(hist):
                     ytd_price = hist["Close"].iloc[ytd_idx]
                     metrics["calc_ret_ytd"] = (current_price - ytd_price) / ytd_price
        except Exception:
            pass

        metrics["calc_ret_1mo"] = get_ret(30)
        metrics["calc_ret_3mo"] = get_ret(90)
        metrics["calc_ret_6mo"] = get_ret(180)
        metrics["calc_ret_9mo"] = get_ret(270)
        metrics["calc_ret_1y"] = get_ret(365)
        metrics["calc_ret_3y"] = get_ret(365*3)
        metrics["calc_ret_5y"] = get_ret(365*5)
        metrics["calc_ret_10y"] = get_ret(365*10)

    # --- 2. Advanced Calcs (CAGR, Debt, Capex) ---
    
    # Net Debt
    try:
        total_debt = info.get("totalDebt")
        total_cash = info.get("totalCash")
        if total_debt is not None and total_cash is not None:
             metrics["calc_net_debt"] = total_debt - total_cash
    except:
        pass

    # CapEx = Operating Cash Flow - Free Cash Flow (Approx)
    try:
        ocf = info.get("operatingCashflow")
        fcf = info.get("freeCashflow")
        if ocf is not None and fcf is not None:
             metrics["calc_capex"] = ocf - fcf
    except:
        pass
        
    # CAGRs (3 Year) from Financials
    # Financials columns are dates. 0 is TTM/CurrentYear, 1 is LastYear, etc.
    # We will try to grab column 0 and column 3 (3 years ago). 
    if financials is not None and not financials.empty and len(financials.columns) >= 4:
         def calc_cagr(row_name):
             try:
                 row_name_key = row_name
                 # Sometimes keys differ slightly in strict strings
                 if row_name_key not in financials.index:
                     # Try lenient matching or predefined keys
                     pass
                     
                 if row_name_key in financials.index:
                     start_val = financials.loc[row_name_key].iloc[3] # 3 years ago
                     end_val = financials.loc[row_name_key].iloc[0]   # Current
                     if start_val and end_val and start_val > 0 and end_val > 0:
                         return (end_val / start_val)**(1/3) - 1
             except:
                 return None
             return None
         
         metrics["calc_cagr_revenue_3y"] = calc_cagr("Total Revenue")
         metrics["calc_cagr_netincome_3y"] = calc_cagr("Net Income")
         metrics["calc_cagr_eps_3y"] = calc_cagr("Basic EPS")

    return metrics

# =========================
# UI - HELPERS
# =========================
def render_snapshot_table(df: pd.DataFrame) -> None:
    """
    Render Portfolio Snapshots with professional financial formatting.
    
    Formatting Rules:
    - Value: 2 decimal places + thousands separator
    - Daily Movement: 2 decimals, green/red coloring
    - Beginning Diff: 2 decimals + thousands separator  
    - Deposit Cash: No decimals, thousands separator
    - Accumulated Cash: No decimals, thousands separator
    - Net Gain: 2 decimals, green/red, parentheses for negative
    - Change %: 2 decimals + %, green/red
    - ROI %: 2 decimals + %, green/red
    """
    if df is None or df.empty:
        st.info("No snapshot data to display.")
        return

    is_dark = st.session_state.get("theme", "light") == "dark"

    # Theme Colors
    c_bg_card = "rgba(17, 24, 39, 0.6)" if is_dark else "rgba(255, 255, 255, 0.8)"
    c_border = "#1f2937" if is_dark else "#e5e7eb"
    c_header_bg = "rgba(31, 41, 55, 0.5)" if is_dark else "#f9fafb"
    c_text_p = "#ffffff" if is_dark else "#111827"
    c_hover = "rgba(31, 41, 55, 0.3)" if is_dark else "rgba(243, 244, 246, 0.8)"
    c_pos = "#10b981"  # Emerald Green
    c_neg = "#ef4444"  # Red

    css = f"""
    <style>
    .snap-table-wrap {{
        background-color: {c_bg_card};
        border: 1px solid {c_border};
        border-radius: 12px;
        overflow: hidden;
        margin-bottom: 1rem;
        box-shadow: 0 4px 6px -1px rgba(0,0,0,0.1);
        font-family: ui-sans-serif, system-ui, sans-serif;
    }}
    .snap-table-scroll {{ overflow-x: auto; }}
    .snap-table {{ width: 100%; border-collapse: collapse; font-size: 0.85rem; }}
    .snap-table th {{
        text-align: right; padding: 12px 16px; background: {c_header_bg};
        color: {c_text_p}; font-weight: 600; border-bottom: 1px solid {c_border};
        white-space: nowrap;
    }}
    .snap-table th:first-child {{ text-align: left; }}
    .snap-table td {{
        padding: 10px 16px; color: {c_text_p}; border-bottom: 1px solid {c_border};
        white-space: nowrap; text-align: right;
    }}
    .snap-table td:first-child {{ text-align: left; font-weight: 600; }}
    .snap-table tr:hover td {{ background-color: {c_hover}; }}
    .snap-pos {{ color: {c_pos} !important; font-weight: 600; }}
    .snap-neg {{ color: {c_neg} !important; font-weight: 600; }}
    </style>
    """

    # Column definitions with formatting rules
    columns = [
        ("snapshot_date", "Date", "date"),
        ("portfolio_value", "Value", "money_2dp"),
        ("daily_movement", "Daily Movement", "money_colored"),
        ("beginning_difference", "Beginning Diff", "money_2dp"),
        ("deposit_cash", "Deposit Cash", "money_0dp"),
        ("accumulated_cash", "Accumulated Cash", "money_0dp"),
        ("net_gain", "Net Gain", "money_colored"),
        ("change_percent", "Change %", "percent_colored"),
        ("roi_percent", "ROI %", "percent_colored"),
    ]

    # Build HTML
    html_out = [
        '<div class="snap-table-wrap"><div class="snap-table-scroll">',
        '<table class="snap-table"><thead><tr>',
    ]

    # Headers
    for col_key, col_label, _ in columns:
        html_out.append(f"<th>{html.escape(col_label)}</th>")
    html_out.append("</tr></thead><tbody>")

    # Format value based on type
    def fmt_snapshot_val(val, fmt_type):
        if pd.isna(val) or val is None:
            return "-", ""
        
        try:
            num = float(val)
        except (ValueError, TypeError):
            return str(val), ""
        
        if fmt_type == "date":
            return str(val)[:10], ""  # YYYY-MM-DD
        
        elif fmt_type == "money_2dp":
            # 2 decimal places, thousands separator
            return f"{num:,.2f}", ""
        
        elif fmt_type == "money_0dp":
            # No decimals, thousands separator
            return f"{num:,.0f}", ""
        
        elif fmt_type == "money_colored":
            # 2 decimals, green/red coloring (no parentheses)
            if num >= 0:
                return f"{num:,.2f}", "snap-pos"
            else:
                return f"{num:,.2f}", "snap-neg"
        
        elif fmt_type == "percent_colored":
            # 2 decimals with %, + sign for positive, green/red
            if num >= 0:
                return f"+{num:.2f}%", "snap-pos"
            else:
                return f"{num:.2f}%", "snap-neg"
        
        return str(val), ""

    # Processing Rows
    for _, row in df.iterrows():
        html_out.append("<tr>")
        for col_key, _, fmt_type in columns:
            val = row.get(col_key, None)
            formatted, css_class = fmt_snapshot_val(val, fmt_type)
            
            if css_class:
                html_out.append(f'<td class="{css_class}">{html.escape(str(formatted))}</td>')
            else:
                html_out.append(f'<td>{html.escape(str(formatted))}</td>')
        html_out.append("</tr>")

    html_out.append("</tbody></table></div></div>")

    st.markdown(css + "".join(html_out), unsafe_allow_html=True)


def render_styled_table(df: pd.DataFrame, highlight_logic: bool = True) -> None:
    """
    Unified renderer with GLOBAL AUTOMATIC FORMATTING.
    Uses format_financial() and detect_column_type() for consistent styling.
    
    Formatting Rules:
    - Quantity (shares, units): Thousands separator, no decimals
    - Money (values, gains, P&L): Green/Red, no decimals, brackets for negative
    - Price (market price, avg cost): 3 decimals, black
    - Percent (ROI, yield, change): 2 decimals with %, Green/Red
    """
    if df is None or df.empty:
        st.info("No data to display.")
        return

    is_dark = st.session_state.get("theme", "light") == "dark"

    # Theme Colors
    c_bg_card = "rgba(17, 24, 39, 0.6)" if is_dark else "rgba(255, 255, 255, 0.8)"
    c_border = "#1f2937" if is_dark else "#e5e7eb"
    c_header_bg = "rgba(31, 41, 55, 0.5)" if is_dark else "#f9fafb"
    c_text_p = "#ffffff" if is_dark else "#111827"
    c_hover = "rgba(31, 41, 55, 0.3)" if is_dark else "rgba(243, 244, 246, 0.8)"
    c_muted = "rgba(156, 163, 175, 0.6)"

    css = f"""
    <style>
    .univ-table-wrap {{
        background-color: {c_bg_card};
        border: 1px solid {c_border};
        border-radius: 12px;
        overflow: hidden;
        margin-bottom: 1rem;
        box-shadow: 0 4px 6px -1px rgba(0,0,0,0.1);
        font-family: ui-sans-serif, system-ui, sans-serif;
    }}
    .univ-table-scroll {{ overflow-x: auto; }}
    .univ-table {{ width: 100%; border-collapse: collapse; font-size: 0.85rem; }}
    .univ-table th {{
        text-align: right; padding: 12px 16px; background: {c_header_bg};
        color: {c_text_p}; font-weight: 600; border-bottom: 1px solid {c_border};
        white-space: nowrap;
    }}
    .univ-table th:first-child {{ text-align: left; }}
    .univ-table td {{
        padding: 10px 16px; color: {c_text_p}; border-bottom: 1px solid {c_border};
        white-space: nowrap; text-align: right;
    }}
    .univ-table td:first-child {{ text-align: left; font-weight: 600; }}
    .univ-table tr:hover td {{ background-color: {c_hover}; }}
    .t-muted {{ color: {c_muted} !important; }}
    </style>
    """

    # Build HTML
    html_out = [
        '<div class="univ-table-wrap"><div class="univ-table-scroll">',
        '<table class="univ-table"><thead><tr>',
    ]

    for col in df.columns:
        html_out.append(f"<th>{html.escape(str(col))}</th>")
    html_out.append("</tr></thead><tbody>")

    # Pre-detect column types for performance
    col_types = {col: detect_column_type(col) for col in df.columns}

    # Processing Rows
    for row in df.itertuples(index=False):
        html_out.append("<tr>")
        for col_idx, col_name in enumerate(df.columns):
            val = row[col_idx]
            
            # Handle None/NaN
            if pd.isna(val) or val is None:
                html_out.append(f'<td class="t-muted">-</td>')
                continue
            
            # Get column type
            col_type = col_types[col_name]
            
            # Format based on type
            if highlight_logic and col_type != "text":
                # Use format_financial for numeric columns
                formatted = format_financial(val, col_type, for_html=True)
                # format_financial returns HTML with spans, so don't escape it
                html_out.append(f'<td>{formatted}</td>')
            else:
                # Text columns - escape and display as-is
                display_val = str(val)
                cls = ""
                
                # Special styling for Status column
                col_lower = str(col_name).lower()
                if 'status' in col_lower:
                    if 'realized' in display_val.lower():
                        cls = "t-muted"
                
                html_out.append(f'<td class="{cls}">{html.escape(display_val)}</td>')
        
        html_out.append("</tr>")

    html_out.append("</tbody></table></div></div>")

    st.markdown(css + "".join(html_out), unsafe_allow_html=True)


# =========================
# UI - PEER ANALYSIS
# =========================
def ui_peer_analysis():
    st.subheader("ðŸ“Š Peer Analysis")
    st.caption("Compare multiple stocks side-by-side using Yahoo Finance data.")

    if 'peer_tickers' not in st.session_state:
        st.session_state.peer_tickers = []

    # Input Section
    with st.expander("âž• Add Stocks to Compare", expanded=True):
        col1, col2 = st.columns([3, 1])
        with col1:
            # Option 1: Kuwait List
            kuwait_options = get_kuwait_stock_options()
            selected_kuwait = st.selectbox(
                "Select from Kuwait Stock List",
                options=kuwait_options,
                key="peer_select_kuwait"
            )
            
            # Option 2: Manual YF Ticker (for non-Kuwait stocks)
            manual_ticker = st.text_input("Or enter generic Yahoo Finance Ticker (e.g. AAPL, TSLA)", key="peer_manual_input")

        with col2:
            st.write("") # Spacing
            st.write("") 
            if st.button("Add to List", type="primary", key="add_peer_btn"):
                ticker_to_add = None
                
                # Prioritize manual input if provided
                if manual_ticker.strip():
                    candidate = manual_ticker.strip().upper()
                    # Validate ticker format for security
                    is_valid, error_msg = validate_stock_symbol(candidate, allow_new=True)
                    if not is_valid:
                        st.error(f"Invalid ticker: {error_msg}")
                    else:
                        ticker_to_add = candidate
                elif selected_kuwait and selected_kuwait != "-- Select from Kuwait Stock List --":
                    _, _, yf_ticker = parse_kuwait_stock_selection(selected_kuwait)
                    if yf_ticker:
                        ticker_to_add = yf_ticker
                    else:
                        ticker_to_add = selected_kuwait.split(" - ")[0] # Fallback
                
                if ticker_to_add:
                    if ticker_to_add not in st.session_state.peer_tickers:
                        st.session_state.peer_tickers.append(ticker_to_add)
                        st.success(f"Added {ticker_to_add}")
                        st.rerun()
                    else:
                        st.warning("Ticker already in list.")
                elif not manual_ticker.strip():  # Only show error if no manual input was attempted
                    st.error("Please select a stock or enter a ticker.")

    st.divider()

    # Display & Manage List
    if st.session_state.peer_tickers:
        col_list, col_clear = st.columns([4, 1])
        with col_list:
            st.write(f"**Selected Peers ({len(st.session_state.peer_tickers):,})**: " + ", ".join(st.session_state.peer_tickers))
        
        with col_clear:
            if st.button("ðŸ—‘ï¸ Clear All", key="clear_all_peers", type="secondary"):
                st.session_state.peer_tickers = []
                st.rerun()
        
        with st.expander("Manage List", expanded=False):
             cols = st.columns(5)
             for i, tick in enumerate(st.session_state.peer_tickers):
                 col_idx = i % 5
                 with cols[col_idx]:
                     if st.button(f"ðŸ—‘ï¸ {tick}", key=f"rm_peer_{tick}_{i}"):
                         st.session_state.peer_tickers.remove(tick)
                         st.rerun()
        
        st.markdown("---")
        
        # ----------------------------------------------------
        # FETCH DATA & RENDER TABLES (New Implementation)
        # ----------------------------------------------------
        if st.button("ðŸš€ Fetch Data & Run Analysis", type="primary", width="stretch"):
            # Lazy-load yfinance
            if not _ensure_yfinance():
                st.error("Yahoo Finance library not available.")
                return

            # Main Progress bar for UX
            prog_bar = st.progress(0, text="Initializing...")
            
            # Dictionary to store fetched data: {ticker: {info:..., calc_returns: ...}}
            fetched_data = {}
            
            # 1. Fetch Loop
            for i, ticker in enumerate(st.session_state.peer_tickers):
                prog_bar.progress((i / len(st.session_state.peer_tickers)), text=f"Fetching data for {ticker}...")
                
                # Fetch Raw Data
                raw_data = fetch_single_peer_data(ticker)
                
                if "error" not in raw_data:
                    # Calculate Stats including new CAGRs etc.
                    metrics_calc = calculate_peer_metrics(
                        raw_data["history"], 
                        raw_data["info"], 
                        raw_data["financials"]
                    )
                    
                    fetched_data[ticker] = {
                        "info": raw_data["info"],
                        "calculated": metrics_calc,
                        "financials": raw_data["financials"],
                        "balance_sheet": raw_data["balance_sheet"]
                    }
                else:
                    st.warning(f"Failed to fetch {ticker}: {raw_data['error']}")
            
            prog_bar.empty()
            
            if not fetched_data:
                st.error("No data fetched.")
                return

            # Helper for formatting
            def fmt_val(val, metric_label, key_type):
                if val is None or (isinstance(val, float) and pd.isna(val)):
                    return "-"
                
                # Identify formatting needs based on label Keywords or prefixes
                label_lower = metric_label.lower()
                key_type_lower = key_type.lower()
                
                # 0. Date Conversion (Unix Timestamp -> String)
                # Check if "date" is in label and value is a large number (likely timestamp)
                if "date" in label_lower or "date" in key_type_lower:
                    if isinstance(val, (int, float)) and val > 1_000_000_000:
                         try:
                             return datetime.fromtimestamp(val).strftime('%Y-%m-%d')
                         except:
                             pass
                
                # Force string if not number
                if not isinstance(val, (int, float)):
                    return str(val)

                # 1. Percentages
                # Keywords: Yield, Margin, Growth, CAGR, Ratio (sometimes), Return, ROE, ROA, Perf
                # Also if key_type implies calculation which is likely % like calc_ret_
                if any(x in label_lower for x in ["yield", "margin", "growth", "cagr", "roe", "roa", "return", "perf"]):
                    # SPECIAL CASE: 5 Year Avg Dividend Yield from Yahoo is typically already a percentage (e.g. 1.41 not 0.0141)
                    # We need to detect if the value is > 0.5 (likely a whole number %) or < 0.5 (likely a decimal)
                    # But this is risky. Let's look at specific keys.
                    
                    is_dividend_yield = "yield" in label_lower or "yield" in key_type_lower
                    
                    # If it's a dividend yield and value is > 0.5, assume it's already multiplied by 100.
                    # E.g. Yahoo returns 'fiveYearAvgDividendYield': 1.86 (which means 1.86%)
                    # while 'dividendYield': 0.014 (which means 1.4%)
                    if is_dividend_yield and abs(val) > 0.30: 
                         # Likely already a percentage number (e.g. 1.86)
                         return f"{val:.2f}%"
                    
                    # Use Python's built-in percentage formatting (handles x100 automatically)
                    return f"{val:.2%}"
                    
                # 2. Multiples (x)
                if any(x in label_lower for x in ["p/e", "ev/", "price/", "peg", "beta", "ratio"]):
                    return f"{val:.2f}x"
                
                # 3. Large Numbers (Millions/Billions)
                # Revenue, Income, Cash, Debt, CapEx, Value, Limit
                if any(x in label_lower for x in ["total", "revenue", "profit", "income", "ebitda", "cash", "debt", "capex", "value", "equity"]):
                    if abs(val) >= 1e9: return f"{val/1e9:.2f}B"
                    if abs(val) >= 1e6: return f"{val/1e6:.2f}M"
                    return f"{val:,.0f}"
                
                return f"{val:,.2f}"

            # 2. Render 8 Tables
            for section_name, metrics_map in PEER_METRICS.items():
                st.subheader(section_name)
                
                # Build Data Frame: Index=Metrics, Cols=Tickers
                section_data = {}
                
                for metric_label, metric_key in metrics_map.items():
                    row_values = []
                    for ticker in st.session_state.peer_tickers:
                        if ticker not in fetched_data:
                            row_values.append("-")
                            continue
                            
                        t_data = fetched_data[ticker]
                        val = None
                        
                        # --- DISPATCH LOGIC ---
                        # Type A: info_
                        if metric_key.startswith("info_"):
                            key = metric_key.replace("info_", "")
                            val = t_data["info"].get(key)
                        
                        # Type B: calc_
                        elif metric_key.startswith("calc_"):
                            val = t_data["calculated"].get(metric_key)
                            
                        # Type C: sheet_ (Financials/Balance Sheet typically)
                        elif metric_key.startswith("sheet_"):
                            # Look in both financials and balance_sheet?
                            # Usually explicit but we will try both recent columns
                            key = metric_key.replace("sheet_", "")
                            
                            # Helper to find row
                            found = False
                            for sheet in [t_data["financials"], t_data["balance_sheet"]]:
                                if sheet is not None and not sheet.empty:
                                    # Try exact match
                                    if key in sheet.index:
                                        val = sheet.loc[key].iloc[0] # Most recent
                                        found = True
                                        break
                                    # Try Case Insensitive
                                    else:
                                         matches = [idx for idx in sheet.index if idx.lower() == key.lower()]
                                         if matches:
                                             val = sheet.loc[matches[0]].iloc[0]
                                             found = True
                                             break

                            if not found:
                                val = None

                        # Format
                        row_values.append(fmt_val(val, metric_label, metric_key))
                    
                    section_data[metric_label] = row_values
                
                # Convert to DF
                df_table = pd.DataFrame(section_data).T 
                df_table.columns = st.session_state.peer_tickers
                
                # FIX: Reset index so the Metric Name becomes a visible column
                df_table = df_table.reset_index()
                df_table = df_table.rename(columns={'index': 'Metric'})

                # Render with custom styled UI
                render_styled_table(df_table)
                # st.dataframe(df_table, width="stretch") # Replaced

    else:
        st.info("Add stocks above to begin comparison.")


# =========================
# MAIN
# =========================
def send_otp_email(to_email: str, otp: str):
    """
    Send OTP via email using SMTP settings from secrets.toml or environment.
    Falls back to simulated mode (prints to UI) if no SMTP config found.
    """
    # 1. Try to load SMTP config
    smtp_server = st.secrets.get("smtp", {}).get("server")
    smtp_port = st.secrets.get("smtp", {}).get("port", 587)
    smtp_user = st.secrets.get("smtp", {}).get("user")
    smtp_pass = st.secrets.get("smtp", {}).get("password")
    
    email_sent = False
    
    if smtp_server and smtp_user and smtp_pass:
        try:
            import smtplib
            from email.mime.text import MIMEText
            from email.utils import formataddr
            
            msg = MIMEText(f"Your password reset OTP is: {otp}\n\nThis code expires in 15 minutes.")
            msg['Subject'] = 'Password Reset OTP - KuwaitPortfolio.ai'
            msg['From'] = formataddr(("Portfolio App", smtp_user))
            msg['To'] = to_email
            
            with smtplib.SMTP(smtp_server, smtp_port) as server:
                server.starttls()
                server.login(smtp_user, smtp_pass)
                server.sendmail(smtp_user, [to_email], msg.as_string())
            
            email_sent = True
        except Exception as e:
            logger.error(f"SMTP Error: {e}")
            email_sent = False
            
    # 2. Fallback / Simulation
    if not email_sent:
        # In production, do NOT show this. For local dev/demo:
        st.toast(f"ðŸ”‘ SIMULATION MODE: OTP for {to_email} is {otp}", icon="ðŸ‘€")
        st.info(f"**Dev Mode**: OTP sent to {to_email}: `{otp}` (Configure SMTP in secrets.toml to send real emails)")
    else:
        st.success(f"OTP sent to {to_email}")

def login_page(cookie_manager=None):
    st.markdown("""
    <style>
    .main { align-items: center; justify-content: center; display: flex; }
    .auth-container { max-width: 400px; padding: 2rem; border-radius: 10px; background: rgba(255,255,255,0.05); border: 1px solid rgba(255,255,255,0.1); }
    </style>
    """, unsafe_allow_html=True)
    
    st.title("ðŸ” Portfolio Access")
    
    if "auth_mode" not in st.session_state:
        st.session_state.auth_mode = "login" # login, register, forgot_pass
        
    # --- NAVIGATION TABS/MODES ---
    # We use custom navigation to handle "Forgot Password" cleanly
    if st.session_state.auth_mode == "forgot_pass":
        st.subheader("ðŸ”„ Reset Password")
        if st.button("â† Back to Login"):
            st.session_state.auth_mode = "login"
            st.rerun()
            
        with st.form("reset_request_form"):
            email_reset = st.text_input("Enter your registered email", max_chars=100)
            btn_reset = st.form_submit_button("Send OTP")
            
            if btn_reset:
                # =============================
                # OTP RATE LIMITING
                # =============================
                # Limit: max 3 OTP requests per email per 15 minutes
                now = int(time.time())
                rate_limit_window = 900  # 15 minutes
                max_otp_requests = 3
                
                conn = get_conn()
                cur = conn.cursor()
                
                # Check rate limit first
                db_execute(cur, 
                    "SELECT COUNT(*) FROM password_resets WHERE email=? AND created_at > ?",
                    (email_reset, now - rate_limit_window))
                otp_count = cur.fetchone()[0]
                
                if otp_count >= max_otp_requests:
                    conn.close()
                    st.error("â° Too many OTP requests. Please wait 15 minutes before trying again.")
                    logger.warning(f"OTP rate limit exceeded for: {email_reset[:30]}...")
                else:
                    db_execute(cur, "SELECT id FROM users WHERE email=? OR username=?", (email_reset, email_reset))
                    res = cur.fetchone()
                    conn.close()
                    
                    if res:
                        # Generate OTP
                        import random
                        otp_code = str(random.randint(100000, 999999))
                        exp_time = now + 900  # 15 mins
                        
                        conn = get_conn()
                        cur = conn.cursor()
                        # Don't delete old OTPs (for rate limiting), just add new one
                        db_execute(cur, "INSERT INTO password_resets (email, otp, expires_at, created_at) VALUES (?, ?, ?, ?)",
                                    (email_reset, otp_code, exp_time, now))
                        conn.commit()
                        conn.close()
                        
                        send_otp_email(email_reset, otp_code)
                        st.session_state.reset_email = email_reset
                        st.session_state.auth_mode = "verify_otp"
                        st.rerun()
                    else:
                        st.error("Email not found.")
                    
    elif st.session_state.auth_mode == "verify_otp":
        st.subheader("ðŸ” Verify OTP")
        st.caption(f"Enter the code sent to {st.session_state.get('reset_email')}")
        
        with st.form("verify_otp_form"):
            otp_input = st.text_input("OTP Code", max_chars=6)
            new_pass_1 = st.text_input("New Password", type="password", max_chars=128)
            new_pass_2 = st.text_input("Confirm New Password", type="password", max_chars=128)
            btn_verify = st.form_submit_button("Reset Password")
            
            if btn_verify:
                if new_pass_1 != new_pass_2:
                    st.error("Passwords do not match")
                elif len(new_pass_1) < 4:
                    st.error("Password too short")
                else:
                    target_email = st.session_state.get("reset_email")
                    now = int(time.time())
                    
                    conn = get_conn()
                    cur = conn.cursor()
                    # Verify OTP
                    db_execute(cur, "SELECT otp FROM password_resets WHERE email=? AND expires_at > ?", (target_email, now))
                    row = cur.fetchone()
                    
                    if row and row[0] == otp_input:
                        # Success - Update Password
                        new_hash = hash_password(new_pass_1)
                        db_execute(cur, "UPDATE users SET password_hash=? WHERE email=? OR username=?", (new_hash, target_email, target_email))
                        db_execute(cur, "DELETE FROM password_resets WHERE email=?", (target_email,))
                        conn.commit()
                        conn.close()
                        st.session_state.auth_mode = "login"
                        st.session_state._password_reset_success = True
                        # Clear temp state
                        del st.session_state.reset_email
                        st.rerun()
                    else:
                        conn.close()
                        st.error("Invalid or expired OTP")
        
        if st.button("Cancel"):
            st.session_state.auth_mode = "login"
            st.rerun()

    elif st.session_state.auth_mode == "register":
        st.subheader("ðŸ“ Register")
        if st.button("â† Back to Login"):
            st.session_state.auth_mode = "login"
            st.rerun()

        with st.form("register_form"):
            reg_email_input = st.text_input("Email Address")
            reg_pass = st.text_input("Choose Password", type="password")
            confirm_pass = st.text_input("Confirm Password", type="password")
            
            submit_reg = st.form_submit_button("Register", width="stretch")
            
            if submit_reg:
                # Normalize email
                reg_email = reg_email_input.strip().lower()

                if reg_pass != confirm_pass:
                    st.error("Passwords do not match")
                elif len(reg_pass) < 4:
                    st.warning("Password too short")
                elif "@" not in reg_email or "." not in reg_email:
                    st.error("Invalid email format")
                else:
                    try:
                        conn = get_conn()
                        cur = conn.cursor()
                        hashed = hash_password(reg_pass)
                        
                        # Check if email exists
                        db_execute(cur, "SELECT id FROM users WHERE email = ? OR username = ?", (reg_email, reg_email))
                        if cur.fetchone():
                            st.error("User with this email already exists.")
                        else:
                            # Insert with username = email
                            db_execute(cur, "INSERT INTO users (username, email, password_hash, created_at) VALUES (?, ?, ?, ?)", 
                                       (reg_email, reg_email, hashed, int(time.time())))
                            conn.commit()
                            st.session_state.auth_mode = "login"
                            st.session_state._register_success = True
                            st.rerun()
                    except Exception as e:
                        st.error(f"Registration error: {e}")
                    finally:
                        conn.close()

    else:
        # standard login page (default)
        st.subheader("ðŸ”‘ Login")
        
        # Show success messages from redirects (registration, password reset)
        if st.session_state.pop('_register_success', False):
            st.success("âœ… Registered successfully! Please login.")
        if st.session_state.pop('_password_reset_success', False):
            st.success("âœ… Password reset successfully! Please login.")

        # Use st.form to ensure variables are captured correctly on submit
        with st.form("login_form"):
            email_login_input = st.text_input("Email")
            password_login = st.text_input("Password", type="password")
            remember_me = st.checkbox("Remember me for 30 days")
            
            submitted = st.form_submit_button("Login", type="primary", width="stretch")

        if submitted:
            email_login = email_login_input.strip().lower()

            conn = get_conn()
            cur = conn.cursor()
            try:
                # Check BOTH email and username columns (case-insensitive)
                db_execute(cur, "SELECT password_hash, username, id FROM users WHERE LOWER(email) = ? OR LOWER(username) = ?", (email_login, email_login))
                row = cur.fetchone()

                if row:
                    stored_hash = row[0]
                    db_username = row[1]
                    user_id = row[2]

                    # Handle various encoding issues (SQLite returns str, PostgreSQL may return bytes/memoryview)
                    if stored_hash is None:
                        st.error("âŒ Account exists but no password set. Please use 'Forgot Password'.")
                    else:
                        # Normalize hash to string for check_password
                        if isinstance(stored_hash, memoryview):
                            stored_hash = bytes(stored_hash).decode('utf-8')
                        elif isinstance(stored_hash, bytes):
                            stored_hash = stored_hash.decode('utf-8')
                        
                        # Use the check_password helper function
                        if check_password(password_login, stored_hash):
                            # SUCCESS CASE
                            st.session_state.logged_in = True
                            st.session_state.user_id = user_id
                            st.session_state.username = db_username
                            st.session_state._auth_checked = True  # Mark as checked

                            # CREATE PERSISTENT SESSION
                            # If "Remember me" is checked: 30 days
                            # If not checked: 7 days (persists through refreshes for a week)
                            session_days = 30 if remember_me else 7
                            
                            if cookie_manager:
                                try:
                                    # Create a secure session token in DB
                                    token, token_expires = create_session_token(user_id, days=session_days)
                                    expires = datetime.now() + timedelta(days=session_days)
                                    # Store token in cookie
                                    cookie_manager.set("portfolio_session", token, expires_at=expires)
                                    
                                    # FIX: Slight delay to ensure browser saves cookie, then force reload
                                    import time as time_module
                                    with st.spinner("Logging in..."):
                                        time_module.sleep(0.5)
                                    st.rerun()
                                except Exception as ce:
                                    logger.error(f"Session Token Error: {ce}")
                            else:
                                st.rerun()
                            
                            # Fallback rerun if cookie_manager block didn't trigger
                            st.rerun()
                        else:
                            st.error("âŒ Invalid email or password.")
                else:
                    st.error("âŒ Invalid email or password. Please check your credentials or register a new account.")

            except Exception as e:
                st.error(f"Login error: {e}")
            finally:
                conn.close()
        
        col_act1, col_act2 = st.columns([1, 1])
        with col_act2:
            if st.button("Forgot Password?", type="secondary", width="stretch"):
                st.session_state.auth_mode = "forgot_pass"
                st.rerun()

        st.markdown("---")
        if st.button("Create an Account", type="secondary", width="stretch"):
            st.session_state.auth_mode = "register"
            st.rerun()
    
    # Show database info at bottom of login page
    st.markdown("---")
    st.caption(f"{get_db_info()}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Personal Financial Management (PFM) - Income, Expenses, Assets, Liabilities
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ui_pfm():
    """Personal Financial Management - Track income, expenses, assets, liabilities with P&L and Balance Sheet reporting."""
    # Persist the current tab selection
    st.session_state.active_main_tab = "Personal Finance"
    
    user_id = st.session_state.get("user_id")
    if not user_id:
        st.warning("Please log in to access Personal Financial Management.")
        return

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CALLBACK FUNCTIONS for seamless add/delete (avoids explicit rerun)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def add_income():
        if "pfm_income_items" not in st.session_state:
            st.session_state.pfm_income_items = []
        st.session_state.pfm_income_items.append({"category": "", "monthly": 0.0})
    
    def add_expense():
        if "pfm_expense_items" not in st.session_state:
            st.session_state.pfm_expense_items = []
        st.session_state.pfm_expense_items.append({"category": "", "monthly": 0.0, "is_finance_cost": False, "is_gna": False})
    
    def add_real_estate():
        if "pfm_real_estate" not in st.session_state:
            st.session_state.pfm_real_estate = []
        st.session_state.pfm_real_estate.append({"category": "Residential", "name": "", "qty": 1, "price": 0, "currency": "KWD", "value_kwd": 0})
    
    def add_share():
        if "pfm_shares" not in st.session_state:
            st.session_state.pfm_shares = []
        st.session_state.pfm_shares.append({"ticker": "", "name": "", "qty": 0, "price": 0, "currency": "KWD"})
    
    def add_gold():
        if "pfm_gold" not in st.session_state:
            st.session_state.pfm_gold = []
        st.session_state.pfm_gold.append({"category": "Bars", "name": "", "qty": 0, "price": 0, "currency": "KWD", "value_kwd": 0})
    
    def add_cash():
        if "pfm_cash" not in st.session_state:
            st.session_state.pfm_cash = []
        st.session_state.pfm_cash.append({"category": "Bank Account", "name": "", "amount": 0, "currency": "KWD", "value_kwd": 0})
    
    def add_crypto():
        if "pfm_crypto" not in st.session_state:
            st.session_state.pfm_crypto = []
        st.session_state.pfm_crypto.append({"name": "", "qty": 0, "price": 0, "currency": "USD", "value_kwd": 0})
    
    def add_other():
        if "pfm_other_assets" not in st.session_state:
            st.session_state.pfm_other_assets = []
        st.session_state.pfm_other_assets.append({"category": "Other", "name": "", "value_kwd": 0})
    
    def add_liability():
        if "pfm_liabilities" not in st.session_state:
            st.session_state.pfm_liabilities = []
        st.session_state.pfm_liabilities.append({"category": "Other", "amount_kwd": 0, "is_current": False, "is_long_term": True})

    # Delete callbacks - use session state to track which item to delete
    def delete_item(list_key: str, index: int):
        """Generic delete function for any PFM list."""
        if list_key in st.session_state and 0 <= index < len(st.session_state[list_key]):
            st.session_state[list_key].pop(index)
    st.header("ðŸ’° Personal Financial Management")
    st.markdown("Track your complete financial picture: income, expenses, assets, and liabilities. Generate P&L statements, balance sheets, and analyze growth over time.")

    # Sub-tabs for PFM sections
    pfm_tabs = st.tabs(["ðŸ“ Data Entry", "ðŸ“Š Financial Statement", "ðŸ“‹ Balance Sheet", "ðŸ“ˆ Ratios & Growth"])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 1: DATA ENTRY (Form-based to prevent refresh while typing)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with pfm_tabs[0]:
        st.subheader("ðŸ“ Financial Data Entry")
        
        # --- YEAR SELECTOR FOR QUICK NAVIGATION ---
        conn = get_conn()
        try:
            cur = conn.cursor()
            db_execute(cur, """
                SELECT id, snapshot_date, notes FROM pfm_snapshots
                WHERE user_id = ?
                ORDER BY snapshot_date DESC
            """, (user_id,))
            all_snapshots = cur.fetchall()
        except:
            all_snapshots = []
        finally:
            conn.close()
        
        # Extract unique years from snapshots
        saved_years = set()
        snapshots_by_year = {}
        for snap in all_snapshots:
            try:
                snap_year = snap[1][:4]  # Get year from date string
                saved_years.add(snap_year)
                if snap_year not in snapshots_by_year:
                    snapshots_by_year[snap_year] = []
                snapshots_by_year[snap_year].append(snap)
            except:
                pass
        
        # Add current year if not in list
        current_year = str(datetime.today().year)
        all_years = sorted(saved_years | {current_year}, reverse=True)
        
        # --- Configuration outside form (for immediate UI updates) ---
        col_year, col_snap, col_notes = st.columns([1, 2, 2])
        
        with col_year:
            selected_year = st.selectbox("ðŸ“… Year", all_years, key="pfm_year_select")
        
        with col_snap:
            # Show snapshots for selected year
            year_snapshots = snapshots_by_year.get(selected_year, [])
            if year_snapshots:
                snap_options = ["âž• New Snapshot"] + [f"{s[1]} - {s[2] or 'No notes'}" for s in year_snapshots]
                snap_dates_list = [None] + [s[1] for s in year_snapshots]
                selected_snap_idx = st.selectbox(
                    "Select Snapshot",
                    range(len(snap_options)),
                    format_func=lambda x: snap_options[x],
                    key="pfm_snap_select"
                )
                if selected_snap_idx > 0:
                    selected_date_str = snap_dates_list[selected_snap_idx]
                    try:
                        snapshot_date = datetime.strptime(selected_date_str, "%Y-%m-%d").date()
                    except:
                        snapshot_date = datetime.today().date()
                else:
                    # New snapshot - default to Dec 31 of selected year for year-end, or today if current year
                    if selected_year == current_year:
                        snapshot_date = datetime.today().date()
                    else:
                        snapshot_date = datetime(int(selected_year), 12, 31).date()
            else:
                st.info(f"No snapshots for {selected_year}")
                # Default to Dec 31 of selected year
                if selected_year == current_year:
                    snapshot_date = datetime.today().date()
                else:
                    snapshot_date = datetime(int(selected_year), 12, 31).date()
        
        with col_notes:
            snapshot_notes = st.text_input("Notes", key="pfm_snapshot_notes", placeholder="e.g., Year-end snapshot")

        # Check for existing snapshot
        conn = get_conn()
        existing_snapshot = None
        try:
            cur = conn.cursor()
            db_execute(cur, """
                SELECT id, notes FROM pfm_snapshots 
                WHERE user_id = ? AND snapshot_date = ?
            """, (user_id, str(snapshot_date)))
            row = cur.fetchone()
            if row:
                existing_snapshot = {"id": row[0], "notes": row[1]}
        except:
            pass
        finally:
            conn.close()

        if existing_snapshot:
            col_info, col_del = st.columns([4, 1])
            with col_info:
                st.info(f"ðŸ“Œ Editing existing snapshot for {snapshot_date}")
            with col_del:
                if st.button("ðŸ—‘ï¸ Delete Snapshot", type="secondary", key="delete_snapshot"):
                    try:
                        conn = get_conn()
                        cur = conn.cursor()
                        # Security: Add user_id filter to prevent cross-user deletion
                        db_execute(cur, "DELETE FROM pfm_income_expense_items WHERE snapshot_id = ? AND user_id = ?", (existing_snapshot["id"], user_id))
                        db_execute(cur, "DELETE FROM pfm_asset_items WHERE snapshot_id = ? AND user_id = ?", (existing_snapshot["id"], user_id))
                        db_execute(cur, "DELETE FROM pfm_liability_items WHERE snapshot_id = ? AND user_id = ?", (existing_snapshot["id"], user_id))
                        db_execute(cur, "DELETE FROM pfm_snapshots WHERE id = ? AND user_id = ?", (existing_snapshot["id"], user_id))
                        conn.commit()
                        conn.close()
                        for key in list(st.session_state.keys()):
                            if key.startswith("pfm_"):
                                del st.session_state[key]
                        st.success(f"âœ… Snapshot deleted!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"Error: {e}")

        # --- Load existing data or set defaults ---
        default_income = [
            {"Category": "Salary", "Monthly (KWD)": 0.0},
            {"Category": "Rental Income", "Monthly (KWD)": 0.0},
            {"Category": "Dividends", "Monthly (KWD)": 0.0},
            {"Category": "Side Business", "Monthly (KWD)": 0.0},
        ]
        default_expense = [
            {"Category": "Housing/Rent", "Monthly (KWD)": 0.0, "Finance Cost": False, "G&A": False},
            {"Category": "Utilities", "Monthly (KWD)": 0.0, "Finance Cost": False, "G&A": False},
            {"Category": "Food & Groceries", "Monthly (KWD)": 0.0, "Finance Cost": False, "G&A": False},
            {"Category": "Transportation", "Monthly (KWD)": 0.0, "Finance Cost": False, "G&A": False},
            {"Category": "Loan Interest", "Monthly (KWD)": 0.0, "Finance Cost": True, "G&A": False},
        ]
        default_real_estate = [{"Name": "", "Value (KWD)": 0.0}]
        default_shares = [{"Ticker": "", "Name": "", "Qty": 0.0, "Price": 0.0, "Currency": "KWD"}]
        default_gold = [{"Type": "Bars", "Grams": 0.0, "Price/Gram (KWD)": 0.0}]
        default_cash = [{"Account": "", "Amount": 0.0, "Currency": "KWD"}]
        default_crypto = [{"Coin": "", "Qty": 0.0, "Price (USD)": 0.0}]
        default_liabilities = [
            {"Category": "Credit Card", "Amount (KWD)": 0.0, "Type": "Current"},
            {"Category": "Bank Loan", "Amount (KWD)": 0.0, "Type": "Long-term"},
        ]

        # Load from database if editing existing snapshot
        if existing_snapshot:
            snap_id = existing_snapshot["id"]
            conn = get_conn()
            cur = conn.cursor()
            
            # Load income
            db_execute(cur, "SELECT category, monthly_amount FROM pfm_income_expense_items WHERE snapshot_id = ? AND kind = 'income' ORDER BY id", (snap_id,))
            income_rows = cur.fetchall()
            if income_rows:
                default_income = [{"Category": r[0], "Monthly (KWD)": float(r[1])} for r in income_rows]
            
            # Load expenses
            db_execute(cur, "SELECT category, monthly_amount, is_finance_cost, is_gna FROM pfm_income_expense_items WHERE snapshot_id = ? AND kind = 'expense' ORDER BY id", (snap_id,))
            expense_rows = cur.fetchall()
            if expense_rows:
                default_expense = [{"Category": r[0], "Monthly (KWD)": float(r[1]), "Finance Cost": bool(r[2]), "G&A": bool(r[3])} for r in expense_rows]
            
            # Load assets
            db_execute(cur, "SELECT asset_type, category, name, quantity, price, currency, value_kwd FROM pfm_asset_items WHERE snapshot_id = ? ORDER BY asset_type, id", (snap_id,))
            asset_rows = cur.fetchall()
            
            re_data, shares_data, gold_data, cash_data, crypto_data = [], [], [], [], []
            for r in asset_rows:
                atype, cat, name, qty, price, curr, val = r
                if atype == "real_estate":
                    re_data.append({"Name": name or cat, "Value (KWD)": float(val or 0)})
                elif atype == "shares":
                    shares_data.append({"Ticker": cat, "Name": name, "Qty": float(qty or 0), "Price": float(price or 0), "Currency": curr or "KWD"})
                elif atype == "gold":
                    gold_data.append({"Type": cat, "Grams": float(qty or 0), "Price/Gram (KWD)": float(price or 0)})
                elif atype == "cash":
                    cash_data.append({"Account": name or cat, "Amount": float(qty or 0), "Currency": curr or "KWD"})
                elif atype == "crypto":
                    crypto_data.append({"Coin": name, "Qty": float(qty or 0), "Price (USD)": float(price or 0)})
            
            if re_data: default_real_estate = re_data
            if shares_data: default_shares = shares_data
            if gold_data: default_gold = gold_data
            if cash_data: default_cash = cash_data
            if crypto_data: default_crypto = crypto_data
            
            # Load liabilities
            db_execute(cur, "SELECT category, amount_kwd, is_current, is_long_term FROM pfm_liability_items WHERE snapshot_id = ? ORDER BY id", (snap_id,))
            liab_rows = cur.fetchall()
            if liab_rows:
                default_liabilities = [{"Category": r[0], "Amount (KWD)": float(r[1]), "Type": "Current" if r[2] else "Long-term"} for r in liab_rows]
            
            conn.close()

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FORM: Batch all inputs to prevent refresh while typing
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        with st.form("pfm_data_entry_form"):
            # --- INCOME & EXPENSES ---
            st.markdown("### ðŸ’µ Income & Expenses (Monthly)")
            col_inc, col_exp = st.columns(2)
            
            with col_inc:
                st.markdown("#### ðŸ“ˆ Income Sources")
                income_df = st.data_editor(
                    pd.DataFrame(default_income),
                    num_rows="dynamic",
                    width="stretch",
                    key=f"pfm_inc_{snapshot_date}",
                    column_config={
                        "Category": st.column_config.TextColumn(width="medium"),
                        "Monthly (KWD)": st.column_config.NumberColumn(format="%.3f", min_value=0)
                    }
                )
            
            with col_exp:
                st.markdown("#### ðŸ“‰ Expenses")
                expense_df = st.data_editor(
                    pd.DataFrame(default_expense),
                    num_rows="dynamic",
                    width="stretch",
                    key=f"pfm_exp_{snapshot_date}",
                    column_config={
                        "Category": st.column_config.TextColumn(width="medium"),
                        "Monthly (KWD)": st.column_config.NumberColumn(format="%.3f", min_value=0),
                        "Finance Cost": st.column_config.CheckboxColumn(width="small"),
                        "G&A": st.column_config.CheckboxColumn(width="small")
                    }
                )

            # Summary metrics
            total_income = income_df["Monthly (KWD)"].sum() if not income_df.empty else 0
            total_expense = expense_df["Monthly (KWD)"].sum() if not expense_df.empty else 0
            net_monthly = total_income - total_expense
            
            col_m1, col_m2, col_m3 = st.columns(3)
            with col_m1:
                st.metric("Monthly Income", f"{total_income:,.2f} KWD")
            with col_m2:
                st.metric("Monthly Expenses", f"{total_expense:,.2f} KWD")
            with col_m3:
                st.metric("Net Monthly", f"{net_monthly:,.2f} KWD", delta=f"{(net_monthly/total_income*100) if total_income else 0:.1f}%")

            st.divider()

            # --- ASSETS & LIABILITIES ---
            st.markdown("### ðŸ¦ Assets & Liabilities")
            
            asset_tabs = st.tabs(["ðŸ¡ Real Estate", "ðŸ“ˆ Shares", "ðŸª™ Gold", "ðŸ’µ Cash", "â‚¿ Crypto", "ðŸ’³ Liabilities"])
            
            # Real Estate
            with asset_tabs[0]:
                re_df = st.data_editor(
                    pd.DataFrame(default_real_estate),
                    num_rows="dynamic",
                    width="stretch",
                    key=f"pfm_re_{snapshot_date}",
                    column_config={
                        "Name": st.column_config.TextColumn(width="large"),
                        "Value (KWD)": st.column_config.NumberColumn(format="%.3f", min_value=0)
                    }
                )
                re_total = re_df["Value (KWD)"].sum() if not re_df.empty and "Value (KWD)" in re_df.columns else 0
                st.markdown(f"**Total Real Estate:** {re_total:,.2f} KWD")

            # Shares
            with asset_tabs[1]:
                # Auto-Import toggle inside the Shares section
                shares_mode = st.radio(
                    "ðŸ“Š Shares Entry Mode",
                    ["Manual Entry", "Auto-Import from Portfolio"],
                    horizontal=True,
                    key="pfm_shares_mode",
                    help="Auto-Import will pull your current portfolio holdings with live prices"
                )
                
                if shares_mode == "Auto-Import from Portfolio":
                    st.info("ðŸ“Š Importing shares from your portfolio holdings at current market values...")
                    
                    # Warning about double-counting with Portfolio Analysis
                    exclude_from_networth = st.checkbox(
                        "âš ï¸ Exclude from Net Worth calculations (avoid double-counting)",
                        value=False,
                        key="pfm_exclude_shares_networth",
                        help="Check this if you already track these investments in Portfolio Analysis. "
                             "This prevents counting the same assets twice in your total net worth."
                    )
                    if exclude_from_networth:
                        st.caption("ðŸ’¡ These shares will be displayed but NOT added to your Net Worth total.")
                    
                    # Calculate portfolio value
                    try:
                        conn = get_conn()
                        cur = conn.cursor()
                        # Calculate holdings directly from transactions (grouped by symbol + portfolio)
                        # This matches how build_portfolio_table works
                        db_execute(cur, """
                            SELECT 
                                t.stock_symbol as symbol,
                                COALESCE(s.name, t.stock_symbol) as name,
                                t.portfolio,
                                SUM(CASE WHEN t.txn_type = 'Buy' THEN t.shares ELSE 0 END) - 
                                SUM(CASE WHEN t.txn_type = 'Sell' THEN t.shares ELSE 0 END) as net_shares,
                                COALESCE(s.current_price, 0) as current_price,
                                COALESCE(s.currency, 'KWD') as currency
                            FROM transactions t
                            LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND t.portfolio = s.portfolio AND s.user_id = t.user_id
                            WHERE t.user_id = ? 
                              AND t.is_deleted = 0
                              AND t.txn_type IN ('Buy', 'Sell')
                            GROUP BY t.stock_symbol, t.portfolio
                            HAVING (SUM(CASE WHEN t.txn_type = 'Buy' THEN t.shares ELSE 0 END) - 
                                SUM(CASE WHEN t.txn_type = 'Sell' THEN t.shares ELSE 0 END)) > 0
                        """, (user_id,))
                        portfolio_rows = cur.fetchall()
                        conn.close()
                        
                        if portfolio_rows:
                            port_data = []
                            total_port = 0.0
                            for row in portfolio_rows:
                                ticker, name, portfolio, qty, price, curr = row
                                qty = float(qty) if qty else 0
                                price = float(price) if price else 0
                                val = qty * price
                                val_kwd = convert_to_kwd(val, curr) if curr != "KWD" else val
                                total_port += val_kwd
                                port_data.append({"Ticker": ticker, "Company": name, "Portfolio": portfolio, "Shares": qty, "Price": price, "Currency": curr, "Value (KWD)": val_kwd})
                            
                            st.dataframe(pd.DataFrame(port_data), use_container_width=True, hide_index=True)
                            
                            # Show appropriate message based on exclusion flag
                            if exclude_from_networth:
                                st.warning(f"**Portfolio Value: {total_port:,.2f} KWD** â€” âš ï¸ EXCLUDED from Net Worth (already tracked in Portfolio Analysis)")
                            else:
                                st.success(f"**Total Portfolio Value:** {total_port:,.2f} KWD")
                            
                            shares_df = pd.DataFrame([{"auto_import": True, "value": total_port}])
                        else:
                            st.warning("No portfolio holdings found. Add stocks in the Transactions tab first.")
                            shares_df = pd.DataFrame()
                    except Exception as e:
                        st.error(f"Error loading portfolio: {e}")
                        shares_df = pd.DataFrame()
                else:
                    st.caption("Enter your shares manually below, or switch to Auto-Import to pull from your portfolio.")
                    shares_df = st.data_editor(
                        pd.DataFrame(default_shares),
                        num_rows="dynamic",
                        use_container_width=True,
                        key=f"pfm_shares_{snapshot_date}",
                        column_config={
                            "Ticker": st.column_config.TextColumn(width="small"),
                            "Name": st.column_config.TextColumn(width="medium"),
                            "Qty": st.column_config.NumberColumn(format="%.0f", min_value=0),
                            "Price": st.column_config.NumberColumn(format="%.3f", min_value=0),
                            "Currency": st.column_config.SelectboxColumn(options=["KWD", "USD", "SAR", "AED", "BHD", "OMR", "QAR"])
                        }
                    )
                    if not shares_df.empty and "Qty" in shares_df.columns and "Price" in shares_df.columns:
                        shares_df["Value"] = shares_df["Qty"] * shares_df["Price"]
                        shares_total = shares_df["Value"].sum()
                        st.markdown(f"**Total Shares Value:** {shares_total:,.2f}")

            # Gold
            with asset_tabs[2]:
                gold_df = st.data_editor(
                    pd.DataFrame(default_gold),
                    num_rows="dynamic",
                    width="stretch",
                    key=f"pfm_gold_{snapshot_date}",
                    column_config={
                        "Type": st.column_config.SelectboxColumn(options=["Bars", "Coins", "Jewelry", "Other"]),
                        "Grams": st.column_config.NumberColumn(format="%.2f", min_value=0),
                        "Price/Gram (KWD)": st.column_config.NumberColumn(format="%.3f", min_value=0)
                    }
                )
                if not gold_df.empty and "Grams" in gold_df.columns:
                    gold_df["Value (KWD)"] = gold_df["Grams"] * gold_df["Price/Gram (KWD)"]
                    gold_total = gold_df["Value (KWD)"].sum()
                    st.markdown(f"**Total Gold Value:** {gold_total:,.2f} KWD")

            # Cash
            with asset_tabs[3]:
                cash_df = st.data_editor(
                    pd.DataFrame(default_cash),
                    num_rows="dynamic",
                    width="stretch",
                    key=f"pfm_cash_{snapshot_date}",
                    column_config={
                        "Account": st.column_config.TextColumn(width="medium"),
                        "Amount": st.column_config.NumberColumn(format="%.3f", min_value=0),
                        "Currency": st.column_config.SelectboxColumn(options=["KWD", "USD", "SAR", "AED", "BHD", "OMR", "QAR"])
                    }
                )
                cash_total = 0.0
                if not cash_df.empty and "Amount" in cash_df.columns:
                    for _, row in cash_df.iterrows():
                        amt = float(row.get("Amount", 0) or 0)
                        curr = row.get("Currency", "KWD")
                        cash_total += convert_to_kwd(amt, curr) if curr != "KWD" else amt
                    st.markdown(f"**Total Cash:** {cash_total:,.2f} KWD")

            # Crypto
            with asset_tabs[4]:
                usd_rate = 0.307
                st.caption(f"Conversion Rate: 1 USD = {usd_rate} KWD")
                crypto_df = st.data_editor(
                    pd.DataFrame(default_crypto),
                    num_rows="dynamic",
                    width="stretch",
                    key=f"pfm_crypto_{snapshot_date}",
                    column_config={
                        "Coin": st.column_config.TextColumn(width="small"),
                        "Qty": st.column_config.NumberColumn(format="%.6f", min_value=0),
                        "Price (USD)": st.column_config.NumberColumn(format="%.2f", min_value=0)
                    }
                )
                if not crypto_df.empty and "Qty" in crypto_df.columns:
                    crypto_df["Value (KWD)"] = crypto_df["Qty"] * crypto_df["Price (USD)"] * usd_rate
                    crypto_total = crypto_df["Value (KWD)"].sum()
                    st.markdown(f"**Total Crypto:** {crypto_total:,.2f} KWD")

            # Liabilities
            with asset_tabs[5]:
                liab_df = st.data_editor(
                    pd.DataFrame(default_liabilities),
                    num_rows="dynamic",
                    width="stretch",
                    key=f"pfm_liab_{snapshot_date}",
                    column_config={
                        "Category": st.column_config.TextColumn(width="medium"),
                        "Amount (KWD)": st.column_config.NumberColumn(format="%.3f", min_value=0),
                        "Type": st.column_config.SelectboxColumn(options=["Current", "Long-term"])
                    }
                )
                liab_total = liab_df["Amount (KWD)"].sum() if not liab_df.empty and "Amount (KWD)" in liab_df.columns else 0
                st.markdown(f"**Total Liabilities:** {liab_total:,.2f} KWD")

            st.divider()
            
            # Submit button
            submitted = st.form_submit_button("ðŸ’¾ Save Financial Snapshot", type="primary", width="stretch")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # HANDLE FORM SUBMISSION (Outside the form)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if submitted:
            try:
                conn = get_conn()
                cur = conn.cursor()
                
                # Get or create snapshot
                db_execute(cur, "SELECT id FROM pfm_snapshots WHERE user_id = ? AND snapshot_date = ?", (user_id, str(snapshot_date)))
                row = cur.fetchone()
                
                if row:
                    snapshot_id = row[0]
                    # Clear existing data (with user_id security check)
                    db_execute(cur, "DELETE FROM pfm_income_expense_items WHERE snapshot_id = ? AND user_id = ?", (snapshot_id, user_id))
                    db_execute(cur, "DELETE FROM pfm_asset_items WHERE snapshot_id = ? AND user_id = ?", (snapshot_id, user_id))
                    db_execute(cur, "DELETE FROM pfm_liability_items WHERE snapshot_id = ? AND user_id = ?", (snapshot_id, user_id))
                else:
                    db_execute(cur, """
                        INSERT INTO pfm_snapshots (user_id, snapshot_date, notes, created_at)
                        VALUES (?, ?, ?, ?)
                    """, (user_id, str(snapshot_date), snapshot_notes, int(time.time())))
                    snapshot_id = cur.lastrowid
                
                # Save income items
                for _, row in income_df.iterrows():
                    cat = str(row.get("Category", "")).strip()
                    amt = float(row.get("Monthly (KWD)", 0) or 0)
                    if cat and amt > 0:
                        db_execute(cur, """
                            INSERT INTO pfm_income_expense_items (snapshot_id, user_id, kind, category, monthly_amount, is_finance_cost, is_gna)
                            VALUES (?, ?, 'income', ?, ?, 0, 0)
                        """, (snapshot_id, user_id, cat, amt))
                
                # Save expense items
                for _, row in expense_df.iterrows():
                    cat = str(row.get("Category", "")).strip()
                    amt = float(row.get("Monthly (KWD)", 0) or 0)
                    fin = 1 if row.get("Finance Cost", False) else 0
                    gna = 1 if row.get("G&A", False) else 0
                    if cat and amt > 0:
                        db_execute(cur, """
                            INSERT INTO pfm_income_expense_items (snapshot_id, user_id, kind, category, monthly_amount, is_finance_cost, is_gna)
                            VALUES (?, ?, 'expense', ?, ?, ?, ?)
                        """, (snapshot_id, user_id, cat, amt, fin, gna))
                
                # Save real estate
                for _, row in re_df.iterrows():
                    name = str(row.get("Name", "")).strip()
                    val = float(row.get("Value (KWD)", 0) or 0)
                    if val > 0:
                        db_execute(cur, """
                            INSERT INTO pfm_asset_items (snapshot_id, user_id, asset_type, category, name, quantity, price, currency, value_kwd)
                            VALUES (?, ?, 'real_estate', 'Real Estate', ?, 1, ?, 'KWD', ?)
                        """, (snapshot_id, user_id, name, val, val))
                
                # Save shares
                # Check if user wants to exclude from net worth (double-counting prevention)
                exclude_shares = st.session_state.get("pfm_exclude_shares_networth", False)
                
                if shares_mode == "Auto-Import from Portfolio" and not shares_df.empty and "auto_import" in shares_df.columns:
                    val = float(shares_df["value"].iloc[0])
                    if val > 0:
                        # Store exclusion flag in notes column (if exists) or value_kwd = 0 if excluded
                        stored_val = 0 if exclude_shares else val
                        db_execute(cur, """
                            INSERT INTO pfm_asset_items (snapshot_id, user_id, asset_type, category, name, quantity, price, currency, value_kwd)
                            VALUES (?, ?, 'shares', 'Portfolio', ?, 1, ?, 'KWD', ?)
                        """, (snapshot_id, user_id, 
                              f"Auto-imported{'  [EXCLUDED from Net Worth]' if exclude_shares else ''}", 
                              val, stored_val))
                elif not shares_df.empty and "Ticker" in shares_df.columns:
                    for _, row in shares_df.iterrows():
                        ticker = str(row.get("Ticker", "")).strip()
                        name = str(row.get("Name", "")).strip()
                        qty = float(row.get("Qty", 0) or 0)
                        price = float(row.get("Price", 0) or 0)
                        curr = row.get("Currency", "KWD")
                        val = qty * price
                        val_kwd = convert_to_kwd(val, curr) if curr != "KWD" else val
                        if val_kwd > 0:
                            db_execute(cur, """
                                INSERT INTO pfm_asset_items (snapshot_id, user_id, asset_type, category, name, quantity, price, currency, value_kwd)
                                VALUES (?, ?, 'shares', ?, ?, ?, ?, ?, ?)
                            """, (snapshot_id, user_id, ticker, name, qty, price, curr, val_kwd))
                
                # Save gold
                if not gold_df.empty and "Grams" in gold_df.columns:
                    for _, row in gold_df.iterrows():
                        gtype = row.get("Type", "Bars")
                        grams = float(row.get("Grams", 0) or 0)
                        price = float(row.get("Price/Gram (KWD)", 0) or 0)
                        val = grams * price
                        if val > 0:
                            db_execute(cur, """
                                INSERT INTO pfm_asset_items (snapshot_id, user_id, asset_type, category, name, quantity, price, currency, value_kwd)
                                VALUES (?, ?, 'gold', ?, '', ?, ?, 'KWD', ?)
                            """, (snapshot_id, user_id, gtype, grams, price, val))
                
                # Save cash
                if not cash_df.empty and "Amount" in cash_df.columns:
                    for _, row in cash_df.iterrows():
                        acc = str(row.get("Account", "")).strip()
                        amt = float(row.get("Amount", 0) or 0)
                        curr = row.get("Currency", "KWD")
                        val_kwd = convert_to_kwd(amt, curr) if curr != "KWD" else amt
                        if val_kwd > 0:
                            db_execute(cur, """
                                INSERT INTO pfm_asset_items (snapshot_id, user_id, asset_type, category, name, quantity, price, currency, value_kwd)
                                VALUES (?, ?, 'cash', ?, ?, ?, 1, ?, ?)
                            """, (snapshot_id, user_id, acc, acc, amt, curr, val_kwd))
                
                # Save crypto
                if not crypto_df.empty and "Qty" in crypto_df.columns:
                    for _, row in crypto_df.iterrows():
                        coin = str(row.get("Coin", "")).strip()
                        qty = float(row.get("Qty", 0) or 0)
                        price = float(row.get("Price (USD)", 0) or 0)
                        val_kwd = qty * price * 0.307
                        if val_kwd > 0:
                            db_execute(cur, """
                                INSERT INTO pfm_asset_items (snapshot_id, user_id, asset_type, category, name, quantity, price, currency, value_kwd)
                                VALUES (?, ?, 'crypto', '', ?, ?, ?, 'USD', ?)
                            """, (snapshot_id, user_id, coin, qty, price, val_kwd))
                
                # Save liabilities
                if not liab_df.empty and "Amount (KWD)" in liab_df.columns:
                    for _, row in liab_df.iterrows():
                        cat = str(row.get("Category", "")).strip()
                        amt = float(row.get("Amount (KWD)", 0) or 0)
                        ltype = row.get("Type", "Current")
                        is_current = 1 if ltype == "Current" else 0
                        is_long = 1 if ltype == "Long-term" else 0
                        if amt > 0:
                            db_execute(cur, """
                                INSERT INTO pfm_liability_items (snapshot_id, user_id, category, amount_kwd, is_current, is_long_term)
                                VALUES (?, ?, ?, ?, ?, ?)
                            """, (snapshot_id, user_id, cat, amt, is_current, is_long))
                
                conn.commit()
                conn.close()
                
                st.success(f"âœ… Financial snapshot saved for {snapshot_date}!")
                st.balloons()
                time.sleep(1)
                st.rerun()
                
            except Exception as e:
                st.error(f"Error saving snapshot: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 2: UNIFIED FINANCIAL STATEMENT (P&L + Balance Sheet + Ratios)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with pfm_tabs[1]:
        st.subheader("ðŸ“Š Unified Financial Statement")
        
        # Load all snapshots for user
        conn = get_conn()
        try:
            cur = conn.cursor()
            db_execute(cur, """
                SELECT id, snapshot_date, notes FROM pfm_snapshots
                WHERE user_id = ?
                ORDER BY snapshot_date ASC
            """, (user_id,))
            snapshots = cur.fetchall()
        except:
            snapshots = []
        finally:
            conn.close()

        if not snapshots:
            st.info("No financial snapshots found. Create one in the Data Entry tab.")
        else:
            # Build unified report data
            dates = [s[1] for s in snapshots]
            snap_ids = {s[1]: s[0] for s in snapshots}
            
            # Master data structure: {Line_Item: {date1: val1, date2: val2...}}
            report_data = {}
            
            def add_val(row_name, date_col, val):
                if row_name not in report_data:
                    report_data[row_name] = {d: 0.0 for d in dates}
                report_data[row_name][date_col] = float(val) if val else 0.0
            
            def get_growth(curr, prev):
                if prev == 0: return 0.0
                return ((curr - prev) / abs(prev)) * 100
            
            # Process each snapshot
            for snap_date in dates:
                snap_id = snap_ids[snap_date]
                conn = get_conn()
                cur = conn.cursor()
                
                # === A. PROFIT & LOSS ===
                db_execute(cur, "SELECT category, monthly_amount FROM pfm_income_expense_items WHERE snapshot_id = ? AND kind = 'income'", (snap_id,))
                income_rows = cur.fetchall()
                
                db_execute(cur, "SELECT category, monthly_amount, is_finance_cost, is_gna FROM pfm_income_expense_items WHERE snapshot_id = ? AND kind = 'expense'", (snap_id,))
                expense_rows = cur.fetchall()
                
                turnover = sum(r[1] for r in income_rows) * 12 if income_rows else 0
                exp_fin = sum(r[1] for r in expense_rows if r[2]) * 12 if expense_rows else 0
                exp_gna = sum(r[1] for r in expense_rows if not r[2]) * 12 if expense_rows else 0
                net_profit = turnover - (exp_fin + exp_gna)
                
                add_val("â•â•â• PROFIT & LOSS â•â•â•", snap_date, "")
                add_val("Turnover (Revenue)", snap_date, turnover)
                add_val("Gross Profit", snap_date, turnover)  # Assuming COGS = 0 for personal
                add_val("General & Admin Expenses", snap_date, exp_gna)
                add_val("Finance Costs", snap_date, exp_fin)
                add_val("NET PROFIT", snap_date, net_profit)
                
                # === B. BALANCE SHEET ===
                db_execute(cur, "SELECT asset_type, category, name, value_kwd FROM pfm_asset_items WHERE snapshot_id = ?", (snap_id,))
                asset_rows = cur.fetchall()
                
                db_execute(cur, "SELECT category, amount_kwd, is_current, is_long_term FROM pfm_liability_items WHERE snapshot_id = ?", (snap_id,))
                liab_rows = cur.fetchall()
                conn.close()
                
                # Group assets by type
                assets_by_type = {}
                for atype, cat, name, val in asset_rows:
                    if atype not in assets_by_type:
                        assets_by_type[atype] = []
                    assets_by_type[atype].append((cat, name, float(val) if val else 0))
                
                add_val("â•â•â• CURRENT ASSETS â•â•â•", snap_date, "")
                
                # Cash
                cash_val = sum(v[2] for v in assets_by_type.get('cash', []))
                add_val("Cash & Bank Balances", snap_date, cash_val)
                
                # Gold
                gold_val = sum(v[2] for v in assets_by_type.get('gold', []))
                add_val("Gold Holdings", snap_date, gold_val)
                
                # Shares - breakdown by individual holdings
                shares_val = 0
                for cat, name, val in assets_by_type.get('shares', []):
                    display_name = name if name else cat if cat else 'Unknown'
                    if display_name and val > 0:
                        add_val(f"  Inv: {display_name}", snap_date, val)
                        shares_val += val
                
                # Crypto
                crypto_val = sum(v[2] for v in assets_by_type.get('crypto', []))
                add_val("Crypto & USA Securities", snap_date, crypto_val)
                
                total_current = cash_val + gold_val + shares_val + crypto_val
                add_val("TOTAL CURRENT ASSETS", snap_date, total_current)
                
                # Fixed Assets (Other category)
                add_val("â•â•â• FIXED ASSETS â•â•â•", snap_date, "")
                other_val = sum(v[2] for v in assets_by_type.get('other', []))
                add_val("Fixed Assets (Legal/Office)", snap_date, other_val)
                add_val("TOTAL FIXED ASSETS", snap_date, other_val)
                
                # Long Term Investments (Real Estate)
                add_val("â•â•â• LONG TERM INVESTMENTS â•â•â•", snap_date, "")
                re_val = sum(v[2] for v in assets_by_type.get('real_estate', []))
                add_val("Real Estate Investment", snap_date, re_val)
                add_val("TOTAL LONG TERM INV", snap_date, re_val)
                
                total_assets = total_current + other_val + re_val
                add_val("TOTAL ASSETS", snap_date, total_assets)
                
                # Liabilities
                add_val("â•â•â• LIABILITIES â•â•â•", snap_date, "")
                curr_liab = sum(r[1] for r in liab_rows if r[2]) if liab_rows else 0
                long_liab = sum(r[1] for r in liab_rows if r[3]) if liab_rows else 0
                
                add_val("Current Liabilities", snap_date, curr_liab)
                add_val("Long Term Loans", snap_date, long_liab)
                add_val("TOTAL LIABILITIES", snap_date, curr_liab + long_liab)
                
                # Net Worth
                net_worth = total_assets - (curr_liab + long_liab)
                add_val("NET WORTH", snap_date, net_worth)
                
                # === C. KEY RATIOS ===
                add_val("â•â•â• KEY RATIOS â•â•â•", snap_date, "")
                
                wc = total_current - curr_liab
                add_val("Working Capital", snap_date, wc)
                
                de = ((curr_liab + long_liab) / net_worth) if net_worth > 0 else 0
                add_val("Debt/Equity Ratio", snap_date, de)
                
                roe = (net_profit / net_worth * 100) if net_worth > 0 else 0
                add_val("Return on Equity %", snap_date, roe)
                
                roa = (net_profit / total_assets * 100) if total_assets > 0 else 0
                add_val("Return on Assets %", snap_date, roa)
                
                savings_rate = (net_profit / turnover * 100) if turnover > 0 else 0
                add_val("Savings Rate %", snap_date, savings_rate)
            
            # === RENDER UNIFIED STATEMENT ===
            st.markdown("""
            <style>
            .fin-section { font-weight: bold; background-color: #1a1a2e; color: #00d4ff; padding: 8px 12px; margin-top: 10px; }
            .fin-total { font-weight: 800; background-color: #16213e; color: #fff; border-top: 2px solid #00d4ff; }
            .fin-subtotal { font-weight: 600; background-color: #0f3460; color: #e2e2e2; }
            </style>
            """, unsafe_allow_html=True)
            
            # Convert to DataFrame
            df_stmt = pd.DataFrame(report_data).T
            df_stmt = df_stmt[sorted(df_stmt.columns)]  # Chronological order
            
            # Format for display
            display_df = df_stmt.copy()
            for col in display_df.columns:
                display_df[col] = display_df[col].apply(
                    lambda x: "" if x == "" or (isinstance(x, str) and "â•â•â•" in str(x)) else 
                              f"{x:,.0f}" if isinstance(x, (int, float)) and abs(x) > 10 else
                              f"{x:.2f}" if isinstance(x, (int, float)) else str(x)
                )
            
            st.markdown(f"### ðŸ“‘ Financial Statement (Latest: {dates[-1]})")
            st.dataframe(display_df, use_container_width=True, height=600)
            
            # === GROWTH ANALYSIS MATRIX ===
            st.divider()
            st.markdown("### ðŸš€ Growth Analysis Matrix")
            
            growth_rows = []
            
            def add_growth_section(label, key_in_data):
                # Value Row
                row_val = {"Metric": label}
                for d in dates:
                    val = report_data.get(key_in_data, {}).get(d, 0)
                    row_val[d] = fmt_money_plain(val, 0) if isinstance(val, (int, float)) else "-"
                growth_rows.append(row_val)
                
                # Growth % Row
                row_pct = {"Metric": f"  â†³ Growth %"}
                prev_val = 0
                for i, d in enumerate(dates):
                    curr_val = report_data.get(key_in_data, {}).get(d, 0)
                    if not isinstance(curr_val, (int, float)):
                        curr_val = 0
                    if i == 0:
                        row_pct[d] = "-"
                    else:
                        g = get_growth(curr_val, prev_val)
                        row_pct[d] = f"{g:+.1f}%"
                    prev_val = curr_val
                growth_rows.append(row_pct)
            
            # Build growth sections
            add_growth_section("Revenue", "Turnover (Revenue)")
            add_growth_section("Net Profit", "NET PROFIT")
            add_growth_section("Cash", "Cash & Bank Balances")
            
            # Shares aggregate
            share_keys = [k for k in report_data.keys() if "Inv:" in k]
            if share_keys:
                report_data["Total Shares"] = {d: sum(report_data[k].get(d, 0) for k in share_keys if isinstance(report_data[k].get(d, 0), (int, float))) for d in dates}
                add_growth_section("Shares Value", "Total Shares")
            
            add_growth_section("Total Assets", "TOTAL ASSETS")
            add_growth_section("Total Liabilities", "TOTAL LIABILITIES")
            add_growth_section("Net Worth", "NET WORTH")
            
            df_growth = pd.DataFrame(growth_rows)
            
            # Style the growth table
            def style_growth(val):
                if isinstance(val, str) and '%' in val:
                    try:
                        pct = float(val.replace('%', '').replace('+', ''))
                        if pct > 0:
                            return 'color: #10b981; font-weight: bold'
                        elif pct < 0:
                            return 'color: #ef4444; font-weight: bold'
                    except:
                        pass
                return ''
            
            styled_growth = df_growth.style.applymap(style_growth)
            st.dataframe(styled_growth, use_container_width=True, hide_index=True)
            
            # CAGR if multiple years
            if len(dates) >= 2:
                st.divider()
                st.markdown("### ðŸ“ˆ Compound Growth (CAGR)")
                
                start_nw = report_data.get("NET WORTH", {}).get(dates[0], 0)
                end_nw = report_data.get("NET WORTH", {}).get(dates[-1], 0)
                
                try:
                    start_date = datetime.strptime(dates[0], "%Y-%m-%d")
                    end_date = datetime.strptime(dates[-1], "%Y-%m-%d")
                    years = (end_date - start_date).days / 365.25
                    
                    if start_nw > 0 and years > 0 and isinstance(end_nw, (int, float)):
                        cagr = (end_nw / start_nw) ** (1 / years) - 1
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ðŸ“Š Net Worth CAGR", f"{cagr:.2%}")
                        with col2:
                            st.metric("ðŸ’° Starting Net Worth", f"{start_nw:,.0f} KWD", help=f"As of {dates[0]}")
                        with col3:
                            delta = end_nw - start_nw
                            st.metric("ðŸ’Ž Current Net Worth", f"{end_nw:,.0f} KWD", delta=f"{delta:+,.0f} KWD")
                except Exception as e:
                    st.warning(f"Could not calculate CAGR: {e}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 3: BALANCE SHEET (Legacy - kept for detailed view)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with pfm_tabs[2]:
        st.subheader("ðŸ“‹ Balance Sheet & Net Worth")

        conn = get_conn()
        try:
            cur = conn.cursor()
            db_execute(cur, """
                SELECT id, snapshot_date, notes FROM pfm_snapshots
                WHERE user_id = ?
                ORDER BY snapshot_date DESC
            """, (user_id,))
            snapshots = cur.fetchall()
        except:
            snapshots = []
        finally:
            conn.close()

        if not snapshots:
            st.info("No financial snapshots found. Create one in the Data Entry tab.")
        else:
            snapshot_options = {f"{s[1]} - {s[2] if s[2] else 'No notes'}": s[0] for s in snapshots}
            selected_dates = st.multiselect("Select Snapshots", list(snapshot_options.keys()), 
                default=list(snapshot_options.keys())[:min(3, len(snapshot_options))], key="bs_snapshots")

            if selected_dates:
                bs_data = {}
                for date_label in selected_dates:
                    snap_id = snapshot_options[date_label]
                    snap_date = date_label.split(" - ")[0]
                    
                    conn = get_conn()
                    cur = conn.cursor()
                    
                    # Get assets by type
                    db_execute(cur, """
                        SELECT asset_type, SUM(value_kwd) FROM pfm_asset_items
                        WHERE snapshot_id = ?
                        GROUP BY asset_type
                    """, (snap_id,))
                    asset_rows = cur.fetchall()
                    assets = {r[0]: float(r[1]) for r in asset_rows}
                    
                    # Get liabilities
                    db_execute(cur, """
                        SELECT SUM(CASE WHEN is_current = 1 THEN amount_kwd ELSE 0 END),
                               SUM(CASE WHEN is_long_term = 1 THEN amount_kwd ELSE 0 END)
                        FROM pfm_liability_items
                        WHERE snapshot_id = ?
                    """, (snap_id,))
                    liab_row = cur.fetchone()
                    current_liab = float(liab_row[0] or 0) if liab_row else 0
                    long_term_liab = float(liab_row[1] or 0) if liab_row else 0
                    conn.close()

                    total_assets = sum(assets.values())
                    total_liab = current_liab + long_term_liab
                    net_worth = total_assets - total_liab

                    # Cash includes cash and crypto as liquid
                    liquid_assets = assets.get("cash", 0) + assets.get("crypto", 0)

                    bs_data[snap_date] = {
                        "Real Estate": assets.get("real_estate", 0),
                        "Shares/Investments": assets.get("shares", 0),
                        "Gold": assets.get("gold", 0),
                        "Cash & Bank": assets.get("cash", 0),
                        "Crypto": assets.get("crypto", 0),
                        "Other Assets": assets.get("other", 0),
                        "TOTAL ASSETS": total_assets,
                        "---": "---",
                        "Current Liabilities": current_liab,
                        "Long-term Liabilities": long_term_liab,
                        "TOTAL LIABILITIES": total_liab,
                        "----": "----",
                        "NET WORTH": net_worth,
                        "Equity Ratio %": (net_worth / total_assets * 100) if total_assets else 0
                    }

                # Create Balance Sheet DataFrame
                bs_df = pd.DataFrame(bs_data).T.T
                display_df = bs_df.copy()
                for col in display_df.columns:
                    display_df[col] = display_df[col].apply(lambda x: f"{x:,.2f}" if isinstance(x, (int, float)) and x not in ["---", "----"] else x)
                
                st.markdown("#### Balance Sheet (KWD)")
                render_styled_table(display_df.reset_index().rename(columns={"index": "Line Item"}), "Balance Sheet")

                # Net Worth Chart
                if len(selected_dates) > 1:
                    nw_chart = pd.DataFrame({
                        "Date": list(bs_data.keys()),
                        "Net Worth": [bs_data[d]["NET WORTH"] for d in bs_data]
                    })
                    st.line_chart(nw_chart.set_index("Date"))

                # Asset Allocation Pie for latest snapshot
                if bs_data:
                    latest = list(bs_data.keys())[0]
                    asset_alloc = {
                        "Real Estate": bs_data[latest]["Real Estate"],
                        "Shares": bs_data[latest]["Shares/Investments"],
                        "Gold": bs_data[latest]["Gold"],
                        "Cash": bs_data[latest]["Cash & Bank"],
                        "Crypto": bs_data[latest]["Crypto"],
                        "Other": bs_data[latest]["Other Assets"]
                    }
                    asset_alloc = {k: v for k, v in asset_alloc.items() if v > 0}
                    if asset_alloc:
                        st.markdown(f"#### Asset Allocation ({latest})")
                        alloc_df = pd.DataFrame(list(asset_alloc.items()), columns=["Asset Type", "Value (KWD)"])
                        alloc_df["Percentage"] = alloc_df["Value (KWD)"] / alloc_df["Value (KWD)"].sum() * 100
                        render_styled_table(alloc_df, "Asset Allocation")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 4: RATIOS & GROWTH
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with pfm_tabs[3]:
        st.subheader("ðŸ“ˆ Financial Ratios & Growth Analysis")

        conn = get_conn()
        try:
            cur = conn.cursor()
            db_execute(cur, """
                SELECT id, snapshot_date, notes FROM pfm_snapshots
                WHERE user_id = ?
                ORDER BY snapshot_date ASC
            """, (user_id,))
            snapshots = cur.fetchall()
        except:
            snapshots = []
        finally:
            conn.close()

        if len(snapshots) < 1:
            st.info("Create financial snapshots to see ratio analysis and growth trends.")
        else:
            # Calculate ratios for all snapshots
            all_metrics = []
            for snap in snapshots:
                snap_id, snap_date, notes = snap
                conn = get_conn()
                cur = conn.cursor()
                
                # Get income/expenses
                db_execute(cur, """
                    SELECT kind, SUM(monthly_amount) FROM pfm_income_expense_items
                    WHERE snapshot_id = ?
                    GROUP BY kind
                """, (snap_id,))
                ie_rows = {r[0]: float(r[1]) * 12 for r in cur.fetchall()}
                
                # Get assets
                db_execute(cur, """
                    SELECT asset_type, SUM(value_kwd) FROM pfm_asset_items
                    WHERE snapshot_id = ?
                    GROUP BY asset_type
                """, (snap_id,))
                assets = {r[0]: float(r[1]) for r in cur.fetchall()}
                
                # Get liabilities
                db_execute(cur, """
                    SELECT SUM(CASE WHEN is_current = 1 THEN amount_kwd ELSE 0 END),
                           SUM(CASE WHEN is_long_term = 1 THEN amount_kwd ELSE 0 END),
                           SUM(amount_kwd)
                        FROM pfm_liability_items
                    WHERE snapshot_id = ?
                """, (snap_id,))
                liab_row = cur.fetchone()
                current_liab = float(liab_row[0] or 0) if liab_row else 0
                long_term_liab = float(liab_row[1] or 0) if liab_row else 0
                total_liab = float(liab_row[2] or 0) if liab_row else 0
                conn.close()

                total_income = ie_rows.get("income", 0)
                total_expense = ie_rows.get("expense", 0)
                net_income = total_income - total_expense
                total_assets = sum(assets.values())
                net_worth = total_assets - total_liab
                liquid_assets = assets.get("cash", 0) + assets.get("crypto", 0)

                # Calculate ratios
                current_ratio = liquid_assets / current_liab if current_liab > 0 else float('inf')
                debt_to_equity = total_liab / net_worth if net_worth > 0 else float('inf')
                debt_to_assets = total_liab / total_assets if total_assets > 0 else 0
                roe = (net_income / net_worth * 100) if net_worth > 0 else 0
                roa = (net_income / total_assets * 100) if total_assets > 0 else 0
                savings_rate = (net_income / total_income * 100) if total_income > 0 else 0

                all_metrics.append({
                    "Date": str(snap_date),
                    "Total Income": total_income,
                    "Total Expenses": total_expense,
                    "Net Income": net_income,
                    "Total Assets": total_assets,
                    "Total Liabilities": total_liab,
                    "Net Worth": net_worth,
                    "Current Ratio": current_ratio if current_ratio != float('inf') else 999,
                    "Debt/Equity": debt_to_equity if debt_to_equity != float('inf') else 999,
                    "Debt/Assets %": debt_to_assets * 100,
                    "ROE %": roe,
                    "ROA %": roa,
                    "Savings Rate %": savings_rate
                })

            metrics_df = pd.DataFrame(all_metrics)
            
            # Display ratios table
            st.markdown("#### Key Financial Ratios")
            ratio_cols = ["Date", "Current Ratio", "Debt/Equity", "Debt/Assets %", "ROE %", "ROA %", "Savings Rate %"]
            ratio_display = metrics_df[ratio_cols].copy()
            for col in ratio_cols[1:]:
                ratio_display[col] = ratio_display[col].apply(lambda x: f"{x:.2f}" if x < 999 else "âˆž")
            render_styled_table(ratio_display, "Financial Ratios")

            # Growth Analysis
            if len(all_metrics) >= 2:
                st.markdown("#### Year-over-Year Growth")
                growth_data = []
                for i in range(1, len(all_metrics)):
                    prev = all_metrics[i-1]
                    curr = all_metrics[i]
                    
                    def calc_growth(curr_val, prev_val):
                        if prev_val == 0:
                            return 0 if curr_val == 0 else 100
                        return ((curr_val - prev_val) / abs(prev_val)) * 100
                    
                    growth_data.append({
                        "Period": f"{prev['Date']} â†’ {curr['Date']}",
                        "Income Growth %": calc_growth(curr["Total Income"], prev["Total Income"]),
                        "Expense Growth %": calc_growth(curr["Total Expenses"], prev["Total Expenses"]),
                        "Net Income Growth %": calc_growth(curr["Net Income"], prev["Net Income"]),
                        "Asset Growth %": calc_growth(curr["Total Assets"], prev["Total Assets"]),
                        "Net Worth Growth %": calc_growth(curr["Net Worth"], prev["Net Worth"])
                    })

                growth_df = pd.DataFrame(growth_data)
                display_growth = growth_df.copy()
                for col in display_growth.columns[1:]:
                    display_growth[col] = display_growth[col].apply(lambda x: f"{x:+.1f}%")
                render_styled_table(display_growth, "Growth Analysis")

                # Growth Charts
                st.markdown("#### Trends Over Time")
                col1, col2 = st.columns(2)
                with col1:
                    st.line_chart(metrics_df.set_index("Date")[["Total Income", "Total Expenses", "Net Income"]])
                with col2:
                    st.line_chart(metrics_df.set_index("Date")[["Total Assets", "Total Liabilities", "Net Worth"]])

            # Quick Health Check
            st.markdown("---")
            st.markdown("#### ðŸ¥ Financial Health Check")
            if all_metrics:
                latest = all_metrics[-1]
                
                checks = []
                # Emergency fund check (3-6 months expenses in liquid assets)
                monthly_expense = latest["Total Expenses"] / 12
                emergency_months = liquid_assets / monthly_expense if monthly_expense > 0 else 0
                if emergency_months >= 6:
                    checks.append(("âœ…", "Emergency Fund", f"{emergency_months:.1f} months of expenses covered"))
                elif emergency_months >= 3:
                    checks.append(("âš ï¸", "Emergency Fund", f"{emergency_months:.1f} months - aim for 6 months"))
                else:
                    checks.append(("âŒ", "Emergency Fund", f"Only {emergency_months:.1f} months - build to 3-6 months"))

                # Savings rate
                if latest["Savings Rate %"] >= 20:
                    checks.append(("âœ…", "Savings Rate", f"{latest['Savings Rate %']:.1f}% - Excellent!"))
                elif latest["Savings Rate %"] >= 10:
                    checks.append(("âš ï¸", "Savings Rate", f"{latest['Savings Rate %']:.1f}% - Good, aim for 20%+"))
                else:
                    checks.append(("âŒ", "Savings Rate", f"{latest['Savings Rate %']:.1f}% - Try to increase savings"))

                # Debt ratio
                debt_ratio = latest["Debt/Assets %"]
                if debt_ratio <= 30:
                    checks.append(("âœ…", "Debt Level", f"{debt_ratio:.1f}% of assets - Healthy"))
                elif debt_ratio <= 50:
                    checks.append(("âš ï¸", "Debt Level", f"{debt_ratio:.1f}% of assets - Moderate"))
                else:
                    checks.append(("âŒ", "Debt Level", f"{debt_ratio:.1f}% of assets - High, focus on debt reduction"))

                for icon, label, msg in checks:
                    st.markdown(f"{icon} **{label}:** {msg}")

            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # WEALTH TRAJECTORY VISUALIZATION
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            st.divider()
            st.subheader("ðŸ“ˆ Wealth Trajectory")
            
            if len(all_metrics) >= 2:
                # Prepare trend data for visualization
                trend_df = metrics_df.set_index("Date")[["Net Worth", "Total Assets", "Total Liabilities"]].copy()
                
                col_chart1, col_chart2 = st.columns([3, 1])
                with col_chart1:
                    st.markdown("##### Net Worth Over Time")
                    st.area_chart(trend_df[["Net Worth"]], color="#10b981", use_container_width=True)
                with col_chart2:
                    st.markdown("##### Assets vs Liabilities")
                    st.line_chart(trend_df[["Total Assets", "Total Liabilities"]], use_container_width=True)
                
                # CAGR Calculation
                start_val = all_metrics[0]["Net Worth"]
                end_val = all_metrics[-1]["Net Worth"]
                start_date = datetime.strptime(all_metrics[0]["Date"], "%Y-%m-%d")
                end_date = datetime.strptime(all_metrics[-1]["Date"], "%Y-%m-%d")
                years = (end_date - start_date).days / 365.25
                
                if start_val > 0 and years > 0:
                    cagr = (end_val / start_val) ** (1 / years) - 1
                    col_cagr1, col_cagr2, col_cagr3 = st.columns(3)
                    with col_cagr1:
                        st.metric("ðŸ“Š Compound Annual Growth (CAGR)", f"{cagr:.2%}")
                    with col_cagr2:
                        st.metric("ðŸ’° Starting Net Worth", f"{start_val:,.0f} KWD", help=f"As of {all_metrics[0]['Date']}")
                    with col_cagr3:
                        delta_val = end_val - start_val
                        st.metric("ðŸ’Ž Current Net Worth", f"{end_val:,.0f} KWD", delta=f"{delta_val:+,.0f} KWD")
            else:
                st.info("ðŸ“Š Create at least 2 snapshots to see your wealth trajectory and CAGR.")


# Google Analytics Tracking Code
GOOGLE_ANALYTICS_CODE = """
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B5N8PQ6JXB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-B5N8PQ6JXB');
</script>
"""


def inject_google_analytics():
    """Inject Google Analytics tracking code into the Streamlit app."""
    import streamlit.components.v1 as components
    components.html(GOOGLE_ANALYTICS_CODE, height=0, width=0)


# =========================
# AI ANALYST HELPER FUNCTIONS
# =========================

def load_pfm_snapshot_details(snapshot_id):
    """Fetches detailed DataFrames for a specific snapshot ID to populate the editor."""
    conn = get_conn()
    data = {}
    
    try:
        # 1. Income
        inc_df = pd.read_sql_query(
            convert_sql_placeholders("SELECT category as 'Category', monthly_amount as 'Monthly (KWD)' FROM pfm_income_expense_items WHERE snapshot_id = ? AND kind='income'"), 
            conn, params=(snapshot_id,)
        )
        data['income'] = inc_df if not inc_df.empty else pd.DataFrame([{"Category": "Salary", "Monthly (KWD)": 0.0}])
        
        # 2. Expense
        exp_df = pd.read_sql_query(
            convert_sql_placeholders("SELECT category as 'Category', monthly_amount as 'Monthly (KWD)', is_finance_cost as 'Finance Cost', is_gna as 'G&A' FROM pfm_income_expense_items WHERE snapshot_id = ? AND kind='expense'"), 
            conn, params=(snapshot_id,)
        )
        if not exp_df.empty:
            exp_df['Finance Cost'] = exp_df['Finance Cost'].astype(bool)
            exp_df['G&A'] = exp_df['G&A'].astype(bool)
            data['expense'] = exp_df
        else:
            data['expense'] = pd.DataFrame([{"Category": "Rent", "Monthly (KWD)": 0.0, "Finance Cost": False, "G&A": True}])

        # 3. Assets (Split by type for tabs)
        assets_all = pd.read_sql_query(
            convert_sql_placeholders("SELECT asset_type, category, name, quantity, price, currency, value_kwd FROM pfm_asset_items WHERE snapshot_id = ?"), 
            conn, params=(snapshot_id,)
        )
        
        if not assets_all.empty:
            # Real Estate
            re_data = assets_all[assets_all['asset_type'] == 'real_estate'][['name', 'value_kwd']].copy()
            re_data.columns = ['Name', 'Value (KWD)']
            data['real_estate'] = re_data if not re_data.empty else pd.DataFrame([{"Name": "", "Value (KWD)": 0.0}])
            
            # Shares
            shares_data = assets_all[assets_all['asset_type'] == 'shares'][['category', 'name', 'quantity', 'price', 'currency']].copy()
            shares_data.columns = ['Ticker', 'Name', 'Qty', 'Price', 'Currency']
            data['shares'] = shares_data if not shares_data.empty else pd.DataFrame([{"Ticker": "", "Name": "", "Qty": 0.0, "Price": 0.0, "Currency": "KWD"}])
            
            # Gold
            gold_data = assets_all[assets_all['asset_type'] == 'gold'][['category', 'quantity', 'price']].copy()
            gold_data.columns = ['Type', 'Grams', 'Price/Gram (KWD)']
            data['gold'] = gold_data if not gold_data.empty else pd.DataFrame([{"Type": "Bars", "Grams": 0.0, "Price/Gram (KWD)": 0.0}])
            
            # Cash
            cash_data = assets_all[assets_all['asset_type'] == 'cash'][['name', 'quantity', 'currency']].copy()
            cash_data.columns = ['Account', 'Amount', 'Currency']
            data['cash'] = cash_data if not cash_data.empty else pd.DataFrame([{"Account": "", "Amount": 0.0, "Currency": "KWD"}])
            
            # Crypto
            crypto_data = assets_all[assets_all['asset_type'] == 'crypto'][['name', 'quantity', 'price']].copy()
            crypto_data.columns = ['Coin', 'Qty', 'Price (USD)']
            data['crypto'] = crypto_data if not crypto_data.empty else pd.DataFrame([{"Coin": "", "Qty": 0.0, "Price (USD)": 0.0}])
        else:
            data['real_estate'] = pd.DataFrame([{"Name": "", "Value (KWD)": 0.0}])
            data['shares'] = pd.DataFrame([{"Ticker": "", "Name": "", "Qty": 0.0, "Price": 0.0, "Currency": "KWD"}])
            data['gold'] = pd.DataFrame([{"Type": "Bars", "Grams": 0.0, "Price/Gram (KWD)": 0.0}])
            data['cash'] = pd.DataFrame([{"Account": "", "Amount": 0.0, "Currency": "KWD"}])
            data['crypto'] = pd.DataFrame([{"Coin": "", "Qty": 0.0, "Price (USD)": 0.0}])
        
        # 4. Liabilities
        liab_df = pd.read_sql_query(
            convert_sql_placeholders("SELECT category as 'Category', amount_kwd as 'Amount (KWD)', is_current FROM pfm_liability_items WHERE snapshot_id = ?"), 
            conn, params=(snapshot_id,)
        )
        if not liab_df.empty:
            liab_df['Type'] = liab_df['is_current'].apply(lambda x: 'Current' if x == 1 else 'Long-term')
            data['liabilities'] = liab_df[['Category', 'Amount (KWD)', 'Type']].copy()
        else:
            data['liabilities'] = pd.DataFrame([{"Category": "Loan", "Amount (KWD)": 0.0, "Type": "Long-term"}])
            
    except Exception as e:
        logger.error(f"Error loading PFM snapshot details: {e}")
        # Return empty defaults
        data = {
            'income': pd.DataFrame([{"Category": "Salary", "Monthly (KWD)": 0.0}]),
            'expense': pd.DataFrame([{"Category": "Rent", "Monthly (KWD)": 0.0, "Finance Cost": False, "G&A": True}]),
            'real_estate': pd.DataFrame([{"Name": "", "Value (KWD)": 0.0}]),
            'shares': pd.DataFrame([{"Ticker": "", "Name": "", "Qty": 0.0, "Price": 0.0, "Currency": "KWD"}]),
            'gold': pd.DataFrame([{"Type": "Bars", "Grams": 0.0, "Price/Gram (KWD)": 0.0}]),
            'cash': pd.DataFrame([{"Account": "", "Amount": 0.0, "Currency": "KWD"}]),
            'crypto': pd.DataFrame([{"Coin": "", "Qty": 0.0, "Price (USD)": 0.0}]),
            'liabilities': pd.DataFrame([{"Category": "Loan", "Amount (KWD)": 0.0, "Type": "Long-term"}])
        }
    finally:
        conn.close()
    
    return data


@st.cache_data(ttl=60, show_spinner=False)  # Cache result for 60 seconds for instant refresh
def get_pfm_history(user_id):
    """Retrieves PFM snapshot history for a user, returns dict keyed by date."""
    history = {}
    
    # Get all snapshots for user
    snapshots = query_df("""
        SELECT id, snapshot_date, notes 
        FROM pfm_snapshots 
        WHERE user_id = ? 
        ORDER BY snapshot_date DESC
    """, (user_id,))
    
    if snapshots.empty:
        return history
    
    for _, snap in snapshots.iterrows():
        snap_id = snap['id']
        snap_date = str(snap['snapshot_date'])
        
        # Get income items
        income = query_df("""
            SELECT category, monthly_amount 
            FROM pfm_income_expense_items 
            WHERE snapshot_id = ? AND kind = 'income'
        """, (snap_id,))
        
        # Get expense items
        expense = query_df("""
            SELECT category, monthly_amount, is_finance_cost, is_gna 
            FROM pfm_income_expense_items 
            WHERE snapshot_id = ? AND kind = 'expense'
        """, (snap_id,))
        
        # Get assets
        assets = query_df("""
            SELECT asset_type, asset_name, value_kwd, currency 
            FROM pfm_assets 
            WHERE snapshot_id = ?
        """, (snap_id,))
        
        # Get liabilities
        liabilities = query_df("""
            SELECT liability_type, name, amount_kwd, currency 
            FROM pfm_liabilities 
            WHERE snapshot_id = ?
        """, (snap_id,))
        
        history[snap_date] = {
            'id': snap_id,
            'notes': snap['notes'],
            'income': income,
            'expense': expense,
            'assets': assets,
            'liabilities': liabilities
        }
    
    return history


def generate_content_safe(prompt):
    """
    Cascading Retry System for Google Gemini Free Tier.
    Tries each hardcoded stable model until one works.
    Returns: (response_text, model_name) on success, or raises Exception on total failure.
    """
    import google.generativeai as genai
    
    # HARDCODED STABLE MODELS - These are known to work on Free Tier
    # Order matters: Most reliable first
    models_to_try = [
        "gemini-1.5-flash",      # Classic stable - highest chance
        "gemini-2.0-flash",      # Standard 2.0
        "gemini-flash-latest",   # Production alias
        "gemini-1.5-pro",        # Pro fallback (lower rate limit)
        "gemini-1.0-pro",        # Legacy stable
    ]
    
    last_error = None
    tried_models = []
    
    for model_name in models_to_try:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            # Success!
            return response.text, model_name
            
        except Exception as e:
            err_str = str(e)
            tried_models.append(f"{model_name}: {err_str[:50]}")
            last_error = e
            
            # If it's a rate limit (429), don't try more - wait is needed
            if "429" in err_str or "RESOURCE_EXHAUSTED" in err_str:
                # Still try next model - it might have separate quota
                continue
            # If it's 404 (model not found), try next
            elif "404" in err_str or "not found" in err_str.lower():
                continue
            # Other errors - try next model anyway
            else:
                continue
    
    # All models failed
    error_summary = "\n".join(tried_models)
    raise Exception(f"All models failed. Tried:\n{error_summary}\n\nLast error: {last_error}")


def render_embedded_ai(context_data=None, role_desc="Senior Investment Analyst", key_prefix="embedded_ai", title="ðŸ¤– AI Investment Advisor", auto_fetch_data=True):
    """
    Reusable AI widget with strict user_id check, debug view, and comprehensive analysis.
    
    Args:
        context_data: Pre-fetched financial context string (optional if auto_fetch_data=True)
        role_desc: The AI persona description (e.g., "Senior CFO", "Portfolio Analyst")
        key_prefix: Unique prefix for widget keys to avoid conflicts
        title: Widget title for the expander
        auto_fetch_data: If True, automatically fetches user's financial data
    """
    with st.expander(title, expanded=False):
        st.caption("AI-powered investment analysis with Buy/Hold/Sell recommendations")
        
        # 1. User ID Check
        user_id = st.session_state.get('user_id')
        if not user_id:
            st.error("Please log in to use AI analysis.")
            return
        
        # 2. API Key Check
        if "gemini_api_key" not in st.session_state or not st.session_state.gemini_api_key:
            conn = get_conn()
            cur = conn.cursor()
            db_execute(cur, "SELECT gemini_api_key FROM users WHERE id = ?", (user_id,))
            res = cur.fetchone()
            conn.close()
            if res and res[0]:
                st.session_state.gemini_api_key = res[0]
        
        api_key = st.text_input(
            "Google Gemini API Key",
            type="password",
            value=st.session_state.get("gemini_api_key", ""),
            help="Get free key: https://aistudio.google.com/app/apikey",
            key=f"{key_prefix}_api_key"
        )
        
        if not api_key:
            st.info("ðŸ”‘ Please enter API Key to enable AI features.")
            st.markdown("[ðŸ‘‰ Get Free API Key](https://aistudio.google.com/app/apikey)")
            return
        
        # Save API key
        st.session_state.gemini_api_key = api_key
        try:
            conn = get_conn()
            cur = conn.cursor()
            db_execute(cur, "UPDATE users SET gemini_api_key = ? WHERE id = ?", (api_key, user_id))
            conn.commit()
            conn.close()
        except Exception:
            pass
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
        except ImportError:
            st.error("Library missing: pip install google-generativeai")
            return
        
        # 3. Quick prompts + Query Input
        st.markdown("**Quick Analysis Options:**")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ðŸ“ˆ Portfolio Analysis", key=f"{key_prefix}_quick_portfolio", width="stretch"):
                st.session_state[f"{key_prefix}_query"] = "Provide a comprehensive portfolio analysis with Buy/Hold/Sell recommendations for each stock."
        with col2:
            if st.button("âš ï¸ Risk Assessment", key=f"{key_prefix}_quick_risk", width="stretch"):
                st.session_state[f"{key_prefix}_query"] = "Analyze the risk level of my portfolio and suggest risk reduction strategies."
        
        col3, col4 = st.columns(2)
        with col3:
            if st.button("ðŸ’° Dividend Analysis", key=f"{key_prefix}_quick_div", width="stretch"):
                st.session_state[f"{key_prefix}_query"] = "Analyze my dividend income and recommend stocks for better dividend yield."
        with col4:
            if st.button("ðŸŽ¯ Investment Strategy", key=f"{key_prefix}_quick_strategy", width="stretch"):
                st.session_state[f"{key_prefix}_query"] = "Based on my portfolio, suggest an optimal investment strategy with specific actions."
        
        custom_query = st.text_area(
            "Your Question:",
            value=st.session_state.get(f"{key_prefix}_query", ""),
            placeholder="e.g., Analyze my portfolio risk, should I buy more of stock X, what is my net gain...",
            height=80,
            key=f"{key_prefix}_query_input"
        )
        
        run_btn = st.button("ðŸš€ Generate Detailed Report", type="primary", width="stretch", key=f"{key_prefix}_run")
        
        # 4. Execution
        if run_btn:
            if not custom_query.strip():
                st.warning("Please enter a question or select a quick option.")
                return
            
            # Fetch user's financial data if not provided or auto_fetch enabled
            if auto_fetch_data or not context_data:
                context_data = get_full_financial_context(user_id)
            
            # Check for errors
            if context_data.startswith("ERROR") or context_data.startswith("CRITICAL"):
                st.error(context_data)
                return
            
            # DEBUG: Show what data is being sent to AI
            with st.expander("ðŸ‘ï¸ View Your Data Sent to AI (Debug)", expanded=False):
                st.info("This is your saved financial data the AI will analyze:")
                st.text_area("Your Financial Data", context_data, height=300, disabled=True, key=f"{key_prefix}_context_view")
                st.caption(f"ðŸ“Š Data size: {len(context_data):,} characters")
            
            with st.spinner("ðŸ¤– Generating detailed investment report..."):
                try:
                    # Build comprehensive professional prompt
                    full_prompt = f"""
You are a {role_desc} at a top-tier investment firm. You provide detailed, professional financial analysis and recommendations.

**CLIENT'S QUESTION:** "{custom_query}"

============================================================
THE CLIENT'S ACTUAL FINANCIAL DATA (ANALYZE ONLY THIS DATA):
============================================================
{context_data}
============================================================

**CRITICAL ANALYSIS REQUIREMENTS:**

1. **DATA ACCURACY**: 
   - Use ONLY the numbers and values from the data above
   - Reference SPECIFIC stock symbols, prices, and dates from the data
   - If information is missing, clearly state: "This data is not available in your records"
   - DO NOT invent or assume any data not explicitly provided

2. **DETAILED REPORT FORMAT** (Provide ALL sections):

   **SECTION A: EXECUTIVE SUMMARY**
   - 3-5 bullet points summarizing key findings
   - Overall portfolio health score (1-10)
   - Primary recommendations

   **SECTION B: PORTFOLIO ANALYSIS BY STOCK**
   For EACH stock in the portfolio, provide:
   - Stock Symbol & Name
   - Current Position: [Shares], [Avg Cost], [Current Price], [Market Value]
   - Performance: [P/L Amount], [P/L Percentage]
   - **RECOMMENDATION: ðŸŸ¢ BUY / ðŸŸ¡ HOLD / ðŸ”´ SELL**
   - Reasoning for recommendation (2-3 sentences)

   **SECTION C: RISK ANALYSIS**
   - Diversification Assessment (Industry/Sector concentration)
   - Volatility Assessment (based on P/L swings)
   - Risk Level: LOW / MEDIUM / HIGH
   - Specific risk factors identified

   **SECTION D: FINANCIAL METRICS**
   - Total Portfolio Value (exact number from data)
   - Total Cost Basis (amount invested)
   - Unrealized P/L (with percentage)
   - Realized P/L (from completed trades)
   - Total Net Gain/Loss (Unrealized + Realized)
   - ROI Percentage
   - Dividend Income (if applicable)

   **SECTION E: ACTIONABLE RECOMMENDATIONS**
   - Top 3 specific actions the investor should take
   - Stocks to consider buying (if any)
   - Stocks to consider selling (if any)
   - Portfolio rebalancing suggestions
   - Cash allocation advice

   **SECTION F: ANSWER TO CLIENT'S SPECIFIC QUESTION**
   - Directly address the question asked: "{custom_query}"
   - Provide specific numbers from the data
   - Give clear, actionable advice

3. **FORMATTING RULES:**
   - Use **bold** for all monetary amounts
   - Use ðŸŸ¢ for positive/good items, ðŸ”´ for negative/concern items
   - Use bullet points for lists
   - Use tables where appropriate for comparisons
   - Currency: Use KWD (Kuwaiti Dinar) unless USD is specified
   - Round numbers to 3 decimal places for KWD

4. **PROFESSIONAL STANDARDS:**
   - Be specific, not vague
   - Provide reasoning for every recommendation
   - Consider both short-term and long-term perspectives
   - Include risk warnings where appropriate
   - Be honest about limitations in the data

Generate the comprehensive report now:
"""
                    
                    response_text, used_model = generate_content_safe(full_prompt)
                    
                    st.session_state[f"{key_prefix}_result"] = response_text
                    st.session_state[f"{key_prefix}_model"] = used_model
                    st.success(f"âœ… Detailed report generated (Model: {used_model})")
                
                except Exception as e:
                    st.error(f"AI Error: {e}")
        
        # 5. Display Result
        if f"{key_prefix}_result" in st.session_state:
            st.divider()
            st.markdown("### ðŸ“„ Investment Analysis Report")
            if f"{key_prefix}_model" in st.session_state:
                st.caption(f"Generated using: {st.session_state[f'{key_prefix}_model']}")
            st.markdown(st.session_state[f"{key_prefix}_result"])
            
            # Download option
            if st.download_button(
                label="ðŸ“¥ Download Report as Text",
                data=st.session_state[f"{key_prefix}_result"],
                file_name=f"investment_report_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                mime="text/plain",
                key=f"{key_prefix}_download"
            ):
                st.success("Report downloaded!")


def get_full_financial_context(user_id):
    """
    Aggregates comprehensive financial data STRICTLY for the provided user_id.
    All values are clearly labeled for AI interpretation.
    """
    import sqlite3
    import pandas as pd
    from datetime import datetime, timedelta
    
    if not user_id:
        return "ERROR: No user logged in."

    context_parts = []
    context_parts.append("=" * 60)
    context_parts.append(f"ðŸ“Š FINANCIAL DATA REPORT")
    context_parts.append(f"User ID: {user_id}")
    context_parts.append(f"Report Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    context_parts.append("=" * 60)

    try:
        # Verify session matches
        current_sess_id = st.session_state.get('user_id')
        if current_sess_id != user_id:
            return "ERROR: Session User ID mismatch."

        conn = get_conn()
        
        # ========================================
        # SECTION 1: CURRENT STOCK HOLDINGS
        # ========================================
        holdings_data = []
        total_cost_basis = 0.0
        total_market_value = 0.0
        total_unrealized_pnl = 0.0
        
        for p_name in ["KFH", "BBYN", "USA"]:
            try:
                df = build_portfolio_table(p_name)
                if not df.empty and "Symbol" in df.columns:
                    active_df = df[df['Shares Qty'] > 0.001] if 'Shares Qty' in df.columns else df
                    if not active_df.empty:
                        for _, r in active_df.iterrows():
                            symbol = r.get('Symbol', 'Unknown')
                            shares = safe_float(r.get('Shares Qty', 0), 0)
                            avg_cost = safe_float(r.get('Avg Cost', 0), 0)
                            market_price = safe_float(r.get('Market Price', 0), 0)
                            market_value = safe_float(r.get('Market Value', 0), 0)
                            unrealized_pnl = safe_float(r.get('Unrealized P/L', 0), 0)
                            pnl_pct = safe_float(r.get('PNL %', 0), 0)
                            currency = r.get('Currency', 'KWD')
                            cost_basis = shares * avg_cost
                            
                            # Convert to KWD for totals
                            market_value_kwd = convert_to_kwd(market_value, currency)
                            unrealized_pnl_kwd = convert_to_kwd(unrealized_pnl, currency)
                            cost_basis_kwd = convert_to_kwd(cost_basis, currency)
                            
                            total_cost_basis += cost_basis_kwd
                            total_market_value += market_value_kwd
                            total_unrealized_pnl += unrealized_pnl_kwd
                            
                            holdings_data.append({
                                'Portfolio': p_name,
                                'Stock Symbol': symbol,
                                'Shares Owned': shares,
                                'Average Cost Per Share': avg_cost,
                                'Current Market Price': market_price,
                                'Total Cost Basis': cost_basis,
                                'Current Market Value': market_value,
                                'Unrealized Profit/Loss': unrealized_pnl,
                                'Return Percentage': pnl_pct,
                                'Currency': currency
                            })
            except Exception as e:
                logger.error(f"Error reading portfolio {p_name}: {e}")

        if holdings_data:
            context_parts.append("\n" + "=" * 60)
            context_parts.append("SECTION 1: CURRENT STOCK HOLDINGS")
            context_parts.append("=" * 60)
            context_parts.append(f"\nSUMMARY METRICS:")
            context_parts.append(f"  â€¢ Number of Stocks Held: {len(holdings_data)}")
            context_parts.append(f"  â€¢ Total Cost Basis (Amount Invested): {total_cost_basis:,.3f} KWD")
            context_parts.append(f"  â€¢ Total Current Market Value: {total_market_value:,.3f} KWD")
            context_parts.append(f"  â€¢ Total Unrealized Profit/Loss: {total_unrealized_pnl:,.3f} KWD")
            if total_cost_basis > 0:
                overall_return_pct = ((total_market_value - total_cost_basis) / total_cost_basis) * 100
                context_parts.append(f"  â€¢ Overall Portfolio Return: {overall_return_pct:.2f}%")
            
            context_parts.append("\nDETAILED HOLDINGS:")
            for h in holdings_data:
                context_parts.append(f"\n  [{h['Stock Symbol']}] - Portfolio: {h['Portfolio']}")
                context_parts.append(f"    Shares Owned: {h['Shares Owned']:,.0f}")
                context_parts.append(f"    Average Cost Per Share: {h['Average Cost Per Share']:.4f} {h['Currency']}")
                context_parts.append(f"    Current Market Price: {h['Current Market Price']:.4f} {h['Currency']}")
                context_parts.append(f"    Total Cost Basis: {h['Total Cost Basis']:,.3f} {h['Currency']}")
                context_parts.append(f"    Current Market Value: {h['Current Market Value']:,.3f} {h['Currency']}")
                context_parts.append(f"    Unrealized Profit/Loss: {h['Unrealized Profit/Loss']:,.3f} {h['Currency']}")
                context_parts.append(f"    Return Percentage: {h['Return Percentage']:.2f}%")
        else:
            context_parts.append("\n" + "=" * 60)
            context_parts.append("SECTION 1: CURRENT STOCK HOLDINGS")
            context_parts.append("=" * 60)
            context_parts.append("\nâš ï¸ USER HAS NO ACTIVE STOCK HOLDINGS")

        # ========================================
        # SECTION 2: REALIZED PROFITS (Closed Trades)
        # ========================================
        context_parts.append("\n" + "=" * 60)
        context_parts.append("SECTION 2: REALIZED PROFITS (COMPLETED TRADES)")
        context_parts.append("=" * 60)
        
        try:
            # From main transactions table (portfolio sells)
            sell_df = pd.read_sql_query(
                convert_sql_placeholders("""
                    SELECT stock_symbol, txn_date, shares, purchase_cost, sell_value,
                           (sell_value - purchase_cost) as profit
                    FROM transactions 
                    WHERE user_id = ? AND txn_type = 'Sell' AND sell_value > 0
                    ORDER BY txn_date DESC
                """),
                conn,
                params=(user_id,)
            )
            
            portfolio_realized = 0.0
            if not sell_df.empty:
                portfolio_realized = sell_df['profit'].sum()
                context_parts.append(f"\nPORTFOLIO REALIZED PROFIT: {portfolio_realized:,.3f} KWD")
                context_parts.append("\nRecent Closed Trades:")
                for _, row in sell_df.head(10).iterrows():
                    profit = safe_float(row['profit'], 0)
                    context_parts.append(f"  â€¢ {row['stock_symbol']}: Sold {row['shares']:,.0f} shares on {row['txn_date']}")
                    context_parts.append(f"    Cost: {row['purchase_cost']:,.3f} | Sold For: {row['sell_value']:,.3f} | Profit: {profit:,.3f} KWD")
            else:
                context_parts.append("\nNo portfolio sell transactions recorded.")
            
            # Calculate FIFO-based realized profit from transactions table
            trading_realized = calculate_trading_realized_profit(user_id)
            
            if trading_realized != 0:
                context_parts.append(f"\nTRADING REALIZED PROFIT (FIFO): {trading_realized:,.3f} KWD")
                context_parts.append(f"  â€¢ (Calculated from matched buy/sell pairs only)")
            else:
                context_parts.append("\nNo closed trading positions with realized profits.")
            
            total_realized = portfolio_realized + trading_realized
            context_parts.append(f"\n** TOTAL REALIZED PROFIT: {total_realized:,.3f} KWD **")
            
        except Exception as e:
            context_parts.append(f"\nError calculating realized profits: {e}")

        # ========================================
        # SECTION 3: DIVIDENDS RECEIVED
        # ========================================
        context_parts.append("\n" + "=" * 60)
        context_parts.append("SECTION 3: DIVIDENDS & BONUS SHARES")
        context_parts.append("=" * 60)
        
        try:
            div_df = pd.read_sql_query(
                convert_sql_placeholders("""
                    SELECT t.stock_symbol, t.txn_date, 
                           t.cash_dividend, t.bonus_shares,
                           COALESCE(s.currency, 'KWD') as currency
                    FROM transactions t
                    LEFT JOIN stocks s ON t.stock_symbol = s.symbol AND s.user_id = t.user_id
                    WHERE t.user_id = ? AND (t.cash_dividend > 0 OR t.bonus_shares > 0)
                    ORDER BY t.txn_date DESC
                """),
                conn,
                params=(user_id,)
            )
            div_df = div_df.rename(columns={
                'stock_symbol': 'Stock', 'txn_date': 'Date',
                'cash_dividend': 'Cash_Dividend', 'bonus_shares': 'Bonus_Shares',
                'currency': 'Currency'
            })
            
            if not div_df.empty:
                total_cash_div = 0.0
                for _, row in div_df.iterrows():
                    total_cash_div += convert_to_kwd(safe_float(row['Cash_Dividend'], 0), row['Currency'])
                total_bonus = div_df['Bonus_Shares'].sum()
                
                context_parts.append(f"\nDIVIDEND SUMMARY:")
                context_parts.append(f"  â€¢ Total Cash Dividends Received: {total_cash_div:,.3f} KWD")
                context_parts.append(f"  â€¢ Total Bonus Shares Received: {total_bonus:,.0f} shares")
                
                context_parts.append("\nDividend History:")
                for _, row in div_df.head(15).iterrows():
                    if row['Cash_Dividend'] > 0:
                        context_parts.append(f"  â€¢ {row['Stock']}: Cash Dividend of {row['Cash_Dividend']:,.3f} {row['Currency']} on {row['Date']}")
                    if row['Bonus_Shares'] > 0:
                        context_parts.append(f"  â€¢ {row['Stock']}: Bonus Shares of {row['Bonus_Shares']:,.0f} on {row['Date']}")
            else:
                context_parts.append("\nâš ï¸ No dividends or bonus shares recorded.")
        except Exception as e:
            context_parts.append(f"\nError reading dividends: {e}")

        # ========================================
        # SECTION 4: CASH DEPOSITS & BALANCES
        # ========================================
        context_parts.append("\n" + "=" * 60)
        context_parts.append("SECTION 4: CASH DEPOSITS & AVAILABLE FUNDS")
        context_parts.append("=" * 60)
        
        try:
            deposits_df = pd.read_sql_query(
                convert_sql_placeholders(
                    "SELECT deposit_date, amount, currency, bank_name FROM cash_deposits WHERE user_id = ? ORDER BY deposit_date DESC"
                ),
                conn,
                params=(user_id,)
            )
            
            total_deposits_kwd = 0.0
            if not deposits_df.empty:
                for _, row in deposits_df.iterrows():
                    total_deposits_kwd += convert_to_kwd(safe_float(row['amount'], 0), row.get('currency', 'KWD'))
                
                context_parts.append(f"\nTOTAL CASH DEPOSITED: {total_deposits_kwd:,.3f} KWD")
                context_parts.append("\nRecent Deposits:")
                for _, row in deposits_df.head(10).iterrows():
                    context_parts.append(f"  â€¢ {row['deposit_date']}: {row['amount']:,.3f} {row['currency']} to {row['bank_name']}")
            else:
                total_deposits_kwd = 0.0
                context_parts.append("\nâš ï¸ No cash deposits recorded.")
            
            # Cash Balance
            cash_df = pd.read_sql_query(
                convert_sql_placeholders("SELECT balance, currency FROM portfolio_cash WHERE user_id = ?"),
                conn,
                params=(user_id,)
            )
            cash_balance_kwd = 0.0
            if not cash_df.empty:
                for _, row in cash_df.iterrows():
                    cash_balance_kwd += convert_to_kwd(safe_float(row['balance'], 0), row['currency'])
                context_parts.append(f"\nAVAILABLE CASH BALANCE: {cash_balance_kwd:,.3f} KWD")
        except Exception as e:
            total_deposits_kwd = 0.0
            cash_balance_kwd = 0.0
            context_parts.append(f"\nError reading cash data: {e}")

        # ========================================
        # SECTION 5: PERSONAL FINANCE (PFM)
        # ========================================
        context_parts.append("\n" + "=" * 60)
        context_parts.append("SECTION 5: PERSONAL FINANCE OVERVIEW")
        context_parts.append("=" * 60)
        
        try:
            history = get_pfm_history(user_id)
            if history:
                latest_date = sorted(history.keys())[-1]
                snap = history[latest_date]
                
                inc = snap['income']['monthly_amount'].sum() if not snap['income'].empty else 0
                exp = snap['expense']['monthly_amount'].sum() if not snap['expense'].empty else 0
                assets = snap['assets']['value_kwd'].sum() if not snap['assets'].empty else 0
                liabs = snap['liabilities']['amount_kwd'].sum() if not snap['liabilities'].empty else 0
                net_worth = assets - liabs
                monthly_savings = inc - exp
                savings_rate = (monthly_savings / inc * 100) if inc > 0 else 0
                
                context_parts.append(f"\nLatest PFM Snapshot Date: {latest_date}")
                context_parts.append(f"\nNET WORTH CALCULATION:")
                context_parts.append(f"  â€¢ Total Assets: {assets:,.3f} KWD")
                context_parts.append(f"  â€¢ Total Liabilities (Debt): {liabs:,.3f} KWD")
                context_parts.append(f"  â€¢ NET WORTH: {net_worth:,.3f} KWD")
                context_parts.append(f"\nMONTHLY CASH FLOW:")
                context_parts.append(f"  â€¢ Monthly Income: {inc:,.3f} KWD")
                context_parts.append(f"  â€¢ Monthly Expenses: {exp:,.3f} KWD")
                context_parts.append(f"  â€¢ Monthly Savings: {monthly_savings:,.3f} KWD")
                context_parts.append(f"  â€¢ Savings Rate: {savings_rate:.1f}%")
                
                if not snap['assets'].empty:
                    context_parts.append("\nASSET BREAKDOWN:")
                    for _, row in snap['assets'].groupby('asset_type')['value_kwd'].sum().reset_index().iterrows():
                        context_parts.append(f"  â€¢ {row['asset_type']}: {row['value_kwd']:,.3f} KWD")
                
                if not snap['liabilities'].empty:
                    context_parts.append("\nLIABILITY BREAKDOWN:")
                    for _, row in snap['liabilities'].groupby('liability_type')['amount_kwd'].sum().reset_index().iterrows():
                        context_parts.append(f"  â€¢ {row['liability_type']}: {row['amount_kwd']:,.3f} KWD")
            else:
                context_parts.append("\nâš ï¸ No Personal Finance data recorded.")
        except Exception as e:
            context_parts.append(f"\nError reading PFM data: {e}")

        # ========================================
        # SECTION 6: PERFORMANCE SUMMARY
        # ========================================
        context_parts.append("\n" + "=" * 60)
        context_parts.append("SECTION 6: OVERALL PERFORMANCE SUMMARY")
        context_parts.append("=" * 60)
        
        try:
            combined_pnl = total_unrealized_pnl + total_realized
            total_portfolio_value = total_market_value + cash_balance_kwd
            
            context_parts.append(f"\nPORTFOLIO VALUE BREAKDOWN:")
            context_parts.append(f"  â€¢ Stock Holdings Value: {total_market_value:,.3f} KWD")
            context_parts.append(f"  â€¢ Cash Balance: {cash_balance_kwd:,.3f} KWD")
            context_parts.append(f"  â€¢ TOTAL PORTFOLIO VALUE: {total_portfolio_value:,.3f} KWD")
            
            context_parts.append(f"\nPROFIT/LOSS SUMMARY:")
            context_parts.append(f"  â€¢ Unrealized P/L (Open Positions): {total_unrealized_pnl:,.3f} KWD")
            context_parts.append(f"  â€¢ Realized P/L (Closed Trades): {total_realized:,.3f} KWD")
            context_parts.append(f"  â€¢ COMBINED TOTAL P/L: {combined_pnl:,.3f} KWD")
            
            # Calculate ROI
            if total_deposits_kwd > 0:
                roi = ((total_portfolio_value - total_deposits_kwd) / total_deposits_kwd) * 100
                context_parts.append(f"\nRETURN ON INVESTMENT:")
                context_parts.append(f"  â€¢ Total Deposited: {total_deposits_kwd:,.3f} KWD")
                context_parts.append(f"  â€¢ Current Value: {total_portfolio_value:,.3f} KWD")
                context_parts.append(f"  â€¢ Net Gain/Loss: {(total_portfolio_value - total_deposits_kwd):,.3f} KWD")
                context_parts.append(f"  â€¢ ROI Percentage: {roi:.2f}%")
            
        except Exception as e:
            context_parts.append(f"\nError calculating performance: {e}")

        conn.close()
        context_parts.append("\n" + "=" * 60)
        context_parts.append("END OF FINANCIAL DATA REPORT")
        context_parts.append("=" * 60)

    except Exception as e:
        return f"CRITICAL ERROR generating context: {str(e)}"

    return "\n".join(context_parts)


def create_pdf_report(analysis_text):
    """Generates a PDF report from the AI analysis."""
    try:
        from reportlab.lib.pagesizes import letter
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib import colors
    except ImportError:
        # Return None if reportlab not available
        return None
    
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []

    # Title
    title_style = styles['Title']
    story.append(Paragraph("Financial Intelligence Report", title_style))
    story.append(Paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}", styles['Normal']))
    story.append(Spacer(1, 12))

    # Content - Handle basic formatting
    style_body = ParagraphStyle('Body', parent=styles['BodyText'], leading=14, spaceAfter=10)
    
    # Split by newlines and create paragraphs
    for line in analysis_text.split('\n'):
        if line.strip():
            # Basic clean up of markdown bolding for PDF
            clean_line = line.replace('**', '')
            clean_line = clean_line.replace('###', '').replace('##', '').replace('#', '')
            # Escape XML characters
            clean_line = clean_line.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            try:
                story.append(Paragraph(clean_line, style_body))
            except:
                story.append(Paragraph(line.replace('&', '').replace('<', '').replace('>', ''), style_body))
                
    doc.build(story)
    buffer.seek(0)
    return buffer


def ui_user_profile_sidebar():
    """Sidebar widget for User Profile & Password Management"""
    if not st.session_state.get('logged_in'):
        return

    st.sidebar.divider()
    
    # Expandable section for Account Security
    with st.sidebar.expander("ðŸ” Account Security", expanded=False):
        user_id = st.session_state.get('user_id')
        user_email = st.session_state.get('username')  # Username might be email
        
        # State Management for this widget
        if "pass_reset_stage" not in st.session_state:
            st.session_state.pass_reset_stage = "request"  # request, verify

        if st.session_state.pass_reset_stage == "request":
            st.caption(f"Update password for: {user_email}")
            if st.button("ðŸ“§ Send OTP to Change Password", width="stretch", key="send_pass_otp"):
                # 1. Fetch real email if username is not email
                conn = get_conn()
                cur = conn.cursor()
                db_execute(cur, "SELECT email FROM users WHERE id = ?", (user_id,))
                res = cur.fetchone()
                conn.close()
                
                real_email = res[0] if res else user_email
                
                if real_email:
                    # 2. Generate & Send OTP
                    import random
                    otp_code = str(random.randint(100000, 999999))
                    exp_time = int(time.time()) + 600  # 10 mins expiry
                    
                    conn = get_conn()
                    cur = conn.cursor()
                    db_execute(cur, "DELETE FROM password_resets WHERE email=?", (real_email,))
                    db_execute(cur, "INSERT INTO password_resets (email, otp, expires_at, created_at) VALUES (?, ?, ?, ?)",
                              (real_email, otp_code, exp_time, int(time.time())))
                    conn.commit()
                    conn.close()
                    
                    # Send via existing helper
                    send_otp_email(real_email, otp_code)
                    
                    st.session_state.pass_reset_email = real_email
                    st.session_state.pass_reset_stage = "verify"
                    st.rerun()
                else:
                    st.error("No email associated with this account.")

        elif st.session_state.pass_reset_stage == "verify":
            st.info(f"OTP sent to {st.session_state.pass_reset_email}")
            
            with st.form("change_pass_form"):
                otp_input = st.text_input("Enter OTP", placeholder="123456")
                new_pass = st.text_input("New Password", type="password")
                confirm_pass = st.text_input("Confirm New Password", type="password")
                
                btn_change = st.form_submit_button("Update Password", type="primary", width="stretch")
                
                if btn_change:
                    if new_pass != confirm_pass:
                        st.error("Passwords do not match.")
                    elif len(new_pass) < 6:
                        st.error("Password too short (minimum 6 characters).")
                    else:
                        conn = get_conn()
                        cur = conn.cursor()
                        # Verify OTP
                        db_execute(cur, """
                            SELECT otp FROM password_resets 
                            WHERE email=? AND expires_at > ?
                        """, (st.session_state.pass_reset_email, int(time.time())))
                        row = cur.fetchone()
                        
                        if row and row[0] == otp_input.strip():
                            # Update Hash
                            new_hash = hash_password(new_pass)
                            db_execute(cur, "UPDATE users SET password_hash=? WHERE id=?", (new_hash, user_id))
                            # Cleanup
                            db_execute(cur, "DELETE FROM password_resets WHERE email=?", (st.session_state.pass_reset_email,))
                            conn.commit()
                            conn.close()
                            
                            st.success("âœ… Password updated!")
                            time.sleep(1)
                            st.session_state.pass_reset_stage = "request"
                            st.rerun()
                        else:
                            conn.close()
                            st.error("Invalid or Expired OTP.")
            
            if st.button("Cancel", key="cancel_pass_change"):
                st.session_state.pass_reset_stage = "request"
                st.rerun()


def show_pre_warm_screen():
    """Display a professional pre-warming/loading screen."""
    st.markdown("""
    <style>
    .prewarm-container {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        height: 70vh;
        text-align: center;
        padding: 2rem;
    }
    .prewarm-title {
        font-size: 1.8rem;
        font-weight: 700;
        margin-bottom: 1rem;
        color: #3b82f6;
    }
    .prewarm-status {
        font-size: 1rem;
        color: #64748b;
        margin: 0.5rem 0;
    }
    .prewarm-spinner {
        margin: 1.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown('<div class="prewarm-container">', unsafe_allow_html=True)
    st.markdown('<div class="prewarm-title">ðŸš€ Initializing Portfolio Intelligence</div>', unsafe_allow_html=True)
    
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    return status_text, progress_bar


def pre_warm_services():
    """Pre-warm critical services and cache results."""
    status_text, progress_bar = show_pre_warm_screen()
    
    steps = [
        ("Validating session...", lambda: st.session_state.get('logged_in', False)),
        ("Fetching USD/KWD rate...", fetch_usd_kwd_rate),
        ("Checking market data access...", _ensure_yfinance),
        ("Loading user preferences...", lambda: st.session_state.get('theme', 'light')),
        ("Verifying database...", get_db_info),
    ]
    
    for i, (msg, func) in enumerate(steps):
        status_text.markdown(f'<div class="prewarm-status">{msg}</div>', unsafe_allow_html=True)
        progress_bar.progress((i + 1) / len(steps))
        try:
            result = func()
            if result is None or result is False:
                logger.warning(f"Pre-warm step failed: {msg}")
        except Exception as e:
            logger.error(f"Pre-warm error in {msg}: {e}")
    
    # Finalize
    status_text.markdown('<div class="prewarm-status">âœ… Ready! Loading your portfolio...</div>', unsafe_allow_html=True)
    time.sleep(0.5)
    progress_bar.empty()


def main():
    # =============================
    # HEALTH CHECK ENDPOINT (for Cloud Deployments)
    # =============================
    # Allows load balancers/health monitors to check if app is running
    # Usage: ?health=check returns "OK" and exits
    if st.query_params.get("health") == "check":
        st.write("OK")
        st.stop()
    
    # NOTE: Cron endpoint moved to top of file (before st.set_page_config)
    # to ensure no UI elements load before the cron response
    
    _log_startup("main() started - About to render UI")
    
    # Inject Google Analytics (runs once per session)
    if 'ga_injected' not in st.session_state:
        inject_google_analytics()
        st.session_state['ga_injected'] = True
    
    # Initialize Cookie Manager FIRST (needed for session restore)
    cookie_manager = None
    cookies_data = None  # CRITICAL FIX: Single fetch variable
    
    if stx:
        try:
            cookie_manager = stx.CookieManager(key="portfolio_auth_v3")
            # --- CRITICAL FIX: Fetch cookies ONCE here ---
            cookies_data = cookie_manager.get_all()
        except Exception as e:
            logger.warning(f"Cookie manager init error: {e}")

    # =============================
    # FAST SESSION CHECK (BEFORE DB INIT)
    # =============================
    # If already authenticated (e.g., from app.py router), skip auth checks
    if st.session_state.get('logged_in') and st.session_state.get('user_id'):
        _log_startup("User already authenticated - skipping auth checks")
        pass  # Continue directly to main app
    else:
        # Try to restore session from cookie
        restored = False
        cookies_loaded = False  # Track if cookies have actually loaded
        
        if cookie_manager:
            try:
                # Use the already fetched cookies_data variable
                if cookies_data is not None:
                    cookies_loaded = True
                    session_token = cookies_data.get("portfolio_session")
                    if session_token:
                        # NOTE: get_user_from_token requires DB - but it handles errors gracefully
                        user_info = get_user_from_token(session_token)
                        if user_info:
                            st.session_state.logged_in = True
                            st.session_state.user_id = user_info["id"]
                            st.session_state.username = user_info["username"]
                            restored = True
                        else:
                            # Token invalid - clean up silently
                            try:
                                cookie_manager.delete("portfolio_session")
                            except:
                                pass
            except Exception as e:
                logger.debug(f"Session restore error: {e}")
        
        # If cookies haven't loaded yet, rerun to let them load
        # Only rerun if we haven't checked AND cookies aren't loaded yet
        if not cookies_loaded and not st.session_state.get('_auth_checked'):
            st.session_state._auth_checked = True
            st.rerun()
        
        # Still not logged in? Show login page and EXIT EARLY
        # This is the key optimization - no DB init for guests!
        if not st.session_state.get('logged_in'):
            _log_startup("Showing login page (no DB init needed for guests)")
            login_page(cookie_manager)
            return  # â¬…ï¸ EXIT EARLY - don't initialize DB for anonymous users

    # =============================
    # DEFERRED DATABASE INITIALIZATION
    # =============================
    # CRITICAL: Only runs AFTER user is authenticated
    # This saves 25-35 seconds on cold starts for the login page
    if "db_initialized" not in st.session_state:
        _log_startup("Initializing database (first authenticated request)...")
        
        # Check for PostgreSQL and show errors if needed
        if is_postgres():
            try:
                init_postgres_schema()
                logger.info("âœ… PostgreSQL schema initialized successfully")
            except Exception as e:
                st.error(f"""
                âŒ **Database Connection Error**
                
                Could not connect to PostgreSQL database: `{e}`
                
                **Possible causes:**
                - DATABASE_URL is not set correctly in DigitalOcean/Heroku config vars
                - DATABASE_URL is empty or malformed
                - Database server is not accessible
                - psycopg2 driver not installed
                
                **To fix:**
                1. Verify DATABASE_URL is set in your app's environment variables
                2. Check the database is running and accessible
                3. Ensure the connection string includes `?sslmode=require`
                """)
                st.stop()
        else:
            if IS_PRODUCTION:
                st.error("""
                âŒ **CRITICAL: No PostgreSQL database in production!**
                
                Your app is running in a cloud environment but is using SQLite.
                **All data will be LOST on each deployment!**
                
                To fix: Add DATABASE_URL to your app's environment variables.
                """)
                st.stop()
            else:
                logger.info("ðŸ“ SQLite database ready (local development)")
        
        # Initialize database schemas (PostgreSQL only - prevents InvalidSchemaName errors)
        try:
            from db_layer import init_db_schemas
            init_db_schemas()
        except Exception as e:
            logger.debug(f"Schema init note: {e}")
        
        # Initialize database schema (handles both SQLite and PostgreSQL)
        try:
            init_db()
            st.session_state.db_initialized = True
            _log_startup("Database initialized successfully")
        except Exception as e:
            st.error(f"Database Initialization Error: {e}")
            logger.error(f"DB Init Error: {e}")
            return  # Exit if DB init fails

    # =============================
    # PRE-WARMING SEQUENCE
    # =============================
    # Run once per session to load FX rates, validate connections, etc.
    if "services_pre_warmed" not in st.session_state:
        pre_warm_services()
        st.session_state.services_pre_warmed = True
        st.rerun()  # Refresh to hide pre-warm screen

    # =============================
    # COOKIE-BASED USER PREFERENCES
    # =============================
    # Load user preferences from cookies (theme, privacy mode, etc.)
    def load_user_preferences(all_cookies):
        """Load user preferences using pre-fetched cookies."""
        if not all_cookies:
            return
        try:
            # Theme preference
            saved_theme = all_cookies.get("portfolio_theme")
            if saved_theme and "theme" not in st.session_state:
                st.session_state.theme = saved_theme
                
            # Privacy mode preference
            saved_privacy = all_cookies.get("portfolio_privacy")
            if saved_privacy is not None and "privacy_mode" not in st.session_state:
                st.session_state.privacy_mode = saved_privacy == "true"
                
            # Last selected portfolio tab (legacy)
            saved_portfolio = all_cookies.get("portfolio_last_tab")
            if saved_portfolio and "last_portfolio_tab" not in st.session_state:
                st.session_state.last_portfolio_tab = saved_portfolio
            
            # Last selected navigation tab (persists user's last page)
            saved_nav_tab = all_cookies.get("portfolio_nav_tab")
            if saved_nav_tab and "last_nav_tab" not in st.session_state:
                st.session_state.last_nav_tab = saved_nav_tab
        except Exception as e:
            logger.debug(f"Error loading preferences: {e}")
    
    def save_preference(key: str, value: str):
        """Save a user preference to cookies (30-day expiry)."""
        if not cookie_manager:
            return
        try:
            expires = datetime.now() + timedelta(days=30)
            cookie_manager.set(f"portfolio_{key}", str(value), expires_at=expires)
        except Exception as e:
            logger.debug(f"Error saving preference {key}: {e}")
    
    # Load preferences on page load using pre-fetched cookies_data
    load_user_preferences(cookies_data or {})

    # --- THEME TOGGLE ---
    if "theme" not in st.session_state:
        st.session_state.theme = "light"  # Default to light
    
    # --- CURRENCY / FX RATE ---
    # Initialize with default, then attempt live fetch on first load
    if "usd_to_kwd" not in st.session_state:
        st.session_state.usd_to_kwd = DEFAULT_USD_TO_KWD
        # Try to fetch live rate on first load (non-blocking fallback to default)
        try:
            live_rate = fetch_usd_kwd_rate(max_retries=1)
            if live_rate and live_rate > 0:
                st.session_state.usd_to_kwd = live_rate
        except Exception:
            pass  # Keep default if fetch fails

    # --- GLOBAL STYLING ---
    st.markdown("""
    <style>
    /* Equal height and width styling for all metric cards across the app */
    div[data-testid="metric-container"] {
        background-color: rgba(28, 131, 225, 0.1);
        border: 1px solid rgba(28, 131, 225, 0.2);
        padding: 15px;
        border-radius: 10px;
        min-height: 120px;
        display: flex;
        flex-direction: column;
        justify-content: center;
    }
    div[data-testid="metric-container"] > div {
        width: 100%;
    }
    </style>
    """, unsafe_allow_html=True)

    def toggle_theme():
        new_theme = "light" if st.session_state.theme == "dark" else "dark"
        st.session_state.theme = new_theme
        save_preference("theme", new_theme)
    
    def toggle_privacy():
        new_privacy = not st.session_state.get("privacy_mode", False)
        st.session_state.privacy_mode = new_privacy
        save_preference("privacy", "true" if new_privacy else "false")

    # Header with theme toggle and logout on the right
    col1, col2, col3 = st.columns([6, 1, 1])
    with col1:
        st.title("ðŸ“Š Portfolio App")
    with col2:
        st.write("")  # Spacing
        st.toggle(
            "ðŸŒ™ Dark",
            value=(st.session_state.theme == "dark"),
            on_change=toggle_theme,
            key="theme_toggle"
        )
    with col3:
        st.write("")
        if "privacy_mode" not in st.session_state:
            st.session_state.privacy_mode = False
        st.toggle(
            "ðŸ‘ï¸ Privacy",
            value=st.session_state.get("privacy_mode", False),
            on_change=toggle_privacy,
            key="privacy_toggle"
        )

    # --- PROFESSIONAL SIDEBAR ---
    with st.sidebar:
        # User Profile Header
        st.markdown(f"""
        <div style="padding: 10px; border-bottom: 1px solid #ddd; margin-bottom: 10px;">
            <h4 style="margin:0; color: #333;">ðŸ‘¤ {st.session_state.get('username', 'User')}</h4>
        </div>
        """, unsafe_allow_html=True)

        # Navigation Options (clean names for routing)
        nav_options = [
            'Overview', 'Add Cash Deposit', 'Add Transactions', 'Portfolio Analysis',
            'Peer Analysis', 'Trading Section', 'Portfolio Tracker', 'Dividends Tracker',
            'Planner', 'Backup & Restore', 'Securities Master', 'Data Integrity', 'Personal Finance'
        ]
        
        # Default selection - restore from session/cookies if available
        saved_tab = st.session_state.get('last_nav_tab')
        if saved_tab and saved_tab in nav_options:
            selected_tab = saved_tab
        else:
            selected_tab = 'Overview'
        
        # LOGIC: Use SAC if installed, otherwise Standard Streamlit
        # Check if sac module was successfully imported (defined at top of file)
        sac_available = 'sac' in dir() and sac is not None
        
        if sac_available:
            try:
                selected_tab = sac.menu([
                    sac.MenuItem('Overview', icon='house-fill'),
                    sac.MenuItem('Add Cash Deposit', icon='wallet-fill'),
                    sac.MenuItem('Add Transactions', icon='cash-coin'),
                    sac.MenuItem('Portfolio Analysis', icon='graph-up-arrow'),
                    sac.MenuItem('Peer Analysis', icon='people-fill'),
                    sac.MenuItem('Trading Section', icon='bar-chart-line'),
                    sac.MenuItem('Portfolio Tracker', icon='pie-chart-fill'),
                    sac.MenuItem('Dividends Tracker', icon='arrow-up-right-circle-fill'),
                    sac.MenuItem('Planner', icon='calendar-event'),
                    sac.MenuItem('Backup & Restore', icon='archive-fill'),
                    sac.MenuItem('Securities Master', icon='database-fill'),
                    sac.MenuItem('Data Integrity', icon='shield-check'),
                    sac.MenuItem('Personal Finance', icon='file-earmark-spreadsheet-fill'),
                    sac.MenuItem(type='divider'),
                    sac.MenuItem('Account Security', icon='shield-lock-fill', children=[
                        sac.MenuItem('Change Password', icon='key'),
                        sac.MenuItem('Logout', icon='box-arrow-right'),
                    ]),
                ], format_func='title', open_all=True)
            except Exception as e:
                logger.debug(f"SAC menu error: {e}")
                sac_available = False  # Force fallback
        
        # Fallback for when SAC library is missing or fails
        if not sac_available or selected_tab is None:
            st.markdown("### ðŸ“Œ Navigation")
            # Get index for default selection
            default_idx = nav_options.index(saved_tab) if saved_tab in nav_options else 0
            selected_tab = st.radio(
                "Select Page",
                nav_options,
                index=default_idx,
                key="nav_radio_main",
                label_visibility="collapsed"
            )
            
            # Account Security Section  
            st.markdown("---")
            st.markdown("### ðŸ” Account")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ðŸ”‘ Password", key="nav_change_pass"):
                    selected_tab = "Change Password"
            with col2:
                if st.button("ðŸšª Logout", key="nav_logout"):
                    selected_tab = "Logout"

        # Persist selected tab for next visit (skip Change Password and Logout)
        if selected_tab and selected_tab not in ['Change Password', 'Logout']:
            if st.session_state.get('last_nav_tab') != selected_tab:
                st.session_state.last_nav_tab = selected_tab
                save_preference("nav_tab", selected_tab)

        # Footer Info
        st.markdown("---")
        st.caption(f"{get_db_info()} | v3.5 Pro")

    # --- MAIN CONTENT ROUTING ---
    # This acts like the "activeItem" state in the React code
    
    if selected_tab == 'Overview':
        ui_overview()
        
    elif selected_tab == 'Add Cash Deposit':
        ui_cash_deposits()
        
    elif selected_tab == 'Add Transactions':
        ui_transactions()
        
    elif selected_tab == 'Portfolio Analysis':
        ui_portfolio_analysis()
        
    elif selected_tab == 'Peer Analysis':
        ui_peer_analysis()
        
    elif selected_tab == 'Trading Section':
        ui_trading_section()
        
    elif selected_tab == 'Portfolio Tracker':
        ui_portfolio_tracker()
        
    elif selected_tab == 'Dividends Tracker':
        ui_dividends_tracker()
        
    elif selected_tab == 'Planner':
        ui_financial_planner()
        
    elif selected_tab == 'Backup & Restore':
        ui_backup_restore()
        
    elif selected_tab == 'Securities Master':
        ui_securities_master()
        
    elif selected_tab == 'Data Integrity':
        ui_data_integrity()
        
    elif selected_tab == 'Personal Finance':
        ui_pfm()
        
    elif selected_tab == 'Change Password':
        st.header("ðŸ” Account Security")
        ui_user_profile_sidebar()  # Render security logic in the main area
        
    elif selected_tab == 'Logout':
        # Logout Logic
        try:
            user_id = st.session_state.get('user_id')
            if user_id:
                conn = get_conn()
                cur = conn.cursor()
                db_execute(cur, "DELETE FROM user_sessions WHERE user_id = ?", (user_id,))
                conn.commit()
                conn.close()
        except Exception as e:
            logger.error(f"Error during logout: {e}")
        if cookie_manager:
            try:
                cookie_manager.delete("portfolio_session")
            except:
                pass
        st.session_state.clear()
        st.rerun()
    
    else:
        # Default fallback
        ui_overview()


_log_startup("All imports and definitions complete - ready to serve")

if __name__ == "__main__":
    main()
